{"id": "8ccf45f0-8784-4a19-90f6-d8f6e69e2bfa", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)  # Ensuring values are within bounds [0, 1]\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            # Initialize or expand the population based on current layers\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            # Evolutionary loop\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            # Gradually grow layers if budget allows\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Combining Differential Evolution with Iterative Layer Addition (DE-ILA) to adaptively grow and refine solutions for multilayered design optimization.", "configspace": "", "generation": 0, "fitness": 0.784936745143574, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.025. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7566708742624959, 0.8169354967428502, 0.781203864425376], "final_y": [0.1670777393862961, 0.148565329294449, 0.1595799328458113]}, "mutation_prompt": null}
{"id": "c2a4a4c1-bebf-4525-ad23-8ca9b69c7f4b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)  # Ensuring values are within bounds [0, 1]\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            # Initialize or expand the population based on current layers\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            # Evolutionary loop\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n                        self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive F\n                        self.CR = 0.7 + 0.2 * np.random.rand()  # Adaptive CR\n\n            pop = next_pop\n\n            # Gradually grow layers if budget allows\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive F and CR based on success history for improved exploration and convergence.", "configspace": "", "generation": 1, "fitness": 0.784936745143574, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.025. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8ccf45f0-8784-4a19-90f6-d8f6e69e2bfa", "metadata": {"aucs": [0.7566708742624959, 0.8169354967428502, 0.781203864425376], "final_y": [0.1670777393862961, 0.148565329294449, 0.1595799328458113]}, "mutation_prompt": null}
{"id": "72394e03-c8e2-49f7-8c4e-f773d2f61f83", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive mutation factor\n        adaptive_F = self.F * (0.5 + np.random.rand()/2)\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)  # Ensuring values are within bounds [0, 1]\n\n    def _crossover(self, target, mutant):\n        # Dynamic crossover probability\n        adaptive_CR = self.CR * (0.9 - 0.5 * np.random.rand())\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            # Initialize or expand the population based on current layers\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            # Evolutionary loop\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            # Gradually grow layers if budget allows\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance Differential Evolution by integrating adaptive mutation scaling and dynamic crossover rates to improve convergence performance.", "configspace": "", "generation": 2, "fitness": 0.7809251338896376, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.014. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8ccf45f0-8784-4a19-90f6-d8f6e69e2bfa", "metadata": {"aucs": [0.7744065834285365, 0.7998316308026765, 0.7685371874376998], "final_y": [0.16389704726519505, 0.15026325585023304, 0.16485738290201568]}, "mutation_prompt": null}
{"id": "6d0775de-5652-4aff-a71e-44c24d21777d", "solution": "import numpy as np\n\nclass DE_IMPR:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)  # Ensuring values are within bounds [0, 1]\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :len(best_solution)] = best_solution[:current_layers]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                # Integrate robustness into score with perturbation\n                robustness_score = np.mean([func(solution + np.random.normal(0, 0.01, size=solution.shape)) for _ in range(3)])\n                final_score = score + 0.1 * robustness_score\n                scores[i] = final_score\n                if final_score < best_score:\n                    best_score = final_score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_IMPR", "description": "An enhanced Differential Evolution with Incremental Modularity Preservation and Robustness (DE-IMPR) for optimizing multilayered designs by integrating modular structure recognition and robustness metrics.", "configspace": "", "generation": 3, "fitness": 0.7434328219866134, "feedback": "The algorithm DE_IMPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.743 with standard deviation 0.046. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "8ccf45f0-8784-4a19-90f6-d8f6e69e2bfa", "metadata": {"aucs": [0.6817879163410829, 0.7910029388591464, 0.757507610759611], "final_y": [0.2071928925751091, 0.16006703667139277, 0.17293479168890002]}, "mutation_prompt": null}
{"id": "c865b2e3-2527-4716-8e07-f73bbfff7ab5", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)  # Ensuring values are within bounds [0, 1]\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            # Initialize or expand the population based on current layers\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            # Evolutionary loop\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            # Gradually grow layers if budget allows\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refining Differential Evolution with Iterative Layer Addition (DE-ILA) by enhancing initialization to leverage global optima proximity in multilayer optimization.", "configspace": "", "generation": 4, "fitness": 0.7888304004856782, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.019. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8ccf45f0-8784-4a19-90f6-d8f6e69e2bfa", "metadata": {"aucs": [0.7683154749579417, 0.8143822795520971, 0.7837934469469956], "final_y": [0.1670777393862961, 0.148565329294449, 0.1595799328458113]}, "mutation_prompt": null}
{"id": "a8973035-1a43-4817-b046-9d3c9030effa", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refining DE-ILA by improving mutation strategy and enhancing population diversity.", "configspace": "", "generation": 5, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c865b2e3-2527-4716-8e07-f73bbfff7ab5", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "fe7d822f-f37f-4ca2-b15d-59419644dd80", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_dynamic = self.F + np.random.rand() * 0.2  # Adapt F dynamically\n        mutant = pop[a] + F_dynamic * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            elite_indices = np.argsort(scores)[:self.pop_size//5]  # Preserve top 20% elites\n            pop[elite_indices] = next_pop[elite_indices]\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by incorporating adaptive control parameters and elite preservation strategy.", "configspace": "", "generation": 6, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "d7905755-f664-4dbd-abbc-97204716855e", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.15 * (np.random.randn(len(pop[a])))  # Increased noise level\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by adjusting mutation strategy for better exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.7820656646257084, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.012. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.766052141466451, 0.7852331068059407, 0.7949117456047335], "final_y": [0.1657821619083406, 0.15661923655501309, 0.14707482434161567]}, "mutation_prompt": null}
{"id": "a162f138-19a3-4aec-b1d8-b38407ffe99c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.evaluations / self.budget)  # Adaptive F based on evaluation progress\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refining DE-ILA by enhancing mutation with adaptive F to improve solution diversity.", "configspace": "", "generation": 8, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "9d9605e8-6158-45ab-ab61-895b287d5627", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = np.random.uniform(0.5, 1.0)  # Adaptive mutation factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = np.random.uniform(0.5, 1.0)  # Adaptive crossover probability\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing adaptive crossover and mutation rates to improve convergence.", "configspace": "", "generation": 9, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "89a41d27-67e9-4ccc-b932-1c7fd23302de", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.75, CR=0.9, initial_layers=10):  # Changed F from 0.8 to 0.75\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by slightly adjusting the differential weight for improved exploration.", "configspace": "", "generation": 10, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "72e84112-6b2c-4ec5-947f-08366198df63", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + (0.1 * np.random.rand() - 0.05)  # Adaptive mutation scaling\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR - (0.1 * np.random.rand() - 0.05)  # Adaptive crossover rate\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE-ILA by incorporating adaptive mutation scaling and crossover rate adjustments based on convergence speed.", "configspace": "", "generation": 11, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "0278d526-3c3c-400d-8c22-61e66ecdad16", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) * np.random.uniform(0.9, 1.1)  # Adjust mutation strategy\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Slightly adjust the mutation strategy in DE-ILA for better exploration.", "configspace": "", "generation": 12, "fitness": 0.7954219245107307, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.009. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.796335213193155, 0.7836940107601237, 0.8062365495789134], "final_y": [0.1526232075896362, 0.16463513031046606, 0.15176659271540516]}, "mutation_prompt": null}
{"id": "dbcb0e03-a59c-4251-aef0-dff5b9658476", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * (1 - (self.evaluations / self.budget))  # Dynamic adjustment of F\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved exploration-exploitation trade-off by dynamically adjusting the differential weight based on evaluation progress.", "configspace": "", "generation": 13, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "83a7ab2b-ab0a-4658-b946-747242e1cecb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * np.random.uniform(0.5, 1.0)  # Adaptive scaling factor\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        dynamic_CR = np.random.uniform(0.8, 1.0)  # Adaptive crossover probability\n        cross_points = np.random.rand(len(target)) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "The refined DE-ILA introduces adaptive scaling factor and crossover probability to improve exploration-exploitation balance and convergence speed.", "configspace": "", "generation": 14, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "16dfa6c3-0f8d-472b-ae97-29df84942d00", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.2 * (np.random.rand() - 0.5)  # Line changed: Added adaptive component to F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced mutation strategy with adaptive differential weight to improve exploration and refinement.", "configspace": "", "generation": 15, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "ee7ed513-d9b8-48f1-b80a-d71bf5709033", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 + 0.1 * (np.random.rand() - 0.5))  # Adaptive differential weight\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c])  # Line changed\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, idx):\n        adaptive_CR = self.CR * (1 + 0.1 * (np.sin(idx) - 0.5))  # Adaptive crossover probability\n        cross_points = np.random.rand(len(target)) < adaptive_CR  # Line changed\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant, i)  # Line changed\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing adaptive crossover probability and layer-specific mutation strategy.", "configspace": "", "generation": 16, "fitness": 0.7954219245107307, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.009. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.796335213193155, 0.7836940107601237, 0.8062365495789134], "final_y": [0.1526232075896362, 0.16463513031046606, 0.15176659271540516]}, "mutation_prompt": null}
{"id": "f1ee13f6-e732-418a-a0e0-3832c2d3d170", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * np.random.rand()\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by altering the mutation strategy to incorporate adaptive scaling of the differential weight for better exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "fbbaea8b-c7be-4520-946f-47cf483a4d4b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, scores):\n        diversity_factor = np.std(scores) / np.mean(scores)\n        cross_points = np.random.rand(len(target)) < self.CR * diversity_factor  # Adaptive crossover\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                if i % 10 == 0:  # Adaptive F adjustment\n                    self.F = 0.5 + 0.5 * np.random.rand()\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant, scores)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive scaling factor F and diversity-based crossover to balance exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.782556409812858, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.015. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7635526360814643, 0.7836940107601237, 0.8004225825969863], "final_y": [0.16154866164175574, 0.16463513031046606, 0.1521089555925903]}, "mutation_prompt": null}
{"id": "40b5cc79-7d53-409d-afc7-4b221fef60d0", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n    \n    def _adaptive_parameters(self):\n        self.F = 0.5 + 0.3 * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        \n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])  # Removed noise for better stability\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            self._adaptive_parameters()\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            elite_idx = np.argmin(scores)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                if i == elite_idx:\n                    continue  # Retain elitism by keeping best solutions\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by incorporating adaptive parameter control and selective elitism for enhanced exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.7989430170345311, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.016. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7944306190126927, 0.7818852473490328, 0.8205131847418677], "final_y": [0.15443140873022831, 0.152255316355416, 0.13275380630645695]}, "mutation_prompt": null}
{"id": "33e0836c-7b4e-4c1d-9aac-ea1994bbf581", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.evaluations / self.budget)  # Adaptive scaling factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve mutation strategy by adding adaptive scaling factor to enhance exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "6ecbbc46-dabb-4cd3-a83d-0a50528b7c7c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10, expansion_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.expansion_prob = expansion_prob  # Probability to expand layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.15 * (np.random.rand(len(pop[a])) - 0.5)  # Amplified random noise\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget and np.random.rand() < self.expansion_prob:  # Probabilistic layer expansion\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduced a probabilistic layer expansion and improved mutation to enhance solution exploration.", "configspace": "", "generation": 21, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "69660734-c21a-48a3-afbf-883fb3252f7a", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 + np.random.rand() * 0.1)  # Adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c])  # Modified mutation\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            best_idx = np.argmin(scores)  # Track best solution\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n            next_pop[0] = pop[best_idx]  # Elitism: preserve the best solution\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by improving the mutation strategy with adaptive F and adding elitism to preserve the best solutions.", "configspace": "", "generation": 22, "fitness": 0.7954219245107307, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.009. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.796335213193155, 0.7836940107601237, 0.8062365495789134], "final_y": [0.1526232075896362, 0.16463513031046606, 0.15176659271540516]}, "mutation_prompt": null}
{"id": "2fc52e5d-85cb-40ef-9283-23b6131e5cf3", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, scores):\n        cross_points = np.random.rand(len(target)) < self.CR + 0.1 * (1 - (np.max(scores) - np.min(scores)) / np.max(scores))  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant, scores)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduce adaptive crossover probability based on convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "9a7cdb6d-d59c-4882-bd69-a3dad66ebac6", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F = np.random.uniform(0.5, 1.0)  # Adaptive F\n        mutant = pop[a] + F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        CR = np.random.uniform(0.7, 0.9)  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by incorporating adaptive differential weight and crossover probability to improve convergence.", "configspace": "", "generation": 24, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "1b9ddd23-c49b-4a93-920f-964b9eca531c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.2 * np.random.rand()  # Adaptive scaling for exploration\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Modify the mutation strategy to introduce adaptive scaling of the differential weight for improved exploration.", "configspace": "", "generation": 25, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "235ebc73-00d8-482a-915f-1bcc767dc2be", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            elite_idx = np.argmin(scores)  # New line for elitism\n            next_pop[0] = pop[elite_idx]  # New line for elitism\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by introducing adaptive selection pressure and incorporating elitism to enhance convergence speed.", "configspace": "", "generation": 26, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "f2d0357e-35c5-49ca-b45f-bc667faa882e", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n            # Adapt crossover probability and population size\n            self.CR = 0.5 + 0.5 * (1 - np.mean(scores) / best_score)  # Adaptive crossover\n            self.pop_size = int(max(20, self.pop_size * (1 + 0.1 * (best_score / np.mean(scores) - 1))))  # Dynamic population size\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by introducing adaptive crossover probability and dynamic population size for enhanced exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.7846996462012242, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.008. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7840553244014535, 0.7951766193658274, 0.7748669948363915], "final_y": [0.16180850666387603, 0.15393289478372008, 0.1622901519860077]}, "mutation_prompt": null}
{"id": "4a1db0f9-d890-45f5-bd61-c4bd1bb9844a", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * (1 - np.var(pop) / (np.mean(pop) + 1e-9))  # Dynamic F\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved the mutation strategy by using a dynamic F value that adapts based on the diversity of the population to enhance exploration to exploitation transition.", "configspace": "", "generation": 28, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "d42cb799-72e4-4dec-985c-e288face0b1a", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n        self.successful_mutations = 0\n        self.total_mutations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                self.total_mutations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n                    self.successful_mutations += 1\n\n            if self.total_mutations > 0:\n                success_rate = self.successful_mutations / self.total_mutations\n                self.F = min(max(self.F + 0.1 * (success_rate - 0.1), 0.4), 1.0)\n                self.CR = min(max(self.CR + 0.1 * (0.1 - success_rate), 0.1), 0.9)\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA with adaptive F and CR values based on success rates to improve convergence and exploration.", "configspace": "", "generation": 29, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "b5339270-b7e8-4e35-834c-ffe970af971a", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.F + (0.2 * np.random.rand() - 0.1)  # Adaptive mutation rate\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        CR_adaptive = self.CR + (0.1 * np.random.rand() - 0.05)  # Adaptive crossover rate\n        cross_points = np.random.rand(len(target)) < CR_adaptive\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing adaptive mutation and crossover rates to improve convergence speed and solution accuracy.", "configspace": "", "generation": 30, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "4180ec6e-077c-4ffa-84e4-851706289ab2", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * (1 - self.evaluations / self.budget)  # Dynamic scaling factor\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE_ILA by enhancing mutation strategy with a dynamic scaling factor based on convergence.", "configspace": "", "generation": 31, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "ac7334a0-497c-4749-ad24-66b0d03cf3f1", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.F + 0.1 * np.random.randn()  # Adaptive F with noise\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c])  # Adaptive F\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by introducing adaptive parameters and targeted local search.", "configspace": "", "generation": 32, "fitness": 0.7899411283716166, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.008. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7896913681540776, 0.8001375360657832, 0.7799944808949888], "final_y": [0.15967730383664114, 0.15546970392632364, 0.163890223007071]}, "mutation_prompt": null}
{"id": "d6183471-0016-4fbf-ba19-b921ddcdc8b4", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + (self.F + 0.1 * np.random.rand()) * (pop[b] - pop[c])  # Dynamically adjusted F\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < (self.CR - 0.1 * np.random.rand())  # Dynamically adjusted CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n            if self.evaluations % 100 == 0:  # Adaptive population size\n                self.pop_size = min(self.pop_size + 5, 100)\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by refining mutation strategy, adaptive population size, and dynamically adjusted F and CR with noise reduction.", "configspace": "", "generation": 33, "fitness": 0.7784067164520825, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.006. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.782026926798057, 0.7836940107601237, 0.7694992117980668], "final_y": [0.16389704726519505, 0.16463513031046606, 0.16838828224031577]}, "mutation_prompt": null}
{"id": "edfc0e01-44e6-464c-888e-75b45831b85b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n        self.adaptive_F = F  # Adaptive differential weight\n        self.adaptive_CR = CR  # Adaptive crossover probability\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.adaptive_F * (pop[b] - pop[c])\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n        \n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n            \n            # Adaptive strategy\n            successful_trials = scores < np.min(scores) + np.std(scores)\n            if np.any(successful_trials):\n                self.adaptive_F = np.mean(scores[successful_trials]) / best_score\n                self.adaptive_CR = 0.5 * (1.0 + self.adaptive_CR)\n\n            pop = next_pop\n            \n            # Elitism\n            pop[np.argmax(scores)] = best_solution\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by incorporating adaptive crossover and mutation rates and introducing elitism to improve convergence.", "configspace": "", "generation": 34, "fitness": 0.7888304004856782, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.019. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7683154749579417, 0.8143822795520971, 0.7837934469469956], "final_y": [0.1670777393862961, 0.148565329294449, 0.1595799328458113]}, "mutation_prompt": null}
{"id": "a263214d-b8f4-4bf0-b955-949bf211ad6e", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            self.CR = 0.9 - (0.5 * (self.evaluations / self.budget))  # Added adaptive crossover probability\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introducing adaptive crossover probability to enhance exploration-exploitation balance in DE-ILA.", "configspace": "", "generation": 35, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "2a380916-1504-49a2-a743-3720885d190b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Initial crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        noise_scale = 0.05 + 0.05 * np.random.rand()  # Adaptive noise scaling\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + noise_scale * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                self.CR = 0.8 + 0.2 * np.random.rand()  # Adaptive crossover rate\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by introducing adaptive crossover rate and noise scaling for enhanced exploration and convergence.", "configspace": "", "generation": 36, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "1a145bb6-e03c-4d3e-9fb3-21fbaf22e5c0", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.evaluations/self.budget)  # Dynamically adjust F based on evaluations\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by dynamically adjusting mutation factor F based on convergence speed to improve search efficiency.", "configspace": "", "generation": 37, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "cdee250c-065f-419d-b5f0-c14caf2e38eb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n    \n    def _adaptive_mutate(self, target_idx, pop, score, best_score):  # Adaptive mutation\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        F = self.F * (1 - score / (best_score + 1e-8))  # Adjust differential weight\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._adaptive_mutate(i, pop, scores[i], best_score)  # Use adaptive mutation\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += np.random.choice([0, 1], p=[0.7, 0.3])  # Stochastic layer adaptation\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA with adaptive mutation factor and stochastic layer adaptation for increased exploration and diversity.", "configspace": "", "generation": 38, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "af6b60a9-4cb5-4e20-b857-dd274d55c561", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.evaluations/self.budget)  # Adaptive mutation factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            if self.evaluations < self.budget:\n                elite_idx = np.argmin(scores)  # Select the elite individual\n                next_pop[0] = pop[elite_idx]  # Ensure elite survival\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing elitism and adaptive mutation factor adjustment for improved convergence.", "configspace": "", "generation": 39, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "26f1dbf4-9f7b-4f68-a592-f11152cd94a0", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, adapt_cr):\n        cross_points = np.random.rand(len(target)) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            adapt_cr = 0.7 + 0.3 * (1 - best_score)  # Adaptive crossover rate\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant, adapt_cr)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n                self.pop_size = min(self.pop_size + 5, 100)  # Dynamically increase population size\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA with adaptive crossover rate and dynamic population size for enhanced exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "c400b81a-2bba-4a80-a8b4-3f80d87e8f61", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + (0.5 + 0.5 * self.evaluations / self.budget) * self.F * (pop[b] - pop[c])  # Progressive mutation scaling\n        mutant += 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE_ILA by introducing adaptive crossover probability and progressive mutation scaling.", "configspace": "", "generation": 41, "fitness": 0.808076384945131, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.018. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7899533632588225, 0.8333646402569067], "final_y": [0.1530542792464199, 0.16191157253391597, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "973e4a17-05d4-4890-9fbe-5572a330338c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.2 * (np.random.rand(len(pop[a])) - 0.5)  # Adjusted random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced diversity and exploration by adjusting mutation noise level.", "configspace": "", "generation": 42, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "7ec82409-5041-4b56-957a-5c8609974da9", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.1 * np.random.rand()  # Adaptive mutation rate\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (0.9 + 0.2 * np.random.rand())  # Adaptive crossover rate\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "DE_ILA with adaptive mutation and crossover rates based on performance.", "configspace": "", "generation": 43, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "b6270bb3-0ff4-465d-9f1d-1f03fe059012", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < (self.CR * (self.evaluations / self.budget))  # Adaptive crossover probability\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduce adaptive crossover probability based on current iteration to enhance exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.7880878625001961, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.010. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7770753304530621, 0.7867656744505399, 0.8004225825969863], "final_y": [0.16113873163749015, 0.15070467183412795, 0.1521089555925903]}, "mutation_prompt": null}
{"id": "cf98ed11-e5d0-4012-aeb1-03efd80657fb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.evaluations / self.budget)  # Adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - np.std(target))  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by incorporating adaptive differential weight and crossover probability based on convergence and diversity.", "configspace": "", "generation": 45, "fitness": 0.7732339132076196, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.007. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7672980573031376, 0.7836940107601237, 0.7687096715595975], "final_y": [0.17013694482814645, 0.16463513031046606, 0.16999026674809892]}, "mutation_prompt": null}
{"id": "6eced669-4e9d-44d6-85d9-498d1f9be498", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.2 * (np.random.rand(len(pop[a])) - 0.5)  # Adjusted random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved mutation strategy by adjusting the random noise factor to enhance exploration and diversity.", "configspace": "", "generation": 46, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "d58c52d8-fa38-4f15-bf51-de274b5fc7cb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n            \n            # Adaptive adjustment\n            if self.evaluations % (self.budget // 10) == 0:  # Every 10% of the budget\n                self.F *= 0.9  # Decrease F\n                self.CR = 1 - self.CR  # Flip CR between 0.1 and 0.9\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adaptive mutation factor and crossover rate adjustments based on convergence speed for improved performance.", "configspace": "", "generation": 47, "fitness": 0.7772679680727345, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7693737190050838, 0.7900807218130079, 0.7723494634001116], "final_y": [0.16762625440265677, 0.16140724046663124, 0.16835495780416176]}, "mutation_prompt": null}
{"id": "ec1ef98d-c62e-4549-bfee-42b1aaf9b939", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        F_dynamic = self.F * (0.5 + np.random.rand() * 0.5)  # Dynamic F\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + F_dynamic * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n            if self.evaluations % (self.budget // 5) == 0:  # Restart mechanism\n                best_solution = None\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE_ILA by adjusting the mutation strategy with dynamic F and integrating a restart mechanism.", "configspace": "", "generation": 48, "fitness": 0.8046208167807034, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.020. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.782580429824425, 0.8317486713821628, 0.7995333491355225], "final_y": [0.16338188868267112, 0.14247228316161797, 0.1524671412923102]}, "mutation_prompt": null}
{"id": "c0f8da22-52e0-49ed-9956-72b18e7b354b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        pop += 0.05 * np.random.randn(*pop.shape)  # Added Gaussian noise for better diversity\n        return np.clip(pop, bounds.lb[:layers], bounds.ub[:layers])  # Ensure population is within bounds\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.2 * np.random.rand()  # Introduced adaptive mutation factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by integrating adaptive mutation factor and improved population initialization.", "configspace": "", "generation": 49, "fitness": 0.7785953577587762, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7617272925988859, 0.8005620342866233, 0.7734967463908198], "final_y": [0.1689256210183463, 0.15730373607781079, 0.16790528222120282]}, "mutation_prompt": null}
{"id": "dd28a1a6-d85a-40d4-a002-7d377b59c55b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.85, CR=0.9, initial_layers=10):  # Adjusted F from 0.8 to 0.85\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Slightly increase the differential weight to enhance the exploration capabilities of the mutation strategy.", "configspace": "", "generation": 50, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "72f9cf2d-f5cc-4559-9a19-cb64e64ddef0", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Line 1: Introduced adaptive F\n        F_adaptive = np.random.uniform(0.5, 0.9)\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        # Line 2: Introduced adaptive CR\n        CR_adaptive = np.random.uniform(0.8, 1.0)\n        cross_points = np.random.rand(len(target)) < CR_adaptive\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by introducing adaptive F and CR values for better exploration-exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "8650e1eb-5311-4267-b6d2-2c6bf51140f4", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        self.F = 0.5 + 0.3 * (self.evaluations / self.budget)  # Dynamically adjust F\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adjusting the differential weight F dynamically based on evaluation progress to improve exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "03f2fc18-8e64-4002-8386-bb01a7a22058", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop, adaptive_factor):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + adaptive_factor * self.F * (pop[b] - pop[c])  # Adaptive differential weight\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                adaptive_factor = 0.5 + 0.5 * np.random.rand()  # Adaptive factor for mutation\n                mutant = self._mutate(i, pop, adaptive_factor)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE-ILA by enhancing mutation strategy with adaptive differential weights and integrating local search for refined exploitation.", "configspace": "", "generation": 53, "fitness": 0.781202119983737, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.007. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7881632730151137, 0.7836940107601237, 0.7717490761759735], "final_y": [0.15777960911882116, 0.16463513031046606, 0.1675040487380579]}, "mutation_prompt": null}
{"id": "b61ad52d-65fc-4346-9974-06f24f6aefbb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + np.random.uniform(-0.1, 0.1)  # Adaptive scaling factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.choice(len(target), size=2, replace=False)] = True  # Enhanced crossover\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by modifying mutation to include adaptive scaling and enhanced crossover mechanism.", "configspace": "", "generation": 54, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "1ca4923e-cb55-4ed8-b991-64a3658f6d6f", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop, success_rate):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * (1 + 0.1 * np.random.rand(1)[0])\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, success_rate):\n        adaptive_CR = self.CR * success_rate\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n        success_rate = 0.5\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop, success_rate)\n                trial = self._crossover(target, mutant, success_rate)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    successful_mutations += 1\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n            success_rate = successful_mutations / self.pop_size if successful_mutations > 0 else success_rate\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by incorporating a dynamic F value and strengthening exploration through adaptive crossover strategies.", "configspace": "", "generation": 55, "fitness": 0.7803244363733843, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.011. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7652229221941603, 0.7880883986533691, 0.7876619882726237], "final_y": [0.16672044029699928, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "6ffbc3a1-b0bc-4b5f-8ab9-81beca17636c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.9, CR=0.95, initial_layers=10):  # Increased F and CR\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.05 * (np.random.rand(len(pop[a])) - 0.5)  # Reduced noise\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by modifying mutation and crossover strategies for better exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "448ba6f5-11b8-4695-ac3b-cd0d796e8b95", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        self.F = 0.5 + 0.3 * np.std(pop)  # Dynamic F based on diversity\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.7 + 0.2 * np.std(mutant)  # Dynamic CR based on diversity\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing dynamic parameter tuning for F and CR based on population diversity.", "configspace": "", "generation": 57, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "81682bdc-a6b2-4924-a95e-d0d6592be03d", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop, adap_F):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + adap_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant, adap_CR):\n        cross_points = np.random.rand(len(target)) < adap_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            adap_F = 0.5 + 0.5 * np.random.rand()  # Adaptive F\n            adap_CR = 0.5 + 0.5 * np.random.rand()  # Adaptive CR\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop, adap_F)\n                trial = self._crossover(target, mutant, adap_CR)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by introducing adaptive mutation and crossover rates to improve convergence speed and solution quality.", "configspace": "", "generation": 58, "fitness": 0.8001311113229304, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.024. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7770753304530621, 0.7899533632588225, 0.8333646402569067], "final_y": [0.16113873163749015, 0.16191157253391597, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "c06296ab-9400-489a-b039-01c92ccc2c52", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.05 * (np.random.rand(len(pop[a])) - 0.5)  # Reduced noise for precision\n        return np.clip(mutant, 0, 1)\n    \n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n                    else:\n                        # Local search for exploitation\n                        local_trial = trial_real + 0.01 * (np.random.rand(len(trial_real)) - 0.5)\n                        local_trial_score = func(local_trial)\n                        self.evaluations += 1\n                        if local_trial_score < best_score:\n                            best_score = local_trial_score\n                            best_solution = local_trial\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE-ILA by incorporating adaptive parameter tuning and hybrid local search for enhanced exploitation.", "configspace": "", "generation": 59, "fitness": 0.7733231108364729, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.013. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7584914471306059, 0.7893698901756737, 0.7721079952031391], "final_y": [0.17416312008663415, 0.15881680640645812, 0.16822124465465405]}, "mutation_prompt": null}
{"id": "84a7fd65-f885-4b19-85c1-d8a5a8143909", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR * (1 - 0.1 * (self.evaluations / self.budget))  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introducing adaptive crossover probability in DE-ILA to enhance exploration and exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "5f99295a-4943-4910-8414-865932eac17d", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1.0 - self.evaluations / self.budget) # Line changed for adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            elite_idx = np.argmin(scores)  # Line changed for elitism\n            next_pop = np.copy(pop)\n            next_pop[0] = pop[elite_idx]  # Preserve elite in next generation\n            for i in range(1, self.pop_size):  # Start from 1 to keep elite unchanged\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by adapting mutation factor F and introducing elitism for maintaining best solutions.", "configspace": "", "generation": 61, "fitness": 0.79969110265412, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.023. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7777458255388668, 0.7890698853719098, 0.8322575970515836], "final_y": [0.162194710529454, 0.15835306442507524, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "41f8bd87-719a-4c5f-9ad1-5da136e1c78c", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        diversity = np.mean(np.std(pop, axis=0))\n        CR_adaptive = self.CR + (0.1 * diversity)  # Adjust CR based on diversity\n        cross_points = np.random.rand(len(target)) < CR_adaptive\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduce adaptive crossover probability (CR) based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'pop' is not defined\").", "error": "NameError(\"name 'pop' is not defined\")", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {}, "mutation_prompt": null}
{"id": "2011c764-8ae5-4d14-9726-4552d3f89212", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]  # Removed squaring for uniform initial diversity\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.05 * (np.random.rand(len(pop[a])) - 0.5)  # Reduced random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by refining population initialization, mutation noise, and trial selection strategy.", "configspace": "", "generation": 63, "fitness": 0.8046131747863633, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.020. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.78488897719009, 0.796691734804205, 0.8322588123647949], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "6ff34e0b-580f-4e7b-9a09-7213d0354007", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(pop, axis=0).mean()\n        adaptive_F = self.F + (0.5 * diversity)  # Dynamically adjust F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by dynamically adjusting F and CR based on population diversity to improve convergence.", "configspace": "", "generation": 64, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "13c7be30-3872-4459-9c02-999721a014d2", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (0.5 + 0.5 * np.random.rand())  # Adaptive mutation factor scaling\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget and np.mean(scores) < best_score:\n                current_layers += 1  # Conditional layer increment\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by adaptive mutation factor scaling and conditional layer increment strategies.", "configspace": "", "generation": 65, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "f913e459-defa-448c-a448-c45781455e60", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (0.5 + np.random.rand() * 0.5)  # Adaptive mutation factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        dynamic_CR = self.CR * np.random.rand()  # Dynamic crossover probability\n        cross_points = np.random.rand(len(target)) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive mutation strategy and dynamic crossover probability to improve exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.7923982505320604, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.015. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8125701186391665, 0.7890786695698514, 0.7755459633871629], "final_y": [0.1437677629589248, 0.16160754960489077, 0.16366291365974472]}, "mutation_prompt": null}
{"id": "ba3b27ac-a041-4b50-80d8-96427ce9ca95", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = 0.7 + 0.2 * np.random.rand()  # Adaptive crossover probability\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refining DE-ILA by incorporating adaptive mutation factor and crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 67, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "857189fd-569e-4377-aa7a-52fdee0d0a3d", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += int(0.1 * self.dim)  # More aggressive layer increment\n\n        return best_solution", "name": "DE_ILA", "description": "Improve adaptive layer increment strategy in DE-ILA for better exploration-exploitation balance.", "configspace": "", "generation": 68, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "c6d73ea1-f237-4f71-8e59-cf841b7e7ae5", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + (0.1 * np.random.rand())  # Adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR - (0.1 * np.random.rand())  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            elite_idx = np.argmin(scores)\n            next_pop[0] = pop[elite_idx]  # Elite selection\n            scores[0] = scores[elite_idx]\n\n            for i in range(1, self.pop_size):  # Start from 1 due to elite selection\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing adaptive mutation and crossover rates, and employing elite selection for improved convergence.", "configspace": "", "generation": 69, "fitness": 0.7809819751282046, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.017. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7584914471306059, 0.7836940107601237, 0.8007604674938839], "final_y": [0.17416312008663415, 0.16463513031046606, 0.1521089555925903]}, "mutation_prompt": null}
{"id": "dc254f5f-2b8d-43d7-b004-633e8e109bbb", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        best_idx = np.argmin([func(pop[i]) for i in indices])  # Injection of best diversity\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant + 0.1 * (pop[best_idx] - pop[a]), 0, 1)  # Adaptive mutation scaling\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by incorporating adaptive mutation scaling and utilizing best individual diversity injection.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {}, "mutation_prompt": null}
{"id": "c4c03c4e-27b3-46d5-8c10-f23fe1a65cd8", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.1 * (np.random.rand() - 0.5) # Adaptive differential weight\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved mutation strategy by incorporating adaptive differential weight scaling to enhance search exploration.", "configspace": "", "generation": 71, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "cc7f78fb-e784-4f78-8506-4fdeba9a1f81", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (0.5 + np.random.rand() /2)  # Adaptive mutation scaling\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 2  # Increase layers more dynamically\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by incorporating adaptive mutation scaling and dynamic layer progression strategies. ", "configspace": "", "generation": 72, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "206e4a6f-4023-4ede-9074-7387cf4aa5d7", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n        self.success_rate = 0.1\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adapt = self.F + 0.1 * (np.random.rand() - 0.5) * self.success_rate  # Adaptive F\n        mutant = pop[a] + F_adapt * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        CR_adapt = self.CR * (1 + 0.1 * (np.random.rand() - 0.5) * self.success_rate)  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < CR_adapt\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            successes = 0  # Count successful mutations\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    successes += 1  # Successful trial\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            self.success_rate = successes / self.pop_size  # Update success rate\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive F and CR values based on success rates of the previous generation to improve convergence speed and solution quality.", "configspace": "", "generation": 73, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "5c1a7f70-4707-4154-b813-c2e651979275", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.F + np.random.rand() * 0.1  # Adaptive differential weight\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve mutation strategy by incorporating adaptive differential weight for enhanced exploration.", "configspace": "", "generation": 74, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "d51713c8-cb2e-4b67-a7db-74b41621aa96", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(pop, axis=0).mean()\n        adaptive_F = self.F + 0.1 * (np.random.rand() - 0.5) * diversity  # Adaptive mutation based on diversity\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        diversity = np.std(mutant)  # Calculate diversity for adaptive crossover\n        adaptive_CR = self.CR + 0.05 * (np.random.rand() - 0.5) * diversity\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by incorporating adaptive mutation and crossover rates based on population diversity.", "configspace": "", "generation": 75, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "ee68b043-1d10-41fe-9b9b-bee92827d06d", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive F calculation based on evaluations and budget\n        adaptive_F = self.F * (1 - self.evaluations / self.budget)\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE-ILA by adapting the mutation factor F based on convergence rate to enhance exploration-exploitation balance.", "configspace": "", "generation": 76, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "4b59322c-19da-42c2-ab01-c2894c541664", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(pop, axis=0).mean()  # Calculate population diversity\n        adaptive_F = self.F + (0.2 * diversity)  # Adapt mutation factor based on diversity\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        diversity = np.std(mutant)  # Calculate diversity of mutant vector\n        adaptive_CR = self.CR - (0.1 * diversity)  # Adapt CR based on diversity\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adapting mutation factor and crossover probability dynamically based on population diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 77, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "99775da9-1c89-4530-b6cc-319873525871", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + 0.1 * np.random.rand()  # Adaptive F for better exploration\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR + 0.1 * (0.5 - np.random.rand())  # Adaptive CR for dynamic diversity\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA with adaptive F and CR to improve exploration-exploitation balance.", "configspace": "", "generation": 78, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "4b0c9d51-62bf-48ae-9fa2-8c4e56422b8d", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        iter_progress = self.evaluations / self.budget\n        adaptive_F = self.F * (1 - iter_progress)\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improving DE-ILA by enhancing the mutation strategy with adaptive scaling based on iteration progress.", "configspace": "", "generation": 79, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "8ac5a358-7c6a-4eb8-91fc-cf7af263ac62", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5) \n        if np.random.rand() > 0.5:  # Added condition for dynamic mutation strength\n            mutant += self.F * (pop[a] - pop[b])\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n                        self.CR = min(1.0, self.CR + 0.05)  # Increment CR on improvement\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance mutation strategy and dynamically adjust CR based on feedback from local improvements to improve solution convergence.", "configspace": "", "generation": 80, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "f9333343-30da-4629-a6af-3381c97479da", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.F * (1.0 - self.evaluations / self.budget)  # Adaptive scaling factor\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        CR_dynamic = self.CR * (0.5 + 0.5 * np.random.rand())  # Dynamic crossover\n        cross_points = np.random.rand(len(target)) < CR_dynamic\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refining DE-ILA by integrating adaptive scaling factor and dynamic crossover probability to enhance solution diversity and convergence speed.", "configspace": "", "generation": 81, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "aad7b2d0-70a2-4e1e-8be2-986dd0bf7eba", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(pop, axis=0)  # Line changed\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * diversity_factor * (np.random.rand(len(pop[a])) - 0.5)  # Line changed\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target)  # Line changed\n        cross_points = np.random.rand(len(target)) < (self.CR * diversity_factor)  # Line changed\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adding adaptive mutation and crossover rates based on population diversity to improve convergence speed and solution quality.", "configspace": "", "generation": 82, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "ab18d944-3c34-4c4e-8347-e0da2e5fe072", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        layer_F = self.F * (1 + 0.1 * (np.random.rand() - 0.5))  # Layer-specific mutation factor\n        mutant = pop[a] + layer_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n                self.pop_size = max(10, self.pop_size - 1)  # Adaptive population scaling\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adding a layer-specific mutation factor and incorporating adaptive population scaling.", "configspace": "", "generation": 83, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "3c001229-b856-4c97-9831-847d650f13a0", "solution": "import numpy as np\n\nclass DE_ILA_Improved:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = np.random.rand(self.pop_size, layers) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]  # Removed squaring for better exploration\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n                self.F *= 0.99  # Adaptive F adjustment to improve convergence\n\n        return best_solution", "name": "DE_ILA_Improved", "description": "Improve DE-ILA by enhancing population initialization strategy and adaptive parameter update.", "configspace": "", "generation": 84, "fitness": 0.8046131747863633, "feedback": "The algorithm DE_ILA_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.020. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.78488897719009, 0.796691734804205, 0.8322588123647949], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "a9c71e3b-0bc5-4655-86ae-d0ed99d3f15a", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        centroid = np.mean(pop, axis=0)  # Calculate population centroid\n        self.F = 0.5 + 0.5 * (1 - np.std(pop, axis=0).mean())  # Adaptive F based on diversity\n        mutant = centroid + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            self.CR = 0.5 + 0.5 * np.std(scores)  # Adaptive CR\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improved DE-ILA by incorporating adaptive crossover probability and mutation factor based on population diversity to enhance convergence.", "configspace": "", "generation": 85, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "c182b61e-0999-4439-b4e0-ad922373ba94", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F + np.random.normal(0, 0.1)  # Adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1.0 + np.random.uniform(-0.1, 0.1))  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE_ILA by incorporating adaptive parameters for mutation and crossover rates to improve convergence and diversity.", "configspace": "", "generation": 86, "fitness": 0.7810077049121782, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.017. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.7584914471306059, 0.7836940107601237, 0.8008376568458049], "final_y": [0.17416312008663415, 0.16463513031046606, 0.1518256081358481]}, "mutation_prompt": null}
{"id": "ed6aada5-2ed1-423f-9c9e-b29d3be4c82e", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        # Dynamically adjust CR based on evaluations\n        self.CR = 0.5 + 0.5 * (self.evaluations / self.budget)\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by modifying the crossover rate dynamically to balance exploration and exploitation.", "configspace": "", "generation": 87, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "2085d36a-9352-40b0-9cd4-2bf7626cc298", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + np.random.uniform(0.5, self.F) * (pop[b] - pop[c])  # Adaptive F\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(max(20, int(self.pop_size * 0.9)), current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(len(pop))\n            for i in range(len(pop)):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(len(pop)):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by integrating adaptive mutation scaling and dynamic population resizing for improved exploration and convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 49 is out of bounds for axis 0 with size 45').", "error": "IndexError('index 49 is out of bounds for axis 0 with size 45')", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {}, "mutation_prompt": null}
{"id": "656ed577-fe91-4c56-a2a3-16a728b88989", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        # Minor change: adjusted the exponent in population initialization for better exploration\n        pop = (np.random.rand(self.pop_size, layers) ** 1.5) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adjusting initial population scaling for improved exploration.", "configspace": "", "generation": 89, "fitness": 0.8079361865762005, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8098650157849165, 0.785490914432802, 0.8284526295108829], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "050dce86-746a-4d75-9ad6-f1159494256b", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n        self.success_rate = 0.2  # Added for adaptive control\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        self.F = 0.5 + 0.3 * np.random.rand() * self.success_rate  # Adaptive F\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.5 + 0.4 * np.random.rand() * self.success_rate  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            successful_mutations = 0  # Track successful mutations\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    successful_mutations += 1  # Increment on success\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            self.success_rate = successful_mutations / self.pop_size  # Update success rate\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by incorporating adaptive F and CR parameters based on success rate to better balance exploration and exploitation.", "configspace": "", "generation": 90, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "6851dc1e-af76-4360-96ba-8e412f9c28b8", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        # Modified line for adaptive CR\n        cross_points = np.random.rand(len(target)) < (self.CR * np.std(target))  \n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduce adaptive crossover probability adjustment based on population diversity to improve convergence.", "configspace": "", "generation": 91, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "7a6819bd-bdb5-427a-afe7-3d18a179e2ce", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop, adapt_F):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + adapt_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n        adapt_F = self.F  # Initialize adaptive F\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop, adapt_F)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n            adapt_F = max(0.5, self.F * (0.5 + 0.5 * (self.budget - self.evaluations) / self.budget)) # Adaptive F\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n                self.pop_size = min(self.pop_size + 1, 100)  # Dynamic population resizing\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive mutation scaling and dynamic population resizing for better exploration and exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "6c2ad1d4-4422-4cc1-bb20-762a7ad20964", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.F * (0.5 + 0.5 * np.random.rand())  # Adaptive mutation factor\n        mutant = pop[a] + F_adaptive * (pop[b] - pop[c])  # Apply adaptive mutation\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            elite_idx = np.argmin(scores)  # Elitism: retain the best solution\n            next_pop[0] = pop[elite_idx]\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by adaptive mutation factor and introducing elitism for improved convergence.", "configspace": "", "generation": 93, "fitness": 0.7954219245107307, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.009. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.796335213193155, 0.7836940107601237, 0.8062365495789134], "final_y": [0.1526232075896362, 0.16463513031046606, 0.15176659271540516]}, "mutation_prompt": null}
{"id": "98a68323-fc25-4f7e-97c2-e61792049c1e", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_component = np.random.rand(len(pop[a])) * (pop[b] - pop[c])\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + adaptive_component  # Added adaptive component for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Refine mutation strategy by adding a novel adaptive component to enhance exploration while maintaining diversity.", "configspace": "", "generation": 94, "fitness": 0.808907082950001, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7924454572734327, 0.8333646402569067], "final_y": [0.1530542792464199, 0.15070467183412795, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "63d02fba-5eda-41c5-84c2-0a06098597d1", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F + 0.2 * np.sin(2 * np.pi * self.evaluations / self.budget)  # Dynamic mutation factor\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n            self.pop_size = max(10, int(self.pop_size * 0.95))  # Adaptive population size reduction\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Improve DE-ILA by adjusting the mutation factor dynamically and implementing adaptive population size.", "configspace": "", "generation": 95, "fitness": 0.7927209867472028, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.014. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8052093115209851, 0.8003066473660401, 0.7726470013545833], "final_y": [0.15217350773029636, 0.1565055066615355, 0.16781934155112732]}, "mutation_prompt": null}
{"id": "e3b62147-dd51-43ee-8150-6cf166069a56", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.5 + 0.4 * np.sin(self.evaluations / self.budget * 2 * np.pi)  # Dynamic adjustment of CR\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhancing DE-ILA by dynamically adjusting crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.808076384945131, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.018. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7899533632588225, 0.8333646402569067], "final_y": [0.1530542792464199, 0.16191157253391597, 0.14060518123537846]}, "mutation_prompt": null}
{"id": "4699ab9f-01a0-458a-bd98-8c883985a7cf", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_layers = initial_layers\n        self.evaluations = 0\n        self.memory = []\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        self.F = 0.5 + np.random.random() * 0.5  # Dynamic adaptation of F\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n                    self.memory.append(best_solution)  # Memory of best solutions\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n                        self.memory.append(best_solution)\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhanced DE-ILA by introducing dynamic adaptation of F parameter and incorporating memory of best solutions.", "configspace": "", "generation": 97, "fitness": 0.7924449556278593, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8015844799575853, 0.7880883986533691, 0.7876619882726237], "final_y": [0.1530542792464199, 0.15849014272946926, 0.1557788394465215]}, "mutation_prompt": null}
{"id": "abeffc44-26f2-49b2-b7c8-0f11fbd06135", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (0.5 + np.random.rand())  # Adaptive F\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (0.5 + np.random.rand())  # Adaptive CR\n        cross_points = np.random.rand(len(target)) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Enhance DE-ILA by introducing adaptive F and CR and refining population diversity through selective replacement.", "configspace": "", "generation": 98, "fitness": 0.7961466892290768, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8145591558479226, 0.7890786695698514, 0.7848022422694565], "final_y": [0.1437677629589248, 0.16160754960489077, 0.1614887862635901]}, "mutation_prompt": null}
{"id": "ce86b940-e4e8-4ea6-a585-965dd5fbfd02", "solution": "import numpy as np\n\nclass DE_ILA:\n    def __init__(self, budget, dim, pop_size=50, F=0.8, CR=0.9, initial_layers=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.initial_layers = initial_layers  # Start with a smaller number of layers\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds, layers):\n        pop = (np.random.rand(self.pop_size, layers) ** 2) * (bounds.ub[:layers] - bounds.lb[:layers]) + bounds.lb[:layers]\n        return pop\n\n    def _mutate(self, target_idx, pop):\n        indices = [i for i in range(self.pop_size) if i != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (np.random.rand(len(pop[a])) - 0.5)  # Added random noise for diversity\n        return np.clip(mutant, 0, 1)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(len(target)) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, len(target))] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_layers = self.initial_layers\n        best_solution = None\n        best_score = float(\"inf\")\n\n        while self.evaluations < self.budget:\n            if best_solution is None:\n                pop = self._initialize_population(bounds, current_layers)\n            else:\n                new_pop = np.random.rand(self.pop_size, current_layers) * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                new_pop[:, :current_layers-len(best_solution)] = best_solution[:current_layers-len(best_solution)]\n                pop = new_pop\n\n            scores = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                solution = pop[i]\n                score = func(solution)\n                self.evaluations += 1\n                scores[i] = score\n                if score < best_score:\n                    best_score = score\n                    best_solution = solution\n\n            next_pop = np.copy(pop)\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                target = pop[i]\n                self.CR = 0.9 * (1 - self.evaluations / self.budget) + 0.1  # Adaptive CR\n                mutant = self._mutate(i, pop)\n                trial = self._crossover(target, mutant)\n                trial_real = trial * (bounds.ub[:current_layers] - bounds.lb[:current_layers]) + bounds.lb[:current_layers]\n                trial_score = func(trial_real)\n                self.evaluations += 1\n                if trial_score < scores[i]:\n                    next_pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial_real\n\n            pop = next_pop\n\n            if current_layers < self.dim and self.evaluations < self.budget:\n                current_layers += 1\n\n        return best_solution", "name": "DE_ILA", "description": "Introduce adaptive crossover probability to improve exploration-exploitation balance in DE-ILA.", "configspace": "", "generation": 99, "fitness": 0.808076384945131, "feedback": "The algorithm DE_ILA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.018. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a8973035-1a43-4817-b046-9d3c9030effa", "metadata": {"aucs": [0.8009111513196636, 0.7899533632588225, 0.8333646402569067], "final_y": [0.1530542792464199, 0.16191157253391597, 0.14060518123537846]}, "mutation_prompt": null}
