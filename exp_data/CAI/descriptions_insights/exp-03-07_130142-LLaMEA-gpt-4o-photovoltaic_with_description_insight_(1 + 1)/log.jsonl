{"id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "The algorithm combines Differential Evolution with a layer-wise adaptive strategy, gradually increasing layer complexity while integrating local search for fine-tuning and robustness evaluation.", "configspace": "", "generation": 0, "fitness": 0.798568043813134, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.006. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7969886431756447, 0.8061404159345112, 0.7925750723292458], "final_y": [0.15460060030284373, 0.15004363576779167, 0.15076679601062015]}, "mutation_prompt": null}
{"id": "fc5422a9-561b-4094-9320-966489075796", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Dynamic crossover probability adjustment based on scores\n                self.CR = 0.9 if scores[i] > np.mean(scores) else 0.7\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "The algorithm enhances the differential evolution strategy by fine-tuning the crossover probability dynamically based on solution quality, improving convergence precision.", "configspace": "", "generation": 1, "fitness": 0.7906741813896733, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.012. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "metadata": {"aucs": [0.7775834931024798, 0.8056538359352903, 0.7887852151312501], "final_y": [0.1582799815072311, 0.1533763376781927, 0.15230943583308088]}, "mutation_prompt": null}
{"id": "ac452341-b0ad-4281-b6e7-fb17f12f008c", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, 0.005) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "The algorithm builds on LayerAdaptiveDE by enhancing the local search with dynamic perturbation based on a Gaussian distribution to facilitate finer solution adjustments.", "configspace": "", "generation": 2, "fitness": 0.7942145233287056, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.010. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "metadata": {"aucs": [0.7989456236064786, 0.8028078013083558, 0.7808901450712822], "final_y": [0.15471194457525983, 0.15580907645490982, 0.16234073524542103]}, "mutation_prompt": null}
{"id": "e65f8928-482f-46b4-8d59-be5b132d7c13", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution + np.random.normal(0, 0.01, size=refined_solution.shape))  # Adding noise-resilient scoring\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhancing robustness by integrating a noise-resilient scoring mechanism inspired by noise-tolerant Differential Evolution.", "configspace": "", "generation": 3, "fitness": 0.7960332055064026, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.008. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "metadata": {"aucs": [0.7964203947079982, 0.8056577373787377, 0.7860214844324719], "final_y": [0.1555654395362812, 0.15337911332718135, 0.15725339341930866]}, "mutation_prompt": null}
{"id": "eae4f8dc-050b-4482-b53d-515c8c92da65", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, 0.01) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhancing the local search by introducing a Gaussian perturbation for more precise fine-tuning of the best solution.", "configspace": "", "generation": 4, "fitness": 0.795613758502915, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.010. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "metadata": {"aucs": [0.8023915224004758, 0.8033248934436845, 0.7811248596645846], "final_y": [0.15309360124851346, 0.1548654461969211, 0.16200158824897892]}, "mutation_prompt": null}
{"id": "b8acd3f8-5c38-413c-b875-6e6c77affca0", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "The algorithm combines Differential Evolution with a layer-wise adaptive strategy, gradually increasing layer complexity while integrating local search for fine-tuning and robustness evaluation, with increased mutation rate for enhanced exploration.", "configspace": "", "generation": 5, "fitness": 0.8026875385789835, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.011. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a294e38a-2bdd-4e94-9f58-3eec68b408b6", "metadata": {"aucs": [0.7927278014201762, 0.7973224794623058, 0.8180123348544683], "final_y": [0.1440144780864785, 0.15864427210249832, 0.13669415790909822]}, "mutation_prompt": null}
{"id": "5bab475b-b6f9-43d5-b8f3-b95047130e65", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.92  # Crossover probability (changed from 0.9 to 0.92)\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "The algorithm combines Differential Evolution with a layer-wise adaptive strategy, gradually increasing layer complexity while integrating local search for fine-tuning and robustness evaluation, with increased mutation rate for enhanced exploration and slightly higher crossover probability for diversity.", "configspace": "", "generation": 6, "fitness": 0.7960171517332242, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.005. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b8acd3f8-5c38-413c-b875-6e6c77affca0", "metadata": {"aucs": [0.7906385417382253, 0.8028861541645359, 0.7945267592969116], "final_y": [0.15743313689465488, 0.1527963036130079, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "a35f5485-8bdb-42d1-b090-ee38ae062d84", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.005, 0.005) * (ub[idx] - lb[idx])  # Adjusted perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Improve the LayerAdaptiveDE by adjusting the local search perturbation range to enhance solution refinement.", "configspace": "", "generation": 7, "fitness": 0.8012793806838306, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.010. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b8acd3f8-5c38-413c-b875-6e6c77affca0", "metadata": {"aucs": [0.7919706942239363, 0.7961668309580043, 0.8157006168695511], "final_y": [0.1440144780864785, 0.1592598065095705, 0.1396903564298504]}, "mutation_prompt": null}
{"id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.02, 0.02) * (ub[idx] - lb[idx])  # Changed perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance local search by increasing perturbation range to improve exploration around the current best solution.", "configspace": "", "generation": 8, "fitness": 0.8047423982359323, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.012. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "b8acd3f8-5c38-413c-b875-6e6c77affca0", "metadata": {"aucs": [0.793814473840674, 0.7983772900896319, 0.8220354307774909], "final_y": [0.1440144780864785, 0.1580819292003024, 0.13179340711305076]}, "mutation_prompt": null}
{"id": "2ad4fa11-39f8-45a4-9116-f32ebefa4ea1", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Calculate population diversity\n            diversity = np.std(pop, axis=0).mean()\n\n            # Adjust the crossover probability (CR) based on diversity\n            self.CR = 0.5 + 0.4 * (diversity / (ub - lb).mean())\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.02, 0.02) * (ub[idx] - lb[idx])  # Changed perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a mechanism to dynamically adjust the crossover probability (CR) based on the diversity of the population to better balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.7858132709707917, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.024. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.7605178106223565, 0.818345840195008, 0.7785761620950102], "final_y": [0.15342708200408195, 0.13903344849622834, 0.15866368974449008]}, "mutation_prompt": null}
{"id": "b85abd6b-9517-4e3e-aacf-655b3723e698", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.015, 0.015) * (ub[idx] - lb[idx])  # Changed perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance local search by refining perturbation range to improve solution accuracy.", "configspace": "", "generation": 10, "fitness": 0.8038436405605869, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.012. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.7933408046621863, 0.7980583032968945, 0.8201318137226798], "final_y": [0.1440144780864785, 0.15825254303977698, 0.1340559234590537]}, "mutation_prompt": null}
{"id": "aac7ed61-d9b4-4273-a319-ce3f05ec1dc0", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            # Dynamic adjustment of crossover probability\n            self.CR = 0.9 - 0.5 * (evals / self.budget)\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.02, 0.02) * (ub[idx] - lb[idx])  # Changed perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic adjustment of the crossover probability (CR) to balance exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.8022796727693837, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.013. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.7913636704168382, 0.8209485885944015, 0.7945267592969116], "final_y": [0.15760406327368925, 0.1421587976252936, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "8b098d75-0647-4c46-86f7-296f58def54f", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        # Adaptive layer complexity strategy\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            # Evaluate population\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            # Keep track of the best solution\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = np.random.uniform(0.5, 1.0)  # Self-adaptive mutation scaling factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            # Gradually increase layer complexity\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            # Local search on the best solution\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.02, 0.02) * (ub[idx] - lb[idx])  # Changed perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Incorporate self-adaptive mutation scaling factor for better balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.7923757264268917, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.023. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.762409117692219, 0.795499319502347, 0.819218742086109], "final_y": [0.1520410500671474, 0.15968285206287525, 0.14755705587581158]}, "mutation_prompt": null}
{"id": "d6ef2dec-44fe-45dc-952d-05a7b3ad0325", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight (changed from 0.5 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = np.random.uniform(0.5, 1.0)  # Adaptive mutation factor\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget and np.random.rand() < 0.5:  # Perform selective local search\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.02, 0.02) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation factors and selective local refinement to enhance convergence and stability.", "configspace": "", "generation": 13, "fitness": 0.7944610651890565, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.022. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.7656386505212249, 0.7979615091560424, 0.8197830358899021], "final_y": [0.15342103700801335, 0.15855381341393093, 0.14751373981312565]}, "mutation_prompt": null}
{"id": "474223d9-c49a-4286-b60e-2de2bd137aac", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10  # Start with 10 layers\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.2 * np.random.rand()  # Adapt differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.01, 0.01) * (ub[idx] - lb[idx])  # Refined perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Employ weight adaptation and enhanced local search to improve convergence and solution robustness.", "configspace": "", "generation": 14, "fitness": 0.793118336703181, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.020. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.7646961589320936, 0.8028957478851393, 0.8117631032923096], "final_y": [0.1608706294744363, 0.1533012694750967, 0.1475565579885022]}, "mutation_prompt": null}
{"id": "452cf4e1-21eb-4f75-a48c-8132717a7f0f", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                adaptive_CR = self.CR * (1 - scores[min_idx] / self.best_score)\n                cross_points = np.random.rand(self.dim) < adaptive_CR\n                \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-0.05, 0.05) * (ub[idx] - lb[idx])  # Enhanced perturbation range\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive crossover rate and enhanced local search to improve convergence and robustness.", "configspace": "", "generation": 15, "fitness": 0.7896981691851694, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.009. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.780505685995045, 0.8024913203831474, 0.7860975011773161], "final_y": [0.16120957972138894, 0.15070375921534396, 0.15801037610899715]}, "mutation_prompt": null}
{"id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive crossover probability and dynamic local search range to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.810015551919229, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.019. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "90f707c4-7386-4dad-99e8-01fdeeb6b953", "metadata": {"aucs": [0.798727669165361, 0.8367922272954149, 0.7945267592969116], "final_y": [0.14582676806438566, 0.13487802855254727, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "bd920a00-1287-4c65-9fdd-599e1dc807e2", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.2 * (np.random.rand())  # Adaptive mutation factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7877420274738371, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.021. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7585283733326005, 0.7954201818409354, 0.8092775272479757], "final_y": [0.1615589708580516, 0.15969767824053194, 0.15163481922893973]}, "mutation_prompt": null}
{"id": "75f56a73-e806-492c-8b88-a5a9cc382853", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 3  # Introduce multiple populations\n        self.populations = [np.random.rand(self.pop_size, dim) for _ in range(self.num_populations)]\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pops = [pop * (ub - lb) + lb for pop in self.populations]\n        \n        layers = 10\n        while evals < self.budget:\n            for pop in pops:\n                scores = np.array([func(ind) for ind in pop])\n                evals += len(pop)\n                \n                min_idx = np.argmin(scores)\n                if scores[min_idx] < self.best_score:\n                    self.best_score = scores[min_idx]\n                    self.best_solution = pop[min_idx].copy()\n\n                for i in range(self.pop_size):\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    adaptive_F = self.F + 0.2 * np.random.rand()  # Adaptive F\n                    mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    trial_score = func(trial)\n                    evals += 1\n\n                    if trial_score < scores[i]:\n                        pop[i] = trial\n                        scores[i] = trial_score\n                        if trial_score < self.best_score:\n                            self.best_score = trial_score\n                            self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce multi-population strategy and adaptive F to enhance exploration and convergence diversity.", "configspace": "", "generation": 18, "fitness": 0.787917947678248, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7776688415687635, 0.7945901820562783, 0.791494819409702], "final_y": [0.161293010766829, 0.1601017669387199, 0.15555324552469818]}, "mutation_prompt": null}
{"id": "e97eab8d-8fbc-4dee-99ce-4695cf031474", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation factor F in LayerAdaptiveDE to further enhance exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.7927274517909906, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.020. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7658330202840246, 0.7977089560415154, 0.814640379047432], "final_y": [0.16229038097044646, 0.15850778855122916, 0.14936242451815984]}, "mutation_prompt": null}
{"id": "1fce0649-59e1-4624-9e32-a3fee86788a4", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                layer_factor = (i % layers) / layers  # Layer-wise mutation strategy\n                mutant = np.clip(a + (self.F + layer_factor) * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Stochastic refinement\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce layer-wise adaptive mutation strategy and stochastic local refinement to enhance search capability.", "configspace": "", "generation": 20, "fitness": 0.791267068075042, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.011. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7750688567626318, 0.7994601700293336, 0.7992721774331604], "final_y": [0.16104845964474235, 0.1569897585017742, 0.15137234426296253]}, "mutation_prompt": null}
{"id": "dbc36ce8-727c-47aa-98c6-d1ced5b411ae", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_dynamic = self.F * (0.9 + 0.1 * (evals / self.budget))  # Dynamic scaling factor\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic scaling factor for enhanced adaptive exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.8056188611442249, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.005. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.8078444116842586, 0.7982223519747605, 0.8107898197736557], "final_y": [0.15092795706174822, 0.15816492511113855, 0.14441635070900072]}, "mutation_prompt": null}
{"id": "b2a74a66-0af2-427b-83ff-ac36091a60f6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.5 * (1 - evals / self.budget)  # Adaptive mutation scaling factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation scaling factor based on evaluation progress to balance exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.788570756193454, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.027. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7505409124263581, 0.8057002540076845, 0.8094711021463192], "final_y": [0.16932696848020035, 0.15132937961050197, 0.14890940551124432]}, "mutation_prompt": null}
{"id": "c5dfb390-d5a9-48a7-8668-ee707d5911e5", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.4 + 0.3 * (1 - self.best_score)  # Adaptive mutation factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance algorithm performance by adapting the mutation factor based on the current best score.", "configspace": "", "generation": 23, "fitness": 0.8099558429527294, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.024. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7915499127603106, 0.843790856800966, 0.7945267592969116], "final_y": [0.15669758811721812, 0.13179794943108325, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "5721729c-0c77-4dc1-9096-184244fa339e", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score) * (1 + 0.1 * (self.best_score < 0.1))  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance local search by adaptively refining the perturbation range based on solution improvements.", "configspace": "", "generation": 24, "fitness": 0.810015551919229, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.019. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.798727669165361, 0.8367922272954149, 0.7945267592969116], "final_y": [0.14582676806438566, 0.13487802855254727, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "25ff8158-ad2c-4887-b63b-7bb901f4fcf5", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n                    self.F = min(1.0, self.F + 0.1)  # Success-based adaptation for mutation factor\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a success-based adaptation mechanism for the mutation factor to improve convergence.", "configspace": "", "generation": 25, "fitness": 0.7906150276424379, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7915499127603106, 0.7982223519747605, 0.7820728181922425], "final_y": [0.15669758811721812, 0.15816492511113855, 0.16288997112654768]}, "mutation_prompt": null}
{"id": "894c756e-47fb-4af3-baf5-32c642a30017", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation factor to enhance the diversity and convergence speed of the population.", "configspace": "", "generation": 26, "fitness": 0.7996047472674742, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.018. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7761875646564541, 0.8034147427484556, 0.819211934397513], "final_y": [0.15451549174457735, 0.1555353146800712, 0.14756885736049696]}, "mutation_prompt": null}
{"id": "65ba1b14-1f17-4369-a634-2d65e2f5cdd2", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_dynamic = 0.5 + 0.2 * np.random.rand()  # Adaptive mutation factor\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.hybrid_local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def hybrid_local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        # Hybrid local search with a small random restart\n        if np.random.rand() < 0.1:\n            perturbed_solution = np.random.rand(self.dim) * (ub - lb) + lb\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration through adaptive mutation factor and hybrid local search to dynamically balance exploration and exploitation.", "configspace": "", "generation": 27, "fitness": 0.7877376528839567, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.021. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7585283733326005, 0.7954201818409354, 0.8092644034783342], "final_y": [0.1615589708580516, 0.15969767824053194, 0.15165819955875848]}, "mutation_prompt": null}
{"id": "fa32b10a-1ebb-4713-905d-933d01fa545a", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.5 + 0.4 * (evals / self.budget)  # Enhanced adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 4, self.dim)  # Faster layer growth\n            \n            if evals < self.budget:\n                refined_sol = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_sol)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_sol\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.04 * (1 - self.best_score)  # Expanded perturbation range\n        workgroup_size = max(2, layers // 4)\n        for _ in range(workgroup_size):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhanced dynamic exploration with adaptive layer growth and workgroup-based local refinement to optimize photonic structures.", "configspace": "", "generation": 28, "fitness": 0.7940444124004201, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.004. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7891423867360026, 0.7945901820562783, 0.7984006684089796], "final_y": [0.15841881554604753, 0.1601017669387199, 0.15116652824858479]}, "mutation_prompt": null}
{"id": "7bd629f6-bfa6-4a50-9849-882bb4d40871", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        convergence_threshold = 0.001  # Change: Early stopping criterion\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            if self.best_score < convergence_threshold:  # Early stopping\n                break\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Integrate early stopping criteria based on convergence threshold to enhance computational efficiency.", "configspace": "", "generation": 29, "fitness": 0.810015551919229, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.019. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.798727669165361, 0.8367922272954149, 0.7945267592969116], "final_y": [0.14582676806438566, 0.13487802855254727, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "9d215aa4-a6a0-40c6-889b-f61da78a25db", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.5 * (1 - evals / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation factor to improve diversity and convergence speed.  ", "configspace": "", "generation": 30, "fitness": 0.788570756193454, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.027. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7505409124263581, 0.8057002540076845, 0.8094711021463192], "final_y": [0.16932696848020035, 0.15132937961050197, 0.14890940551124432]}, "mutation_prompt": null}
{"id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation scaling factor to improve exploration and convergence.", "configspace": "", "generation": 31, "fitness": 0.8117690685335117, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "6a2e401d-1702-4f3a-ac35-051ececb05c7", "metadata": {"aucs": [0.7917108737875321, 0.8490695725160914, 0.7945267592969116], "final_y": [0.15463710257930974, 0.12971597530694434, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "ce455a67-a3e4-42dc-a0d8-9ff1186c710a", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            # Dynamically adjust population size for improving exploration-exploitation\n            self.pop_size = max(5, int(10 * self.dim * (1 - evals / self.budget)))\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic adaptation of population size for improved exploration-exploitation balance.", "configspace": "", "generation": 32, "fitness": 0.7952334990412225, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.002. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7922067059823317, 0.7973130029354841, 0.796180788205852], "final_y": [0.1566885578288536, 0.1571426508561019, 0.156737286676512]}, "mutation_prompt": null}
{"id": "28527678-8059-4d36-8838-a7a8a27cda4e", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_layer = self.F * ((layers / self.dim) + 0.1 * np.random.rand())  # Adaptive F\n                mutant = np.clip(a + F_layer * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Incorporate adaptive layer-wise mutation and enhance local search for improved exploration and refinement.", "configspace": "", "generation": 33, "fitness": 0.784366678151828, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.019. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7582165304137748, 0.7954201818409354, 0.7994633222007741], "final_y": [0.16758050196160257, 0.15969767824053194, 0.15482984826634882]}, "mutation_prompt": null}
{"id": "0292a5f5-6c30-49e2-bb55-3740faf5932c", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.4 + 0.5 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.6 + 0.25 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(min(layers, 5)):  # Multi-scale local search\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Leverage multi-scale local search and adaptive population scaling to enhance exploration and convergence efficiency.", "configspace": "", "generation": 34, "fitness": 0.8076977203409611, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.8179888271682185, 0.7945901820562783, 0.8105141517983864], "final_y": [0.14292628084027414, 0.1601017669387199, 0.14881302455748358]}, "mutation_prompt": null}
{"id": "ff98b2ae-fac5-4672-8735-243a85bff5ff", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            diversity = np.mean(np.std(pop, axis=0))  # Diversity metric\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) + 0.1 * diversity  # Adaptive mutation scaling\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score) * np.random.uniform(0.8, 1.2)  # Adaptive perturbation\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration and robustness by integrating diversity preservation and adaptive perturbation to improve convergence.", "configspace": "", "generation": 35, "fitness": 0.7951442298937627, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.003. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7912508329687081, 0.7996550974156678, 0.7945267592969116], "final_y": [0.15727783910942517, 0.1574696299310453, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "eb11ce57-f888-4bb6-a881-8f7ded6613ac", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.cos((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Adjust mutation scaling factor based on oscillating cosine function to improve exploration.", "configspace": "", "generation": 36, "fitness": 0.8081764287711236, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.021. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7915499127603106, 0.8384526142561484, 0.7945267592969116], "final_y": [0.15669758811721812, 0.1341003327711222, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "17c0c452-a7f6-42bf-8e84-ae1e50b43dd2", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        gradient_estimation = np.zeros_like(solution)  # New line added\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Refine local search by incorporating a dynamic gradient estimation to enhance convergence on high-performing solutions.", "configspace": "", "generation": 37, "fitness": 0.8117690685335117, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7917108737875321, 0.8490695725160914, 0.7945267592969116], "final_y": [0.15463710257930974, 0.12971597530694434, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "6fe62b82-a9c6-40fd-9a30-bf73a75debbc", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            \n            # Modified line for adaptive mutation factor:\n            self.F = 0.5 + 0.2 * np.cos((np.pi / 2) * (scores[min_idx] / self.best_score))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive scaling of the mutation factor based on convergence speed.", "configspace": "", "generation": 38, "fitness": 0.8106995245469619, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.025. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7915499127603106, 0.8460219015836637, 0.7945267592969116], "final_y": [0.15669758811721812, 0.1315458788407723, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "40a61fc3-3333-49dd-ac16-6dbf9a605d38", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = int(10 * self.dim * (1 - evals / self.budget)) + 1  # Dynamic population size scaling\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Implement a dynamic population size scaling to improve exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.7953635397037077, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.004. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7907404604955931, 0.799371020271537, 0.795979138343993], "final_y": [0.15819478783748653, 0.1544249921682631, 0.15083776788050418]}, "mutation_prompt": null}
{"id": "79c2beb5-2197-4f1f-a5e5-09dedb319937", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = int(10 * dim * (1 - 0.5 * (evals / self.budget)))  # Adaptive pop size scaling\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive population size scaling based on the evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {}, "mutation_prompt": null}
{"id": "ec6a0696-c0f0-48f3-b498-3352126f4c56", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n            \n            self.pop_size = int(10 * self.dim * (1 + np.cos(np.pi * evals / self.budget)))  # Dynamic population adjustment\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration by adjusting the population size dynamically based on the remaining budget to improve diversity.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 101 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 101 is out of bounds for axis 0 with size 100')", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {}, "mutation_prompt": null}
{"id": "870062ce-8110-4ecc-ba9d-1d480139079c", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10 * dim, 20)  # Ensure minimum population size\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = max(int(10 * self.dim * (1 - evals/self.budget)), 20)  # Dynamic population size\n        \n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Improve diversity by dynamically adjusting population size based on convergence progress.", "configspace": "", "generation": 42, "fitness": 0.7951800680903798, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.002. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7922067059823317, 0.7971527100829556, 0.796180788205852], "final_y": [0.1566885578288536, 0.15796167156776653, 0.156737286676512]}, "mutation_prompt": null}
{"id": "71fcbc08-6253-4ab2-a132-e16207532a23", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget))  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.01 * (1 - self.best_score)  # Reduced perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation scaling factor and improved perturbation range for better exploration and convergence.", "configspace": "", "generation": 43, "fitness": 0.8111072015691588, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.026. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7906159416227496, 0.848178903787815, 0.7945267592969116], "final_y": [0.15463710257930974, 0.13027178190664823, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.random.rand()  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce noise reduction in mutation scaling to stabilize the optimization process.", "configspace": "", "generation": 44, "fitness": 0.8124131990560719, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a136cabb-1500-4ee5-adfa-fd02577f76b7", "metadata": {"aucs": [0.7915153965614621, 0.8486177948445788, 0.7971064057621748], "final_y": [0.15713773698020483, 0.13019613109414963, 0.1483681541409334]}, "mutation_prompt": null}
{"id": "8ac7fca6-3984-4535-9913-f9cb54163a38", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.random.rand()  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.01 * (1 - self.best_score)  # Slightly reduced dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Refine the local search perturbation range dynamically based on convergence to enhance solution refinement.", "configspace": "", "generation": 45, "fitness": 0.8116758454502516, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7902340782227822, 0.8476870523657977, 0.7971064057621748], "final_y": [0.15807507996266712, 0.13063561720562955, 0.1483681541409334]}, "mutation_prompt": null}
{"id": "a690ad5d-0597-48e6-8150-dbb92b2319fc", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) + 0.1 * (1 - self.best_score)  # Improved mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance mutation scaling factor adaptively based on previous best scores to improve convergence.", "configspace": "", "generation": 46, "fitness": 0.8101819920407962, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.024. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915499127603106, 0.8444693040651667, 0.7945267592969116], "final_y": [0.15669758811721812, 0.1315382673940918, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "04bf5acf-7994-4acb-9e15-25a285ec5462", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.random.rand()  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            direction = 1 if np.random.rand() > 0.5 else -1  # Add directional perturbation\n            perturbation = direction * np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Refine local search by adding directional perturbation to enhance convergence.", "configspace": "", "generation": 47, "fitness": 0.8075523225439593, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.016. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7920092533840702, 0.8295301035973919, 0.8011176106504158], "final_y": [0.15593003877564204, 0.14218779434839035, 0.14824301587796918]}, "mutation_prompt": null}
{"id": "173b9dec-33f9-4bcd-b798-9794412afbc8", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.random.rand()  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Utilize sigmoid-based dynamic mutation scaling to enhance adaptive diversity in population.", "configspace": "", "generation": 48, "fitness": 0.8124131990560719, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915153965614621, 0.8486177948445788, 0.7971064057621748], "final_y": [0.15713773698020483, 0.13019613109414963, 0.1483681541409334]}, "mutation_prompt": null}
{"id": "9e190115-aa31-4eab-9bf8-5243076c0800", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * np.std(pop)  # Dynamic mutation scaling\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance mutation strategy by introducing dynamic scaling influenced by population diversity.", "configspace": "", "generation": 49, "fitness": 0.7947663413439944, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.003. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915499127603106, 0.7982223519747605, 0.7945267592969116], "final_y": [0.15669758811721812, 0.15816492511113855, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "b6118afd-99ab-4c94-b237-4ccc9ef6aa94", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.random.rand()  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * max((1 - self.best_score), 0.01)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Implemented dynamic adjustment of the perturbation range in local search to enhance exploration.", "configspace": "", "generation": 50, "fitness": 0.8124131990560719, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915153965614621, 0.8486177948445788, 0.7971064057621748], "final_y": [0.15713773698020483, 0.13019613109414963, 0.1483681541409334]}, "mutation_prompt": null}
{"id": "b41ec553-d71b-41e7-b021-2bb41ec229cb", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) - 0.1 * np.cos((np.pi / 2) * (evals / self.budget))  # Cosine-adjusted noise reduction\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhanced mutation scaling to strengthen convergence stability using cosine variation.", "configspace": "", "generation": 51, "fitness": 0.8095512037243351, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.023. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915499127603106, 0.842576939115783, 0.7945267592969116], "final_y": [0.15669758811721812, 0.133448581900808, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "b855aa3b-8ca6-43d5-b895-6914a6c2d483", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        successful_mutations = 0\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    successful_mutations += 1\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            success_rate = successful_mutations / self.pop_size\n            self.F = 0.5 + 0.2 * success_rate - 0.1 * np.random.rand()  # Adaptive mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation scaling factor based on success rate to enhance convergence.", "configspace": "", "generation": 52, "fitness": 0.811880147329011, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.027. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7915153965614621, 0.8495982861286592, 0.7945267592969116], "final_y": [0.15713773698020483, 0.12956301233696854, 0.15697475734017285]}, "mutation_prompt": null}
{"id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce robust adaptive mutation scaling to stabilize the exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.8130540281125289, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.026. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c2161eda-7c51-4803-aaf9-6bb534a92044", "metadata": {"aucs": [0.7917440408678039, 0.8495974576473848, 0.7978205858223979], "final_y": [0.15421074180689665, 0.12956433483738583, 0.1457951353532505]}, "mutation_prompt": null}
{"id": "cc9fa160-df9e-41f3-9ccc-92f6af151837", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce robust adaptive mutation scaling to stabilize the exploration-exploitation balance.", "configspace": "", "generation": 54, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.7917440408678039, 0.8495974576473848, 0.7978205858223979], "final_y": [0.15421074180689665, 0.12956433483738583, 0.1457951353532505]}, "mutation_prompt": null}
{"id": "b28529c7-82df-49ab-b252-a39fa6ef97b7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.3 * np.cos((np.pi / 2) * (evals / self.budget))  # Enhanced mutation scaling\n\n            if layers < self.dim:\n                layers = min(layers + 3, self.dim)  # Dynamic layer growth\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic layer growth and enhanced mutation scaling for improved exploration and exploitation.", "configspace": "", "generation": 55, "fitness": 0.801482060080521, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.012. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.7915499127603106, 0.8183695081843406, 0.7945267592969116], "final_y": [0.15669758811721812, 0.14460548974876508, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "7faaa100-1bcf-4c86-8435-ac56569c1ef6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * (1 - self.best_score)  # Changed line\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance mutation strategy by introducing adaptive factor adjustment based on current best score.", "configspace": "", "generation": 56, "fitness": 0.8129993456772201, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.026. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.7917571229473841, 0.8494893310224026, 0.7977515830618732], "final_y": [0.15404492998826202, 0.12965845146874055, 0.14604177587000733]}, "mutation_prompt": null}
{"id": "6c48ba53-d247-483a-ad3a-0d8ebbc0c4f7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.3 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Fine-tuned noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Fine-tune the noise-reduced mutation scaling factor for better convergence.  ", "configspace": "", "generation": 57, "fitness": 0.8116891998827036, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.7915153965614621, 0.8490254437897368, 0.7945267592969116], "final_y": [0.15713773698020483, 0.12973196288258604, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "3e79d627-64b4-4aa4-b292-c180fbfff421", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = max(4, self.pop_size - 1)  # Dynamic update of population size\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic update of population size for enhanced convergence efficiency.", "configspace": "", "generation": 58, "fitness": 0.7970118032773175, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.001. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.7968885317989443, 0.7987417678870508, 0.7954051101459573], "final_y": [0.15316245519010585, 0.15757276935971964, 0.15612687225054833]}, "mutation_prompt": null}
{"id": "da5c2504-99ef-4576-8696-f8be18a51955", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n            \n            self.pop_size = max(4, int(10 * self.dim * (1 - evals / self.budget)))  # Dynamic population size reduction\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic population size reduction to enhance exploitation in later stages.", "configspace": "", "generation": 59, "fitness": 0.8062200531807582, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.013. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.8240935647984866, 0.7985661289998836, 0.7960004657439044], "final_y": [0.13730576661850424, 0.15634531387546313, 0.15480356702598985]}, "mutation_prompt": null}
{"id": "2c05ed59-1651-4f3f-93bd-a8f739086dd6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.pop_size = self.initial_pop_size\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            new_pop = []\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    new_pop.append(trial)\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n                else:\n                    new_pop.append(pop[i])\n\n            pop = np.array(new_pop)\n            self.pop_size = max(5, int(self.initial_pop_size * (1 - evals / self.budget))) # Dynamic population size\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration-exploitation balance by dynamic population size adjustment and refined mutation strategy.", "configspace": "", "generation": 60, "fitness": 0.8002422693172028, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.003. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.8033023238983222, 0.8012000782861748, 0.7962244057671117], "final_y": [0.14762751504119698, 0.15169822895931384, 0.1557314055271316]}, "mutation_prompt": null}
{"id": "983235a2-92ef-48a7-809b-0a502a3a89e8", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand())  # Noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = max(5 * int(self.dim * (1 - evals / self.budget)), 2)  # Dynamic population size\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic population sizing to adaptively balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 61, "fitness": 0.8063338117334352, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.008. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.796591081324394, 0.807322609705896, 0.8150877441700156], "final_y": [0.15287570330138156, 0.15256899887136532, 0.13912111877541944]}, "mutation_prompt": null}
{"id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a stochastic component to mutation scaling for better exploration.", "configspace": "", "generation": 62, "fitness": 0.8131126437936528, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.026. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "b58af6f2-4506-446f-ae53-8fb7f5a57c92", "metadata": {"aucs": [0.792017895357181, 0.8493755433532741, 0.797944492670503], "final_y": [0.1561462890754749, 0.1297911621925223, 0.14535329307867506]}, "mutation_prompt": null}
{"id": "824887b4-353e-465c-aa15-68241f2a22a5", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub, evals)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub, evals):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score) * (1 - evals / self.budget)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic perturbation range in local search based on the current evaluation ratio.", "configspace": "", "generation": 63, "fitness": 0.8123439191383026, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "metadata": {"aucs": [0.7907661730872368, 0.8483210916571676, 0.797944492670503], "final_y": [0.15791919847881608, 0.13047903374213998, 0.14535329307867506]}, "mutation_prompt": null}
{"id": "cfcb89d3-cd87-429b-9eb1-38d3d3c521f7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            self.pop_size = int((9 + (1 - evals / self.budget) * 5) * self.dim)  # Time-varying population size\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a time-varying population size to enhance exploration and exploitation balance.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 104 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 104 is out of bounds for axis 0 with size 100')", "parent_id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "metadata": {}, "mutation_prompt": null}
{"id": "a6ac4e73-b2d2-46cf-8519-98127bb1d242", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        learning_rate = 0.1 * (1 - self.best_score)  # Adaptive learning rate\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = learning_rate * np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive learning rate in local search to enhance exploitation.", "configspace": "", "generation": 65, "fitness": 0.8113759614314698, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.026. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "metadata": {"aucs": [0.7890439548966406, 0.8471394367272658, 0.797944492670503], "final_y": [0.15883174477730277, 0.130874587484333, 0.14535329307867506]}, "mutation_prompt": null}
{"id": "7df361bf-429b-469f-b525-452d3d838e72", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = int(10 * self.dim * (1 - (evals / self.budget)**0.5))  # Dynamically adjust population size\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a non-linear adaptive strategy to adjust the population size dynamically for improved exploration and exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.8012051214376358, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.006. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "metadata": {"aucs": [0.7966333497971454, 0.8097678116793379, 0.7972142028364242], "final_y": [0.15261638008575507, 0.14326455867716714, 0.15392137730248034]}, "mutation_prompt": null}
{"id": "648159c4-9d67-4b3b-b735-7afc80583757", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance local search strategy by increasing perturbation adaptability.", "configspace": "", "generation": 67, "fitness": 0.8137725033598876, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.026. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "dd2716ce-04f0-44a4-a8de-58b9d216edc6", "metadata": {"aucs": [0.793286986995244, 0.8500860304139155, 0.797944492670503], "final_y": [0.15498453922738076, 0.12943488835650285, 0.14535329307867506]}, "mutation_prompt": null}
{"id": "012d76a8-2ffd-41b0-8bff-985cf3a980f9", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = max(int(10 * self.dim * (1 - evals / self.budget)), 4)  # Dynamic population size adjustment\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance convergence speed by adapting population size dynamically based on budget exhaustion.", "configspace": "", "generation": 68, "fitness": 0.8066297872122484, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.012. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.8241759823751144, 0.7990309116100831, 0.7966824676515479], "final_y": [0.13645986440009994, 0.15806592811013498, 0.1545465065475633]}, "mutation_prompt": null}
{"id": "cf1253ab-95ca-4a4a-81cd-a0d62d1fe869", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n\n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.4 + 0.5 * (evals / self.budget)  # More adaptive crossover probability\n            self.F = 0.6 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.03 * np.random.rand()) * np.random.uniform(0.95, 1.05)  # Further noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 3, self.dim)  # Adjust layer increment\n\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.02 * (1 - self.best_score)  # Refined dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Integrate adaptive layer increment strategy with noise-resilient mutation factors for enhanced convergence.", "configspace": "", "generation": 69, "fitness": 0.8076182690669254, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.013. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.792017895357181, 0.8080687331382381, 0.8227681787053569], "final_y": [0.1561462890754749, 0.1510854244771539, 0.13569495017598887]}, "mutation_prompt": null}
{"id": "c70099dc-7887-43a7-a606-e7942ea5990e", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a deterministic component to the mutation strategy to enhance convergence reliability.", "configspace": "", "generation": 70, "fitness": 0.8137725033598876, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.026. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.793286986995244, 0.8500860304139155, 0.797944492670503], "final_y": [0.15498453922738076, 0.12943488835650285, 0.14535329307867506]}, "mutation_prompt": null}
{"id": "8dca8b02-59b8-425d-9ce9-950cbe7e1b0f", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR + 0.05 * np.random.rand())  # Introduced stochastic component\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a small stochastic component to the crossover points to enhance exploration.", "configspace": "", "generation": 71, "fitness": 0.8059097175466307, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.034. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.7578586435535316, 0.8289021569985044, 0.8309683520878558], "final_y": [0.15091781558190676, 0.14075380996362363, 0.13992304396188715]}, "mutation_prompt": null}
{"id": "5b41dd7a-60c3-4eb1-8d32-accec68fd0b6", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        diversity_threshold = 0.1  # Diversity threshold for maintaining population diversity\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.5 + 0.4 * np.exp(-evals / (0.5 * self.budget))  # Adaptive crossover probability with exponential decay\n            self.F = 0.5 + 0.3 * np.cos((np.pi / 2) * (evals / self.budget)) * (1 + 0.1 * np.random.rand())  # Modified scaling factor with fluctuating component\n\n            population_diversity = np.mean(np.std(pop, axis=0))\n            if population_diversity < diversity_threshold:\n                self.population = np.random.rand(self.pop_size, self.dim)  # Reinitialize population to maintain diversity\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration with adaptive scaling and integrate diversity preservation for robust optimization.", "configspace": "", "generation": 72, "fitness": 0.801536937273348, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.005. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.8078554537937574, 0.8022285987293747, 0.7945267592969116], "final_y": [0.13897377846710723, 0.15548275440890336, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "677cb68e-2b2c-4c47-b947-1e88e862c61e", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = 10 * self.dim * (1 - evals / self.budget) + 4 * self.dim * (evals / self.budget)  # Dynamic population size adjustment\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic population size adjustment to better adapt exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'float' object cannot be interpreted as an integer\").", "error": "TypeError(\"'float' object cannot be interpreted as an integer\")", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {}, "mutation_prompt": null}
{"id": "e6905254-82d9-4f80-96b1-a1ba18732aa3", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Integrate Gaussian perturbation into local search for enhanced layer adaptation.", "configspace": "", "generation": 74, "fitness": 0.814309279124987, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.023. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "648159c4-9d67-4b3b-b735-7afc80583757", "metadata": {"aucs": [0.8014598669396134, 0.846837462813999, 0.7946305076213486], "final_y": [0.15329527781285335, 0.1310576008782368, 0.1546507659393641]}, "mutation_prompt": null}
{"id": "2059cbc1-cf93-4473-a7c2-00470d8a4dea", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1)  # Noise-reduced mutation scaling factor with stochastic component\n\n            layers = int((np.cos(np.pi * evals / self.budget) + 1) * (self.dim / 4)) + 10  # Dynamic layer adaptation with cosine annealing\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic layer adaptation with cosine annealing to enhance solution exploration.", "configspace": "", "generation": 75, "fitness": 0.8102421894182804, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.018. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e6905254-82d9-4f80-96b1-a1ba18732aa3", "metadata": {"aucs": [0.8004070167196033, 0.8357927922383265, 0.7945267592969116], "final_y": [0.1538487075532219, 0.13891227449826127, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "5fd9adb9-ae1d-47f2-aaa7-613534bcefbc", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2)  # Incrementally modified noise-reduced mutation scaling factor with stochastic component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Incrementally adjust the mutation scaling factor to enhance exploration capabilities.", "configspace": "", "generation": 76, "fitness": 0.8143329818574075, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.023. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "e6905254-82d9-4f80-96b1-a1ba18732aa3", "metadata": {"aucs": [0.8015032725068754, 0.846841315493611, 0.7946543575717364], "final_y": [0.15274907113978642, 0.13105566640324784, 0.153880609552847]}, "mutation_prompt": null}
{"id": "bee742b5-d77d-42dc-ae15-2fb18c33882b", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10))  # Incrementally modified noise-reduced mutation scaling factor with stochastic component and adaptive factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Refine the mutation scaling factor F to dynamically adapt based on the best score achieved, improving convergence speed and exploration.", "configspace": "", "generation": 77, "fitness": 0.8147650770470939, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.021. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5fd9adb9-ae1d-47f2-aaa7-613534bcefbc", "metadata": {"aucs": [0.8019727434813742, 0.8437096151828914, 0.7986128724770161], "final_y": [0.14968275652578233, 0.13263758899434308, 0.14717599839328765]}, "mutation_prompt": null}
{"id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance LayerAdaptiveDE by introducing a momentum-based component in the noise-reduced mutation scaling factor to improve convergence consistency.", "configspace": "", "generation": 78, "fitness": 0.8152011421649726, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.021. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "bee742b5-d77d-42dc-ae15-2fb18c33882b", "metadata": {"aucs": [0.8014526891706093, 0.8447306501643045, 0.7994200871600041], "final_y": [0.15338578938170344, 0.13211974459044262, 0.14122414318408294]}, "mutation_prompt": null}
{"id": "b90bb3bd-1dc9-4481-9388-c1fa2a6f80f3", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score) * np.sin(np.pi * layers / self.dim)  # Adaptive perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive mutation scaling in the refinement phase to enhance local search efficiency.", "configspace": "", "generation": 79, "fitness": 0.8109591114780786, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.024. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.7887265971099271, 0.8447306501643045, 0.7994200871600041], "final_y": [0.15911555947902922, 0.13211974459044262, 0.14122414318408294]}, "mutation_prompt": null}
{"id": "43532fbb-57e8-48d2-9e1c-dcad9fef36c7", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance LayerAdaptiveDE by introducing a momentum-based component in the noise-reduced mutation scaling factor to improve convergence consistency.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "An exception occurred: InternalServerError(\"Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_460f4ff355ace6db8b187877f2eb6f54 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\").", "error": "InternalServerError(\"Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_460f4ff355ace6db8b187877f2eb6f54 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\")", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.8014526891706093, 0.8447306501643045, 0.7994200871600041], "final_y": [0.15338578938170344, 0.13211974459044262, 0.14122414318408294]}, "mutation_prompt": null}
{"id": "84913b25-767e-4fb9-9f7e-de216823dcfb", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + np.random.randint(1, 3), self.dim)  # Stochastic layer updating \n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce stochastic layer updating to enhance diversity and robustness.", "configspace": "", "generation": 81, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {}, "mutation_prompt": null}
{"id": "c413445f-4f19-4019-8579-ba4016d6c3cf", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9 \n\n            if layers < self.dim:\n                layers = min(layers + 3, self.dim)  # Change: Adjust layers more dynamically\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.04 * (1 - self.best_score)  # Change: Slightly increase perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhanced LayerAdaptiveDE by incorporating a dynamic layer adjustment strategy and adaptive momentum for improved exploration and convergence in high-dimensional spaces.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {}, "mutation_prompt": null}
{"id": "0273c72f-8772-4814-889d-ec5e73b59a41", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            if self.best_score < 0.1:\n                self.pop_size = max(5 * self.dim, self.pop_size // 2)  # Dynamic population adjustment\n\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Integrate dynamic population size adjustment and layer-specific mutation factors for enhanced exploration and exploitation balance.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {}, "mutation_prompt": null}
{"id": "c68d8176-e34e-4311-a753-8ed9ed08c95b", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n            \n            if evals / self.budget > 0.5:  # Dynamic population size adjustment\n                self.pop_size = max(5 * self.dim, int(self.pop_size * 0.9))\n                pop = pop[:self.pop_size]\n                scores = scores[:self.pop_size]\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  \n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  \n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        # Enhanced local search with adaptive step size\n        adaptive_step = 0.01 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, adaptive_step) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce dynamic population size adjustment and enhanced local search to improve convergence and solution quality.", "configspace": "", "generation": 84, "fitness": 0.8093011324993302, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.012. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.8014388924300605, 0.8256881056759323, 0.8007763993919979], "final_y": [0.15339188810832438, 0.13930190899932293, 0.15339728846265277]}, "mutation_prompt": null}
{"id": "edbc9cd0-a3df-4d55-818b-37400fd71cb3", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9  # Added momentum component to the noise-reduced mutation scaling factor\n\n            if layers < self.dim:\n                layers = min(layers + 2 + (1 - self.best_score) * 10, self.dim)  # Adaptive layer increment strategy\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce an adaptive layer increment strategy and a feedback loop for convergence to enhance solution refinement and consistency.", "configspace": "", "generation": 85, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {}, "mutation_prompt": null}
{"id": "21b7af9e-bf16-42e0-9b18-2514aa623cbf", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                layer_factor = (i / self.pop_size)  # Adaptive layer-wise mutation\n                mutant = np.clip(a + self.F * (b - c) * layer_factor, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * 0.9\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            self.pop_size = max(5, int(self.pop_size * (0.9 + 0.1 * (self.best_score / np.mean(scores)))))  # Dynamic resizing\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance LayerAdaptiveDE by introducing adaptive layer-wise mutation and dynamic population resizing for better scalability and convergence.", "configspace": "", "generation": 86, "fitness": 0.8032558333930823, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.005. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.8097392179687452, 0.8017004252757591, 0.7983278569347427], "final_y": [0.13483905159309895, 0.1468241683720013, 0.1463081859502674]}, "mutation_prompt": null}
{"id": "43ebc5d8-1bdb-4989-ac51-30b9d167b0b2", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * np.exp(-0.001 * evals)  # Adjusted mutation factor with decay\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance convergence by adjusting the mutation factor update with a decay function to better balance exploration and exploitation over time.", "configspace": "", "generation": 87, "fitness": 0.8144560806432768, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.022. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.8014526891706093, 0.8454183668316999, 0.7964971859275213], "final_y": [0.15338578938170344, 0.13177209119603495, 0.1496386085818049]}, "mutation_prompt": null}
{"id": "1df186a4-771a-4985-9d2e-c58ba8ec44f9", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx]))  # Adjusted momentum component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic adjustment to the mutation factor based on convergence speed to improve LayerAdaptiveDE's exploitation.", "configspace": "", "generation": 88, "fitness": 0.8152022861267852, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.021. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d788948d-cfcd-4ea7-a06c-5db389848dd4", "metadata": {"aucs": [0.8014526891706093, 0.8447306501643045, 0.799423519045442], "final_y": [0.15338578938170344, 0.13211974459044262, 0.1412106209173446]}, "mutation_prompt": null}
{"id": "2999a162-e9de-42d8-a086-df799274740d", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx]))  # Adjusted momentum component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range/1.5) * (ub[idx] - lb[idx])  # Refined Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhanced local search with refined perturbation distribution to improve LayerAdaptiveDE's precision.", "configspace": "", "generation": 89, "fitness": 0.81384766836158, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.022. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1df186a4-771a-4985-9d2e-c58ba8ec44f9", "metadata": {"aucs": [0.7973888358749934, 0.8447306501643045, 0.799423519045442], "final_y": [0.15519270397653306, 0.13211974459044262, 0.1412106209173446]}, "mutation_prompt": null}
{"id": "5bd5286e-a6fc-4aed-ae57-925cd058fa54", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.9, 1.1) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx]))  # Changed mutation factor range\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Fine-tune the differential evolution's mutation factor to enhance convergence rate in LayerAdaptiveDE.", "configspace": "", "generation": 90, "fitness": 0.8147207835600653, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.021. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1df186a4-771a-4985-9d2e-c58ba8ec44f9", "metadata": {"aucs": [0.8014526891706093, 0.8446837269354714, 0.7980259345741152], "final_y": [0.15338578938170344, 0.13214349854214047, 0.14630294942730915]}, "mutation_prompt": null}
{"id": "c1f1ee3d-3122-4807-bb8c-f4eebd0cf891", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) + 0.1 * (evals / self.budget)  # Adjusted momentum component and added adaptive component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduced a small adaptive component to mutation factor F using budget utilization to enhance convergence.", "configspace": "", "generation": 91, "fitness": 0.8143145737780845, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.020. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1df186a4-771a-4985-9d2e-c58ba8ec44f9", "metadata": {"aucs": [0.8027339160089482, 0.8429089236559121, 0.797300881669393], "final_y": [0.14442342471889402, 0.1330451000273759, 0.15444322399485644]}, "mutation_prompt": null}
{"id": "b5d208ce-5696-438a-a149-9f48a3646c70", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())  # Added learning component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Refine dynamic adjustment of mutation factor by introducing a learning component for improved exploration.", "configspace": "", "generation": 92, "fitness": 0.8168046292265859, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.021. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "1df186a4-771a-4985-9d2e-c58ba8ec44f9", "metadata": {"aucs": [0.8014526891706093, 0.8471556286986767, 0.8018055698104721], "final_y": [0.15338578938170344, 0.1308941011918705, 0.15155379413579306]}, "mutation_prompt": null}
{"id": "8dbb5d40-11a5-4160-a341-101118f18968", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())  # Added learning component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n            # Adjust population size based on evaluations\n            self.pop_size = max(5, int(10 * self.dim * (1 - evals / (2 * self.budget))))\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce adaptive population size adjustments to enhance exploration and exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.803401591523862, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.005. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {"aucs": [0.8086598071903468, 0.7965271854355799, 0.8050177819456596], "final_y": [0.14852636908368233, 0.157357830724962, 0.14657250848846393]}, "mutation_prompt": null}
{"id": "753c7cf4-50fe-4c3c-a646-189b3fa3e9db", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())  # Added learning component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n\n            self.pop_size = max(10, int(10 * self.dim * (1 - (self.best_score / np.max(scores)))))  # Dynamic population size\n\n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduce a dynamic population size adjustment based on convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.8104890513928718, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.014. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {"aucs": [0.8044666404795222, 0.7967827281258011, 0.8302177855732921], "final_y": [0.15102655446430557, 0.15753134063032126, 0.140133634951768]}, "mutation_prompt": null}
{"id": "5498ecef-bcc9-4709-8cef-17050e056284", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 + 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())  # Improved learning component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Introduced strategic adjustment of mutation factors using a dynamic learning mechanism for enhanced exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {}, "mutation_prompt": null}
{"id": "45711d5f-8752-42c4-befd-6eee7bd816ec", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n        self.success_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    self.success_history.append(trial_score)\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)\n            success_rate = len(self.success_history) / (1 + len(self.success_history) + evals) \n            self.F = 0.5 + 0.3 * success_rate  # Dynamic scaling factor based on success rate\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploitation capabilities by introducing a dynamic scaling factor and adapting mutation based on success history.", "configspace": "", "generation": 96, "fitness": 0.8108687428518196, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.027. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {"aucs": [0.7889384941079685, 0.8491409751505784, 0.7945267592969116], "final_y": [0.15892012742761752, 0.1296586976512023, 0.1580460845796885]}, "mutation_prompt": null}
{"id": "773059e9-c93e-4339-9991-ada645c332ef", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * (evals / self.budget)  # Adaptive crossover probability\n            self.F = 0.5 + 0.2 * np.sin((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())  # Added learning component\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.03 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Incorporate an adaptive learning component in the mutation strategy for enhanced exploration.", "configspace": "", "generation": 97, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {}, "mutation_prompt": null}
{"id": "d5bb984b-2da1-4a8f-bc42-ae56d74e1839", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial.copy()\n\n            self.CR = 0.6 + 0.3 * np.sin((np.pi / 2) * (evals / self.budget))  # Enhanced adaptive crossover\n            self.F = 0.5 + 0.4 * np.cos((np.pi / 2) * (evals / self.budget)) * (1 - 0.05 * np.random.rand()) * np.random.uniform(0.8, 1.2) * (1 + (1 - self.best_score/10)) * (0.9 + 0.1 * (self.best_score - scores[min_idx])) * (0.8 + 0.2 * np.random.rand())\n\n            if layers < self.dim:\n                layers = min(layers + 3, self.dim)  # Gradual increase in layers\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.05 * (1 - self.best_score)  # Increased dynamic perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance exploration and exploitation by dynamically adjusting population size and mutation strategy in LayerAdaptiveDE.", "configspace": "", "generation": 98, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {}, "mutation_prompt": null}
{"id": "8c68309c-0dbe-4046-8601-b0992a5705bf", "solution": "import numpy as np\n\nclass LayerAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.population = np.random.rand(self.pop_size, dim)\n        self.best_solution = None\n        self.best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.population * (ub - lb) + lb\n\n        layers = 10\n        while evals < self.budget:\n            scores = np.array([func(ind) for ind in pop])\n            evals += len(pop)\n            \n            min_idx = np.argmin(scores)\n            if scores[min_idx] < self.best_score:\n                self.best_score = scores[min_idx]\n                self.best_solution = pop[min_idx].copy()\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                evals += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_solution = trial.copy()\n\n            self.CR = 0.5 + 0.4 * (evals / self.budget)  # Modified adaptive crossover probability\n            noise_factor = 1 + np.std(scores) / 10  # New noise-aware component\n            self.F = 0.5 + 0.3 * np.sin((np.pi / 2) * (evals / self.budget)) * noise_factor  # Incorporated noise factor\n\n            if layers < self.dim:\n                layers = min(layers + 2, self.dim)\n            \n            if evals < self.budget:\n                refined_solution = self.local_search(self.best_solution, func, layers, lb, ub)\n                evals += layers\n                refined_score = func(refined_solution)\n                if refined_score < self.best_score:\n                    self.best_score = refined_score\n                    self.best_solution = refined_solution\n\n        return self.best_solution\n\n    def local_search(self, solution, func, layers, lb, ub):\n        perturbed_solution = solution.copy()\n        perturbation_range = 0.04 * (1 - self.best_score)  # Adjusted perturbation range\n        for _ in range(layers):\n            idx = np.random.randint(0, len(solution))\n            perturbation = np.random.normal(0, perturbation_range) * (ub[idx] - lb[idx])  # Gaussian perturbation\n            perturbed_solution[idx] = np.clip(perturbed_solution[idx] + perturbation, lb[idx], ub[idx])\n        return perturbed_solution", "name": "LayerAdaptiveDE", "description": "Enhance dynamic adaptation by incorporating a noise-aware component and improved crossover strategy for better convergence.", "configspace": "", "generation": 99, "fitness": 0.8156590131189678, "feedback": "The algorithm LayerAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.033. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "b5d208ce-5696-438a-a149-9f48a3646c70", "metadata": {"aucs": [0.7887866219224726, 0.8623733808935891, 0.795817036540842], "final_y": [0.15887669853573738, 0.12397970644378986, 0.1563600139628213]}, "mutation_prompt": null}
