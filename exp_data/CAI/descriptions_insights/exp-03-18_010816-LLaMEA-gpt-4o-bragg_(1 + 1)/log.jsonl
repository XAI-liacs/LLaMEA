{"id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm combines differential mutation and adaptive learning to explore and exploit the search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.9241016829544826, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.028. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9439782992718211, 0.8838323156132648, 0.9444944339783621], "final_y": [0.16485935457456757, 0.18813064535955992, 0.16485604302759027]}, "mutation_prompt": null}
{"id": "61039800-97e3-434e-9a35-28f92daf6282", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.std(fitness) / np.mean(fitness)  # Adjusted line\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm refines differential mutation by dynamically adjusting the mutation factor based on fitness variance to enhance exploration capabilities.", "configspace": "", "generation": 1, "fitness": 0.8854409347265019, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.007. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.8786778580492312, 0.8945985187435924, 0.8830464273866817], "final_y": [0.2005499326564122, 0.1942186318063398, 0.19110340435807494]}, "mutation_prompt": null}
{"id": "4d34fe1b-953c-4444-aca8-15e8e2225c09", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            fitness_std = np.std(fitness)\n            self.mutation_factor = 0.5 + 0.5 * (1 - fitness_std)\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm refines adaptive learning by adjusting the mutation factor and crossover rate based on the standard deviation of the population's fitness. ", "configspace": "", "generation": 2, "fitness": 0.887297893102161, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.034. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.8891253123622931, 0.928207620221478, 0.8445607467227121], "final_y": [0.16489876255063862, 0.16486315293671483, 0.18188947353515994]}, "mutation_prompt": null}
{"id": "81906e38-4b5f-4b06-9b02-1bab5e7975e1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            \n            # Adjust population size dynamically\n            self.population_size = int(self.population_size * (0.9 + 0.2 * np.random.rand()))\n            self.population_size = max(4, min(self.population_size, 50))\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm combines differential mutation, adaptive learning, and dynamic population size adjustment to explore and exploit the search space efficiently.", "configspace": "", "generation": 3, "fitness": 0.7700039427182648, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.140. And the mean value of best solutions found was 0.250 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.6687631106488396, 0.6735246457368855, 0.9677240717690693], "final_y": [0.2947580288671776, 0.28459904404299463, 0.17013616176875068]}, "mutation_prompt": null}
{"id": "588e3475-6dbb-4fc9-8f33-577bfcc7d1fa", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            if _ % (self.budget // 10) == 0:  # Change line 1\n                self.population_size = max(4, self.population_size // 2)  # Change line 2\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm introduces dynamic population resizing to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8963457523729493, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.058. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.874354929920335, 0.8391625406293659, 0.975519786569147], "final_y": [0.20011841296601474, 0.211485923339917, 0.1698217561164581]}, "mutation_prompt": null}
{"id": "91fadf73-44a3-4a57-b0d6-826029997ed1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.beta(0.5, 0.5)  # Changed line\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm integrates adaptive differential mutation with stochastic crossover adjustments to efficiently navigate the search space. ", "configspace": "", "generation": 5, "fitness": 0.8824858554671433, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.041. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.9346146807663968, 0.8337568099258074, 0.8790860757092256], "final_y": [0.16485611219393892, 0.20044493106920136, 0.18187929931334268]}, "mutation_prompt": null}
{"id": "501abe6e-1a6f-45bf-b3db-5c2616e4cdce", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            \n            # Adjust population size dynamically\n            population_score = np.mean(fitness)\n            if population_score < 0.2:\n                self.population_size = min(self.population_size + 1, 2 * self.initial_population_size)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n            population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n            fitness = np.array([func(ind) for ind in population])\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Incorporate adaptive population sizing and dynamic parameter tuning to enhance exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.6341325145985788, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.634 with standard deviation 0.034. And the mean value of best solutions found was 0.292 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.6082701867264608, 0.6821427702179147, 0.6119845868513607], "final_y": [0.27995089075639135, 0.2720832390907344, 0.32393229881924945]}, "mutation_prompt": null}
{"id": "2762d6d4-2b97-4cd2-908c-522afbab275f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.8 * fitness[np.argmin(fitness)] / np.min(fitness)  # Adjusted line\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm now dynamically adjusts the mutation factor based on the best solution's fitness to enhance convergence speed.", "configspace": "", "generation": 7, "fitness": 0.9088942529339494, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.027. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.9063626211552611, 0.9432629685692475, 0.8770571690773397], "final_y": [0.18187809681240164, 0.16485577275621865, 0.1818780968695154]}, "mutation_prompt": null}
{"id": "9470ee7b-9845-4be6-975c-718f50a82e9a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            diversity = np.std(population, axis=0).mean()  # Calculate population diversity\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand() * (1 + diversity)\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration with adaptive mutation factor scaling based on population diversity.", "configspace": "", "generation": 8, "fitness": 0.4989763395286216, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.499 with standard deviation 0.056. And the mean value of best solutions found was 0.329 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.576222863488222, 0.4449920166903307, 0.475714138407312], "final_y": [0.27015959127703915, 0.4007890369033851, 0.3157842733576034]}, "mutation_prompt": null}
{"id": "8d35fe23-9cc9-4e31-9380-e1f4e3787e1f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.85  # Slightly increased mutation factor\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm combines differential mutation and adaptive learning with a slightly increased mutation factor to enhance exploration capabilities.", "configspace": "", "generation": 9, "fitness": 0.9226672255993941, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.018. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.9439782992718211, 0.9001661349257224, 0.9238572426006387], "final_y": [0.16485935457456757, 0.18187816365405307, 0.16487156017210758]}, "mutation_prompt": null}
{"id": "ea1e50b9-1ebb-47fb-aec1-d14311d1d4b7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            # Adjust population size dynamically\n            self.population_size = min(self.population_size + 1, 50) \n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm combines differential mutation and adaptive learning to explore and exploit the search space efficiently while dynamically adjusting the population size.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {}, "mutation_prompt": null}
{"id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm introduces a dynamic adaptation mechanism for mutation factor based on fitness improvement to enhance solution exploration.", "configspace": "", "generation": 11, "fitness": 0.9283927035132505, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db69f83a-3c51-4932-92fe-4e2f5ba86bcb", "metadata": {"aucs": [0.9365880212433955, 0.9510360437384485, 0.8975540455579079], "final_y": [0.16485577649076955, 0.16485577357784653, 0.1818780967733996]}, "mutation_prompt": null}
{"id": "e2eab399-1a81-48e5-8513-439a35468cb1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm dynamically adjusts the mutation factor based on fitness improvements, enhancing exploration by incorporating fitness-based mutation factor updates.", "configspace": "", "generation": 12, "fitness": 0.9283927035132505, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.9365880212433955, 0.9510360437384485, 0.8975540455579079], "final_y": [0.16485577649076955, 0.16485577357784653, 0.1818780967733996]}, "mutation_prompt": null}
{"id": "e5f1f75c-d06a-4546-b5e1-eb0a3c67a583", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            if _ % 10 == 0:  # Dynamic adjustment of the population size\n                self.population_size = min(4 + int(3 * np.log(self.dim + np.random.rand())), 50)\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce adaptive population size based on convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {}, "mutation_prompt": null}
{"id": "6cc07d32-31dc-4f2c-a530-4f1f6942995a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1  # New parameter for elitism\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            # Dynamic population resizing\n            self.population_size = min(self.population_size + 1, 100)\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection with stochastic ranking\n                trial_fitness = func(trial)\n                rank = np.random.rand()\n                if trial_fitness < fitness[i] or rank < 0.1:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            # Elitism: retain the top solutions\n            elite_count = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_count]\n            population[:elite_count] = population[elite_indices]\n            fitness[:elite_count] = fitness[elite_indices]\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive differential learning with dynamic population resizing and stochastic ranking for improved exploration and exploitation.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {}, "mutation_prompt": null}
{"id": "8d51e46c-d4c1-47f3-bf8c-06f4ba31b5ff", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for gen in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            self.mutation_factor *= 0.99  # Introduce decay for mutation factor\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduces an adaptive mutation factor decay mechanism based on generation progress to improve solution exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.9117425544380522, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.044. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.8625431318397185, 0.9694080396106142, 0.9032764918638241], "final_y": [0.18188554571386228, 0.16485577203459933, 0.18187810250526015]}, "mutation_prompt": null}
{"id": "5744a389-fd5c-466c-8462-ff147b5ac899", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # Adjusting mutation factor based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            self.mutation_factor = 0.5 + 0.5 * diversity\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm dynamically adjusts the mutation factor based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.5064212495878233, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.506 with standard deviation 0.058. And the mean value of best solutions found was 0.373 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.522891181081172, 0.5678248475770213, 0.42854772010527653], "final_y": [0.3783040013546305, 0.29937377798833, 0.44242383262174334]}, "mutation_prompt": null}
{"id": "ef6d90e4-f51b-4a91-a36a-0e9e3d7f47b7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.population_size = self.base_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n            \n            fitness_diversity = np.std(fitness)\n            self.population_size = max(4, int(self.base_population_size * (1 + fitness_diversity / (np.mean(fitness) + 1e-8))))\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm incorporates adaptive scaling for population size based on fitness diversity for enhanced exploration and convergence.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {}, "mutation_prompt": null}
{"id": "4828d5ab-b4ec-4833-8628-b37aa2a19bcd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            diversity = np.std(population, axis=0).mean()\n            self.crossover_rate = 0.6 + 0.4 * (1 - diversity / (upper_bound - lower_bound))\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm adaptively adjusts the crossover rate based on the diversity of the population to maintain exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.9030809655109571, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.028. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.8664758176115407, 0.9075058426742499, 0.9352612362470808], "final_y": [0.20198290226508797, 0.18791044656780176, 0.17544323525542727]}, "mutation_prompt": null}
{"id": "9f54efed-0750-4056-8328-2b6fbca8b16b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.inertia_weight = 0.5  # Added for swarm behavior\n        self.cognitive_coef = 1.5  # Added for swarm behavior\n        self.social_coef = 1.5     # Added for swarm behavior\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))  # Added for PSO-like behavior\n        fitness = np.array([func(ind) for ind in population])\n        personal_best = population.copy()  # Added for tracking personal bests\n        personal_best_fitness = fitness.copy()  # Added for tracking personal best fitness\n        \n        for _ in range(self.budget - self.population_size):\n            global_best = population[np.argmin(fitness)]  # Added for swarm behavior\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)  # Added for random coefficients\n                # Update velocity with PSO components\n                velocity[i] = (self.inertia_weight * velocity[i]\n                               + self.cognitive_coef * r1 * (personal_best[i] - population[i])\n                               + self.social_coef * r2 * (global_best - population[i]))\n                # Differential Mutation\n                a, b, c = population[np.random.choice(self.population_size, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c) + velocity[i], lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    personal_best[i], personal_best_fitness[i] = trial, trial_fitness  # Update personal best\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances its performance by incorporating adaptive parameter control and swarm behavior inspired by particle swarm optimization to balance exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.6242798176726715, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.100. And the mean value of best solutions found was 0.284 (0. is the best) with standard deviation 0.083.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.6228859657243864, 0.5019270718521809, 0.7480264154414471], "final_y": [0.25351463164811394, 0.3963917136884051, 0.2007906519078927]}, "mutation_prompt": null}
{"id": "1d4fce7a-9f77-4e31-bb5b-13ffbcb566a5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * (1 - np.std(fitness) / np.mean(fitness))\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration by dynamically adjusting both mutation factor and crossover rate based on current fitness trends.", "configspace": "", "generation": 20, "fitness": 0.8335543635469195, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.018. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.8084835489387587, 0.8492735304399178, 0.8429060112620819], "final_y": [0.22440499959069693, 0.20922074382021927, 0.21024474484394773]}, "mutation_prompt": null}
{"id": "1f11473a-22e9-419b-b2a6-a380bf5edbaf", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for _ in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adjust population size based on diversity\n            diversity = np.mean(np.std(population, axis=0))\n            if diversity < 0.1:  # Threshold for diversity\n                self.population_size = min(self.population_size + 1, 50)\n            else:\n                self.population_size = max(self.population_size - 1, 4)\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced Adaptive Differential Evolution using dynamic population size based on diversity to improve convergence.", "configspace": "", "generation": 21, "fitness": 0.7758019827264947, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.101. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.6342811666617545, 0.8600802717869305, 0.8330445097307992], "final_y": [0.3143928304144269, 0.18369393847148197, 0.20438874494261539]}, "mutation_prompt": null}
{"id": "f92f3868-5a3e-4b1f-8c7c-12f56fa2113c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.population_size = self.base_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            if iteration % 10 == 0:\n                self.population_size = min(self.base_population_size + int(np.sin(iteration / 10) * 2), 50)\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                # Differential Mutation with weighted factor\n                weight = 0.5 + 0.5 * (fitness[i] / np.max(fitness))\n                mutant = np.clip(a + self.mutation_factor * weight * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() # Adjusting mutation factor\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced Adaptive Differential Learning with dynamic control of population size and weighted mutation factor for improved exploration and exploitation balance.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {}, "mutation_prompt": null}
{"id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Adjust based on iteration\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution exploration by dynamically adjusting both mutation factor and crossover rate based on iteration progress.", "configspace": "", "generation": 23, "fitness": 0.931800675812743, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ea88fb6d-6b6d-44bb-b941-bece6ae02393", "metadata": {"aucs": [0.9090986103904921, 0.9464921899603278, 0.9398112270874087], "final_y": [0.16485618131786461, 0.16485584333243786, 0.16485615765844297]}, "mutation_prompt": null}
{"id": "4304832e-2161-4141-9712-3c9607004824", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            diversity = np.mean(np.std(population, axis=0))  # Added line\n            self.mutation_factor = 0.6 + 0.4 * (diversity / (upper_bound - lower_bound).max())  # Modified line\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm improves convergence by incorporating diversity preservation strategies through adaptive mutation factor adjustments.", "configspace": "", "generation": 24, "fitness": 0.9197515393360293, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.014. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.9377211871287054, 0.9184907734308453, 0.9030426574485371], "final_y": [0.16485578934234002, 0.16485578377137977, 0.18187809688848677]}, "mutation_prompt": null}
{"id": "cbde1eaa-2e2d-4124-96bb-9b048814508e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            diversity = np.std(population, axis=0).mean() / (upper_bound - lower_bound).mean()\n            self.crossover_rate = 0.5 + 0.5 * diversity  # Adjust based on diversity\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhancing exploration by dynamically adjusting the crossover rate based on the diversity of the population.", "configspace": "", "generation": 25, "fitness": 0.9234384615591722, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.010. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.9097560638897088, 0.9314433122287941, 0.9291160085590137], "final_y": [0.1818782520723906, 0.16492516488253317, 0.16485641748334223]}, "mutation_prompt": null}
{"id": "035b63d2-13ab-4778-83e5-d18eb326903c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    # Update mutation factor based on fitness diversity\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand() * (np.std(fitness) / (np.mean(fitness) + 1e-6))\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Adjust based on iteration\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm boosts exploration by dynamically adjusting mutation factor and enhancing selection pressure based on fitness diversity.", "configspace": "", "generation": 26, "fitness": 0.9129889441942031, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.016. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.8967546203695841, 0.9071735068713361, 0.9350387053416889], "final_y": [0.1825348917592483, 0.18191194834048485, 0.16856268031770794]}, "mutation_prompt": null}
{"id": "dc8c2542-b1ba-46a4-b07e-2ba8dcce09e0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.7 * (iteration / self.budget) + 0.3  # Improved adaptive strategy\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution exploration by dynamically adjusting both mutation factor and crossover rate based on iteration progress, with an improved adaptive strategy for crossover rate adjustment.", "configspace": "", "generation": 27, "fitness": 0.908725438697314, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.9074901349941928, 0.9020887110628633, 0.9165974700348861], "final_y": [0.16488215992291544, 0.16489969933408632, 0.16486990136573576]}, "mutation_prompt": null}
{"id": "ce0d00bc-8305-491d-b6d9-5a30eceb0b5e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.5 + 0.5 * np.cos((np.pi * iteration) / self.budget)  # Adjust based on iteration\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm dynamically adjusts the crossover rate using a cosine function for improved exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.7609890695893405, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.087. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.7629646819439719, 0.8662727067055683, 0.6537298201184816], "final_y": [0.22156060526192478, 0.1933895863591386, 0.2940318026739791]}, "mutation_prompt": null}
{"id": "41a702fd-c5c8-4e2b-a0ce-b9783de1d684", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        successful_attempts = 0  # Track successful attempts for adaptation\n        \n        for iteration in range(self.budget - self.population_size):\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n                    successful_attempts += 1  # Increment on success\n\n            # Adaptive learning to adjust mutation factor and crossover rate\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  \n            self.mutation_factor = 0.5 + 0.5 * (successful_attempts / (iteration + 1))  # Adjust based on success rate\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced AdaptiveDifferentialLearning that dynamically adjusts both mutation factor and crossover rate based on both iteration progress and cumulative success rate.", "configspace": "", "generation": 29, "fitness": 0.8774748114775139, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.013. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.8679291450412587, 0.8964842056112042, 0.8680110837800789], "final_y": [0.1818984238177056, 0.16486767584345807, 0.1658091537105596]}, "mutation_prompt": null}
{"id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm improves solution diversity by introducing a diversity factor in the mutation strategy and a gradual adjustment of the population size based on convergence speed.", "configspace": "", "generation": 30, "fitness": 0.953941829967703, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "63fbc1bc-8802-4af9-b0c9-3d7e7969edc8", "metadata": {"aucs": [0.9639544854527609, 0.937531900593026, 0.9603391038573225], "final_y": [0.1648557789707792, 0.16485577527118334, 0.16485577219285907]}, "mutation_prompt": null}
{"id": "894575f7-013c-41fc-a0e7-050d396bf129", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution diversity by integrating a dynamic crossover rate adjustment based on iteration progress and a sinusoidal diversity factor modulation for improved exploration.", "configspace": "", "generation": 31, "fitness": 0.936666248470274, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9291420550874026, 0.9309718669997007, 0.9498848233237187], "final_y": [0.16485589202708795, 0.16485603406320382, 0.1648559190208836]}, "mutation_prompt": null}
{"id": "a9f7d9fb-96f5-4b56-9097-2dc1abc04f3b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()  # Randomly adjust mutation factor\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n            self.mutation_factor = 0.9 - 0.4 * (np.std(fitness) / np.mean(fitness))  # Adjust mutation factor based on diversity\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhances solution exploration by dynamically adjusting the mutation factor based on population diversity and convergence.", "configspace": "", "generation": 32, "fitness": 0.9185825954059651, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.019. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9081066777028002, 0.9027692057007267, 0.9448719028143682], "final_y": [0.18187809871116445, 0.18239055577823682, 0.164855890397693]}, "mutation_prompt": null}
{"id": "fe1fdff6-84bd-4750-886e-5f9ec1eefe55", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) * np.var(fitness) / (np.mean(fitness)+1e-10)\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution exploration by introducing a dynamic adjustment of the crossover rate based on iteration progress and previous convergence trends.", "configspace": "", "generation": 33, "fitness": 0.9475420883836326, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9627562217471032, 0.9312765946754917, 0.9485934487283026], "final_y": [0.16485577599995116, 0.16485584068802162, 0.1653879128961443]}, "mutation_prompt": null}
{"id": "1548f43d-9952-4c65-b1db-fcfaf2526fde", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * np.std(fitness) / (np.mean(fitness) if np.mean(fitness) != 0 else 1)  # Adjust crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduces adaptive crossover rate adjustment based on fitness variance for improved exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.9329190671305035, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.019. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9396916984991072, 0.9516071756945339, 0.90745832719787], "final_y": [0.16485579832789288, 0.16485577279655617, 0.1818781284163946]}, "mutation_prompt": null}
{"id": "3bddedb8-9b5f-4fc2-a2c2-cc2d06625a15", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n            fitness_variance = np.var(fitness)\n            self.mutation_factor *= 1 + 0.1 * fitness_variance   # Dynamic scaling of mutation factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm introduces a dynamic scaling of the mutation factor based on fitness variance to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 35, "fitness": 0.9526239476833197, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9658160103202204, 0.9298229757270791, 0.9622328570026599], "final_y": [0.16485577455890987, 0.16485716818275897, 0.16485846081270905]}, "mutation_prompt": null}
{"id": "4a08ac36-4df2-4c64-acf3-f0afcaace00d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            fitness_variance = np.var(fitness)  # Calculate fitness variance\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            self.mutation_factor *= 0.9 if fitness_variance < 0.05 else 1.1  # Adaptive mutation adjustment\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances diversity and convergence by dynamically adjusting mutation factors based on fitness variance and incorporating adaptive scaling of dimensional perturbation.", "configspace": "", "generation": 36, "fitness": 0.9003573832198225, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.053. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9056171467898408, 0.8323975604593066, 0.9630574424103201], "final_y": [0.17774888537820288, 0.20212379956162196, 0.1648557829691989]}, "mutation_prompt": null}
{"id": "440ba91f-d104-4b1b-b804-67c3639d345d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * diversity_factor  # Change in crossover rate adjustment\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce adaptive crossover rate adjustment based on diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 37, "fitness": 0.8746908528769524, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.005. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.8816644649799621, 0.8716599901079901, 0.8707481035429046], "final_y": [0.18548329555778775, 0.19303684113164754, 0.20254506318383614]}, "mutation_prompt": null}
{"id": "f8f6b761-b846-46f5-9795-4273e5955e40", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Tweaked formula\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhancing exploration by tweaking the diversity factor formula in AdaptiveDifferentialLearning.", "configspace": "", "generation": 38, "fitness": 0.9538781456257208, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9632258136661535, 0.9373836565908316, 0.9610249666201771], "final_y": [0.16485577633768989, 0.16485579173416587, 0.164855781852546]}, "mutation_prompt": null}
{"id": "6c2bfd2b-530b-43fd-9058-076129331e40", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            diversity = np.std(population, axis=0).mean()  # Calculate population diversity\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation with adaptive factor\n                mutant = np.clip(\n                    a + (diversity_factor + 0.5 * diversity) * self.mutation_factor * (b - c), \n                    lower_bound, upper_bound\n                )\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)  # Adjusted crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration-exploitation balance by adding adaptive mutation and crossover strategies based on population diversity metrics.", "configspace": "", "generation": 39, "fitness": 0.5689794933130724, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.030. And the mean value of best solutions found was 0.300 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.5588679175852805, 0.6097889849889284, 0.538281577365008], "final_y": [0.30901579804505086, 0.25916592872352284, 0.3312761013241101]}, "mutation_prompt": null}
{"id": "f2dbbaf2-5b3a-4627-905e-f366d58d29af", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.3 * (iteration / self.budget) + 0.2 * (np.min(fitness) / (np.mean(fitness) + 1e-9))\n            diversity_factor = 0.9 + 0.2 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration by dynamically adjusting the diversity factor and refines exploitation by incorporating a fitness-weighted crossover rate.", "configspace": "", "generation": 40, "fitness": 0.9225145128187511, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.024. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9545422841540503, 0.8951401171842049, 0.9178611371179981], "final_y": [0.1648557760998487, 0.1818780973204398, 0.18187810476692734]}, "mutation_prompt": null}
{"id": "0ca93cda-d54c-4565-ae79-661984743a78", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n        successes = np.zeros(self.population_size)\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                successes = successes[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                parents = np.random.choice(indices, 3, replace=False)\n                a, b, c = population[parents]\n                \n                # Differential Mutation with adaptive factor\n                self.mutation_factor = 0.5 + 0.3 * np.tanh(successes[i])  # Self-adaptive mutation factor\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    successes[i] += 1  # Record successful offspring\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm improves convergence by introducing a self-adaptive mutation factor and employs a successful parent selection strategy based on historical performance.", "configspace": "", "generation": 41, "fitness": 0.902992222414205, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.021. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9194660232283824, 0.8734822823380166, 0.9160283616762157], "final_y": [0.1740805604233856, 0.18187810640833313, 0.1818780968946836]}, "mutation_prompt": null}
{"id": "ef9d65f9-8c32-4a4c-aca9-2d1af65a9a5c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Adaptive Crossover (changed)\n                crossover = np.random.rand(self.dim) < self.crossover_rate * (1 - iteration / self.budget)\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * (np.random.rand() * (fitness[i] - trial_fitness) / max(fitness))\n            \n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introducing adaptive crossover and a dynamic mutation strategy based on exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.9392628236232419, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.012. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9453281939772743, 0.9498327978672793, 0.9226274790251721], "final_y": [0.16507156379472454, 0.16551880493847315, 0.18235640319111734]}, "mutation_prompt": null}
{"id": "c46db356-a3d1-4ae3-b667-4af6021712f7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            fitness_variance = np.var(fitness)\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget * (1 - fitness_variance)) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce adaptive crossover rate adjustments based on fitness variance to maintain exploration-exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.953941829967703, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9639544854527609, 0.937531900593026, 0.9603391038573225], "final_y": [0.1648557789707792, 0.16485577527118334, 0.16485577219285907]}, "mutation_prompt": null}
{"id": "d156fba1-8f5a-4baf-b1e3-40961d841598", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (np.max(fitness) - np.min(fitness)) / np.max(fitness) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced exploration by dynamically adjusting the crossover rate based on population diversity.", "configspace": "", "generation": 44, "fitness": 0.904284549109819, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.021. And the mean value of best solutions found was 0.184 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9173924943578822, 0.8741864599611343, 0.9212746930104405], "final_y": [0.181878096768897, 0.18813522393106508, 0.18187809678279798]}, "mutation_prompt": null}
{"id": "b40970d5-a78c-45fe-9ec9-17db3aab8ef5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.4 + 0.6 * np.random.rand()  # Changed crossover rate modulation\n            if np.std(population) < 1e-5:  # Added diversity threshold check\n                diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution quality by introducing adaptive crossover rate modulation and iterative diversity checking using a diversity threshold.", "configspace": "", "generation": 45, "fitness": 0.9036792073373885, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.025. And the mean value of best solutions found was 0.184 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9131856403493046, 0.8688534373155904, 0.9289985443472704], "final_y": [0.18187810441098684, 0.1881320874318304, 0.18187809678164968]}, "mutation_prompt": null}
{"id": "5f4d373f-8245-4004-b6e6-d84739f10d62", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) * (1 - np.mean(fitness) / np.max(fitness))  # Adjust crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm adjusts the crossover rate dynamically based on both iteration progress and fitness improvement over recent generations to enhance exploration and exploitation balance.", "configspace": "", "generation": 46, "fitness": 0.946592403450469, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9665996810946776, 0.9242770743693549, 0.9489004548873743], "final_y": [0.16485577280599562, 0.16485607134167435, 0.16538791279338005]}, "mutation_prompt": null}
{"id": "05a5c63f-6a7e-44d9-9121-4ced5c534aa1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (1 - iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution diversity by dynamically adapting the crossover rate based on iterative performance feedback.", "configspace": "", "generation": 47, "fitness": 0.8212721616054345, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.038. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.8744934245208807, 0.7999747237658801, 0.7893483365295428], "final_y": [0.1900035617890038, 0.22006956623751517, 0.23505798523715993]}, "mutation_prompt": null}
{"id": "f8f24060-290b-493b-84dc-aadecc8c9536", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        learning_rate = np.full(self.population_size, 0.5)  # New: Initialize learning rate per individual\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  \n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                learning_rate = learning_rate[:self.population_size]  # Adjust learning rate array size\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    learning_rate[i] = 0.5 + 0.5 * np.random.rand()  # New: Update learning rate\n\n            # New: Update mutation factor based on fitness improvement\n            self.mutation_factor = np.mean(learning_rate)\n            self.crossover_rate = 0.3 + 0.7 * np.sin((np.pi * iteration) / self.budget)\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  \n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhances the exploration-exploitation balance by incorporating a dynamic fitness-based learning rate and adaptive crossover strategy.", "configspace": "", "generation": 48, "fitness": 0.9287562681158156, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.8912396037474135, 0.9315628575742659, 0.9634663430257672], "final_y": [0.16485937462762645, 0.1648557852876137, 0.16485580879074346]}, "mutation_prompt": null}
{"id": "d5279bac-af43-48cd-afea-6747e6bc5b2a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation with dynamic mutation factor\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover with dynamic strategy\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            # Adjust crossover rate dynamically\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)\n            diversity_factor = 0.8 + 0.2 * np.sin((np.pi * iteration) / self.budget)  # Modified diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced Diversity Differential Learning: The algorithm introduces dynamic mutation and crossover strategies with adaptive diversity control for robust exploration and exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.9510952598377639, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9422789127420964, 0.9504253583797249, 0.9605815083914708], "final_y": [0.16496933820465298, 0.16504014922888788, 0.16485583442174578]}, "mutation_prompt": null}
{"id": "ff96227c-9142-4894-bff3-e702de0dbd91", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n            self.mutation_factor = 0.5 + (0.3 * iteration / self.budget)  # Dynamic adjustment of mutation factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhancing convergence by introducing a dynamic adjustment of the mutation factor based on iteration progress.", "configspace": "", "generation": 50, "fitness": 0.9368225759041637, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.039. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.8826066367911644, 0.955122038187001, 0.9727390527343258], "final_y": [0.18702379468940133, 0.16487092480141874, 0.1648830306324075]}, "mutation_prompt": null}
{"id": "5fbc84a9-3591-4864-b2ee-24e30aab91e7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n            new_population = []  # Added new population tracking\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                # Differential Mutation with adaptive diversity factor\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    new_population.append(trial)  # Add to new population\n                    fitness[i] = trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n                else:\n                    new_population.append(population[i])  # Keep current\n\n            population = np.array(new_population)  # Replace old population\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "An adaptive differential evolution algorithm with a dynamic crossover rate and diversity preservation strategy.", "configspace": "", "generation": 51, "fitness": 0.9486173173849365, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9292481100700396, 0.9565533309673544, 0.9600505111174154], "final_y": [0.16485577864040257, 0.16485577238861893, 0.1648557741509824]}, "mutation_prompt": null}
{"id": "9bc97d44-b55e-46fb-a601-44edc3cbb0f2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.3 + 0.7 * np.random.rand()  # Adjusted mutation factor range\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)  # Adjusted crossover rate range\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Refines diversity management and parameter adaptation for improved convergence in differential learning.", "configspace": "", "generation": 52, "fitness": 0.9461165271057742, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9501945879560301, 0.9450223651786765, 0.9431326281826159], "final_y": [0.1649314604979284, 0.16485577534705653, 0.16485580049954518]}, "mutation_prompt": null}
{"id": "b8788025-e00b-48c5-b28d-f84acdce728d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0: \n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                learning_rate = 0.1 + 0.4 * (iteration / self.budget)\n                mutant = np.clip(a + learning_rate * diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.3 * (iteration / self.budget)\n            diversity_factor = 0.8 + 0.2 * np.cos((np.pi * iteration) / self.budget)  # Introduce diversity factor\n      \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "This algorithm enhances solution exploration by introducing adaptive learning rates and incorporating dynamic diversity modulation to refine convergence speed and accuracy.", "configspace": "", "generation": 53, "fitness": 0.8532340313755161, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.034. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.8841802161247695, 0.8061443520079045, 0.8693775259938745], "final_y": [0.19317099347640088, 0.22933542408226604, 0.20433588821911697]}, "mutation_prompt": null}
{"id": "37202365-639a-4b09-aae3-aa79551d5db1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation with dynamic adaptation\n                current_diversity = np.std(population, axis=0).mean()\n                mutant = np.clip(a + current_diversity * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < (self.crossover_rate * current_diversity)\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration by dynamically adjusting both the mutation strategy and crossover rate based on population diversity metrics.", "configspace": "", "generation": 54, "fitness": 0.3964901296812821, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.396 with standard deviation 0.025. And the mean value of best solutions found was 0.490 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.40116926828217403, 0.36359203406564744, 0.4247090866960248], "final_y": [0.4851222111652522, 0.5192011663143732, 0.46469205749927356]}, "mutation_prompt": null}
{"id": "aa27ee18-799b-4dc0-b946-1e543cbe6e73", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Oscillating crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm introduces an oscillating crossover rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.9447101364628457, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9678984999603388, 0.9198732195405928, 0.9463586898876057], "final_y": [0.16485577194976386, 0.16485581713540665, 0.16485585868216412]}, "mutation_prompt": null}
{"id": "d8f83fa3-6318-473d-b224-2c1532da708d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) * diversity_factor  # Adjust crossover rate dynamically \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm refines crossover and mutation strategies by dynamically adapting the crossover rate based on diversity to enhance convergence performance.", "configspace": "", "generation": 56, "fitness": 0.9435847859808534, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9640424692311165, 0.9238144132284624, 0.9428974754829814], "final_y": [0.164855777193891, 0.16485815217252708, 0.16485581210199807]}, "mutation_prompt": null}
{"id": "e264f690-c747-4710-8f4f-e37fd8d39498", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.sin((np.pi * iteration) / self.budget)  # Use cyclic function\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm uses a dynamic mutation factor influenced by a cyclic function to enhance exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.9298674867423213, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.049. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9755020982015411, 0.8625943345578855, 0.9515060274675372], "final_y": [0.16525477845709147, 0.1909680173231756, 0.17312215399655162]}, "mutation_prompt": null}
{"id": "65f06aa6-e9d0-4615-b229-819cc7fb32e1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n        prev_best_fitness = np.min(fitness)\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)  \n            if np.min(fitness) < prev_best_fitness:\n                self.mutation_factor *= 1.1  # Increase mutation if improvement\n            prev_best_fitness = np.min(fitness)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm refines diversity using adaptive mutation and crossover rates based on fitness improvement over iterations.", "configspace": "", "generation": 58, "fitness": 0.9475844195067529, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.033. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9648949791560641, 0.9012110262535905, 0.9766472531106036], "final_y": [0.16485577386051475, 0.16485606439265277, 0.16485577351778147]}, "mutation_prompt": null}
{"id": "0e3c7ebb-01bf-464a-91b2-68eb1ff94f7d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:  # Adjust population size dynamically\n                self.population_size = max(4, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Differential Mutation\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) \n            diversity_factor = 0.9 + 0.1 * np.cos((np.pi * iteration) / self.budget)  # Introduce diversity factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced exploration by modifying the crossover strategy to incorporate a dynamic adaptation based on iteration feedback.", "configspace": "", "generation": 59, "fitness": 0.8848111880467243, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.036. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9148706591227516, 0.8334536281258281, 0.9061092768915933], "final_y": [0.1648558081315299, 0.2016658736635053, 0.18187809681981948]}, "mutation_prompt": null}
{"id": "cb7536e3-5919-47d9-b5d5-391da577a4dd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.9  # Increased initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration by introducing a dynamic mutation strategy and adaptive crossover, utilizing a nonlinear population size reduction to improve solution quality.", "configspace": "", "generation": 60, "fitness": 0.9559590839767199, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2a2d92d0-369f-4528-ae41-bd6f62e7bcf1", "metadata": {"aucs": [0.9471357571278148, 0.9497476604252323, 0.9709938343771126], "final_y": [0.16485578290967773, 0.16485587841510108, 0.16487210442026334]}, "mutation_prompt": null}
{"id": "3f695218-6bdb-4987-8a1d-725cfd69e245", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.9  # Increased initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand() * np.sin(np.pi * iteration / self.budget)  # Sinusoidal variation\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm refines its exploration by dynamically adjusting the mutation factor based on diversity metrics and employing a sinusoidal variation in the mutation factor to enhance global search.", "configspace": "", "generation": 61, "fitness": 0.9395496809267122, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.022. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "cb7536e3-5919-47d9-b5d5-391da577a4dd", "metadata": {"aucs": [0.9153549880126369, 0.9688200698605076, 0.934473984906992], "final_y": [0.18224498528593558, 0.1652659744355376, 0.1819477477313305]}, "mutation_prompt": null}
{"id": "dc7ab17e-25e7-4754-a831-f1640f163a3b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.9  # Increased initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.1 * np.cos((np.pi * iteration) / self.budget)  # Changed sine to cosine\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances exploration by introducing a dynamic mutation strategy and adaptive crossover, utilizing a nonlinear population size reduction and sinusoidal diversity adjustment to improve solution quality.", "configspace": "", "generation": 62, "fitness": 0.9456042112159292, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb7536e3-5919-47d9-b5d5-391da577a4dd", "metadata": {"aucs": [0.9358051411116136, 0.9359523762926741, 0.9650551162435002], "final_y": [0.164888217487411, 0.16485613833445978, 0.16492583053469856]}, "mutation_prompt": null}
{"id": "11355eb9-f0fc-472f-91f7-6d7df104c35b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 0.8  # Initial mutation factor adjusted for chaos\n        self.crossover_rate = 0.6  # Adjusted initial crossover rate\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        chaos_factor = self._logistic_map(0.7, self.budget)\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = chaos_factor[iteration]  # Chaotic mutation factor\n                \n                mutant = np.clip(a + self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < np.random.uniform(0.3, 0.8)  # Stochastic adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.5 * np.random.rand()\n\n            self.crossover_rate = 0.3 + 0.7 * np.sin(iteration / self.budget * np.pi)\n            \n        best_index = np.argmin(fitness)\n        return population[best_index]\n    \n    def _logistic_map(self, r, size):\n        x = np.zeros(size)\n        x[0] = 0.5\n        for i in range(1, size):\n            x[i] = r * x[i-1] * (1 - x[i-1])\n        return x", "name": "EnhancedAdaptiveDifferentialLearning", "description": "Enhance exploration and exploitation by introducing chaotic mutation factors and stochastic adaptive crossover rates, combined with competitive selection for improved convergence.", "configspace": "", "generation": 63, "fitness": 0.7314795503098476, "feedback": "The algorithm EnhancedAdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.731 with standard deviation 0.043. And the mean value of best solutions found was 0.265 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "cb7536e3-5919-47d9-b5d5-391da577a4dd", "metadata": {"aucs": [0.7544336633574623, 0.768860854901384, 0.6711441326706961], "final_y": [0.25471675718008213, 0.24552145988590013, 0.29553590406255725]}, "mutation_prompt": null}
{"id": "ef7d37e1-e7b2-4991-9799-18ea329966cb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "The algorithm enhances solution quality by introducing a dynamic adaptation strategy for both mutation and crossover rates, with the mutation factor being slightly more aggressive at the start for better exploration.", "configspace": "", "generation": 64, "fitness": 0.9586627198002251, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.010. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cb7536e3-5919-47d9-b5d5-391da577a4dd", "metadata": {"aucs": [0.9479578371116255, 0.9718873447672293, 0.9561429775218208], "final_y": [0.164857704640344, 0.1649501813955666, 0.16892869048367165]}, "mutation_prompt": null}
{"id": "cadd1c4c-36e9-421b-a5d5-871e4c5c9b94", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + np.random.rand() * 0.3 * (1 - iteration / self.budget)  # Stochastic adaptive part\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((np.pi * iteration) / self.budget)\n            self.mutation_factor = 0.5 + (0.5 * (iteration / self.budget))  # More aggressive final phase for mutation scaling\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "An enhanced adaptive strategy that refines both mutation and crossover dynamics by introducing stochastic elements and a more aggressive final phase for mutation scaling.", "configspace": "", "generation": 65, "fitness": 0.9386921306707366, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.037. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "ef7d37e1-e7b2-4991-9799-18ea329966cb", "metadata": {"aucs": [0.9623334546955378, 0.8862004879648083, 0.9675424493518638], "final_y": [0.16783056329276647, 0.1976009727034509, 0.16533499088882075]}, "mutation_prompt": null}
{"id": "3d736755-9617-4d35-9efe-d981444f7d07", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n        self.initial_temperature = 1.0\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        \n        temperature = self.initial_temperature\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = np.exp(-iteration / self.budget)  # Simulated annealing-based adaptation\n\n                mutant = np.clip(a + temperature * self.mutation_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n            \n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)\n            temperature *= 0.99  # Cooling schedule\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce a temperature-controlled adaptive strategy for mutation and crossover rates using simulated annealing for enhanced performance.", "configspace": "", "generation": 66, "fitness": 0.903849335712669, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.066. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "ef7d37e1-e7b2-4991-9799-18ea329966cb", "metadata": {"aucs": [0.811331627652986, 0.9546626374395089, 0.9455537420455121], "final_y": [0.20726814195413013, 0.16695204974844502, 0.1702778401649273]}, "mutation_prompt": null}
{"id": "6ed12c6c-1ca8-4389-a90a-b3da2d215e3e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Improved the convergence speed by adjusting the diversity factor to better balance exploration and exploitation.", "configspace": "", "generation": 67, "fitness": 0.9586724957592869, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.010. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef7d37e1-e7b2-4991-9799-18ea329966cb", "metadata": {"aucs": [0.9479564777748815, 0.9719186225087111, 0.9561423869942681], "final_y": [0.16485879535771086, 0.16493417423527956, 0.168929171781926]}, "mutation_prompt": null}
{"id": "d4cbc0a3-c441-4d25-af5f-f8248fb27a3e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            self.mutation_factor = 0.9 * np.std(fitness) / np.mean(fitness)  # Dynamic adjustment based on fitness variance\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduced dynamic adjustment of mutation factor based on fitness variance to enhance adaptive capability.", "configspace": "", "generation": 68, "fitness": 0.8550145208320741, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.061. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "6ed12c6c-1ca8-4389-a90a-b3da2d215e3e", "metadata": {"aucs": [0.8814121782469709, 0.7709258862634653, 0.9127054979857859], "final_y": [0.19814856593740238, 0.24200995228601896, 0.18730400496693755]}, "mutation_prompt": null}
{"id": "25282bb7-5063-4957-808e-8afcf8eb93cb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                # Line changed to include diversity-based mutation adjustment\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Improved convergence by fine-tuning the mutation factor based on population diversity.", "configspace": "", "generation": 69, "fitness": 0.9586724957592869, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.010. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6ed12c6c-1ca8-4389-a90a-b3da2d215e3e", "metadata": {"aucs": [0.9479564777748815, 0.9719186225087111, 0.9561423869942681], "final_y": [0.16485879535771086, 0.16493417423527956, 0.168929171781926]}, "mutation_prompt": null}
{"id": "d5b293ed-a4e9-44c3-8d9e-5dd6a31884c6", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)\n                \n                # Dynamic feedback introduced for mutation factor\n                if iteration > 0 and fitness[i] < fitness[i-1]:\n                    self.mutation_factor = max(0.5, self.mutation_factor - 0.1)\n                else:\n                    self.mutation_factor = min(1.0, self.mutation_factor + 0.1)\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.6 * np.random.rand()\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduced a dynamic feedback mechanism to adaptively adjust the mutation factor based on performance trend.", "configspace": "", "generation": 70, "fitness": 0.9308492437684094, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.022. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "6ed12c6c-1ca8-4389-a90a-b3da2d215e3e", "metadata": {"aucs": [0.9515122435172788, 0.9410850369411334, 0.899950450846816], "final_y": [0.1650407688990263, 0.16488460036066388, 0.1858271951501459]}, "mutation_prompt": null}
{"id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced convergence by dynamically adjusting the mutation factor based on diversity measures and iteration progress.", "configspace": "", "generation": 71, "fitness": 0.9632493972889992, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6ed12c6c-1ca8-4389-a90a-b3da2d215e3e", "metadata": {"aucs": [0.9572084500319059, 0.9594827846885114, 0.9730569571465799], "final_y": [0.1698454229839722, 0.1664361369213444, 0.16656847497615734]}, "mutation_prompt": null}
{"id": "c8c56c5d-45f3-4f55-9392-684eaa294781", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 50  # Reduced factor to intensify diversity adjustment\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced diversity control by dynamically adjusting the mutation factor and crossover rate based on fitness variance.", "configspace": "", "generation": 72, "fitness": 0.9351622911915759, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.030. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9329344897014342, 0.8999005476076394, 0.9726518362656543], "final_y": [0.1787548728718954, 0.1892267588033515, 0.1667485756832855]}, "mutation_prompt": null}
{"id": "51ab9a2c-f62f-4d83-99fb-8d55ba4ff000", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (1 - iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduced a dynamic crossover rate to further enhance exploration during early iterations.", "configspace": "", "generation": 73, "fitness": 0.8226187691443033, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.050. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.886846177621615, 0.7651317224064489, 0.8158784074048462], "final_y": [0.19560384751340454, 0.24691095204343194, 0.22554274723543455]}, "mutation_prompt": null}
{"id": "02f38530-cb8a-4123-b06c-9b1c02678ed5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.9))  # Adjusted reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)\n                \n                # Adjusted mutation strategy with fitness variance influence\n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c) * (1 + np.var(fitness) / 10), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduced a dynamic population size adjustment and improved mutation strategy based on fitness variance to enhance convergence.", "configspace": "", "generation": 74, "fitness": 0.9333786161725461, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.030. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9313566676187386, 0.8980432172836933, 0.9707359636152064], "final_y": [0.17947348067617064, 0.18999349656232944, 0.1673416229861674]}, "mutation_prompt": null}
{"id": "bd23a35c-cb11-4e42-aee8-9320dd0ff98a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor) * (fitness[i] - trial_fitness) / (np.abs(fitness[i]) + 1e-8)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive control by modifying the mutation factor formula to balance exploration and exploitation based on fitness improvement rate.", "configspace": "", "generation": 75, "fitness": 0.9613813461303596, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.015. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9753072550168208, 0.9398249228112356, 0.9690118605630224], "final_y": [0.16493533456469278, 0.17031487951704394, 0.16823818927994216]}, "mutation_prompt": null}
{"id": "cf345368-6309-40f7-babc-ee61e033ad01", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n            self.mutation_factor *= 1.01  # Change: Introducing a learning rate to mutation factor\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Improved convergence by introducing a learning rate to the mutation factor based on fitness improvement trends.", "configspace": "", "generation": 76, "fitness": 0.9465302360776878, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.031. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9676058810483597, 0.9024986567939662, 0.9694861703907378], "final_y": [0.1661285431353159, 0.1887582615149036, 0.16774861390081508]}, "mutation_prompt": null}
{"id": "a7b72ea5-c89d-45e7-a42e-1d06b38e667d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - np.std(population) / (upper_bound - lower_bound))  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced convergence by implementing a more sophisticated adaptive mutation factor that considers both population diversity and iteration progress.", "configspace": "", "generation": 77, "fitness": 0.9451031095887704, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9239535810400914, 0.9528041248499572, 0.9585516228762626], "final_y": [0.16485577331310708, 0.16515473543934045, 0.1648557728257546]}, "mutation_prompt": null}
{"id": "f729e278-fb2e-4778-9e5e-e38c1a338840", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 50  # Additional adjustment line changed\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Improved exploration by enhancing diversity control and mutation scaling.", "configspace": "", "generation": 78, "fitness": 0.9351622911915759, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.030. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9329344897014342, 0.8999005476076394, 0.9726518362656543], "final_y": [0.1787548728718954, 0.1892267588033515, 0.1667485756832855]}, "mutation_prompt": null}
{"id": "0af2c61c-0d58-43e9-b8c9-159cc084871e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100 + 0.2 * (iteration // (self.budget // 3) % 2)  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce a phase-based diversity factor to enhance diversity control during stagnation.", "configspace": "", "generation": 79, "fitness": 0.9632493972889992, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9572084500319059, 0.9594827846885114, 0.9730569571465799], "final_y": [0.1698454229839722, 0.1664361369213444, 0.16656847497615734]}, "mutation_prompt": null}
{"id": "ffbe72f5-c765-4476-8fee-0aa1f39074a6", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) * np.cos(np.std(fitness))  # Modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Further enhanced convergence by adjusting mutation and crossover rates based on both diversity and temporal factors.", "configspace": "", "generation": 80, "fitness": 0.9632493972889992, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9572084500319059, 0.9594827846885114, 0.9730569571465799], "final_y": [0.1698454229839722, 0.1664361369213444, 0.16656847497615734]}, "mutation_prompt": null}
{"id": "d844bcd5-55ae-407f-811f-28a07f677f56", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) + 0.1 * np.std(fitness)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Improved exploration by utilizing a dynamic crossover rate adjustment based on diversity and iteration progress.", "configspace": "", "generation": 81, "fitness": 0.9493587889763638, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.025. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9738877615974828, 0.9594386458225526, 0.9147499595090558], "final_y": [0.16547209924832895, 0.16518854697434848, 0.18357515824685766]}, "mutation_prompt": null}
{"id": "f7e1596b-7e97-4c2b-a35a-d509fc0fd073", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.6 + 0.4 * (iteration / self.budget)  # Modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 50  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced exploration by dynamically adjusting mutation and crossover rates based on iteration progress and population diversity.", "configspace": "", "generation": 82, "fitness": 0.9107244293890204, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.011. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.8975454857588031, 0.923421071479196, 0.911206730929062], "final_y": [0.1871363483267835, 0.17192955122493603, 0.1847417758906692]}, "mutation_prompt": null}
{"id": "804262d4-1df2-4105-81e9-e7ea5ab72f7f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.3 * np.random.rand() + 0.2 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced convergence by further calibrating the mutation factor for diversity sensitivity.", "configspace": "", "generation": 83, "fitness": 0.9505631694298943, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.023. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9440858344039946, 0.9256114632427646, 0.9819922106429236], "final_y": [0.1648690983100135, 0.1690392317522743, 0.16522306902510453]}, "mutation_prompt": null}
{"id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            # Line modified below\n            self.mutation_factor += 0.05 * np.sin((2 * np.pi * iteration) / self.budget)  # Slight mutation factor adjustment\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced strategy with dynamic mutation factor adjustment based on historical performance trends.", "configspace": "", "generation": 84, "fitness": 0.9668039435415166, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.011. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "19cc68ff-ae8a-4bc4-bd78-a748034da2b7", "metadata": {"aucs": [0.9758176406618868, 0.9514238266793928, 0.9731703632832699], "final_y": [0.16491722355359495, 0.17031544669293952, 0.1665616906262839]}, "mutation_prompt": null}
{"id": "95ea691d-9e30-4c23-8f23-32fc9b845022", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.5 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.7 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            # Line modified below\n            self.mutation_factor += 0.08 * np.sin((2 * np.pi * iteration) / self.budget)  # Slight mutation factor adjustment\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhancing convergence speed by optimizing mutation and crossover factors with fine-tuned adaptive dynamicity.", "configspace": "", "generation": 85, "fitness": 0.9486958830522046, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.015. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "metadata": {"aucs": [0.9424055375283721, 0.9346873900203964, 0.9689947216078457], "final_y": [0.1648559218245209, 0.16931781305320248, 0.16485898536314803]}, "mutation_prompt": null}
{"id": "c0618a17-c9d5-4e76-ac28-96c34cc6d2cd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 50  # Modified adjustment line\n\n            # Line modified below\n            self.mutation_factor += 0.05 * np.sin((2 * np.pi * iteration) / self.budget)  # Slight mutation factor adjustment\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Optimized diversity factor adjustment to improve convergence rate and solution diversity.", "configspace": "", "generation": 86, "fitness": 0.9482695194095155, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.038. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "metadata": {"aucs": [0.9759443431150798, 0.894360859193718, 0.9745033559197488], "final_y": [0.1648645643699851, 0.19137385545404895, 0.1660426116066196]}, "mutation_prompt": null}
{"id": "c5b6128a-c292-44b6-a8dd-9a742a89b764", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            # Line modified below\n            self.mutation_factor += 0.05 * np.sin((2 * np.pi * iteration + np.mean(fitness)) / self.budget)  # Slight mutation factor adjustment\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Slightly enhanced mutation factor adjustment by incorporating past trend analysis for better exploration.", "configspace": "", "generation": 87, "fitness": 0.9667999799929877, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.011. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "metadata": {"aucs": [0.9758150743599283, 0.951414521150021, 0.973170344469014], "final_y": [0.16491884221624797, 0.17032537701695527, 0.16656167823064172]}, "mutation_prompt": null}
{"id": "3a2d3ad6-164c-4f09-accb-c886e959d8e0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget) + 0.05 * np.random.rand()  # Modified line\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            # Line modified below\n            self.mutation_factor += 0.05 * np.sin((2 * np.pi * iteration) / self.budget) + 0.05 * np.random.rand()  # Modified line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Integrates stochastic variation in mutation and crossover rates to refine search precision in adaptive differential evolution.", "configspace": "", "generation": 88, "fitness": 0.9564245205249442, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.005. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "metadata": {"aucs": [0.9495809587457683, 0.9592222779349171, 0.9604703248941469], "final_y": [0.16701460806590318, 0.16508983791505083, 0.1657244992471829]}, "mutation_prompt": null}
{"id": "4e2a3fdc-890f-495d-9a24-bd70c9992ef5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduced enhanced diversity and mutation scaling through sinusoidal adaptation for improved global exploration. ", "configspace": "", "generation": 89, "fitness": 0.9673031349295592, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.007. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98cd9988-5a3c-4b4c-8fd5-779d689dfc73", "metadata": {"aucs": [0.969736851341579, 0.9581354013348845, 0.974037152112214], "final_y": [0.16566588259719817, 0.16793022188929152, 0.16571894858389713]}, "mutation_prompt": null}
{"id": "273de9c7-be2b-4346-8673-966129f97078", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.cos((2 * np.pi * iteration) / self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Refine mutation factor adaptation using cosine modulation for enhanced convergence stability.", "configspace": "", "generation": 90, "fitness": 0.9405290376372988, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.011. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4e2a3fdc-890f-495d-9a24-bd70c9992ef5", "metadata": {"aucs": [0.9260024039974437, 0.9448910172294166, 0.950693691685036], "final_y": [0.16491078266020687, 0.16505977620186785, 0.17062407946550628]}, "mutation_prompt": null}
{"id": "12092546-598f-4910-8121-2b7e6a953b4d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive mutation factor with exponential decay to improve local exploitation.", "configspace": "", "generation": 91, "fitness": 0.9673808750351984, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.007. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4e2a3fdc-890f-495d-9a24-bd70c9992ef5", "metadata": {"aucs": [0.970076337775421, 0.9581208933829058, 0.9739453939472684], "final_y": [0.1655353984471304, 0.16793745350316946, 0.16576021725840717]}, "mutation_prompt": null}
{"id": "f2e71fc6-f904-4c48-8d06-f4730019a7b7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 * np.exp(-2 * iteration / self.budget) + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive mutation factor with exponential decay and diversity modulation for improved exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.9663553633636056, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9695274481024838, 0.9632295487857225, 0.9663090932026105], "final_y": [0.1654934906006007, 0.1659152510526678, 0.16830869104336776]}, "mutation_prompt": null}
{"id": "433c881d-ac18-4e89-90a8-16ec11799cfd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * (0.90 + 0.05 * np.random.rand())))  # Dynamic reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Introduce a dynamic population adaptation mechanism to enhance convergence efficiency.", "configspace": "", "generation": 93, "fitness": 0.9527974250459019, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.009. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9432314355539424, 0.9649795024025021, 0.9501813371812612], "final_y": [0.16902304356337317, 0.1648804500291574, 0.170866586530937]}, "mutation_prompt": null}
{"id": "909234f5-4780-4986-b519-4e390dac4ac3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.45 + 0.25 * np.random.rand() + 0.3 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.15 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced diversity control via a dynamic mutation factor adjustment to improve exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.956130516480783, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9646681787490011, 0.9296708414745691, 0.9740525292187785], "final_y": [0.16493704998293168, 0.1662688098351055, 0.16500843713886293]}, "mutation_prompt": null}
{"id": "35eef771-e6f5-45a5-8f0c-82907e495521", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)\n\n            self.crossover_rate = 0.5 + 0.5 * np.cos((np.pi * iteration) / self.budget)  # Line changed\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)\n            diversity_factor += np.std(fitness) / 100\n\n            self.mutation_factor += 0.1 * np.cos((np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Line changed\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive learning with dynamic crossover and mutation factors using cosine modulation for better exploration.", "configspace": "", "generation": 95, "fitness": 0.8772723930700561, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.009. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.8898457261015035, 0.8701485470682544, 0.8718229060404106], "final_y": [0.193496209456256, 0.2023960210391409, 0.20045663121295942]}, "mutation_prompt": null}
{"id": "11e70b18-9af0-4465-91fa-3a5b42517ba5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n            \n            rate_of_improvement = 1 - np.min(fitness) / np.mean(fitness)  # Newly added line\n            \n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced Adaptive Differential Learning with dynamic mutation factor scaling based on fitness improvement rate.", "configspace": "", "generation": 96, "fitness": 0.9673808750351984, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.007. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.970076337775421, 0.9581208933829058, 0.9739453939472684], "final_y": [0.1655353984471304, 0.16793745350316946, 0.16576021725840717]}, "mutation_prompt": null}
{"id": "7ee7fc75-5cc5-4544-9577-7eaf2d71582f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.4 * (1 - iteration / self.budget)  # Adjusted line for better exploration\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.9 + 0.1 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Refined adaptive mutation factor and crossover to enhance exploration and convergence balance.", "configspace": "", "generation": 97, "fitness": 0.9355248722148294, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.020. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9145480824233979, 0.9630227631679962, 0.9290037710530941], "final_y": [0.182301631535573, 0.16504197997187597, 0.18188795155600934]}, "mutation_prompt": null}
{"id": "804211fb-5c49-419a-bd89-c61ec289492f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0  # More aggressive initial mutation factor\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))  # Gradual reduction\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)  # Adaptive part for mutation\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor  # Adaptive crossover\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)  # Adjusted line\n\n            self.crossover_rate = 0.5 + 0.5 * (iteration / self.budget)  # Slightly modified adaptive crossover rate\n            diversity_factor = 0.95 + 0.05 * np.sin((2 * np.pi * iteration) / (self.budget / 2))  # Adjusted line\n            diversity_factor += np.std(fitness) / 100  # Additional adjustment line\n\n            self.mutation_factor += 0.1 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Adjusted diversity factor modulation to improve convergence speed.", "configspace": "", "generation": 98, "fitness": 0.9423237467984892, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.024. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9549399471445794, 0.9083957063086511, 0.9636355869422372], "final_y": [0.1655077158699384, 0.1825046620055819, 0.16968151134907472]}, "mutation_prompt": null}
{"id": "a2f59251-5089-46e6-a525-79479489793f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(4 + int(3 * np.log(self.dim)), 50)\n        self.mutation_factor = 1.0\n        self.crossover_rate = 0.7\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lower_bound, upper_bound = bounds.lb, bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        diversity_factor = 1.0\n\n        for iteration in range(self.budget - self.population_size):\n            if iteration % (self.budget // 10) == 0:\n                self.population_size = max(4, int(self.population_size * 0.95))\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adapt_factor = 0.5 + 0.3 * (1 - iteration / self.budget)\n                \n                mutant = np.clip(a + diversity_factor * self.mutation_factor * adapt_factor * (b - c), lower_bound, upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate * adapt_factor\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    self.mutation_factor = 0.4 + 0.3 * np.random.rand() + 0.35 * (1 - diversity_factor)\n\n            self.crossover_rate = 0.4 + 0.6 * (iteration / self.budget)  # Adjusted line\n            diversity_factor = 0.9 + 0.05 * np.sin((2 * np.pi * iteration) / self.budget)  # Adjusted line\n            diversity_factor += np.std(fitness) / 50  # Adjusted line\n\n            self.mutation_factor += 0.05 * np.sin((2 * np.pi * iteration) / self.budget) * (1 - iteration/self.budget)  # Adjusted line\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "name": "AdaptiveDifferentialLearning", "description": "Enhanced adaptive crossover rate and diversity control to improve search efficiency.", "configspace": "", "generation": 99, "fitness": 0.9471195220120925, "feedback": "The algorithm AdaptiveDifferentialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.026. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "12092546-598f-4910-8121-2b7e6a953b4d", "metadata": {"aucs": [0.9105273447987461, 0.9600183805884999, 0.9708128406490314], "final_y": [0.18207638728442743, 0.16488032117329687, 0.16508622039112741]}, "mutation_prompt": null}
