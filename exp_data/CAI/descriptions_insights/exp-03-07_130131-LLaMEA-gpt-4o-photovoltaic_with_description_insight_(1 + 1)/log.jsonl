{"id": "b6f693b8-195b-41b6-b21e-929534026542", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm that combines Differential Evolution (DE) for global exploration and a Memetic Search using Local Search refinements to effectively tackle complex high-dimensional, noisy optimization tasks with a focus on modularity and robustness.", "configspace": "", "generation": 0, "fitness": 0.7895228825412612, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7795404871834797, 0.7945901820562783, 0.7944379783840255], "final_y": [0.15795303518107018, 0.1601017669387199, 0.15808392127048776]}, "mutation_prompt": null}
{"id": "391b664c-b629-42ff-ae58-3240a0c7d065", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            adaptive_f = self.f * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + adaptive_f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        # Dynamic local search iterations\n        iters = int(self.local_search_iters * (1 + 0.5 * (1 - best_score / np.max(self.scores))))\n\n        for _ in range(iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.scores = scores\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm using adaptive DE parameters and dynamic local search iterations for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7709649198725138, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.025. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7423820363094582, 0.8024119684032434, 0.76810075490484], "final_y": [0.17924064183162647, 0.15645088669157337, 0.1690992360708693]}, "mutation_prompt": null}
{"id": "50604399-a999-4322-8730-4c7bed8fc1e6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        initial_iters = self.local_search_iters\n\n        for _ in range(initial_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n            else:\n                self.local_search_iters += 1  # Adaptive adjustment\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.f = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive DE mutation factor\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic utilizing adaptive parameters in DE and dynamically adjusted local search iterations for improved exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7868320049601616, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.011. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7709711944872975, 0.7945901820562783, 0.7949346383369091], "final_y": [0.16511416545723934, 0.1601017669387199, 0.15657956167055032]}, "mutation_prompt": null}
{"id": "e858a0f9-3e1c-43e9-aa4b-c2213dd6d991", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr_initial = 0.9  # Initial DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores, current_step):\n        new_population = np.copy(population)\n        cr = self.cr_initial * (0.5 + 0.5 * (1 - current_step / (self.budget // self.pop_size)))  # Dynamic crossover rate\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n        current_step = 0\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores, current_step)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n            current_step += 1\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduced a dynamic crossover rate in Differential Evolution based on the iteration count to enhance global exploration and local exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.7797144115579454, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.021. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7501150742335325, 0.7945901820562783, 0.7944379783840255], "final_y": [0.1684836003834287, 0.1601017669387199, 0.15808392127048776]}, "mutation_prompt": null}
{"id": "05557b39-f235-4a28-a715-d67792a3b4d0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n        self.layer_progression = int(dim / 10)\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f_adaptive = self.f * np.random.uniform(0.9, 1.1)\n            mutant = np.clip(a + f_adaptive * (b - c), self.bounds.lb, self.bounds.ub) \n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget / 4) == 0:  # Increase complexity gradually\n                self.dim += self.layer_progression\n                self.pop_size = self.dim * 10\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that incorporates adaptive parameter tuning and a progressive layer complexity approach for optimizing high-dimensional, noisy tasks.", "configspace": "", "generation": 4, "fitness": 0.7885405041971612, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.008. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7863761330789798, 0.7991628798454913, 0.7800824996670124], "final_y": [0.1537728316516901, 0.15408775688226473, 0.16428300894795944]}, "mutation_prompt": null}
{"id": "b4d1ce9b-bfaf-433c-a8b2-5ce18ab95d58", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual, evaluations):\n        best = individual\n        best_score = self.evaluate(best)\n        adaptive_scale = 0.01 * (1 - evaluations / self.budget)  # Adaptive perturbation scaling\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, adaptive_scale, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual, evaluations)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced local search by incorporating adaptive perturbation scaling based on search progress for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.7895228825412612, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7795404871834797, 0.7945901820562783, 0.7944379783840255], "final_y": [0.15795303518107018, 0.1601017669387199, 0.15808392127048776]}, "mutation_prompt": null}
{"id": "cd13ec6b-77d2-4b63-9181-dcdd1d9829d1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        dynamic_iters = min(10, self.local_search_iters * (1 + ((1 - best_score) / 5)))  # Dynamic iters\n        for _ in range(int(dynamic_iters)):  # Adjusted loop based on dynamic_iters\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "This refined metaheuristic algorithm enhances local search by dynamically adjusting local search iterations based on the quality of solutions to improve convergence in high-dimensional, noisy optimization tasks.", "configspace": "", "generation": 6, "fitness": 0.7895228825412612, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7795404871834797, 0.7945901820562783, 0.7944379783840255], "final_y": [0.15795303518107018, 0.1601017669387199, 0.15808392127048776]}, "mutation_prompt": null}
{"id": "fb860672-2a41-4af4-8dd4-2876f1e39017", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n        self.layer_increase_step = max(1, dim // 10)  # Gradual layer increase step\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n            # Gradual increase in dimensions (layers) for complexity management\n            if evaluations < self.budget // 2:\n                self.dim = min(self.dim + self.layer_increase_step, func.bounds.ub.size)\n                self.pop_size = self.dim * 10\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with a gradual layer increase strategy to manage computational cost and complexity with improved robustness.", "configspace": "", "generation": 7, "fitness": 0.7895228825412612, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7795404871834797, 0.7945901820562783, 0.7944379783840255], "final_y": [0.15795303518107018, 0.1601017669387199, 0.15808392127048776]}, "mutation_prompt": null}
{"id": "9dcb57c0-daf6-46e3-bbbc-da87aab4c455", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.5  # DE minimum mutation factor\n        self.f_max = 0.9  # DE maximum mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced DE and local search integration with adaptive mutation for improved exploration and convergence in noisy environments.", "configspace": "", "generation": 8, "fitness": 0.7903439158889406, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.006. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b6f693b8-195b-41b6-b21e-929534026542", "metadata": {"aucs": [0.7815867087935089, 0.794785633124429, 0.7946594057488838], "final_y": [0.15654390699614606, 0.15951704353604723, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "817fcd5a-b564-43c7-bd77-20036afe0813", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.5  # DE minimum mutation factor\n        self.f_max = 0.9  # DE maximum mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        # Calculate crowding distance for diversity preservation\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "HybridMetaheuristic with diversity preservation via crowding distance to enhance exploration and avoid premature convergence.", "configspace": "", "generation": 9, "fitness": 0.7946860437280808, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.000. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9dcb57c0-daf6-46e3-bbbc-da87aab4c455", "metadata": {"aucs": [0.7948085433790806, 0.7945901820562783, 0.7946594057488838], "final_y": [0.147779091251939, 0.1601017669387199, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "49ccb3f4-38db-4feb-bb33-d2e4a5d5afdf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.2  # DE minimum mutation factor (changed)\n        self.f_max = 1.0  # DE maximum mutation factor (changed)\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual + np.random.normal(0, 0.005, self.dim)  # Added Gaussian noise\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        # Calculate crowding distance for diversity preservation\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced exploration by dynamically adjusting mutation factor and incorporating noise resilience through Gaussian noise analysis.", "configspace": "", "generation": 10, "fitness": 0.7811883191202306, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.012. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "817fcd5a-b564-43c7-bd77-20036afe0813", "metadata": {"aucs": [0.7658892438998254, 0.7945901820562783, 0.783085531404588], "final_y": [0.16294159383670526, 0.1601017669387199, 0.16160302469522592]}, "mutation_prompt": null}
{"id": "85acbc14-7511-44b2-af80-bb2128d24174", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.5  # DE minimum mutation factor\n        self.f_max = 0.9  # DE maximum mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n        self.conv_rate_thresh = 0.01  # Convergence rate threshold for adaptive local search\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        # Calculate crowding distance for diversity preservation\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            # Adaptive local search check\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "HybridMetaheuristic enhanced with adaptive local search frequency based on convergence rate to balance exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.7953883618925088, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.010. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "817fcd5a-b564-43c7-bd77-20036afe0813", "metadata": {"aucs": [0.783890953119766, 0.8076147268088765, 0.7946594057488838], "final_y": [0.15230236718398849, 0.15202017530954648, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "17959586-c6e2-4a0b-90ee-d1ab69fa5079", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.5  # DE minimum mutation factor\n        self.f_max = 0.9  # DE maximum mutation factor\n        self.cr = 0.9  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n        self.conv_rate_thresh = 0.01  # Convergence rate threshold for adaptive local search\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c) + np.random.normal(0, 0.1, self.dim), self.bounds.lb, self.bounds.ub)  # Added Gaussian mutation\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        # Calculate crowding distance for diversity preservation\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            # Adaptive local search check\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced population diversity by incorporating Gaussian mutation into DE step for improved exploration.", "configspace": "", "generation": 12, "fitness": 0.7846833677094008, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.013. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "85acbc14-7511-44b2-af80-bb2128d24174", "metadata": {"aucs": [0.7747811270098901, 0.8027994769764378, 0.7764694991418746], "final_y": [0.1610312664089274, 0.15385563209755737, 0.15851176151170465]}, "mutation_prompt": null}
{"id": "cb65743e-84a5-4a99-81b0-e5239e18f49f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = self.dim * 20  # Maximum population size\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            # Dynamic population size adjustment\n            self.pop_size = min(self.max_pop_size, max(self.min_pop_size, self.pop_size + (evaluations // self.budget)))\n            new_population = self.de_step(population[:self.pop_size], scores[:self.pop_size])\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic population size adjustment based on convergence for improved exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.7953883618925088, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.010. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "85acbc14-7511-44b2-af80-bb2128d24174", "metadata": {"aucs": [0.783890953119766, 0.8076147268088765, 0.7946594057488838], "final_y": [0.15230236718398849, 0.15202017530954648, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "3d391ed6-b48e-41d6-94b3-1abccd10cae0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10  # Population size for DE\n        self.f_min = 0.5  # DE minimum mutation factor\n        self.f_max = 0.9  # DE maximum mutation factor\n        self.cr = 0.7  # DE crossover probability\n        self.local_search_iters = 5  # Number of local search iterations\n        self.bounds = None\n        self.conv_rate_thresh = 0.01  # Convergence rate threshold for adaptive local search\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Adaptive mutation factor\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score > best_score:\n                best, best_score = candidate, candidate_score\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        # Calculate crowding distance for diversity preservation\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            # Adaptive local search check\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced DE crossover probability to improve exploration and balance between exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.7910909092329673, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.014. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "85acbc14-7511-44b2-af80-bb2128d24174", "metadata": {"aucs": [0.805609666296061, 0.7945901820562783, 0.7730728793465629], "final_y": [0.14895696681581716, 0.1601017669387199, 0.16715671835402635]}, "mutation_prompt": null}
{"id": "162de62b-2c75-4022-b586-d93503a455da", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with enhanced local search using simulated annealing for better exploitation and adaptive DE parameters for robust exploration.", "configspace": "", "generation": 15, "fitness": 0.7953898021200936, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.010. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "85acbc14-7511-44b2-af80-bb2128d24174", "metadata": {"aucs": [0.7838930759645887, 0.8076169246468082, 0.7946594057488838], "final_y": [0.1523007928365051, 0.1520188465936816, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "9d00c694-69ff-4441-b1f0-b6c52182a90b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity_factor = np.std(population)  # Measure diversity of the population\n        adjusted_f_max = self.f_max * (1 + 0.1 * diversity_factor)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (adjusted_f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced exploration-exploitation balance by adjusting DE parameters dynamically with population diversity consideration.", "configspace": "", "generation": 16, "fitness": 0.769480929781723, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7714705709794323], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16792077891368418]}, "mutation_prompt": null}
{"id": "01078d46-51c0-4241-acd9-7040342818c1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n        self.layer_increase_step = max(1, self.dim // 10)  # Change 1\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for i in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9 - (i / self.local_search_iters) * 0.05  # Change 2\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            current_dim = min(self.dim, (evaluations // self.pop_size) * self.layer_increase_step)  # Change 3\n            new_population = self.de_step(population[:, :current_dim], scores)  # Change 4\n            new_population = np.hstack((new_population, population[:, current_dim:]))  # Change 5\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introducing adaptive layer complexity and a dynamic cooling schedule in simulated annealing to enhance exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (10,) into shape (1,)').", "error": "ValueError('could not broadcast input array from shape (10,) into shape (1,)')", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {}, "mutation_prompt": null}
{"id": "81560071-1162-44e1-9efd-0b5a5d4dd066", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for step in range(1, self.local_search_iters + 1):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9 * (1 - step / self.local_search_iters)  # Dynamic cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce a dynamic cooling schedule in simulated annealing to improve local search efficacy.", "configspace": "", "generation": 18, "fitness": 0.7953898021200936, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.010. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7838930759645887, 0.8076169246468082, 0.7946594057488838], "final_y": [0.1523007928365051, 0.1520188465936816, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "05d656ab-5c3f-4096-988d-ce22e8b6ddab", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    self.local_search_iters = int(self.local_search_iters * 1.5)  # Adjust local search iterations\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic local search iterations based on convergence rate for improved exploitation.", "configspace": "", "generation": 19, "fitness": 0.7867724606152038, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.014. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7667862463537084, 0.7988717297430195, 0.7946594057488838], "final_y": [0.16442670727428477, 0.15780406843654704, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "24babdb9-69cb-47a1-bddd-3db439c4c318", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n        self.layer_increment_strategy = [10, 20, 32]\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        initial_layers = self.dim\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, initial_layers))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n            if evaluations < self.budget // 2 and self.dim < max(self.layer_increment_strategy):\n                self.dim = next((l for l in self.layer_increment_strategy if l > self.dim), self.dim)\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with modular structure preservation and dynamic layer adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,) (10,) (10,) ')", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {}, "mutation_prompt": null}
{"id": "815b2fdd-2023-4e1f-a4be-a99a748780bc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            self.f_min = max(0.3, self.f_min * 0.99)  # Adaptation of DE parameter\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    self.local_search_iters = min(10, self.local_search_iters + 1)  # Dynamic local search intensity\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced parameter adaptation and dynamic local search intensity to improve convergence speed and solution quality.", "configspace": "", "generation": 21, "fitness": 0.7853462023649355, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.013. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7667511878273603, 0.7945901820562783, 0.7946972372111677], "final_y": [0.1455721993250303, 0.1601017669387199, 0.15797345561141785]}, "mutation_prompt": null}
{"id": "2df4819c-3568-4719-93aa-2b106fc7a338", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n            if evaluations < 0.5 * self.budget and conv_rate < self.conv_rate_thresh / 2:\n                self.pop_size = int(self.pop_size * 1.2)  # Adjust population size\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic population size adjustment based on convergence, maintaining a balance between exploration and exploitation.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 109 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 109 is out of bounds for axis 0 with size 100')", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {}, "mutation_prompt": null}
{"id": "c75f694e-6d9f-4461-937c-ebec992b946d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def levy_flight(self, scale=0.01):\n        return np.random.normal(0, scale, self.dim) / np.power(np.random.normal(0, 1), 2)\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + self.levy_flight()  # Use Lvy flight\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enriched exploration using Lvy flights with a step-size adaptation and hybrid local search to enhance convergence on high-dimensional noisy landscapes.", "configspace": "", "generation": 23, "fitness": 0.7909768170083812, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.005. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7836808632199819, 0.7945901820562783, 0.7946594057488838], "final_y": [0.15243342923668324, 0.1601017669387199, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "04328992-872d-4e71-9735-385caff76df9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        cr_adaptive = max(0.1, self.cr * diversity)  # Change 1\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr_adaptive  # Change 2\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced exploration in DE step by introducing adaptive crossover probability based on diversity.", "configspace": "", "generation": 24, "fitness": 0.7827922261910443, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.017. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7591270907679706, 0.7945901820562783, 0.7946594057488838], "final_y": [0.16920680402010024, 0.1601017669387199, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "06736e00-e4d3-44c0-870c-16340a6c54cd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce progressive layer increase by starting with fewer layers and gradually adding layers during optimization for improved exploration-exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.7953898021200936, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.010. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.7838930759645887, 0.8076169246468082, 0.7946594057488838], "final_y": [0.1523007928365051, 0.1520188465936816, 0.1579895701254992]}, "mutation_prompt": null}
{"id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores)) # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by incorporating adaptive crowding distance factor and dynamic mutation scaling for improved diversity and convergence.", "configspace": "", "generation": 26, "fitness": 0.7992037049852421, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.003. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "162de62b-2c75-4022-b586-d93503a455da", "metadata": {"aucs": [0.8038214464900527, 0.7975028121403698, 0.7962868563253038], "final_y": [0.1530614136523658, 0.15390864221034994, 0.15010086234748754]}, "mutation_prompt": null}
{"id": "d692f80c-522b-41aa-be8d-42ce1639ef81", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            diversity = np.std(population, axis=0).mean()  # Line changed\n            f = self.f_min + diversity * (self.f_max - self.f_min)  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation step size based on population diversity to enhance exploration.", "configspace": "", "generation": 27, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "51dbee95-5327-4374-b4e2-436ec7a10343", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n        self.init_pop_size = self.pop_size\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def adjust_population(self, evaluations, budget): # Line added\n        prev_pop_size = self.pop_size\n        self.pop_size = max(self.init_pop_size // 2, int(self.init_pop_size * (1 - evaluations / budget))) # Line added\n        return prev_pop_size != self.pop_size # Line added\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            if self.adjust_population(evaluations, self.budget): # Line added\n                population = population[:self.pop_size] # Line added\n                scores = scores[:self.pop_size] # Line added\n\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive population resizing and layer-specific mutation guidance to improve exploration and convergence.", "configspace": "", "generation": 28, "fitness": 0.7849663583439078, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.016. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.7621558541623582, 0.7945901820562783, 0.7981530388130873], "final_y": [0.16515086868910445, 0.1601017669387199, 0.14913834664479908]}, "mutation_prompt": null}
{"id": "709abfad-1420-4212-bb3c-2702d717986b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores)) # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argsort(scores)[-2]]  # Line changed", "name": "HybridMetaheuristic", "description": "Introduced stochastic ranking to balance objective function and penalty constraints, potentially improving convergence behavior.", "configspace": "", "generation": 29, "fitness": 0.7992037049852421, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.003. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8038214464900527, 0.7975028121403698, 0.7962868563253038], "final_y": [0.1530614136523658, 0.15390864221034994, 0.15010086234748754]}, "mutation_prompt": null}
{"id": "1d4f54a8-800c-4075-a79f-ecc439d36e77", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores)) # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    self.local_search_iters = min(10, self.local_search_iters + 1)  # Change made here\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive local search iteration count based on convergence rate for enhanced refinement.", "configspace": "", "generation": 30, "fitness": 0.7974932477037879, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.004. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8038214464900527, 0.7945901820562783, 0.7940681145650328], "final_y": [0.1530614136523658, 0.1601017669387199, 0.15701809913852316]}, "mutation_prompt": null}
{"id": "1ef4431d-7e64-40e9-b0d9-dd7fe86d592d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))  # New line for diversity\n        adaptive_cr = self.cr * (1 - diversity)  # New line for adaptive crossover rate\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_cr  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduced adaptive crossover rate based on diversity to balance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.7815498138394329, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.010. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.7795504365064908, 0.7945901820562783, 0.7705088229555297], "final_y": [0.15618545005654283, 0.1601017669387199, 0.16791289008592936]}, "mutation_prompt": null}
{"id": "593eac3f-0d46-4ca6-8da1-a275f9be1659", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    self.cr = max(0.5, self.cr * 0.95)  # Adaptive crossover probability\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive crossover probability based on convergence stagnation and improved local search cooling schedule to accelerate convergence.", "configspace": "", "generation": 32, "fitness": 0.79663170943347, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.005. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8038214464900527, 0.7945901820562783, 0.791483499754079], "final_y": [0.1530614136523658, 0.1601017669387199, 0.15934824214326293]}, "mutation_prompt": null}
{"id": "0a6ed94c-06fb-4232-9a7b-0217132af772", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= np.random.uniform(0.85, 0.95)  # Dynamic cooling schedule \n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                if np.random.rand() < 0.5:  # Probability-based local search trigger\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by incorporating a probability-based local search trigger and a dynamic cooling schedule for simulated annealing.", "configspace": "", "generation": 33, "fitness": 0.79716368553078, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.005. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8044428045759178, 0.7955647522623434, 0.791483499754079], "final_y": [0.15246909512090512, 0.1587152732245416, 0.15934824214326293]}, "mutation_prompt": null}
{"id": "afad4f8e-8325-4cb7-87d2-0df212223604", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            f_dynamic = self.f_min + (self.f_max - self.f_min) * np.random.rand() # Line changed\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic by adjusting the mutation scale dynamically based on convergence rate to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 34, "fitness": 0.7930545307543234, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.023. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8200219751286921, 0.7945901820562783, 0.7645514350779998], "final_y": [0.1421892035015362, 0.1601017669387199, 0.17087817978348097]}, "mutation_prompt": null}
{"id": "ee58e960-19e4-4e49-8c3b-f8bdea7d3849", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            # Implement adaptive crossover rate\n            adaptive_cr = self.cr * (1 - scores[i] / np.max(scores))\n            cross_points = np.random.rand(self.dim) < adaptive_cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover rate based on performance to enhance diversity and convergence.", "configspace": "", "generation": 35, "fitness": 0.7727915161023522, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.022. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7814023299413199], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16085125263296718]}, "mutation_prompt": null}
{"id": "a19bbff8-6b00-4abd-bf35-a1e23e1c3c51", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity_factor = np.std(population, axis=0).mean()  # Line changed\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + diversity_factor * (self.f_max - self.f_min)  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance convergence by incorporating adaptive mutation scaling based on population diversity.", "configspace": "", "generation": 36, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "45f65cd8-2379-489e-98b6-dbffd8159520", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def dynamic_layer_growth(self, population):  # New function\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.1:\n                population[i] = np.append(population[i], np.random.uniform(self.bounds.lb, self.bounds.ub))\n        return population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            population = self.dynamic_layer_growth(population)  # New call\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic by introducing adaptive layer growth and an energy-based acceptance criterion for refined exploration. ", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (20,) into shape (10,)').", "error": "ValueError('could not broadcast input array from shape (20,) into shape (10,)')", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {}, "mutation_prompt": null}
{"id": "74b88393-6361-49cc-8a5a-d4c981b6186b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improved local search by adjusting the mutation scale during simulated annealing to enhance convergence.", "configspace": "", "generation": 38, "fitness": 0.7992039616558982, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.003. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6e4c54a2-c614-4042-a09f-c30db6e5e008", "metadata": {"aucs": [0.8038214464900527, 0.7975029970697038, 0.7962874414079382], "final_y": [0.1530614136523658, 0.15390825670088648, 0.15009976929057134]}, "mutation_prompt": null}
{"id": "06dfac61-6b91-4b20-a06f-a4c66f0999da", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced mutation scale with adaptive cooling schedule for improved convergence.", "configspace": "", "generation": 39, "fitness": 0.7992040788986667, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.003. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "74b88393-6361-49cc-8a5a-d4c981b6186b", "metadata": {"aucs": [0.8038214464900527, 0.7975030518020851, 0.7962877384038625], "final_y": [0.1530614136523658, 0.153908142604249, 0.15009921444302177]}, "mutation_prompt": null}
{"id": "4452b681-143b-4ae7-99db-0a3bea6760f3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        distances[index[0]] = distances[index[-1]] = np.inf  # Boundary solutions\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = (scores[index[i + 1]] - scores[index[i - 1]]) / (np.max(scores) - np.min(scores))\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced crowding distance calculation to improve diversity and convergence.", "configspace": "", "generation": 40, "fitness": 0.7988428167915697, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.004. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "06dfac61-6b91-4b20-a06f-a4c66f0999da", "metadata": {"aucs": [0.8038214464900527, 0.7948831729681461, 0.7978238309165102], "final_y": [0.1530614136523658, 0.1596266561293348, 0.15175470190409512]}, "mutation_prompt": null}
{"id": "d27f2883-83be-4ed1-82fc-cd607817ef14", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improved mutation factor scaling to enhance exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.799536044700217, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "06dfac61-6b91-4b20-a06f-a4c66f0999da", "metadata": {"aucs": [0.8067365979717622, 0.8109422905420387, 0.7809292455868497], "final_y": [0.15191903840799081, 0.15291541043916312, 0.163947911381643]}, "mutation_prompt": null}
{"id": "9b7377d5-2b40-47ea-9fbd-032d2e2be061", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                    self.pop_size = int(self.dim * 10 * (1 - conv_rate))  # Adjust population size dynamically\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Dynamic population size adjustment based on convergence rate to optimize exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 99 is out of bounds for axis 0 with size 99').", "error": "IndexError('index 99 is out of bounds for axis 0 with size 99')", "parent_id": "d27f2883-83be-4ed1-82fc-cd607817ef14", "metadata": {}, "mutation_prompt": null}
{"id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve convergence by adjusting mutation factor scaling in DE step for better global search capability.", "configspace": "", "generation": 43, "fitness": 0.8069675253374804, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d27f2883-83be-4ed1-82fc-cd607817ef14", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845897269229819], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175097427637464]}, "mutation_prompt": null}
{"id": "2f9477d1-dcd0-4e33-a005-eb3425f93e59", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < (scores[i] / np.sum(scores))  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            scale_factor = max(0.005, 0.01 * (1 - best_score))  # Line changed\n            candidate = best + np.random.normal(0, scale_factor * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive mutation scale in local search and use fitness proportionate selection for crossover to enhance exploitation focus.", "configspace": "", "generation": 44, "fitness": 0.7777611907979908, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7700237618560158, 0.7945901820562783, 0.7686696284816784], "final_y": [0.16586964127040948, 0.1601017669387199, 0.16892393696300312]}, "mutation_prompt": null}
{"id": "d83059ed-b864-4ba5-82ee-e0230c4d5455", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            mutation_scale = np.random.uniform(0.005, 0.015)  # Dynamically adjust mutation scale\n            candidate = best + np.random.normal(0, mutation_scale * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= np.random.uniform(0.80, 0.90)  # Adaptive cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve local search efficiency by dynamically adjusting mutation scales and using adaptive cooling in local optimization.", "configspace": "", "generation": 45, "fitness": 0.8013088415687973, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.011. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8079956635262313, 0.8107729457310761, 0.7851579154490845], "final_y": [0.1514282821905708, 0.1529507681424409, 0.16025795020806188]}, "mutation_prompt": null}
{"id": "f38ec8f1-a5f7-49d7-af42-673272b886aa", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance local exploration by adjusting the simulated annealing mutation scale relative to convergence rate.  ", "configspace": "", "generation": 46, "fitness": 0.8069675253374804, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845897269229819], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175097427637464]}, "mutation_prompt": null}
{"id": "57f70ad0-09c4-4965-92e8-039b152d1e8b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cr_dynamic = self.cr * (1 - scores[i] / np.max(scores))  # Line changed\n            cross_points = np.random.rand(self.dim) < cr_dynamic  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance crossover operation by making crossover rate dynamic based on convergence status.", "configspace": "", "generation": 47, "fitness": 0.7715450006815917, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.022. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7776627836790383], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16425106967181224]}, "mutation_prompt": null}
{"id": "9d41d2cb-8219-4393-b82e-244417ff1868", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr_min = 0.7  # New line: Minimum crossover rate\n        self.cr_max = 0.95  # New line: Maximum crossover rate\n        self.local_search_iters = 10  # Changed the number of local search iterations\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            cr = self.cr_min + (self.cr_max - self.cr_min) * (scores[i] / np.max(scores))  # Changed line\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr  # Changed line to use adaptive cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Changed mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploitation by increasing the precision of local search and adaptively adjusting crossover rates for DE.", "configspace": "", "generation": 48, "fitness": 0.8003444511457897, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8077928444973662, 0.8107729457310761, 0.7824675632089269], "final_y": [0.15150722935916616, 0.1529507681424409, 0.16326931837692993]}, "mutation_prompt": null}
{"id": "ed035ad7-9b54-46fb-a0a0-96d57bf63b1e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = self.dim * 10  # Line changed\n        self.pop_size = self.initial_pop_size\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + np.random.rand() * (self.f_max - self.f_min)  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Line changed\n                self.pop_size = max(self.initial_pop_size // 2, 4)  # Line changed\n                population = np.resize(population, (self.pop_size, self.dim))  # Line changed\n                scores = np.resize(scores, self.pop_size)  # Line changed\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration and exploitation through adaptive population size and dynamic DE mutation.", "configspace": "", "generation": 49, "fitness": 0.7939909420649075, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.024. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7616685325581873, 0.8024984862347919, 0.8178058074017434], "final_y": [0.16369999887534536, 0.1547594892334827, 0.14832429289064508]}, "mutation_prompt": null}
{"id": "2d6834d9-0dee-4811-8e87-dfe05328c727", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr_min = 0.7  # Added line\n        self.cr_max = 0.9  # Added line\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            cr = self.cr_min + 0.3 * (self.cr_max - self.cr_min) * (scores[i] / np.max(scores))  # Changed line\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr  # Changed line\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve convergence by dynamically adjusting both mutation factor and crossover rate based on fitness.", "configspace": "", "generation": 50, "fitness": 0.79158073793142, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.013. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.77842884796518, 0.809674645347577, 0.7866387204815029], "final_y": [0.1527405413505193, 0.1533160307916347, 0.1574788865413027]}, "mutation_prompt": null}
{"id": "bd06aaca-91cd-4b7a-85cf-89eaac648abc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr_min = 0.7  # Added adaptive crossover rate parameters\n        self.cr_max = 0.95\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            cr = self.cr_min + (scores[i] / np.max(scores)) * (self.cr_max - self.cr_min)  # Adaptive crossover rate\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance adaptive differential evolution by incorporating adaptive crossover rate and selective elitism for improved convergence.", "configspace": "", "generation": 51, "fitness": 0.8062102579124845, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8077928444973662, 0.8283703660311604, 0.7824675632089269], "final_y": [0.15150722935916616, 0.14405222662446915, 0.16326931837692993]}, "mutation_prompt": null}
{"id": "2b973942-b429-4b76-bd92-e1df568b667a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.4  # Line changed\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (0.5 + scores[i] / np.max(scores)) * (self.f_max - self.f_min)  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances = (distances / np.max(distances)) * 0.5  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance convergence by adaptive crowding-distance influence and dynamic mutation factor adjustment in DE.", "configspace": "", "generation": 52, "fitness": 0.7773747007089291, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7568163370557492, 0.7948891895005632, 0.7804185755704748], "final_y": [0.17123207707325383, 0.1592152908776835, 0.16417380454493413]}, "mutation_prompt": null}
{"id": "c4d4c32e-9f43-48a2-abf2-3fe34fa8d988", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.4  # Changed\n        self.f_max = 0.95 # Changed\n        self.cr = 0.9\n        self.local_search_iters = 7  # Changed\n        self.bounds = None\n        self.conv_rate_thresh = 0.005  # Changed\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - (scores[i] / np.max(scores))**1.5)  # Changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.8  # Changed\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance convergence by adaptive mutation and a more aggressive local search cooling schedule.", "configspace": "", "generation": 53, "fitness": 0.7950404542867525, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.013. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8007665076502448, 0.8079413457950485, 0.7764135094149641], "final_y": [0.15426778718243384, 0.15430509036107598, 0.1659562587115314]}, "mutation_prompt": null}
{"id": "633ca2ee-2f90-4658-ab37-99fe655846ec", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            self.cr = 0.5 + 0.4 * (scores[i] / np.max(scores))  # Changed adaptive crossover rate\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover rate in DE step to better explore solution space.", "configspace": "", "generation": 54, "fitness": 0.7843724919981584, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.018. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7676105459205641, 0.809674645347577, 0.7758322847263337], "final_y": [0.15879397744306667, 0.1533160307916347, 0.14967656722498168]}, "mutation_prompt": null}
{"id": "8d4febf8-d917-42e9-a481-c61c4aa6533b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cr_adaptive = self.cr * (1 - scores[i] / np.max(scores))  # Line changed\n            cross_points = np.random.rand(self.dim) < cr_adaptive  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances *= 0.9 / np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover rates and crowding distance scaling to enhance diversity and convergence speed.", "configspace": "", "generation": 55, "fitness": 0.7715450006815917, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.022. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7776627836790383], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16425106967181224]}, "mutation_prompt": null}
{"id": "c316af4a-ad9a-4595-846c-f6c45cdffb90", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.4  # Changed\n        self.f_max = 0.95  # Changed\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.55 * (self.f_max - self.f_min) * ((np.max(scores) - scores[i]) / (np.max(scores) + 1e-9))  # Changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n            elite_idx = np.argmax(scores)  # Added\n            population[0] = population[elite_idx]  # Added\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance convergence by dynamic adjustment of mutation factor and introduce elitism for population improvement.", "configspace": "", "generation": 56, "fitness": 0.7923727212745609, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.014. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7967129117827226, 0.8068850103855087, 0.7735202416554519], "final_y": [0.15550803455161855, 0.15487366171753125, 0.1656843565697066]}, "mutation_prompt": null}
{"id": "7ad9c0b2-ea59-4832-9925-09ec26d640de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = (self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))) * (1 + diversity)  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve exploration-exploitation balance by enhancing mutation factor scaling based on population diversity.", "configspace": "", "generation": 57, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "601540e9-c76a-4014-b717-48c00e409b60", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr_min = 0.6  # Changed line\n        self.cr_max = 1.0  # Changed line\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            cr = self.cr_min + (self.cr_max - self.cr_min) * (scores[i] / np.max(scores))  # Changed line\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr  # Changed line\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance the exploration by introducing a dynamic crossover rate and adaptive population scaling for improved convergence.", "configspace": "", "generation": 58, "fitness": 0.8055005003493529, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.010. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8079956635262313, 0.8168214474539134, 0.7916843900679139], "final_y": [0.1514282821905708, 0.14633562596752292, 0.1561725359362932]}, "mutation_prompt": null}
{"id": "66651a42-92f3-4320-8c3c-0b0f20cd043d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / (temperature + 1e-9)) > np.random.rand():  # Line changed\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for adaptive cooling\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:  # Line changed for dynamic population sizing\n                self.pop_size = max(10, self.pop_size // 2)  # Line changed\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive cooling and dynamic population sizing for efficiency in HybridMetaheuristic.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 80 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 80 is out of bounds for axis 0 with size 50')", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {}, "mutation_prompt": null}
{"id": "b3650860-4b3f-45b9-b755-80b2d82b1da4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            score_diff = scores[i] - np.min(scores)\n            cr = self.cr * (1 - score_diff / (np.max(scores) - np.min(scores) + 1e-9))  # Line changed\n            cross_points = np.random.rand(self.dim) < cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance DE step by dynamically adjusting crossover rate based on score difference for better exploration.", "configspace": "", "generation": 60, "fitness": 0.7773757099308943, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.020. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.756261547943576, 0.8048419962966896, 0.7710235855524177], "final_y": [0.15400339206843416, 0.15595257487232372, 0.16833211472338128]}, "mutation_prompt": null}
{"id": "2b9b6571-aa2b-40cb-8210-0be3319d1b3d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr_min = 0.6  # Line changed\n        self.cr_max = 1.0  # Line changed\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores)) \n            cr = self.cr_min + (self.cr_max - self.cr_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim) \n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85 \n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) \n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing adaptive crossover rates for better balance between exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.7777915720147544, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.014. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7777107170402099, 0.7945901820562783, 0.7610738169477751], "final_y": [0.15027089781703917, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "4b3f003c-6ab8-403a-a262-c7c13bdb413c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.6  # Changed line\n        self.f_max = 0.95  # Changed line\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / (temperature + 1e-9)) > np.random.rand():  # Changed line\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by adapting differential evolution parameters and fine-tuning local search acceptance rules for improved solution quality.", "configspace": "", "generation": 62, "fitness": 0.7992171649843768, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.005. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8021760446515661, 0.803253468744717, 0.7922219815568471], "final_y": [0.1537099941623815, 0.1561687096247395, 0.15903127620225532]}, "mutation_prompt": null}
{"id": "058ce4c1-7910-42cc-ae0e-eb2bc8d3fba7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            self.cr = 0.7 * (1 - scores[i] / np.max(scores)) + 0.3  # Line changed\n            cross_points = np.random.rand(self.dim) < self.cr  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            perturbation = np.random.normal(0, 0.02 * temperature, self.dim)  # Line changed\n            candidate = best + perturbation\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance search diversity by incorporating adaptive crossover rates and a novel perturbation in local search.", "configspace": "", "generation": 63, "fitness": 0.7754250227593076, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.7568912162753115, 0.7945901820562783, 0.7747936699463329], "final_y": [0.17145811637336983, 0.1601017669387199, 0.16201628815302793]}, "mutation_prompt": null}
{"id": "879fd97b-9c92-4b98-b118-b3e5f711c8b9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.90  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve local search efficiency by increasing the cooling schedule rate in simulated annealing.", "configspace": "", "generation": 64, "fitness": 0.8069675097442363, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845896801432493], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175100758975325]}, "mutation_prompt": null}
{"id": "f022cbd4-fc60-4922-9389-09f377ab3fe0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity = np.mean(np.std(population, axis=0))  # Calculate diversity based on population std dev\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        if diversity < 0.1:  # Change DE strategy based on diversity\n            self.cr = 0.8  \n        else:\n            self.cr = 0.9  # Reset the crossover rate if diversity is high\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by adjusting differential evolution strategy selection based on population diversity.", "configspace": "", "generation": 65, "fitness": 0.8069675253374804, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845897269229819], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175097427637464]}, "mutation_prompt": null}
{"id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance local search by optimizing mutation scale and introduce adaptive cooling in simulated annealing to improve convergence.", "configspace": "", "generation": 66, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9adc1f4f-2c87-490d-b326-ee429ff432dd", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "a5467a32-442a-4c71-af15-37771ac5be5a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            if evaluations / self.budget > 0.5 and evaluations % (self.pop_size * 5) == 0:  # New random restart condition\n                population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))  # Random restart\n                scores = np.array([self.evaluate(ind) for ind in population])\n                evaluations += self.pop_size\n\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance global exploration by introducing a random restart mechanism to diversify search.", "configspace": "", "generation": 67, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "22332d4a-0097-44d6-903b-a57bce278c80", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + np.random.rand() * (self.f_max - self.f_min)  # Changed mutation factor adaptation\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            step_size = 0.005 * temperature  # Added dynamic step size change\n            candidate = best + np.random.normal(0, step_size, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing adaptive mutation scaling and improve local search efficiency with a dynamic step size.", "configspace": "", "generation": 68, "fitness": 0.7957719033397468, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.023. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.7648598990541253, 0.8046500035633717, 0.8178058074017434], "final_y": [0.15396238389283345, 0.15143067622659334, 0.14832429289064508]}, "mutation_prompt": null}
{"id": "754a472e-cbbc-4078-a26d-dddafa6febec", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        best_solution = population[np.argmax(scores)]\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            # Insert elitism\n            if scores[best_idx] > self.evaluate(best_solution):\n                best_solution = best_individual\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n\n                # Adjust population size dynamically\n                if conv_rate < self.conv_rate_thresh:\n                    self.pop_size = max(5, int(self.pop_size * 0.9))\n\n                refined_best = self.local_search(best_individual)\n                refined_score = self.evaluate(refined_best)\n                evaluations += self.local_search_iters\n\n                if refined_score > scores[best_idx]:\n                    population[best_idx] = refined_best\n                    scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce elitism, and dynamic population size adjustment based on convergence to improve diversity and exploration.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 90 is out of bounds for axis 0 with size 90').", "error": "IndexError('index 90 is out of bounds for axis 0 with size 90')", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {}, "mutation_prompt": null}
{"id": "d3a5c7bb-2fae-412a-93c5-c90a690dbdfd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        max_score = np.max(scores)\n        probabilities = scores / max_score  # Fitness-proportional selection probabilities\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            selected_idxs = np.random.choice(idxs, 3, replace=False, p=probabilities)\n            a, b, c = population[selected_idxs]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / max_score)\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Incorporate fitness-proportional selection in differential evolution to enhance diversity and exploitation.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {}, "mutation_prompt": null}
{"id": "00c81b61-4762-4988-999b-4625838b3dc4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            self.pop_size = min(max(self.dim * 5, self.pop_size * 2 // 3), self.dim * 15)  # Changed line\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size based on convergence to enhance exploration and exploitation balance.", "configspace": "", "generation": 71, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 90 is out of bounds for axis 0 with size 66').", "error": "IndexError('index 90 is out of bounds for axis 0 with size 66')", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {}, "mutation_prompt": null}
{"id": "2c5e708d-a92f-4d3a-8b9b-fe2470ea1c3b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Modified perturbation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            scale_factor = 1.02  # Adaptive scaling factor\n            distances[index[i]] = (scores[index[i + 1]] - scores[index[i - 1]]) * scale_factor\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive crowding distance scaling and modify local search perturbation for improved diversity and convergence.  ", "configspace": "", "generation": 72, "fitness": 0.8069675097442363, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845896801432493], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175100758975325]}, "mutation_prompt": null}
{"id": "aef465e8-df70-4a9f-9e31-d7f5e948aff5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + (self.f_max - self.f_min) * (1 - np.tanh(scores[i] / np.max(scores)))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Adjust mutation factor scaling using a nonlinear function and enhance local search by modifying mutation scale.", "configspace": "", "generation": 73, "fitness": 0.7999516569698345, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.006. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8035074833904118, 0.8045615821570525, 0.7917859053620389], "final_y": [0.1531849592349278, 0.15354698426528157, 0.15921836943556866]}, "mutation_prompt": null}
{"id": "50827ac3-7a4c-4bce-a554-9c6e12217751", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances) + 1e-9  # Adjusted normalization to avoid division by zero\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive crowding distance normalization to enhance diversity preservation in the population.", "configspace": "", "generation": 74, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "ac8f4390-53a7-4d93-b7a3-289dafa347ed", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            # Introduce diversity by reinitializing part of the population\n            reinit_indices = np.random.choice(self.pop_size, size=int(0.1 * self.pop_size), replace=False)\n            new_population[reinit_indices] = np.random.uniform(self.bounds.lb, self.bounds.ub, (len(reinit_indices), self.dim))\n            new_scores[reinit_indices] = [self.evaluate(ind) for ind in new_population[reinit_indices]]\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce diversity by randomly reinitializing a fraction of the population at each iteration to prevent premature convergence.", "configspace": "", "generation": 75, "fitness": 0.8013328554718729, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.011. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8079956635262313, 0.8107729457310761, 0.7852299571583115], "final_y": [0.1514282821905708, 0.1529507681424409, 0.1606280984935604]}, "mutation_prompt": null}
{"id": "6fcb7a8c-4b9d-4521-8594-05818dc0de9b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n        self.failed_improv_limit = 50  # Added line\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n        failed_improvements = 0  # Added line\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            if failed_improvements > self.failed_improv_limit:  # Added line\n                self.pop_size = int(self.pop_size * 0.9)  # Added line\n                population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))  # Added line\n                scores = np.array([self.evaluate(ind) for ind in population])  # Added line\n                evaluations += self.pop_size  # Added line\n                failed_improvements = 0  # Added line\n\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n                        failed_improvements = 0  # Added line\n                    else:\n                        failed_improvements += 1  # Added line\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance diversity by varying the population size dynamically and introducing a limit on consecutive failed improvements.", "configspace": "", "generation": 76, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "95b744bd-b52c-4d4e-abb3-ad5fde8adfb8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        crowding_distances = self.crowding_distance(population, scores)  # Added line for crowding distance\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - crowding_distances[i])  # Modified line\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Integrate crowding distance into selection and adjust mutation scale to improve diversity.", "configspace": "", "generation": 77, "fitness": 0.7940356950413072, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.013. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.777425277679791, 0.8103682821112057, 0.7943135253329248], "final_y": [0.1638044628469637, 0.1530110105780862, 0.15813697597904186]}, "mutation_prompt": null}
{"id": "b4d831f1-733f-4b5d-9c0e-7f5510cc3475", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()  # Calculate diversity as the mean of std deviations\n        self.cr = 0.9 * (1 - diversity)  # Adjust crossover rate based on diversity\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance DE adaptation by using a dynamic crossover rate linked to population diversity to improve convergence.", "configspace": "", "generation": 78, "fitness": 0.7809749714056792, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.010. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.769681578708646, 0.7945901820562783, 0.7786531534521135], "final_y": [0.16687027839638802, 0.1601017669387199, 0.15917915358718426]}, "mutation_prompt": null}
{"id": "3eedc1ce-999d-4b38-ab5f-60c1a111e4eb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        population_std = np.std(population, axis=0)  # Calculate standard deviation of population\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores) + np.mean(population_std))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve exploration by dynamically adjusting the mutation scale based on the diversity of the population.", "configspace": "", "generation": 79, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "60cb16b5-09f3-499d-bdec-ffc0f2c504a5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.95  # Changed cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n        last_best_score = -np.inf\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n            # Dynamic population resizing\n            if evaluations / self.budget > 0.5:\n                self.pop_size = int(self.dim * 15)  # Increase population size\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance adaptability by integrating dynamic population resizing and layer-wise refinement to optimize resource allocation and precision.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 147 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 147 is out of bounds for axis 0 with size 100')", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {}, "mutation_prompt": null}
{"id": "c6fca3ce-9c20-489f-b113-10a30ba8b9b1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            mutation_scale = 0.005 * temperature  # Adjusted mutation scale based on temperature\n            candidate = best + np.random.normal(0, mutation_scale, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Fine-tune the local search by dynamically adjusting the mutation scale based on the current temperature.", "configspace": "", "generation": 81, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "f60cfe55-431c-484a-8d57-7cd808b64a91", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.5 * (self.f_max - self.f_min) * np.random.rand()  # Changed mutation scaling\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.01 * temperature, self.dim)  # Adjusted local search step size\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce dynamic mutation scaling and adaptive local search step size to enhance convergence and solution quality.", "configspace": "", "generation": 82, "fitness": 0.7946631419462528, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.012. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.7804291601910545, 0.7945901820562783, 0.8089700835914253], "final_y": [0.15894455262637863, 0.1601017669387199, 0.15191730791454694]}, "mutation_prompt": null}
{"id": "5560e612-eef6-4988-8f51-4fc98e2ea9b3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9       \n        self.cr_min = 0.7  # Adjusted minimum crossover rate\n        self.cr_max = 1.0  # Adjusted maximum crossover rate\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cr = self.cr_min + (self.cr_max - self.cr_min) * (scores[i] / np.max(scores))  # Line changed\n            cross_points = np.random.rand(self.dim) < cr  # Line changed\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            perturbation_scale = 0.005 * (1 + 0.5 * np.random.rand())  # Line changed\n            candidate = best + np.random.normal(0, perturbation_scale * temperature, self.dim)  # Line changed\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by adapting crossover probability dynamically and refine local search with adaptive perturbations.", "configspace": "", "generation": 83, "fitness": 0.800442674954903, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.013. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8079956635262313, 0.8107729457310761, 0.7825594156074014], "final_y": [0.1514282821905708, 0.1529507681424409, 0.16271331357104046]}, "mutation_prompt": null}
{"id": "7571640e-7b38-4faf-8cd9-b832746bae43", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        best_idx = np.argmax(scores)  # Line changed\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            if np.random.rand() < 0.2:  # Adaptive mutation condition, line changed\n                f = self.f_max\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        new_population[best_idx] = population[best_idx]  # Preserve elite, line changed\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance the exploration phase with adaptive mutation and incorporate elite preservation to optimize convergence.", "configspace": "", "generation": 84, "fitness": 0.7990406404421903, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.011. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.783554510813955, 0.8041513430050837, 0.8094160675075321], "final_y": [0.1590082979244355, 0.15402392460306347, 0.14916376791988195]}, "mutation_prompt": null}
{"id": "b8d36789-fbd2-4da2-87bb-c900220dd2be", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        avg_score = np.mean(scores)  # Add a line\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - avg_score / np.max(scores))  # Changed line\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Refine mutation scale by dynamically adjusting based on average population score for improved exploration.", "configspace": "", "generation": 85, "fitness": 0.8019815225294039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.008. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8079283915114694, 0.807716486744789, 0.7902996893319533], "final_y": [0.15145446321586287, 0.15428398941224042, 0.15873646700183497]}, "mutation_prompt": null}
{"id": "2336ebd8-2251-43d5-9c22-32708094ccd8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual, adaptive_iters):  # Change 1\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(adaptive_iters):  # Change 2\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)  # Adjusted mutation scale\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    adaptive_iters = int(self.local_search_iters * (1 - conv_rate))  # Change 3\n                    refined_best = self.local_search(best_individual, adaptive_iters)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduced adaptive local search intensity based on convergence rate to improve refinement and convergence.", "configspace": "", "generation": 86, "fitness": 0.8069675941561926, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7845899333791184], "final_y": [0.14202310262788054, 0.1529507681424409, 0.16175082725228873]}, "mutation_prompt": null}
{"id": "a3e575e8-3b33-4906-81b4-64878f28b94c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.4 * (self.f_max - self.f_min) * (1 - np.exp(scores[i] - np.max(scores)))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            candidate = best + np.random.normal(0, 0.005 * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            acceptance_probability = np.exp(delta_score / (temperature + np.abs(candidate_score)))  # Line changed\n            if delta_score > 0 or acceptance_probability > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance adaptive mutation scaling and incorporate a sophisticated acceptance criterion in local search to improve convergence.", "configspace": "", "generation": 87, "fitness": 0.7952512201723329, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.015. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.7991280025253661, 0.8114159184988607, 0.7752097394927719], "final_y": [0.15491873383555854, 0.15282110018767003, 0.1664957692287804]}, "mutation_prompt": null}
{"id": "f1e3c7ec-0a38-467a-8b2b-d578c262a295", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.005 * (1 + np.random.rand())  # Changed mutation scale to be adaptive\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce adaptive mutation scale in local search to enhance exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.8070668483751898, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "1dd958df-3894-4d9b-8ba4-ceca2e8f1909", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7848876960361097], "final_y": [0.14202310262788054, 0.1529507681424409, 0.14989580721842788]}, "mutation_prompt": null}
{"id": "471a2cb5-2a47-4535-bedf-e721210b9995", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.005 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n                temperature *= 0.9  # Updated cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        dynamic_conv_thresh = self.conv_rate_thresh  # Adaptive convergence threshold\n\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < dynamic_conv_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n                dynamic_conv_thresh *= 0.95  # Line added: reduce the convergence threshold adaptively\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance convergence by introducing an adaptive convergence threshold and improving local search termination.", "configspace": "", "generation": 89, "fitness": 0.8070668483751898, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f1e3c7ec-0a38-467a-8b2b-d578c262a295", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7848876960361097], "final_y": [0.14202310262788054, 0.1529507681424409, 0.14989580721842788]}, "mutation_prompt": null}
{"id": "6fa4cb2c-ff9a-4dd0-a453-0b83a82ecd0d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.005 * (1 + np.random.rand())  # Changed mutation scale to be adaptive\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            gradient = np.gradient(candidate_score, candidate)  # Added gradient calculation\n            best -= 0.01 * gradient  # Gradient descent step\n            best = np.clip(best, self.bounds.lb, self.bounds.ub)\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhanced local search by incorporating a gradient-based step to refine exploration and exploitation balance.", "configspace": "", "generation": 90, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('invalid number of arguments').", "error": "TypeError('invalid number of arguments')", "parent_id": "f1e3c7ec-0a38-467a-8b2b-d578c262a295", "metadata": {}, "mutation_prompt": null}
{"id": "0fdf3ff5-0b19-4616-814a-11380161855c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            diversity = np.std(population) / np.mean(population)  # Calculate diversity in the population\n            self.cr = 0.8 * (1.0 - diversity) + 0.4  # Adjust crossover rate based on diversity\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.005 * (1 + np.random.rand())  # Changed mutation scale to be adaptive\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Changed cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve exploration by introducing a dynamic crossover rate strategy based on population diversity.", "configspace": "", "generation": 91, "fitness": 0.8017222663784711, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.010. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f1e3c7ec-0a38-467a-8b2b-d578c262a295", "metadata": {"aucs": [0.8077928444973662, 0.8099421500571055, 0.7874318045809419], "final_y": [0.15150722935916616, 0.1533160307916347, 0.15513854684155626]}, "mutation_prompt": null}
{"id": "d71edfe1-445e-4605-8fa3-7841038acf0a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))  # Line changed\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())  # Changed mutation scale to be smaller\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Modified cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)  # Line changed\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Introduce multi-phase local search adaptation to enhance solution refinement in high-dimensional spaces.", "configspace": "", "generation": 92, "fitness": 0.8070668490158844, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f1e3c7ec-0a38-467a-8b2b-d578c262a295", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7848876979581939], "final_y": [0.14202310262788054, 0.1529507681424409, 0.14989573350697583]}, "mutation_prompt": null}
{"id": "79cd4159-0de3-4482-8ccd-291c12aecbd3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.4  # Adjusted to enhance exploration\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        hierarchical_weight = np.linspace(self.f_max, self.f_min, self.dim)  # New weighting strategy\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = hierarchical_weight[i % self.dim]  # Use layered weight based on index\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Implement hierarchical layer mutation and adaptive weights to enhance exploration-exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.8067377325095544, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.022. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d71edfe1-445e-4605-8fa3-7841038acf0a", "metadata": {"aucs": [0.7776174278400523, 0.8109067531666139, 0.8316890165219969], "final_y": [0.163251190753965, 0.15291072592527366, 0.13677865064747807]}, "mutation_prompt": null}
{"id": "a423f310-fcfc-4494-bba7-e7fe0080dbe6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        diversity_factor = np.std(population) / np.mean(population)  # Calculate diversity factor\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < (self.cr * diversity_factor)  # Change: Adjust crossover rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0  # Simulated annealing initial temperature\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Adaptively adjust the crossover rate based on diversity in the population to balance exploration and exploitation.", "configspace": "", "generation": 94, "fitness": 0.7813685216954721, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.015. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d71edfe1-445e-4605-8fa3-7841038acf0a", "metadata": {"aucs": [0.7604711679028227, 0.7955623003000574, 0.7880720968835362], "final_y": [0.16562738329635363, 0.15965554530572557, 0.15667665695484856]}, "mutation_prompt": null}
{"id": "d52e108d-d217-492a-be1b-c8746d822af1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Modified cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve convergence by adjusting the cooling schedule in the simulated annealing step.", "configspace": "", "generation": 95, "fitness": 0.8070668491024507, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d71edfe1-445e-4605-8fa3-7841038acf0a", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7848876982178927], "final_y": [0.14202310262788054, 0.1529507681424409, 0.14989572354759562]}, "mutation_prompt": null}
{"id": "6593f92f-a238-4b40-83d7-389be188e9b1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            probabilities = scores / np.sum(scores)\n            a, b, c = population[np.random.choice(idxs, 3, replace=False, p=probabilities)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.85  # Adjusted cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve algorithm by incorporating fitness-proportional selection and adaptive mutation rates based on convergence.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "d52e108d-d217-492a-be1b-c8746d822af1", "metadata": {}, "mutation_prompt": null}
{"id": "7cd2fa69-6818-44af-859e-d6149a14aee8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            # Change: Adjust crossover rate dynamically\n            diversity = np.std(population, axis=0).mean() / (self.bounds.ub - self.bounds.lb).mean()\n            self.cr = 0.5 + 0.4 * (1 - diversity)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.9  # Modified cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration by dynamically adjusting crossover rates based on population diversity.", "configspace": "", "generation": 97, "fitness": 0.7796874995651749, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.021. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d52e108d-d217-492a-be1b-c8746d822af1", "metadata": {"aucs": [0.7634201817692461, 0.809674645347577, 0.7659676715787014], "final_y": [0.1511568459331617, 0.1533160307916347, 0.1687874173665942]}, "mutation_prompt": null}
{"id": "2a93f511-fb83-467a-95ea-4fa9751586df", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            f *= np.random.rand()  # Adaptive mutation scaling\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.95  # Adjusted cooling schedule\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Enhance exploration and escape strategies by integrating dynamic strategy adaptation and mutation scaling in DE.", "configspace": "", "generation": 98, "fitness": 0.7821141440453937, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.018. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d52e108d-d217-492a-be1b-c8746d822af1", "metadata": {"aucs": [0.7570005206745879, 0.7945901820562783, 0.794751729405315], "final_y": [0.16969404305773628, 0.1601017669387199, 0.15850035077386226]}, "mutation_prompt": null}
{"id": "6d798b99-a58e-4e21-ad97-dd77d0832a1a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = self.dim * 10\n        self.f_min = 0.5\n        self.f_max = 0.9\n        self.cr = 0.9\n        self.local_search_iters = 5\n        self.bounds = None\n        self.conv_rate_thresh = 0.01\n\n    def de_step(self, population, scores):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            f = self.f_min + 0.6 * (self.f_max - self.f_min) * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(a + f * (b - c), self.bounds.lb, self.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_individual = np.where(cross_points, mutant, population[i])\n            new_population[i] = new_individual\n\n        return new_population\n\n    def local_search(self, individual):\n        best = individual\n        best_score = self.evaluate(best)\n        temperature = 1.0\n\n        for _ in range(self.local_search_iters):\n            adaptive_scale = 0.0025 * (1 + np.random.rand())\n            candidate = best + np.random.normal(0, adaptive_scale * temperature, self.dim)\n            candidate = np.clip(candidate, self.bounds.lb, self.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            delta_score = candidate_score - best_score\n            if delta_score > 0 or np.exp(delta_score / temperature) > np.random.rand():\n                best, best_score = candidate, candidate_score\n            temperature *= 0.95  # Modified cooling schedule for simulated annealing\n\n        return best\n\n    def evaluate(self, individual):\n        return self.func(individual)\n\n    def crowding_distance(self, population, scores):\n        distances = np.zeros(self.pop_size)\n        index = np.argsort(scores)\n        for i in range(1, self.pop_size - 1):\n            distances[index[i]] = scores[index[i + 1]] - scores[index[i - 1]]\n        distances /= np.max(distances)\n        return distances\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        scores = np.array([self.evaluate(ind) for ind in population])\n        evaluations = self.pop_size\n\n        last_best_score = -np.inf\n        while evaluations < self.budget:\n            new_population = self.de_step(population, scores)\n            new_scores = np.array([self.evaluate(ind) for ind in new_population])\n            evaluations += self.pop_size\n\n            distances = self.crowding_distance(new_population, new_scores)\n            for i in range(self.pop_size):\n                if new_scores[i] > scores[i] or distances[i] > distances[np.argmax(scores)]:\n                    population[i], scores[i] = new_population[i], new_scores[i]\n\n            best_idx = np.argmax(scores)\n            best_individual = population[best_idx]\n\n            if evaluations + self.local_search_iters <= self.budget:\n                current_best_score = scores[best_idx]\n                conv_rate = (current_best_score - last_best_score) / abs(last_best_score + 1e-9)\n                if conv_rate < self.conv_rate_thresh:\n                    refined_best = self.local_search(best_individual)\n                    refined_score = self.evaluate(refined_best)\n                    evaluations += self.local_search_iters\n\n                    if refined_score > scores[best_idx]:\n                        population[best_idx] = refined_best\n                        scores[best_idx] = refined_score\n\n                last_best_score = current_best_score\n\n        return population[np.argmax(scores)]", "name": "HybridMetaheuristic", "description": "Improve the local search by modifying the temperature reduction factor for better exploration.", "configspace": "", "generation": 99, "fitness": 0.8070668492029055, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d52e108d-d217-492a-be1b-c8746d822af1", "metadata": {"aucs": [0.8255399033583832, 0.8107729457310761, 0.7848876985192568], "final_y": [0.14202310262788054, 0.1529507681424409, 0.14989571199035567]}, "mutation_prompt": null}
