{"id": "df914c5b-e652-45cd-ba66-c3a38f8aac25", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.5  # DE mutation factor\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.5 + np.random.rand() / 2  # inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "A novel hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) to balance exploration and exploitation in noisy optimization landscapes.", "configspace": "", "generation": 0, "fitness": 0.6603569536526961, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.6609572654665903], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21730847703432987]}, "mutation_prompt": null}
{"id": "ad6c334a-5a5a-47a2-b578-cf11c854b31d", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.5  # DE mutation factor\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced PSODEOptimizer by fine-tuning the inertia weight for better exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.6606887762267101, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.000. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "df914c5b-e652-45cd-ba66-c3a38f8aac25", "metadata": {"aucs": [0.660056797745749, 0.6610611343463422, 0.660948396588039], "final_y": [0.21891901516198964, 0.21724362873345537, 0.21734512187345245]}, "mutation_prompt": null}
{"id": "f38093c7-9080-4d28-8f47-06d79b1b3448", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.7  # DE mutation factor (changed from 0.5)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced PSODEOptimizer by modifying the DE mutation factor to improve solution diversity.", "configspace": "", "generation": 2, "fitness": 0.6609331264379396, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ad6c334a-5a5a-47a2-b578-cf11c854b31d", "metadata": {"aucs": [0.660056797745749, 0.6614569435200346, 0.6612856380480349], "final_y": [0.21891901516198964, 0.21658170774674101, 0.21671017554606498]}, "mutation_prompt": null}
{"id": "c3455235-b436-435f-8051-1a06b97c886b", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.7  # DE mutation factor (changed from 0.5)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced dynamic adjustment of DE crossover rate (CR) for balancing exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.6612864927381715, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f38093c7-9080-4d28-8f47-06d79b1b3448", "metadata": {"aucs": [0.660056797745749, 0.6619086268212642, 0.6618940536475013], "final_y": [0.21891901516198964, 0.2150224754093214, 0.21643924063675657]}, "mutation_prompt": null}
{"id": "a0d50611-5db0-4178-a068-4287a9071533", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced DE mutation factor (F) by slightly increasing it for improved exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.6614551232586253, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c3455235-b436-435f-8051-1a06b97c886b", "metadata": {"aucs": [0.660056797745749, 0.6621608531872888, 0.6621477188428381], "final_y": [0.21891901516198964, 0.21434574791569794, 0.21598367879733726]}, "mutation_prompt": null}
{"id": "fcdc43ea-a111-4aed-98a7-2bf277674b3d", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            learning_rate = 0.9 + 0.1 * (eval_count / self.budget)  # New adaptive learning rate\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i] * learning_rate\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive learning rate adjustment to enhance exploration and exploitation balance near optimal solutions.", "configspace": "", "generation": 5, "fitness": 0.6614549477665355, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a0d50611-5db0-4178-a068-4287a9071533", "metadata": {"aucs": [0.660056797745749, 0.6621605642093954, 0.6621474813444621], "final_y": [0.21891901516198964, 0.21434827642869758, 0.21600343242468178]}, "mutation_prompt": null}
{"id": "754b73e0-cd86-479d-847c-bede09b08b65", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + np.random.rand() * 0.3  # Adjusted inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce adaptive mutation factor (F) to improve exploration-exploitation balance in PSODEOptimizer.", "configspace": "", "generation": 6, "fitness": 0.661480974439404, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a0d50611-5db0-4178-a068-4287a9071533", "metadata": {"aucs": [0.660056797745749, 0.6621874038788422, 0.6621987216936207], "final_y": [0.21891901516198964, 0.21450678142499113, 0.21611417039116865]}, "mutation_prompt": null}
{"id": "aaf21071-7ade-4859-854f-cc6e41b1e684", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic inertia weight adjustment\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic inertia weight for PSO, enhancing convergence by linearly decreasing `w` from 0.9 to 0.4.", "configspace": "", "generation": 7, "fitness": 0.6614422150512689, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "754b73e0-cd86-479d-847c-bede09b08b65", "metadata": {"aucs": [0.660056797745749, 0.6619621329857425, 0.6623077144223153], "final_y": [0.21891901516198964, 0.216160641971602, 0.21520512968365235]}, "mutation_prompt": null}
{"id": "b91fe5be-75dc-41d5-bab3-e603db9f8200", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Dynamic inertia weight adjustment\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic inertia weight adjustment based on the budget utilization to improve convergence speed and solution accuracy.", "configspace": "", "generation": 8, "fitness": 0.6612802677229562, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "754b73e0-cd86-479d-847c-bede09b08b65", "metadata": {"aucs": [0.660056797745749, 0.6621460452306854, 0.6616379601924344], "final_y": [0.21891901516198964, 0.21605965269839644, 0.21611695258583097]}, "mutation_prompt": null}
{"id": "d1b78490-a8ed-42be-89c4-5d8c3ab721f4", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce dynamic inertia weight to enhance exploration-exploitation trade-off in PSODEOptimizer.", "configspace": "", "generation": 9, "fitness": 0.6615017819628498, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.662 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "754b73e0-cd86-479d-847c-bede09b08b65", "metadata": {"aucs": [0.660056797745749, 0.6621405640058526, 0.6623079841369477], "final_y": [0.21891901516198964, 0.21605965269839644, 0.21520512968365235]}, "mutation_prompt": null}
{"id": "52e8d009-0567-471d-8ff4-298f6bb919dd", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Dynamic inertia weight\n            c1 = 1.5  # cognitive coefficient\n            c2 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine dynamic parameters in PSODEOptimizer with adaptive social coefficient for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.661461907319862, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d1b78490-a8ed-42be-89c4-5d8c3ab721f4", "metadata": {"aucs": [0.660056797745749, 0.6620209400768894, 0.6623079841369477], "final_y": [0.21891901516198964, 0.21546590175293845, 0.21520512968365235]}, "mutation_prompt": null}
{"id": "63fd9189-8423-40b5-a00a-e01020c1bb9b", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Adjust the inertia weight to be more exploratory at the start and more exploitative towards the end in PSODEOptimizer.", "configspace": "", "generation": 11, "fitness": 0.66150244675474, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.662 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d1b78490-a8ed-42be-89c4-5d8c3ab721f4", "metadata": {"aucs": [0.660056797745749, 0.6621422853491956, 0.6623082571692755], "final_y": [0.21891901516198964, 0.21605965269839644, 0.21520512968365235]}, "mutation_prompt": null}
{"id": "1dafaa89-a2e9-41a7-9c1f-af8d1b045e55", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine the PSODEOptimizer by adjusting the DE mutation factor to dynamically increase exploration capabilities as the budget progresses.", "configspace": "", "generation": 12, "fitness": 0.6619445951961181, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.662 with standard deviation 0.001. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "63fd9189-8423-40b5-a00a-e01020c1bb9b", "metadata": {"aucs": [0.660056797745749, 0.662241421492104, 0.6635355663505013], "final_y": [0.21891901516198964, 0.2159591692097842, 0.21458139557987588]}, "mutation_prompt": null}
{"id": "d8ec1b8a-1968-4dd3-9995-868a0bbba371", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b])\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine PSODEOptimizer by increasing diversity in the mutation process with a small modification to the DE mutation strategy.", "configspace": "", "generation": 13, "fitness": 0.6619555337938391, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.662 with standard deviation 0.001. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1dafaa89-a2e9-41a7-9c1f-af8d1b045e55", "metadata": {"aucs": [0.660056797745749, 0.6622644102379722, 0.6635453933977962], "final_y": [0.21891901516198964, 0.21588058811610145, 0.2146092157154288]}, "mutation_prompt": null}
{"id": "71cd5bc2-2911-4ba4-8efc-e5213ac83c2f", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # New line for random perturbation\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced a random perturbation in Differential Evolution (DE) mutation to enhance exploration capabilities.", "configspace": "", "generation": 14, "fitness": 0.686416430077152, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.686 with standard deviation 0.036. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "d8ec1b8a-1968-4dd3-9995-868a0bbba371", "metadata": {"aucs": [0.660056797745749, 0.7375942514118783, 0.6615982410738286], "final_y": [0.21891901516198964, 0.15935395860507817, 0.21624152443165456]}, "mutation_prompt": null}
{"id": "244d55be-e8b8-4e9f-9e17-e6bba81b6a2a", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Adjusted dynamic cognitive coefficient\n            c2 = 1.5  # social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # New line for random perturbation\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced global exploration by adjusting the PSO cognitive coefficient dynamically based on remaining budget.", "configspace": "", "generation": 15, "fitness": 0.6686000516375091, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.669 with standard deviation 0.011. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "71cd5bc2-2911-4ba4-8efc-e5213ac83c2f", "metadata": {"aucs": [0.660056797745749, 0.6841463176412239, 0.6615970395255546], "final_y": [0.21891901516198964, 0.19268476689019887, 0.21624147041585284]}, "mutation_prompt": null}
{"id": "25beab1a-7ecb-4643-872c-27fa1ba8b8d9", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            velocity_mean = np.mean(self.velocities, axis=0)  # Historical velocity average\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social + 0.05 * velocity_mean  # Modified line\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # New line for random perturbation\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced particle velocity updating by incorporating historical velocity averages for improved convergence stability.", "configspace": "", "generation": 16, "fitness": 0.6864157302051757, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.686 with standard deviation 0.036. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "71cd5bc2-2911-4ba4-8efc-e5213ac83c2f", "metadata": {"aucs": [0.660056797745749, 0.7375934663819561, 0.661596926487822], "final_y": [0.21891901516198964, 0.159354307909505, 0.21624152176015743]}, "mutation_prompt": null}
{"id": "baae1b73-bbdd-46cf-9159-d562a07b0a46", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.1\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic random perturbation scale in Differential Evolution mutation for adaptive exploration.", "configspace": "", "generation": 17, "fitness": 0.6864197817110754, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.686 with standard deviation 0.036. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "71cd5bc2-2911-4ba4-8efc-e5213ac83c2f", "metadata": {"aucs": [0.660056797745749, 0.737580534914881, 0.6616220124725963], "final_y": [0.21891901516198964, 0.15937006811146393, 0.21619410286639207]}, "mutation_prompt": null}
{"id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Adjust the velocity clamping in PSO to enhance the exploration of the search space.", "configspace": "", "generation": 18, "fitness": 0.6872638430429436, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "baae1b73-bbdd-46cf-9159-d562a07b0a46", "metadata": {"aucs": [0.660056797745749, 0.7376342637167598, 0.664100467666322], "final_y": [0.21891901516198964, 0.15685663088862112, 0.21404662346804015]}, "mutation_prompt": null}
{"id": "9efd43af-22e0-4c76-8d2a-bd31164d6170", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.16  # Increased max velocity for broader search (changed from 0.15)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine the velocity clamping in PSO by slightly increasing `v_max` to expand search capabilities and improve convergence.", "configspace": "", "generation": 19, "fitness": 0.6872542371243621, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7376044710166714, 0.6641014426106657], "final_y": [0.21891901516198964, 0.1593225629798244, 0.21403570805588945]}, "mutation_prompt": null}
{"id": "6456ea07-3f48-4946-b7df-b9a2e82e9e83", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 52  # Increased population size to improve search (changed from 50)\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Increase population size to enhance exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.6635004699581716, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.664 with standard deviation 0.002. And the mean value of best solutions found was 0.214 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.6649935626511666, 0.6654510494775994, 0.660056797745749], "final_y": [0.2105464048634198, 0.21258460776863297, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "369899ce-f696-4b98-b57e-32cd7817a175", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.7  # cognitive and social coefficients (changed c2 from 1.5 to 1.7)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Fine-tune the PSO social coefficient to enhance the global search capability.", "configspace": "", "generation": 21, "fitness": 0.687243977595934, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7375719563362829, 0.6641031787057702], "final_y": [0.21891901516198964, 0.15687561687136953, 0.21404390499660153]}, "mutation_prompt": null}
{"id": "f47334bd-ddf6-4ffa-8a8d-23404c6f4446", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            self.v_max = 0.1 + 0.05 * (1 - eval_count / self.budget)  # Dynamic max velocity adjustment\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Fine-tune velocity clamping by dynamically adjusting max velocity based on remaining budget.", "configspace": "", "generation": 22, "fitness": 0.6872455924913116, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.737582071974068, 0.6640979077541178], "final_y": [0.21891901516198964, 0.15934894944616818, 0.21408351169836748]}, "mutation_prompt": null}
{"id": "46babf2e-c389-4bc6-a074-ff1fc5afdb54", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -(self.v_max * (1 - eval_count / self.budget)), self.v_max * (1 - eval_count / self.budget))\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Incorporate adaptive velocity clamping based on function evaluations to balance exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.6872468032086007, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7375776329868984, 0.6641059788931547], "final_y": [0.21891901516198964, 0.15720551631693946, 0.21352482963755337]}, "mutation_prompt": null}
{"id": "52435cec-45f7-4097-b246-a1878067dc3b", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.v_max = 0.15 * (1 - eval_count / self.budget)  # Dynamically adjusted max velocity\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhance search space exploration by dynamically adjusting the velocity clamping based on the evaluation count.", "configspace": "", "generation": 24, "fitness": 0.6872468032086007, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7375776329868984, 0.6641059788931547], "final_y": [0.21891901516198964, 0.15720551631693946, 0.21352482963755337]}, "mutation_prompt": null}
{"id": "5fb17cfa-85dd-43b8-9436-e38d8d2701c3", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.72  # DE crossover rate increased from 0.7 to 0.72\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Slightly increase the DE crossover rate to promote diversity and exploration.", "configspace": "", "generation": 25, "fitness": 0.6872638430429436, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7376342637167598, 0.664100467666322], "final_y": [0.21891901516198964, 0.15685663088862112, 0.21404662346804015]}, "mutation_prompt": null}
{"id": "187be94c-21eb-4e5e-ae51-cb7cf1ed2bb9", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Dynamic cognitive coefficient\n            c2 = 1.5 + 0.5 * (eval_count / self.budget)      # Dynamic social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce dynamic cognitive and social coefficients in PSO to improve adaptability and convergence.", "configspace": "", "generation": 26, "fitness": 0.6864848478015961, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.686 with standard deviation 0.036. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7376059277781069, 0.6617918178809328], "final_y": [0.21891901516198964, 0.156822271328922, 0.21481112830618487]}, "mutation_prompt": null}
{"id": "c931e5bf-5236-4612-a4c2-f6db20435362", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  # Dynamic population size reduction\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Apply dynamic population size reduction to refine exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.7038916003654617, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.704 with standard deviation 0.031. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "b5cd34c1-1aa8-4b3f-9487-f066c5cc395a", "metadata": {"aucs": [0.660056797745749, 0.7212507465683093, 0.7303672567823267], "final_y": [0.21891901516198964, 0.15903504273925717, 0.13926938836730807]}, "mutation_prompt": null}
{"id": "817271d0-bce6-43a0-b517-1ea6737145d6", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.92 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  # Dynamic population size reduction\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhance exploration by slightly increasing the inertia weight for PSO updates.", "configspace": "", "generation": 28, "fitness": 0.7038932712004721, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.704 with standard deviation 0.031. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "c931e5bf-5236-4612-a4c2-f6db20435362", "metadata": {"aucs": [0.660056797745749, 0.7212584635436582, 0.7303645523120088], "final_y": [0.21891901516198964, 0.1590234940217078, 0.1392729349616778]}, "mutation_prompt": null}
{"id": "d496b927-839e-425f-bb45-45fd1da5e8c6", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.92 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.55  # cognitive and social coefficients (changed c2 from 1.5 to 1.55)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  # Dynamic population size reduction\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a slight increase in the social coefficient to enhance global exploration in the PSO step.", "configspace": "", "generation": 29, "fitness": 0.7038932137023334, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.704 with standard deviation 0.031. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "817271d0-bce6-43a0-b517-1ea6737145d6", "metadata": {"aucs": [0.660056797745749, 0.7212560500626917, 0.7303667932985594], "final_y": [0.21891901516198964, 0.15902395679299375, 0.13926390631133356]}, "mutation_prompt": null}
{"id": "69a5bbc7-7db1-4709-847c-2d85cf1ca445", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15  # Increased max velocity for broader search (changed from 0.1)\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8  # DE mutation factor (changed from 0.7)\n        self.CR = 0.7  # DE crossover rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.92 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic inertia weight\n            c1, c2 = 1.5, 1.5  # cognitive and social coefficients\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)  # Dynamic crossover rate adjustment\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)  # Dynamic perturbation scale\n                perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Gaussian noise integration\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  # Dynamic population size reduction\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Integrate a small adaptive mutation factor scaling with a Gaussian noise component for improved exploration.", "configspace": "", "generation": 30, "fitness": 0.6900008807724888, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.690 with standard deviation 0.014. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "817271d0-bce6-43a0-b517-1ea6737145d6", "metadata": {"aucs": [0.6802716261975692, 0.6804792105656546, 0.7092518055542423], "final_y": [0.18994006934600105, 0.20267970455030226, 0.1359096902986352]}, "mutation_prompt": null}
{"id": "eae2a939-2aa9-4d7d-b9d2-9038d3becda4", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.92 - 0.5 * ((eval_count / self.budget) ** 2)  # Nonlinear inertia decay (changed)\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive cognitive coefficient (changed)\n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  # Adaptive social coefficient (changed)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Integrate adaptive learning rates and nonlinear inertia weight decay to enhance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.70453866107341, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.705 with standard deviation 0.032. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "817271d0-bce6-43a0-b517-1ea6737145d6", "metadata": {"aucs": [0.660056797745749, 0.7232185273961531, 0.7303406580783277], "final_y": [0.21891901516198964, 0.1368943001981049, 0.13934987996178672]}, "mutation_prompt": null}
{"id": "7099dd11-a02a-4390-aed1-e15a22118f13", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a small random inertia weight factor to enhance exploration capabilities.  ", "configspace": "", "generation": 32, "fitness": 0.7155846640778218, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.716 with standard deviation 0.041. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "eae2a939-2aa9-4d7d-b9d2-9038d3becda4", "metadata": {"aucs": [0.7737660094333006, 0.6844370414789567, 0.6885509413212085], "final_y": [0.14599519089188384, 0.19479427467438426, 0.1856852543872356]}, "mutation_prompt": null}
{"id": "8c379d8b-689d-4f05-b6ea-83050288b073", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.6 + 0.4 * (1 - eval_count / self.budget)  # Adjusted mutation scaling factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce adaptive mutation scaling in DE for enhanced diversity and convergence speed.", "configspace": "", "generation": 33, "fitness": 0.6678974423719408, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.668 with standard deviation 0.003. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.6659643016882439, 0.6719671891863985, 0.6657608362411799], "final_y": [0.21014985553405907, 0.19692313117130056, 0.20680582202152975]}, "mutation_prompt": null}
{"id": "f277fa78-d824-49ef-95f7-5e2bc7a52b1e", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.5 + 0.5 * np.random.rand()  # Line modified for dynamic F\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce adaptive learning factors and a dynamic differential weight to balance exploration and exploitation effectively.", "configspace": "", "generation": 34, "fitness": 0.6688715327130179, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.669 with standard deviation 0.001. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.6703111522230101, 0.6681093346421907, 0.6681941112738528], "final_y": [0.20139505554012727, 0.2023901394223948, 0.1941520786686023]}, "mutation_prompt": null}
{"id": "78dabf51-2b8e-429a-a458-d4cb49a188f5", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.6 + 0.5 * (1 - eval_count / self.budget)  # Modified line: Adjusted the scaling range of F\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Modify the mutation factor scaling in Differential Evolution to improve solution diversity and convergence.", "configspace": "", "generation": 35, "fitness": 0.708319765036725, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.708 with standard deviation 0.048. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.7765784713710143, 0.6740155474557494, 0.6743652762834109], "final_y": [0.13173568627008458, 0.19392118191042196, 0.20746527015470695]}, "mutation_prompt": null}
{"id": "86e1fc25-f94f-466f-875f-39068d5e6190", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Gaussian noise for perturbation\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Leverage adaptive random perturbation using Gaussian noise for enhanced exploration and to escape local optima.", "configspace": "", "generation": 36, "fitness": 0.6657689912888359, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.666 with standard deviation 0.008. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.660056797745749, 0.6771933783750099, 0.660056797745749], "final_y": [0.21891901516198964, 0.19254831788572235, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "4cf64321-482a-4e82-8f1e-43200097cd82", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 4)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Adjust the inertia weight factor to enhance exploitation near convergence.", "configspace": "", "generation": 37, "fitness": 0.7153711241923216, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.715 with standard deviation 0.041. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.7737787844246122, 0.6837599248268229, 0.6885746633255297], "final_y": [0.14592979918769855, 0.19909295079327338, 0.1856988624621564]}, "mutation_prompt": null}
{"id": "83ea23b3-c644-4b25-ab1a-087772473b3e", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Incorporate an adaptive velocity clamping mechanism for improved convergence control.", "configspace": "", "generation": 38, "fitness": 0.8270866665982113, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7099dd11-a02a-4390-aed1-e15a22118f13", "metadata": {"aucs": [0.82509627992309, 0.8472278722765736, 0.8089358475949702], "final_y": [0.11923381524985188, 0.12140761602802097, 0.11979900415353872]}, "mutation_prompt": null}
{"id": "5dc63afd-926a-4d03-bd76-b28056508b0b", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            # Opposite population for enhanced exploration\n            opposite_particles = bounds.lb + bounds.ub - self.particles\n            opposite_scores = np.array([func(p) for p in opposite_particles])\n            eval_count += self.population_size\n            better_opposite_indices = opposite_scores < self.personal_best_scores\n            self.personal_best_scores[better_opposite_indices] = opposite_scores[better_opposite_indices]\n            self.personal_best_positions[better_opposite_indices] = opposite_particles[better_opposite_indices]\n            global_best_opposite_index = np.argmin(opposite_scores)\n            if opposite_scores[global_best_opposite_index] < self.global_best_score:\n                self.global_best_score = opposite_scores[global_best_opposite_index]\n                self.global_best_position = opposite_particles[global_best_opposite_index]\n\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce opposition-based learning to enhance exploration capabilities.", "configspace": "", "generation": 39, "fitness": 0.7596326242513988, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.036. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "83ea23b3-c644-4b25-ab1a-087772473b3e", "metadata": {"aucs": [0.7947616026250817, 0.7110023257464333, 0.7731339443826812], "final_y": [0.13009794929345575, 0.18566108483246224, 0.13179042183714396]}, "mutation_prompt": null}
{"id": "36d4229d-1b8a-48f8-8528-ad7c240a492e", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand()) \n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  \n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Enhanced local exploration (adaptive perturbation)\n            adaptive_perturbation = 0.1 * np.exp(-5 * (eval_count / self.budget))\n            for i in range(self.population_size):\n                self.particles[i] += adaptive_perturbation * np.random.randn(self.dim)\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n        \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce enhanced local exploration using adaptive perturbation to balance exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.8259344874384361, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.030. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "83ea23b3-c644-4b25-ab1a-087772473b3e", "metadata": {"aucs": [0.7830272815048476, 0.8508852837005066, 0.8438908971099546], "final_y": [0.12912302551013477, 0.11887309673047142, 0.12042771687255627]}, "mutation_prompt": null}
{"id": "833e5b19-874c-403c-a8fb-1760556e2eff", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = (0.92 - 0.5 * ((eval_count / self.budget) ** 2)) * (0.9 + 0.2 * np.random.rand())  # Nonlinear inertia decay with random factor\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                # Lvy flight for enhanced exploration\n                levy_step = 0.01 * (np.random.normal(size=self.dim) / np.abs(np.random.normal(size=self.dim))**(1/3))\n                self.particles[i] += levy_step\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Apply Lvy flight for particle position updates to enhance exploration capability.", "configspace": "", "generation": 41, "fitness": 0.7629203250574959, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.065. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "83ea23b3-c644-4b25-ab1a-087772473b3e", "metadata": {"aucs": [0.8544491197307914, 0.7186683366980712, 0.7156435187436248], "final_y": [0.12097690332074751, 0.18500988340725233, 0.18523321401004988]}, "mutation_prompt": null}
{"id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine the inertia weight decay function for more effective exploration and exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.8455290858499963, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "83ea23b3-c644-4b25-ab1a-087772473b3e", "metadata": {"aucs": [0.8610749563260826, 0.8466786460512986, 0.8288336551726075], "final_y": [0.11931235302413368, 0.11879549529930666, 0.11966589779568682]}, "mutation_prompt": null}
{"id": "14fe04e9-067a-4c0d-9c43-31fa183c6b0f", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 2.0 - 1.0 * (eval_count / self.budget)  # Adaptive cognitive component\n            c2 = 2.0 - 0.5 * (eval_count / self.budget)  # Adaptive social component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce adaptive learning factors in the velocity update to enhance convergence speed.", "configspace": "", "generation": 43, "fitness": 0.8417848990126465, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.005. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8393083401855208, 0.8490744335180622, 0.8369719233343565], "final_y": [0.12356229688268194, 0.1210380538931799, 0.12165708624237048]}, "mutation_prompt": null}
{"id": "79807076-ab46-4185-8050-e07b7ee19b78", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Incorporate a dynamic parameter adjustment for better balance between exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.8455290858499963, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8610749563260826, 0.8466786460512986, 0.8288336551726075], "final_y": [0.11931235302413368, 0.11879549529930666, 0.11966589779568682]}, "mutation_prompt": null}
{"id": "3a4ee92e-bd32-4727-9514-fad878ed5180", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) * 0.5  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Fine-tune the velocity clamping strategy for enhanced convergence speed and stability.", "configspace": "", "generation": 45, "fitness": 0.8455290858499963, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8610749563260826, 0.8466786460512986, 0.8288336551726075], "final_y": [0.11931235302413368, 0.11879549529930666, 0.11966589779568682]}, "mutation_prompt": null}
{"id": "3dfe9a0e-7d22-4068-9965-84269733c7a2", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 1.5  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refine the inertia weight decay function for improved dynamic velocity clamping, enhancing exploration and exploitation balance.", "configspace": "", "generation": 46, "fitness": 0.8381831311118413, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.011. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8393216336470665, 0.8511008857965574, 0.8241268738919], "final_y": [0.11986949930567814, 0.11876645238813399, 0.1247984554582392]}, "mutation_prompt": null}
{"id": "c550dd8a-3b21-4b4f-8d93-4e030bf6f647", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Dynamic adjustment\n            c2 = 1.5 - 0.5 * (1 - eval_count / self.budget)  # Dynamic adjustment\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce dynamic adjustment to the cognitive and social coefficients for better convergence.  ", "configspace": "", "generation": 47, "fitness": 0.7862427040020249, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.061. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8403315887071755, 0.817421923254667, 0.7009746000442324], "final_y": [0.1212814096463013, 0.1190367039506609, 0.1872510548449834]}, "mutation_prompt": null}
{"id": "46c3d907-95ed-4342-acda-29fbd3a67486", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 2.0 - (0.5 * (eval_count / self.budget))  # Adaptive cognitive coefficient\n            c2 = 1.0 + (0.5 * (eval_count / self.budget))  # Adaptive social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive cognitive and social coefficients to further enhance exploration and exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.7862427040020249, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.061. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8403315887071755, 0.817421923254667, 0.7009746000442324], "final_y": [0.1212814096463013, 0.1190367039506609, 0.1872510548449834]}, "mutation_prompt": null}
{"id": "788c565d-2a13-4b9d-a236-de35c5cfed90", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget) + 0.1 * np.sin(2 * np.pi * eval_count / self.budget)  # Updated inertia weight decay with dynamic component\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget)  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Add a dynamic component to the inertia weight for enhanced exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.8399200650488847, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.011. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8500001348140145, 0.8450746395853148, 0.8246854207473246], "final_y": [0.12318712044901747, 0.1204071841327462, 0.1249517459334426]}, "mutation_prompt": null}
{"id": "d6a98865-d987-4ac8-9c7b-b47ac0c3c1b7", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget)\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a time-varying cognitive component to enhance exploration and exploitation trade-offs.", "configspace": "", "generation": 50, "fitness": 0.8455943310231276, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c6452feb-76d7-4af2-adbf-c4b6b53c60e8", "metadata": {"aucs": [0.8576459846849112, 0.8496290154965098, 0.8295079928879616], "final_y": [0.1210188825189652, 0.11897557450391871, 0.12052458255881238]}, "mutation_prompt": null}
{"id": "6c6a2049-be6a-428a-8d28-d030990122d8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic perturbation scale based on the population's diversity to enhance convergence. ", "configspace": "", "generation": 51, "fitness": 0.8457389233891591, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d6a98865-d987-4ac8-9c7b-b47ac0c3c1b7", "metadata": {"aucs": [0.8579250190022282, 0.8491709292701932, 0.8301208218950562], "final_y": [0.12050006748337683, 0.11926560532304509, 0.11920488517050765]}, "mutation_prompt": null}
{"id": "60523c78-2566-4fe0-b24a-1d3849718559", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Integrate an adaptive mutation perturbation that considers both evaluation progress and population diversity to enhance exploration without compromising convergence speed.", "configspace": "", "generation": 52, "fitness": 0.8459881151088177, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6c6a2049-be6a-428a-8d28-d030990122d8", "metadata": {"aucs": [0.858851629035912, 0.8496355207326314, 0.8294771955579098], "final_y": [0.11897365432411733, 0.11891903075824872, 0.12048674299652018]}, "mutation_prompt": null}
{"id": "e9f94225-743a-40d7-9d35-33b66453e528", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Integrate an adaptive mutation perturbation that considers both evaluation progress and population diversity to enhance exploration without compromising convergence speed.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "60523c78-2566-4fe0-b24a-1d3849718559", "metadata": {"aucs": [0.858851629035912, 0.8496355207326314, 0.8294771955579098], "final_y": [0.11897365432411733, 0.11891903075824872, 0.12048674299652018]}, "mutation_prompt": null}
{"id": "579288e0-f225-48f1-9150-9c72923341d6", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            success_count = 0  # Count successful updates\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    success_count += 1  # Increment success count\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (success_count / self.population_size)  # Adjusted inertia weight based on success rate\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (success_count / self.population_size)  # Adjusted CR based on success rate\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce an adaptive inertia weight and adaptive CR based on success rates for improved convergence and diversity balance.", "configspace": "", "generation": 54, "fitness": 0.8299990550767923, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.007. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "60523c78-2566-4fe0-b24a-1d3849718559", "metadata": {"aucs": [0.8302119683072628, 0.8216663825628361, 0.8381188143602779], "final_y": [0.11957075821056651, 0.1228939658516599, 0.11905459178088751]}, "mutation_prompt": null}
{"id": "55c88259-5638-4f06-b40d-106b9226d97a", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget) * (1 + 0.02 * np.mean(population_std))))  # Change made here\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic population size update factor based on the diversity measure to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "60523c78-2566-4fe0-b24a-1d3849718559", "metadata": {}, "mutation_prompt": null}
{"id": "4f833de7-d8bf-453d-bec4-4e55d2e9baf8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Implement dynamic population resizing and adaptive control parameter adjustments to enhance exploration and exploitation balance while adhering to the 3.8% modification constraint.", "configspace": "", "generation": 56, "fitness": 0.8459881151088177, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "60523c78-2566-4fe0-b24a-1d3849718559", "metadata": {"aucs": [0.858851629035912, 0.8496355207326314, 0.8294771955579098], "final_y": [0.11897365432411733, 0.11891903075824872, 0.12048674299652018]}, "mutation_prompt": null}
{"id": "1da5b878-002f-48d6-9177-afb4fc756e03", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced a dynamic adjustment for the inertia weight to improve exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.8472516339216583, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "60523c78-2566-4fe0-b24a-1d3849718559", "metadata": {"aucs": [0.8613565773012153, 0.847543535117345, 0.8328547893464147], "final_y": [0.12122029355973529, 0.11919980226762783, 0.1188482447556436]}, "mutation_prompt": null}
{"id": "9f7b27f2-8d2c-451e-a7f7-a29a3fa61483", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.7 + 0.5 * (eval_count / self.budget)  # Adjusted cognitive component\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced the exploration phase by adjusting the cognitive component for improved diversity.", "configspace": "", "generation": 58, "fitness": 0.8409703910862983, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.009. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.8516166243598158, 0.8406687404127813, 0.8306258084862981], "final_y": [0.12259571946178671, 0.11931259258064308, 0.11887435953561232]}, "mutation_prompt": null}
{"id": "91115adf-3de0-4e76-a2fa-4732224283d8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            c1 *= 0.9 + 0.1 * np.cos(2 * np.pi * eval_count / self.budget)  # Adaptive cognitive scaling\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive cognitive and social scaling for improved balance between exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.838965665721395, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.8580288965581928, 0.8316938906165382, 0.8271742099894541], "final_y": [0.12085851063596398, 0.1261292270628548, 0.12201953963985401]}, "mutation_prompt": null}
{"id": "b2d704e5-9c0b-45b5-b87a-9a502297b5f4", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + 0.7 * cognitive + social  # Non-linear adjustment to cognitive component\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Refined the velocity update mechanism by incorporating a non-linear adjustment factor for improved convergence.", "configspace": "", "generation": 60, "fitness": 0.8392005564840578, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.013. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.8560162961036302, 0.8363420952336775, 0.8252432781148655], "final_y": [0.1237392031868968, 0.12305824707191948, 0.11974366699040617]}, "mutation_prompt": null}
{"id": "aebb21be-1188-4c6f-b29f-36f413a081c8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / (2 * self.budget))))  # Modified line for better adaptive scaling\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive population size scaling for better convergence and solution quality.", "configspace": "", "generation": 61, "fitness": 0.8307857880965189, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.013. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.848165761712173, 0.8265605840739907, 0.8176310185033933], "final_y": [0.1260505264494053, 0.12051529506880865, 0.11897411027744664]}, "mutation_prompt": null}
{"id": "39b8a405-06a8-4ae7-a62f-1ec257e7993e", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                sinusoidal_perturbation = 0.05 * np.sin(2 * np.pi * eval_count / self.budget)  # Sinusoidal perturbation\n                self.velocities[i] = w * self.velocities[i] + cognitive + social + sinusoidal_perturbation\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved exploration by adding a sinusoidal perturbation to velocity update for diverse movement patterns.", "configspace": "", "generation": 62, "fitness": 0.8460817567327815, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.014. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.8615708474226069, 0.8482178201296119, 0.8284566026461256], "final_y": [0.12079486066707767, 0.11887166057076404, 0.12148713481235163]}, "mutation_prompt": null}
{"id": "31fb2e9e-e1b4-4efe-9418-14307ffad6ce", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 1.5  # changed divisor for dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.05 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced the dynamic velocity clamping to improve convergence speed while maintaining exploration-exploitation balance.", "configspace": "", "generation": 63, "fitness": 0.8436533003415886, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.857482930614565, 0.8513730958463614, 0.822103874563839], "final_y": [0.11929156961332199, 0.11927683791095489, 0.12531610253460657]}, "mutation_prompt": null}
{"id": "d71aa0ef-deea-464e-957f-0e746ba2c73d", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced the convergence rate by increasing the population diversity component in the DE perturbation strategy.", "configspace": "", "generation": 64, "fitness": 0.8473902998982288, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1da5b878-002f-48d6-9177-afb4fc756e03", "metadata": {"aucs": [0.8616101429702542, 0.8476379438220307, 0.8329228129024016], "final_y": [0.12074114849123496, 0.11917968728179595, 0.11879246188329062]}, "mutation_prompt": null}
{"id": "57b7f4a8-b120-427c-a3f4-dc347dc243c8", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            w = w * (1 + np.mean(population_std))  # Adaptive inertia weight based on population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced an adaptive inertia weight to balance exploration and exploitation based on diversity in PSODEOptimizer.", "configspace": "", "generation": 65, "fitness": 0.8473902998982288, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d71aa0ef-deea-464e-957f-0e746ba2c73d", "metadata": {"aucs": [0.8616101429702542, 0.8476379438220307, 0.8329228129024016], "final_y": [0.12074114849123496, 0.11917968728179595, 0.11879246188329062]}, "mutation_prompt": null}
{"id": "143757a0-93a3-4290-b9ed-0fdc4adcc4b9", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.1 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget) * np.mean(population_std)))  # change applied here\n\n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved convergence by dynamically adjusting population size based on diversity, enhancing exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "d71aa0ef-deea-464e-957f-0e746ba2c73d", "metadata": {}, "mutation_prompt": null}
{"id": "8e8c0627-bd5d-4e41-8844-158439ffa97d", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.6 + 0.3 * np.sin(eval_count / self.budget * np.pi)  # Altered adaptive scaling\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.15 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploitation through adaptive scaling and improved diversity balance for better solution precision.", "configspace": "", "generation": 67, "fitness": 0.7814404656657569, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.051. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "d71aa0ef-deea-464e-957f-0e746ba2c73d", "metadata": {"aucs": [0.7808907401033649, 0.7196245767732542, 0.8438060801206515], "final_y": [0.12647781481271436, 0.18500984804923892, 0.12061421680324069]}, "mutation_prompt": null}
{"id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive mutation scale based on diversity to enhance exploration in later stages.", "configspace": "", "generation": 68, "fitness": 0.847423734399679, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d71aa0ef-deea-464e-957f-0e746ba2c73d", "metadata": {"aucs": [0.8616357006036741, 0.8477091127602475, 0.8329263898351152], "final_y": [0.12052329234979964, 0.11900761129186666, 0.11878955885427078]}, "mutation_prompt": null}
{"id": "cd545a7e-976a-4811-8a79-5dab580be6f2", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)**2  # Non-linear inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced a non-linear decay for the inertia weight to enhance exploitation in later stages.", "configspace": "", "generation": 69, "fitness": 0.8398959110129165, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.851989108259285, 0.8407916484443054, 0.826906976335159], "final_y": [0.12637446916926498, 0.12010084855038416, 0.12160603271510984]}, "mutation_prompt": null}
{"id": "dfc81983-be2a-4950-9087-9c670f99a6e4", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget) + 0.2 * np.mean(population_std)  # Modified F to depend on population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced dynamic adjustment of `F` based on population diversity to enhance convergence stability.", "configspace": "", "generation": 70, "fitness": 0.8247982771389601, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.015. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8146899005499229, 0.813792561369546, 0.8459123694974116], "final_y": [0.12689658253927183, 0.1280488420879704, 0.12270067273313134]}, "mutation_prompt": null}
{"id": "18a2d2b3-51eb-44d4-9d3e-71402410abc6", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.5 * np.sin(np.pi * eval_count / self.budget)  # Adjusted sine modulation amplitude\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration by adjusting the sine modulation amplitude in the time-varying cognitive component.", "configspace": "", "generation": 71, "fitness": 0.8393282042249733, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.012. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8485935693356412, 0.8473064853183215, 0.8220845580209574], "final_y": [0.12243597154466612, 0.1211599732968821, 0.12870369286748462]}, "mutation_prompt": null}
{"id": "2109a640-459a-4682-8110-bfa4b7461c05", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = 0.5 * np.linalg.norm(self.global_best_position - self.particles[i]) / (1.0 + eval_count / self.budget)  # Modified dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration by adjusting the dynamic velocity clamping factor for improved diversity control.", "configspace": "", "generation": 72, "fitness": 0.8283351061097383, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.027. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8625306575486387, 0.8250528693367682, 0.7974217914438078], "final_y": [0.12126903794696453, 0.12228105908429554, 0.13200118788404525]}, "mutation_prompt": null}
{"id": "cdc0e42e-65b8-4c56-9ee8-92f67f0ba91c", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                sine_wave_component = 0.1 * np.sin(2 * np.pi * eval_count / self.budget) * (self.global_best_position - self.particles[i])  # New line\n                self.velocities[i] = w * self.velocities[i] + cognitive + social + sine_wave_component\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration by incorporating a sinusoidal time-varying component in the velocity update.", "configspace": "", "generation": 73, "fitness": 0.8408037203203285, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8415400870294587, 0.8485346909568201, 0.8323363829747066], "final_y": [0.12181924330201654, 0.11937981267644349, 0.11927632739997174]}, "mutation_prompt": null}
{"id": "876b207a-94ae-4bd7-ab2c-fd49eeff74a1", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget) + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic cognitive component\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration by introducing a dynamic acceleration coefficient for the cognitive component.", "configspace": "", "generation": 74, "fitness": 0.8425654923471372, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8532795746934194, 0.8454653868531674, 0.8289515154948244], "final_y": [0.1193048146690251, 0.11879283538177354, 0.11962898295838797]}, "mutation_prompt": null}
{"id": "81d8b633-59c3-4912-b849-c6c963e345ed", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.5 * (eval_count / self.budget)  \n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i] + np.random.uniform(-0.01, 0.01, self.dim)  # Adding a small random shift to enhance diversity\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced particle diversity by incorporating a small random shift to each particle's position in the PSO update phase.", "configspace": "", "generation": 75, "fitness": 0.7879058097145314, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.050. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.7999097819067394, 0.8419479548720115, 0.7218596923648434], "final_y": [0.12136248252841153, 0.12226849215414892, 0.18500984965579714]}, "mutation_prompt": null}
{"id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration with dynamically adjusted cognitive and social components in PSO.  ", "configspace": "", "generation": 76, "fitness": 0.8498914310594561, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fd9932cd-7348-43b5-8c0e-62f64603996a", "metadata": {"aucs": [0.8664941883237454, 0.849414918225815, 0.833765186628808], "final_y": [0.11883787111765276, 0.11877465375446927, 0.11875305705932648]}, "mutation_prompt": null}
{"id": "0707e3bd-70e0-4c94-8ee2-26dff4c7fe2b", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.5 + 0.4 * np.cos(np.pi * eval_count / self.budget)  # Updated inertia weight with cosine function\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved exploration in PSO by adjusting the inertia weight formula.", "configspace": "", "generation": 77, "fitness": 0.8435945921840636, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.861204633777182, 0.8412673971296982, 0.8283117456453107], "final_y": [0.12012834427446983, 0.12021670303370813, 0.12162368419313241]}, "mutation_prompt": null}
{"id": "b2144789-fc29-442b-a8f2-522e88fb19ea", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / (1 + eval_count / self.budget)  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced PSO with dynamic component adjustment and adaptive velocity clamping for improved exploration and convergence.", "configspace": "", "generation": 78, "fitness": 0.8368093501821882, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.010. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8502109699975471, 0.8261679381880794, 0.8340491423609379], "final_y": [0.12347034573472027, 0.12335955030241508, 0.12033288042863866]}, "mutation_prompt": null}
{"id": "ddfa0f2f-4d54-4590-8250-c35b8fad8a46", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            population_std = np.std(self.particles, axis=0)\n            w = 0.9 - (0.5 * (np.mean(population_std) / (bounds.ub - bounds.lb)))  # Adaptive inertia weight based on diversity\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive inertia weight based on diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.842842517130971, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.010. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8526589890082069, 0.8473126650518793, 0.8285558973328266], "final_y": [0.12703291405304473, 0.1193648266184858, 0.1202679899747332]}, "mutation_prompt": null}
{"id": "ae49878b-e2df-4f98-8d0a-e1f3e2118efe", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.6 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved PSO exploration by adjusting inertia dynamics for enhanced convergence.", "configspace": "", "generation": 80, "fitness": 0.8481854638946893, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8685658951261371, 0.8462174143497805, 0.8297730822081504], "final_y": [0.11877863174546077, 0.11885300216875216, 0.1195320626878793]}, "mutation_prompt": null}
{"id": "6e3a0660-6710-4afe-aa70-a762ba3815d1", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget) + 0.1 * np.sin(np.pi * 2 * eval_count / self.budget)  # Dynamic inertia oscillation\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced a dynamic inertia weight oscillation to balance exploration and exploitation in PSO.", "configspace": "", "generation": 81, "fitness": 0.8369411748232377, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.019. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.854928890791127, 0.8457539054625647, 0.8101407282160216], "final_y": [0.12501558030859106, 0.11905188338445805, 0.12649723065732354]}, "mutation_prompt": null}
{"id": "d0d12683-e835-49d4-a88b-f58d8397f808", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.7 * (eval_count / self.budget)  # Adjusted inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Adaptive inertia weight modulation for improved convergence in PSO.", "configspace": "", "generation": 82, "fitness": 0.8437776400364628, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.011. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.855435066832479, 0.8470380850494805, 0.8288597682274291], "final_y": [0.12194007771975923, 0.1188136704461854, 0.12034359332443056]}, "mutation_prompt": null}
{"id": "4246d9e5-0000-4069-b260-910e4daf4825", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.6 + 0.5 * (1 - eval_count / self.budget)  # Adjusted mutation scaling factor\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Fine-tuning the DE mutation scaling factor for improved exploration and exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.8483357806811685, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8666374627489689, 0.846716906056472, 0.8316529732380645], "final_y": [0.11876556962592044, 0.11889140426284683, 0.11876562420005321]}, "mutation_prompt": null}
{"id": "c0a87ca2-1ff8-4983-8f25-320e381fe310", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2.5  # dynamic velocity clamping adjusted\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved balance between exploration and exploitation by tweaking velocity update.", "configspace": "", "generation": 84, "fitness": 0.8213581821692738, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.039. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8494823872367573, 0.8479176676637283, 0.7666744916073358], "final_y": [0.12154375199228828, 0.11880748485319825, 0.14308258044431799]}, "mutation_prompt": null}
{"id": "7ff4f7bf-3225-48e3-bcf6-893edc53c0d7", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / (1 + 0.1 * np.linalg.norm(self.particles[i]))  # Updated dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Integrated adaptive step-size scaling for enhanced convergence speed and stability.", "configspace": "", "generation": 85, "fitness": 0.7977940810052232, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.023. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8297988094825152, 0.785081734844811, 0.7785016986883434], "final_y": [0.12538108157653793, 0.13771431293227865, 0.1345908722898822]}, "mutation_prompt": null}
{"id": "cf3a8e31-5064-4bcd-a8de-19d5e604fb16", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration with dynamically adjusted cognitive and social components in PSO.  ", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8664941883237454, 0.849414918225815, 0.833765186628808], "final_y": [0.11883787111765276, 0.11877465375446927, 0.11875305705932648]}, "mutation_prompt": null}
{"id": "bfc19cc8-6ae5-4b0c-9b22-5875128ab0b5", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget))) + 1  # Slight adjustment for dynamic diversity\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Small perturbation-based adaptive dynamic diversity enhancement in PSO with DE for improved exploration.", "configspace": "", "generation": 87, "fitness": 0.7925750009177687, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.054. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8412340582849516, 0.819505903500679, 0.7169850409676755], "final_y": [0.122248224000153, 0.12394250931657136, 0.18531669631457082]}, "mutation_prompt": null}
{"id": "5a7be9fe-a107-49c1-b533-68f6173a5c4e", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.9 - 0.5 * (eval_count / self.budget)\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.3 * np.mean(population_std))  # Increased diversity weight\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive inertia and diversity-based perturbation to enhance exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.8498266821207473, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8663480231374759, 0.8493923071425535, 0.8337397160822126], "final_y": [0.1191048121096493, 0.11877388866849181, 0.11877936958198343]}, "mutation_prompt": null}
{"id": "1807796c-fdb5-4db7-8b6a-6240a1bec863", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget) + 0.1 * np.sin(2 * np.pi * eval_count / self.budget)  # Introduced oscillating term\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Incorporate a non-linear, oscillating term in the inertia weight for improved adaptability over iterations.", "configspace": "", "generation": 89, "fitness": 0.8369411748232377, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.019. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.854928890791127, 0.8457539054625647, 0.8101407282160216], "final_y": [0.12501558030859106, 0.11905188338445805, 0.12649723065732354]}, "mutation_prompt": null}
{"id": "2440de4e-becf-4c27-83ed-7dbac12254eb", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            self.CR = 0.7 + 0.3 * (1.0 - np.mean(population_std) / np.max((1e-9, np.std(bounds.ub - bounds.lb))))  # Dynamic CR based on diversity\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:  # Dynamic CR based on diversity\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduce a dynamic crossover rate modulation based on particle diversity to refine exploration and exploitation balance in PSODEOptimizer.", "configspace": "", "generation": 90, "fitness": 0.7130716642828271, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.713 with standard deviation 0.002. And the mean value of best solutions found was 0.187 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.714114630318889, 0.7109084513816117, 0.7141919111479804], "final_y": [0.187618251473733, 0.18752529199581203, 0.18603091864465904]}, "mutation_prompt": null}
{"id": "68e5a71f-9aa2-4d5f-955a-6be924cf96f4", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.2 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Enhanced exploration with dynamically adjusted cognitive and social components in PSO with improved mutation perturbation scale.", "configspace": "", "generation": 91, "fitness": 0.8498502781421982, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8663678879177521, 0.8493576161727818, 0.8338253303360605], "final_y": [0.11885587325032221, 0.11875340153420211, 0.1188041651671512]}, "mutation_prompt": null}
{"id": "c5dbab23-fa90-49fb-814d-350c6b533c59", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget) + 0.1 * np.sin(2 * np.pi * eval_count / self.budget)  # Introduced dynamic F adjustment\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Utilizing a dynamic learning factor adjustment for improved balance between exploration and exploitation in PSO-DE hybrid.", "configspace": "", "generation": 92, "fitness": 0.8365578601112865, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.010. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8436425606030751, 0.8431027742766999, 0.8229282454540846], "final_y": [0.12192702100704633, 0.1213269215769397, 0.12364342146798768]}, "mutation_prompt": null}
{"id": "e09cac76-7408-4eb0-8a8d-e26197c85e04", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.4 * (eval_count / self.budget)  # Updated inertia weight decay for improved exploitation\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved exploitation by modifying the inertia weight decay function in the PSO component for better convergence.", "configspace": "", "generation": 93, "fitness": 0.8450545101951312, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.010. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8557133669316868, 0.847510857408862, 0.8319393062448449], "final_y": [0.1223584924982144, 0.11881600810655524, 0.11891562542296441]}, "mutation_prompt": null}
{"id": "c428a0c6-da17-4389-8d72-42c3638c4d8f", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Incorporate adaptive mutation scaling based on the diversity of the population to enhance exploration.", "configspace": "", "generation": 94, "fitness": 0.8498914310594561, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8664941883237454, 0.849414918225815, 0.833765186628808], "final_y": [0.11883787111765276, 0.11877465375446927, 0.11875305705932648]}, "mutation_prompt": null}
{"id": "e6b1889e-2b64-436a-9a54-d615d2c53a9a", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Changed line: Introduced adaptive F\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive learning rate for DE to enhance exploitation and convergence precision.", "configspace": "", "generation": 95, "fitness": 0.8366404339354907, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.008. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8482915723307722, 0.8306800833594746, 0.8309496461162253], "final_y": [0.12293173316089734, 0.12226864663510018, 0.11899511561006582]}, "mutation_prompt": null}
{"id": "65726fcf-9cf5-4200-9f75-435bb81f0591", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation + 0.1 * (self.global_best_position - self.personal_best_positions[i])  # Added global best influence\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive particle update strategy by incorporating global best position into mutation for enhanced convergence.", "configspace": "", "generation": 96, "fitness": 0.8381393820627215, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.006. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8429414036557507, 0.8420793096219916, 0.8293974329104221], "final_y": [0.12178054467186006, 0.12363316838745353, 0.12010933980827021]}, "mutation_prompt": null}
{"id": "22f97943-5e8d-4105-bb90-cad2bf8a2b8d", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            population_std = np.std(self.particles, axis=0)  # Calculate population diversity\n            c1 = 1.5 + 0.6 * (eval_count / self.budget) * np.mean(population_std)  # Dynamic cognitive component\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced a dynamic adjustment to the cognitive component based on population diversity for enhanced exploration and convergence.", "configspace": "", "generation": 97, "fitness": 0.8268783838739208, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.014. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8463958321196564, 0.821873370229774, 0.8123659492723315], "final_y": [0.12331491398395511, 0.12724579262980962, 0.12557063368811106]}, "mutation_prompt": null}
{"id": "7f95c3ed-9ed4-4d19-aa61-cdb3be2ab5b2", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 - 0.4 * np.sin(np.pi * eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Improved PSO-DE hybrid by adjusting cognitive component dynamically to enhance convergence.", "configspace": "", "generation": 98, "fitness": 0.8329974588449378, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.015. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8508488982506208, 0.8346331717112037, 0.8135103065729892], "final_y": [0.126210654161672, 0.12457414874607209, 0.12298502751596196]}, "mutation_prompt": null}
{"id": "c345c539-cc60-4c9c-a35d-4caef72681ac", "solution": "import numpy as np\n\nclass PSODEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.v_max = 0.15\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.F = 0.8\n        self.CR = 0.7\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                if eval_count >= self.budget:\n                    break\n            \n            # Update velocities and positions (PSO)\n            w = 0.9 - 0.5 * (eval_count / self.budget)  # Updated inertia weight decay\n            c1 = 1.5 + 0.6 * (eval_count / self.budget)  # Slightly increased cognitive component for better convergence\n            c2 = 1.5 - 0.5 * (eval_count / self.budget) + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Time-varying cognitive component\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social = c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                v_max_dynamic = np.linalg.norm(self.global_best_position - self.particles[i]) / 2  # dynamic velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -v_max_dynamic, v_max_dynamic)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], bounds.lb, bounds.ub)\n            \n            # Differential Evolution mutation and crossover\n            self.CR = 0.7 + 0.3 * (eval_count / self.budget)\n            self.F = 0.7 + 0.4 * (1 - eval_count / self.budget)\n            population_std = np.std(self.particles, axis=0)  # Added line for calculating population diversity\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                perturbation_scale = 0.05 + 0.1 * (eval_count / self.budget) * (1.0 + 0.2 * np.mean(population_std))  # Modified perturbation scale\n                perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n                mutant = self.personal_best_positions[a] + self.F * (self.personal_best_positions[b] - self.personal_best_positions[c]) + 0.1 * (self.particles[a] - self.particles[b]) + perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.particles[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial\n                if eval_count >= self.budget:\n                    break\n            \n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))\n        \n        return self.global_best_position, self.global_best_score", "name": "PSODEOptimizer", "description": "Introduced adaptive mutation scaling in Differential Evolution to enhance convergence in later stages.", "configspace": "", "generation": 99, "fitness": 0.8498914310594561, "feedback": "The algorithm PSODEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e23a5584-2977-4f6c-807f-f5274c5daebf", "metadata": {"aucs": [0.8664941883237454, 0.849414918225815, 0.833765186628808], "final_y": [0.11883787111765276, 0.11877465375446927, 0.11875305705932648]}, "mutation_prompt": null}
