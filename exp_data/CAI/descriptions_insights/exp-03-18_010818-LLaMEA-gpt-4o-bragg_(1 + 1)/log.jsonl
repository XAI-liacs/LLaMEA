{"id": "5513b900-d190-4ca0-bf8f-9514c79e2adf", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        self.population = np.vstack((self.population, opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm leverages a combination of opposition-based learning and adaptive differential evolution to efficiently explore and exploit the search space within the given budget constraints.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 63, in __call__\n  File \"<string>\", line 26, in mutate\nNameError: name 'bounds' is not defined. Did you mean: 'round'?\n.", "error": "NameError(\"name 'bounds' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 63, in __call__\n  File \"<string>\", line 26, in mutate\nNameError: name 'bounds' is not defined. Did you mean: 'round'?\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "9bacbad0-1bdc-4cb9-a34a-c78b3bdb67a1", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):  # New method for improved initialization\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)  # Pass bounds to the mutate function\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm utilizes a combination of adaptive differential evolution with improved initialization using hybrid opposition-based learning to achieve efficient exploration and exploitation in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.7698198186485555, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.119. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "5513b900-d190-4ca0-bf8f-9514c79e2adf", "metadata": {"aucs": [0.9380721860106315, 0.6983739195663567, 0.6730133503686779], "final_y": [0.17028242757172407, 0.26623597041366975, 0.2912891561073455]}, "mutation_prompt": null}
{"id": "ca49ed9b-74c4-46cd-b19c-71fadda73f27", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(self.budget // 3, budget // 5)  # Changed population size\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):  # New method for improved initialization\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)  # Pass bounds to the mutate function\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm enhances exploration by increasing population size to one-third of the budget, allowing more diverse candidate solutions.", "configspace": "", "generation": 2, "fitness": 0.6668381727339326, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.667 with standard deviation 0.054. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "9bacbad0-1bdc-4cb9-a34a-c78b3bdb67a1", "metadata": {"aucs": [0.6144222497189807, 0.7409468525812115, 0.6451454159016055], "final_y": [0.3134298421743149, 0.24348740506996291, 0.2685558424381227]}, "mutation_prompt": null}
{"id": "9d4736a3-7151-4bfa-ab5e-73a18e481aff", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):  # New method for improved initialization\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)  # Pass bounds to the mutate function\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness \n                    best_individual = target + 0.01 * (best_individual - target)  # Minor refinement\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm employs adaptive differential evolution with refined initialization and hybrid opposition-based learning for enhanced exploration and exploitation in black-box optimization.", "configspace": "", "generation": 3, "fitness": 0.7698198186485555, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.119. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "9bacbad0-1bdc-4cb9-a34a-c78b3bdb67a1", "metadata": {"aucs": [0.9380721860106315, 0.6983739195663567, 0.6730133503686779], "final_y": [0.17028242757172407, 0.26623597041366975, 0.2912891561073455]}, "mutation_prompt": null}
{"id": "3906011b-1554-4fbf-9adb-e9a073a6470d", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm employs adaptive differential evolution with enhanced crossover using a dynamic control parameter to balance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 4, "fitness": 0.8412589024492269, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.043. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "9bacbad0-1bdc-4cb9-a34a-c78b3bdb67a1", "metadata": {"aucs": [0.8646462930659643, 0.8775550937241494, 0.781575320557567], "final_y": [0.201845618784103, 0.19485510240583126, 0.2346052597158761]}, "mutation_prompt": null}
{"id": "bbcdb97a-78bb-4b2d-8d34-95fb8e5958c2", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - (self.function_evaluations + 0.5) / self.budget)  # Adjusted dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm slightly adjusts the dynamic control parameter in the crossover method for better balance between exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8412164017821308, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.043. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "3906011b-1554-4fbf-9adb-e9a073a6470d", "metadata": {"aucs": [0.8646462930659643, 0.8775550937241494, 0.7814478185562783], "final_y": [0.201845618784103, 0.19485510240583126, 0.23477158997156145]}, "mutation_prompt": null}
{"id": "5c966b86-ea45-46a7-ac3a-ab6d7304283c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.function_evaluations / self.budget)  # Adaptive scaling of mutation factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive scaling of the mutation factor to enhance exploration-exploitation balance in differential evolution.", "configspace": "", "generation": 6, "fitness": 0.8435661049215266, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.089. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "3906011b-1554-4fbf-9adb-e9a073a6470d", "metadata": {"aucs": [0.8675998938965245, 0.9389517779423182, 0.7241466429257372], "final_y": [0.2006147237767404, 0.17224117952805584, 0.26390653077843385]}, "mutation_prompt": null}
{"id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a minor enhancement by adjusting the adaptive scaling formula for the mutation factor to further refine exploration-exploitation balance in differential evolution.", "configspace": "", "generation": 7, "fitness": 0.8920520149473283, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.023. And the mean value of best solutions found was 0.193 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5c966b86-ea45-46a7-ac3a-ab6d7304283c", "metadata": {"aucs": [0.9195243340814508, 0.8929983404886266, 0.8636333702719073], "final_y": [0.18170555330535765, 0.19219216631775593, 0.204334468002224]}, "mutation_prompt": null}
{"id": "88b120b4-8f0a-4d43-adc4-abb9c62305d5", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Refine mutation by enhancing parent selection to diversify the search\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Refine the mutation by enhancing the selection of parent vectors to diversify the search process in differential evolution.", "configspace": "", "generation": 8, "fitness": 0.8920520149473283, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.023. And the mean value of best solutions found was 0.193 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9195243340814508, 0.8929983404886266, 0.8636333702719073], "final_y": [0.18170555330535765, 0.19219216631775593, 0.204334468002224]}, "mutation_prompt": null}
{"id": "03225dcb-1785-4fb5-972d-0f6ee787f178", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) + np.random.normal(0, 0.05)  # Stochastic adjustment\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance diversity by introducing a stochastic adjustment to the dynamic control parameter CR for improved exploration.", "configspace": "", "generation": 9, "fitness": 0.8225457749681363, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.083. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9363557293510948, 0.7399091312138695, 0.7913724643394444], "final_y": [0.18000593024804412, 0.2551897018976056, 0.23425112976207052]}, "mutation_prompt": null}
{"id": "64f9456e-4747-4f50-a0fc-6d04dd8cfa93", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(self.population) / (np.mean(bounds.ub - bounds.lb) + 1e-8)  # Added dynamic adjustment\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5 + diversity_factor)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate an additional dynamic adjustment to the mutation factor based on the diversity of the population along with the existing adaptive scaling mechanism.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {}, "mutation_prompt": null}
{"id": "c6e11132-c3fe-4ac4-aaaf-e9e03808da3b", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def dynamic_population_resize(self):\n        if self.function_evaluations / self.budget < 0.5:\n            self.population_size += 1\n        else:\n            self.population_size = max(5, self.population_size - 1)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.dynamic_population_resize()\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance population diversity and convergence by introducing a dynamic population resizing strategy within differential evolution.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {}, "mutation_prompt": null}
{"id": "d93caedc-32bc-4db5-b220-df4944e53ef3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2  # Modified to midpoint for better exploration\n        return lb + ub - np.random.uniform(lb, midpoint, (self.population_size, self.dim))\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.6)  # Slightly adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a slight adjustment to the adaptive scaling for the mutation factor and modify the opposition-based population to enhance exploration in differential evolution.", "configspace": "", "generation": 12, "fitness": 0.7826111076376288, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.049. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.8346455046663176, 0.7163383485028917, 0.796849469743677], "final_y": [0.20966593352583074, 0.2637164506088644, 0.22708856557602475]}, "mutation_prompt": null}
{"id": "9590d1ed-8d20-40b0-bc47-3ec6245b136c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.4)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Fine-tune the adaptive scaling by modifying the power in the mutation factor formula for enhanced balance.", "configspace": "", "generation": 13, "fitness": 0.8620786349675185, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.052. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9270186217154186, 0.7999411006171866, 0.8592761825699502], "final_y": [0.17858207827199468, 0.23035251837934623, 0.20550104188560436]}, "mutation_prompt": null}
{"id": "d873fbc5-9cfd-4644-8092-42bc5d32e807", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        np.random.shuffle(self.population)  # Swapping random individuals for diversity enhancement\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce diversity enhancement by swapping random individuals between the initial and opposition populations.", "configspace": "", "generation": 14, "fitness": 0.8302080745814117, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.089. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9440057713426651, 0.8196006393088627, 0.7270178130927072], "final_y": [0.17183073291608664, 0.21392173428436823, 0.26489659152644995]}, "mutation_prompt": null}
{"id": "cabb0c36-af8c-41c8-918a-b3122bc2e6cb", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        threshold = 1.05 * np.mean([f_target, f_trial])  # Adaptive selection threshold\n        if f_trial < f_target and f_trial < threshold:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Implement a refined selection strategy where selection pressure is dynamically adjusted using an adaptive threshold based on current fitness distribution.", "configspace": "", "generation": 15, "fitness": 0.8920520149473283, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.023. And the mean value of best solutions found was 0.193 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9195243340814508, 0.8929983404886266, 0.8636333702719073], "final_y": [0.18170555330535765, 0.19219216631775593, 0.204334468002224]}, "mutation_prompt": null}
{"id": "69511841-af07-4532-b4d4-405f930fdc0a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n        self.no_improvement_count = 0  # Add counter for no improvement\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                    self.no_improvement_count = 0  # Reset counter on improvement\n                else:\n                    self.no_improvement_count += 1\n\n                if self.no_improvement_count >= 10:  # Reset mechanism\n                    self.population = self.initialize_population(bounds)\n                    fitness = np.array([func(ind) for ind in self.population])\n                    self.function_evaluations += len(self.population)\n                    self.no_improvement_count = 0\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve exploration by introducing a reset mechanism if no improvement in a designated number of iterations within differential evolution.", "configspace": "", "generation": 16, "fitness": 0.6345861258135855, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.635 with standard deviation 0.033. And the mean value of best solutions found was 0.283 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.5897724659628234, 0.6695847870222575, 0.6444011244556755], "final_y": [0.3011598055229906, 0.2604961965319639, 0.2883231127962803]}, "mutation_prompt": null}
{"id": "e5320538-b551-466e-b298-e1403afe8444", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        stochastic_F = self.F * np.random.uniform(0.5, 1.5)  # Added stochastic scaling\n        adaptive_F = stochastic_F * (1 - (self.function_evaluations / self.budget)**0.5)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Add stochastic scaling to adaptive mutation factor for improved exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7657845962498043, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.086. And the mean value of best solutions found was 0.246 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.8867624299469127, 0.7042478327943555, 0.706343526008145], "final_y": [0.19420293044000736, 0.2708046444396027, 0.272856360246579]}, "mutation_prompt": null}
{"id": "8da725b9-74d7-4678-a828-a5bb4affcb94", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n        self.success_rates = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - np.mean(self.success_rates))  # Dynamic control parameter based on success rates\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        success = f_trial < f_target\n        self.success_rates.append(success)  # Update success rates\n        if success:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a small enhancement by incorporating a dynamic scaling factor for the crossover rate based on the success of earlier trials to balance exploration and exploitation more effectively.", "configspace": "", "generation": 18, "fitness": 0.8836638997112524, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.048. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.8294311776898593, 0.8762446017447605, 0.9453159196991372], "final_y": [0.19915192015849104, 0.18816691385271644, 0.16760050070098043]}, "mutation_prompt": null}
{"id": "4fc64bd7-385c-43cc-b2dd-ce83327dc759", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.population_size = int(min(10, (self.budget - self.function_evaluations) // 5) + 1)  # Dynamic population size reduction\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Incorporate dynamic population size reduction as the function evaluations progress to enhance convergence speed.", "configspace": "", "generation": 19, "fitness": 0.8758224729598508, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.055. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.915215517506509, 0.9139335854578312, 0.7983183159152121], "final_y": [0.1823840536389283, 0.18089883912802063, 0.2296541526331457]}, "mutation_prompt": null}
{"id": "8d3fb5ba-914a-46b3-a246-03a67cc5b43a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def adaptive_population_size(self):\n        min_size = max(5, self.population_size // 2)\n        max_size = min(20, self.population_size * 2)\n        return min_size + int((max_size - min_size) * (1 - self.function_evaluations / self.budget))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            current_population_size = self.adaptive_population_size()\n            for i in range(current_population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[np.random.randint(0, self.population_size)]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i % self.population_size] = target\n                fitness[i % self.population_size] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance the balance between exploration and exploitation by integrating adaptive learning rates and dynamic population resizing in differential evolution.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('list.remove(x): x not in list').", "error": "ValueError('list.remove(x): x not in list')", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {}, "mutation_prompt": null}
{"id": "e609cc38-9305-4b25-8063-7bb15864b1c4", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds, fitness):\n        lb, ub = bounds.lb, bounds.ub\n        worst_indices = fitness.argsort()[-2:]  # Select the two worst-performing individuals\n        for idx in worst_indices:\n            self.population[idx] = np.random.uniform(lb, ub, self.dim)\n            fitness[idx] = func(self.population[idx])\n            self.function_evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n            self.random_reinitialize(bounds, fitness)  # Reinitialize worst-performing individuals\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance population diversity by integrating random re-initialization of individuals with low contribution to fitness improvement.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {}, "mutation_prompt": null}
{"id": "4a82a362-93b9-49ff-958a-8328bc47bb64", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(midpoint, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * (1 - 0.5 * (self.function_evaluations / self.budget))  # Additional adaptive factor based on generation\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Modify the mutation strategy by introducing an adaptive differential weight influenced by generation count to enhance convergence speed.", "configspace": "", "generation": 22, "fitness": 0.890069009805951, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.017. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.9076082378750367, 0.8959720333629718, 0.8666267581798442], "final_y": [0.18628086469834193, 0.1915296782211261, 0.20300142654495545]}, "mutation_prompt": null}
{"id": "5414dc3e-2fde-4c6c-9495-f227f3613b32", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by increasing initial population diversity through a modified hybrid opposition-based initialization technique.", "configspace": "", "generation": 23, "fitness": 0.8937422462984549, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.025. And the mean value of best solutions found was 0.193 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "17eb8ea0-a3ee-4754-9cc6-2d0517a40060", "metadata": {"aucs": [0.923925854252972, 0.8936675143704851, 0.8636333702719073], "final_y": [0.18170555330535765, 0.19219216631775593, 0.204334468002224]}, "mutation_prompt": null}
{"id": "deebd033-93ca-4b80-9182-83875e92889a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5)  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population_size += self.budget // 100  # Increased population size dynamically\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve convergence by increasing the population size dynamically based on the remaining budget.", "configspace": "", "generation": 24, "fitness": 0.7788665324162999, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.046. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5414dc3e-2fde-4c6c-9495-f227f3613b32", "metadata": {"aucs": [0.8440546406125334, 0.7455016505873275, 0.7470433060490387], "final_y": [0.17197177762665206, 0.18987972474310388, 0.1797735934749073]}, "mutation_prompt": null}
{"id": "8fb3657b-59d7-4867-ae33-2116cc425ed0", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds, best_fitness, current_fitness):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * (1 - (best_fitness / current_fitness))  # Adjusted adaptive scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds, best_fitness, fitness[i])\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate a dynamic mutation strategy by modifying the scaling factor based on the current best fitness improvement rate.", "configspace": "", "generation": 25, "fitness": 0.7074211296928782, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.707 with standard deviation 0.029. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "5414dc3e-2fde-4c6c-9495-f227f3613b32", "metadata": {"aucs": [0.6978003620446982, 0.6771383008991876, 0.7473247261347487], "final_y": [0.28229814383259544, 0.29289754694090764, 0.25472404926091374]}, "mutation_prompt": null}
{"id": "e72fd1cf-99c1-4a4c-b07c-4a5c13977f38", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - np.sin((self.function_evaluations / self.budget) * np.pi / 2))  # Dynamic mutation scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by incorporating dynamic mutation scaling to improve diverse solution generation.", "configspace": "", "generation": 26, "fitness": 0.8222400171832517, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.076. And the mean value of best solutions found was 0.221 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "5414dc3e-2fde-4c6c-9495-f227f3613b32", "metadata": {"aucs": [0.8305848011256178, 0.9103384710706831, 0.7257967793534541], "final_y": [0.21700511054438154, 0.18360382753426419, 0.2629046611529696]}, "mutation_prompt": null}
{"id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Incorporate adaptive mutation scaling with temperature-based cooling to enhance exploration and convergence balance.", "configspace": "", "generation": 27, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5414dc3e-2fde-4c6c-9495-f227f3613b32", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "9b3c70a1-5ec9-41fb-9d23-fd54214ea797", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - np.mean(self.population, axis=0))  # Modified line for diversity boost\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance the mutation strategy by adjusting the selection of individuals to increase population diversity.", "configspace": "", "generation": 28, "fitness": 0.6789046462470295, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.679 with standard deviation 0.075. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.7738842062316416, 0.5914525200115783, 0.6713772124978687], "final_y": [0.23014942156476004, 0.32564065968763634, 0.2758647912301717]}, "mutation_prompt": null}
{"id": "15d4a231-1220-4418-89de-ec519e8f4357", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        self.population[0] = best_individual  # Keep the best historical solution\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a memory mechanism to retain the best historical solution to enhance exploitation.", "configspace": "", "generation": 29, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "2a36a400-1c0d-400f-b2ae-ed8672954489", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n            self.population[0] = best_individual  # Elite-preserving strategy: retain the best individual\n            fitness[0] = best_fitness\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate elite-preserving strategy by retaining the best individual across generations to enhance convergence.", "configspace": "", "generation": 30, "fitness": 0.8558864759244731, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.089. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.955848794555668, 0.8730877828124212, 0.7387228504053303], "final_y": [0.173440668812318, 0.20230797603098005, 0.25889144639298234]}, "mutation_prompt": null}
{"id": "09f28276-646b-4594-ac1b-464cd73214e4", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-2 * self.function_evaluations / self.budget)  # Adjusted exponential cooling rate\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Adjust the adaptive mutation scaling factor's cooling rate to enhance convergence efficiency.", "configspace": "", "generation": 31, "fitness": 0.8983661162347193, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.010. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9057417441059873, 0.8845754553235421, 0.9047811492746287], "final_y": [0.18875121492028468, 0.19661275370603348, 0.1876690145276375]}, "mutation_prompt": null}
{"id": "70409f40-8378-4b0c-aaa4-f1b78378150f", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * ((1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) + 0.1)  # Enhanced mutation factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Refine adaptive mutation factor to improve exploration early and convergence later.", "configspace": "", "generation": 32, "fitness": 0.8469039743955621, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.051. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.905748078283054, 0.8545844212041969, 0.780379423699435], "final_y": [0.18834026609768162, 0.2052944082665532, 0.23750878741910642]}, "mutation_prompt": null}
{"id": "b70182da-0499-4743-984b-188762a27408", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        decay_factor = 1 - (self.function_evaluations / self.budget)  # New line for enhanced dynamic crossover\n        dynamic_CR = self.CR * decay_factor  # Dynamic control parameter with decay factor\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Utilize enhanced dynamic crossover by introducing a linear decay factor to improve balance between exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "45087bca-2671-4911-a73e-fedd829de4fe", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n            # Adjust the population size dynamically based on remaining budget\n            self.population_size = max(4, min(10, self.budget - self.function_evaluations))\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce dynamic population resizing to enhance exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "83e1308c-9ec8-4592-9414-87cef4bf19e6", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(self.population, axis=0).mean()  # Added line for adaptive mutation based on diversity\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) * (1 + diversity)  # Modified line\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce diversity-based adaptive mutation to enhance exploration-exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.5818651387737006, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.582 with standard deviation 0.052. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.6548288749867426, 0.5572092958620769, 0.5335572454722823], "final_y": [0.2713809707234506, 0.272946980063727, 0.3021794926228034]}, "mutation_prompt": null}
{"id": "90da0f8a-6ccc-4eca-962d-c034391b3ca6", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        levy_step = np.random.normal(size=self.dim) * adaptive_F  # Added Levy flight-based perturbation\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) + levy_step\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by integrating a levy flight-based perturbation technique within the mutation process of the population.", "configspace": "", "generation": 36, "fitness": 0.8460978973915951, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.051. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.8201628356539208, 0.8004421744653382, 0.9176886820555266], "final_y": [0.20503432565184365, 0.21553332378547585, 0.17362802247471365]}, "mutation_prompt": null}
{"id": "acc80557-88e8-417c-bd38-3884d61aad02", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        # Refinement: Incorporate opposition-based trial selection to improve exploration\n        opposition_trial = self.opposition_based_population(func.bounds)[0]\n        f_opposition = func(opposition_trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        elif f_opposition < f_target:\n            return opposition_trial, f_opposition\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce opposition-based learning enhancement by refining trial vector selection to improve exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.8846547527406239, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.041. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9030171939150569, 0.8283082733317426, 0.9226387909750721], "final_y": [0.18650238055959256, 0.21119377815686058, 0.17485937441260024]}, "mutation_prompt": null}
{"id": "01f999a2-8f24-4efc-bde6-ef3af4379fc1", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        self.population = 0.5 * (self.population + lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim)))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-2 * self.function_evaluations / self.budget)  # Modified line\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate an adaptive opposition mechanism and enhance mutation cooling for improved convergence velocity and solution quality.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 2 has size 1').", "error": "ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 2 has size 1')", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {}, "mutation_prompt": null}
{"id": "36c6ddd2-5b65-4344-954a-ca3b2e4925d9", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Utilize adaptive opposition-based learning to improve convergence by dynamically adjusting exploration based on population diversity.", "configspace": "", "generation": 39, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "9ebd1f07-367c-497b-89f9-007b9808f3f8", "solution": "# Description: Enhanced selection strategy by incorporating a probability-based approach to accept worse solutions to escape local optima.\n# Code: \nimport numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        acceptance_prob = np.exp((f_target - f_trial) / (1 + self.function_evaluations / self.budget))  # Probability-based acceptance\n        if f_trial < f_target or np.random.rand() < acceptance_prob:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced selection strategy by incorporating a probability-based approach to accept worse solutions to escape local optima.", "configspace": "", "generation": 40, "fitness": 0.6530054468925303, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.653 with standard deviation 0.082. And the mean value of best solutions found was 0.309 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.64230808477752, 0.558403923437828, 0.7583043324622428], "final_y": [0.3134298421743149, 0.3637958453101473, 0.25038378396920824]}, "mutation_prompt": null}
{"id": "1359d296-3993-4407-bbc8-60520169f46b", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def adjust_population_size(self, fitness):\n        elite_size = max(1, int(self.population_size * 0.1))\n        elite_indices = np.argsort(fitness)[:elite_size]\n        self.population = self.population[elite_indices]\n        self.population_size = elite_size + min(10, (self.budget - self.function_evaluations) // 5)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.adjust_population_size(fitness)\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive population size scaling with elite retention for enhanced diversity and convergence in optimization.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 1 is out of bounds for axis 0 with size 1').", "error": "IndexError('index 1 is out of bounds for axis 0 with size 1')", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {}, "mutation_prompt": null}
{"id": "f9780bc2-077c-4f0f-a260-d4832cba34ac", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n        self.chaotic_sequence = np.random.rand(self.population_size)  # Chaotic sequence initialization\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def chaotic_perturbation(self):\n        self.chaotic_sequence = 4 * self.chaotic_sequence * (1 - self.chaotic_sequence)  # Logistic map\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        chaotic_F = adaptive_F * self.chaotic_sequence[target_idx]  # Chaotic influence\n        if np.random.rand() < 0.5:  # Dual strategy\n            mutant = self.population[a] + chaotic_F * (self.population[b] - self.population[c])\n        else:\n            mutant = self.population[c] + chaotic_F * (self.population[a] - self.population[b])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.chaotic_perturbation()  # Apply chaotic perturbation\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce chaotic perturbations and dual mutation strategies to enhance exploration and exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.6638074138542988, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.664 with standard deviation 0.023. And the mean value of best solutions found was 0.299 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.6843127694407831, 0.6320673762855913, 0.6750420958365217], "final_y": [0.288599723864688, 0.3161113961372971, 0.2928279003479084]}, "mutation_prompt": null}
{"id": "b68f12a0-1fc8-42b4-b0aa-3595d1b5e110", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) * (1.1 - np.mean(np.array([func(ind) for ind in self.population])))  # Added dynamic fitness adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance the mutation strategy by integrating a dynamic scaling factor influenced by both the budget and current fitness landscape.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {}, "mutation_prompt": null}
{"id": "8bca4f23-be01-4825-ac1e-c31b00788c59", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 + 0.5 * np.sin(2 * np.pi * self.function_evaluations / self.budget))  # Sinusoidal adjustment\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance convergence by replacing dynamic_CR adjustment with a sinusoidal factor to vary crossover probability.", "configspace": "", "generation": 44, "fitness": 0.7365491414461811, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.737 with standard deviation 0.048. And the mean value of best solutions found was 0.262 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.669425219623021, 0.7778838445410001, 0.7623383601745222], "final_y": [0.29756140537937326, 0.23884493924882555, 0.2487624107684696]}, "mutation_prompt": null}
{"id": "d3bf3d7f-3c03-4b48-80c3-8ae14075b529", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**2) * np.exp(-self.function_evaluations / self.budget)  # Adjusted line with quadratic cooling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce quadratic cooling in adaptive mutation scaling to further enhance exploration-convergence trade-off.", "configspace": "", "generation": 45, "fitness": 0.8466695606605589, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.091. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.8753144886190036, 0.9405359054864129, 0.7241582878762605], "final_y": [0.1996459225644973, 0.17260356820905187, 0.2639025274783061]}, "mutation_prompt": null}
{"id": "b242e301-5ef0-4ad0-9af8-1dcb1905ffe8", "solution": "# Description: Introduce cosine-based mutation scaling to improve search space navigation in optimization.\n# Code:\nimport numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.cos(self.function_evaluations / self.budget * np.pi / 2)  # Modified line\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce cosine-based mutation scaling to improve search space navigation in optimization.", "configspace": "", "generation": 46, "fitness": 0.8983307103172485, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.021. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9262255260817213, 0.8917446871825028, 0.8770219176875216], "final_y": [0.1808180062035476, 0.1930066684589633, 0.19872849369305634]}, "mutation_prompt": null}
{"id": "02e75587-faa6-44f7-a802-1102bd2570b7", "solution": "# Description: Integrate cognitive feedback from the best individual to guide exploration and convergence.\n# Code: \nimport numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) + 0.1 * (self.best_individual - self.population[a]) # Added cognitive feedback\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        self.best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    self.best_individual = target\n\n        return self.best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate cognitive feedback from the best individual to guide exploration and convergence.", "configspace": "", "generation": 47, "fitness": 0.8318001111873096, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.017. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.8366562017244512, 0.8498684845502278, 0.8088756472872498], "final_y": [0.21702187813938145, 0.21031754105254963, 0.2251819787309226]}, "mutation_prompt": null}
{"id": "9665f608-c52e-4048-95c4-bcb2954fdec8", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.population_size = max(5, int(self.population_size * (1 + 0.1 * (best_fitness / np.mean(fitness)))))  # Dynamic population size adjustment\n\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance diversity by introducing dynamic population size adjustment based on convergence speed.", "configspace": "", "generation": 48, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "13dc49f0-3532-4bdf-b772-50f89d9786f2", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                if np.random.rand() < (1 - self.function_evaluations / self.budget):  # Adaptive mutation probability\n                    mutant = self.mutate(i, bounds)\n                    trial = self.crossover(target, mutant)\n\n                    target, target_fitness = self.select(target, trial, func)\n                    self.population[i] = target\n                    fitness[i] = target_fitness\n                    self.function_evaluations += 1\n\n                    if target_fitness < best_fitness:\n                        best_fitness = target_fitness\n                        best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive mutation probability by scaling based on function evaluations to improve diversity.", "configspace": "", "generation": 49, "fitness": 0.7970213299538692, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.018. And the mean value of best solutions found was 0.232 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.8215079269142663, 0.7816501001404833, 0.7879059628068583], "final_y": [0.2186870883179406, 0.23941330902970315, 0.23642167034096528]}, "mutation_prompt": null}
{"id": "46f88032-abd0-4e77-930c-949f4fc55c48", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n                # Dynamic opposition population update\n                if self.function_evaluations % (self.budget // 10) == 0:\n                    self.population = np.vstack((self.population, self.opposition_based_population(bounds)))\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic opposition population update to maintain diversity and enhance exploration.", "configspace": "", "generation": 50, "fitness": 0.900051796819976, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.9114742273883388, 0.9161008046834783, 0.8725803583881108], "final_y": [0.1865023805595898, 0.1843096966257124, 0.20078839420828098]}, "mutation_prompt": null}
{"id": "4d366857-d943-4df9-8de0-c05e60f190b7", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) * np.random.uniform(0.8, 1.2)  # Randomized scaling factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance mutation diversity by introducing a randomized scaling factor.", "configspace": "", "generation": 51, "fitness": 0.7409220450803375, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.741 with standard deviation 0.065. And the mean value of best solutions found was 0.259 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.7886273794825295, 0.785217414562521, 0.6489213411959622], "final_y": [0.23707457202820104, 0.235863356284579, 0.3042934534007068]}, "mutation_prompt": null}
{"id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate a novel adaptive weighting mechanism to further balance exploration and exploitation in the mutation step.", "configspace": "", "generation": 52, "fitness": 0.9011664714430486, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "26605a6f-defb-4485-a69a-b4bc763b3b4b", "metadata": {"aucs": [0.905668864609582, 0.8917709919640396, 0.9060595577555242], "final_y": [0.1887811675395703, 0.19342316452149, 0.18710557495000457]}, "mutation_prompt": null}
{"id": "feb6423b-9272-4cb1-9995-dffc80b4f321", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        # Change made here: scaling factor is further adjusted based on best_fitness\n        adaptive_F *= (1 + 0.1 * (self.population[best_idx].sum() / self.dim))\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a self-adaptive scaling factor adjustment based on the current best solution to enhance exploration in early stages.", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_idx' is not defined\").", "error": "NameError(\"name 'best_idx' is not defined\")", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {}, "mutation_prompt": null}
{"id": "6d6a9a4e-cc3f-47f0-96a6-af8f69e7d553", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget) * 0.9  # New adaptive weighting mechanism with scaling factor\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance the algorithm by applying an additional scaling factor to the adaptive weighting mechanism in the mutation step.", "configspace": "", "generation": 54, "fitness": 0.791540093614004, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.094. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8535682388132291, 0.6591709428207826, 0.8618810992080006], "final_y": [0.20819387763532604, 0.2958741310754135, 0.20561849788158604]}, "mutation_prompt": null}
{"id": "f79bf7d8-55ae-4c87-960a-5ed1cf15f60e", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        population_diversity = np.std(self.population, axis=0).sum() / self.dim  # New dynamic diversification measure\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) * population_diversity\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by integrating a dynamic adjustment to the crossover rate based on population diversity.", "configspace": "", "generation": 55, "fitness": 0.6790138624718068, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.679 with standard deviation 0.023. And the mean value of best solutions found was 0.291 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.6882810176387542, 0.7018562772217741, 0.6469042925548922], "final_y": [0.28741223422086715, 0.2787329782112692, 0.307433521350424]}, "mutation_prompt": null}
{"id": "db970e5c-b05a-43ec-b6e0-a48b99baa5c0", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        perturbation = np.random.normal(0, 0.1, self.dim)  # Added perturbation for diversity\n        trial = np.where(cross_points, mutant + perturbation, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a perturbation factor in crossover for enhanced diversity and robustness.", "configspace": "", "generation": 56, "fitness": 0.8320215007282448, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.045. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8922560018476862, 0.8189875534855184, 0.7848209468515297], "final_y": [0.1837446334341365, 0.21326545437626176, 0.21867184908517023]}, "mutation_prompt": null}
{"id": "4774d127-9edc-4481-9cc6-d0e0ef3b59a4", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - np.cos((self.function_evaluations / self.budget) * np.pi / 2))  # Nonlinear scaling\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - (self.function_evaluations / self.budget)**2)  # Nonlinear dynamic CR\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance local search efficiency by implementing a nonlinear dynamic crossover rate and adaptive mutation scale.", "configspace": "", "generation": 57, "fitness": 0.5897815593066751, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.590 with standard deviation 0.058. And the mean value of best solutions found was 0.346 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.64230808477752, 0.5084499750055551, 0.6185866181369502], "final_y": [0.3134298421743149, 0.3992702095910784, 0.324323908275405]}, "mutation_prompt": null}
{"id": "e892af85-b6e2-4926-b426-dc603dc36060", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        perturbation = np.random.normal(0, 0.1, size=self.dim)  # Introduce perturbation to enhance diversity\n        mutant = mutant + perturbation  # Only line changed\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a perturbation mechanism in the mutation step to enhance solution diversity.", "configspace": "", "generation": 58, "fitness": 0.7923332891581824, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.081. And the mean value of best solutions found was 0.226 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.83958100867661, 0.6788600467256825, 0.8585588120722546], "final_y": [0.2096405727386813, 0.27251504521119807, 0.19592577912111586]}, "mutation_prompt": null}
{"id": "7c6a9170-c110-4967-be07-2bfb11452d49", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_metric = np.std(self.population, axis=0).mean()  # Added line\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget) * diversity_metric  # Modified line\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a self-adaptive mutation factor that adjusts based on population diversity to improve exploration and exploitation balance.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {}, "mutation_prompt": null}
{"id": "bb19d312-11a9-4a67-af35-f05d51a5dc42", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.initial_population_size = min(10, budget // 5)\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - np.tanh(self.function_evaluations / self.budget))  # Modified adaptive weighting\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n            # Dynamic population resizing\n            if self.function_evaluations / self.budget > 0.5 and self.population_size > 5:\n                self.population_size -= 1  # Decrease population size gradually\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce dynamic population resizing and enhanced adaptive weighting mechanism for improved exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.9010934601696192, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.9056715658994189, 0.8915445520139407, 0.9060642625954982], "final_y": [0.18878003480843353, 0.1935267603027142, 0.18710363050751855]}, "mutation_prompt": null}
{"id": "41304705-b150-4096-928e-c31062ddac43", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.population_size = max(4, min(10, (self.budget - self.function_evaluations) // 5))  # Dynamic adjustment\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by dynamically adjusting population size based on remaining budget.", "configspace": "", "generation": 61, "fitness": 0.9011664714430486, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.905668864609582, 0.8917709919640396, 0.9060595577555242], "final_y": [0.1887811675395703, 0.19342316452149, 0.18710557495000457]}, "mutation_prompt": null}
{"id": "193bd977-6f55-4384-8934-56594150b779", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + np.random.normal(0, 0.01, (self.population_size, self.dim)) # Added Gaussian noise\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance diversity by introducing Gaussian noise in initialization.", "configspace": "", "generation": 62, "fitness": 0.7528930110904429, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.054. And the mean value of best solutions found was 0.246 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8124525712256966, 0.7640812935221525, 0.6821451685234798], "final_y": [0.22285916670004735, 0.23864188223920124, 0.277087124823551]}, "mutation_prompt": null}
{"id": "2f7a629d-a931-4b22-b778-21fb4c42b803", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.population_size = min(10, self.budget // (5 + int(self.function_evaluations / self.budget * 5)))  # Updated line\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive control of population size to maintain diversity and exploitation balance throughout the optimization process.", "configspace": "", "generation": 63, "fitness": 0.9011664714430486, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.905668864609582, 0.8917709919640396, 0.9060595577555242], "final_y": [0.1887811675395703, 0.19342316452149, 0.18710557495000457]}, "mutation_prompt": null}
{"id": "a2eafebf-9283-44b1-87f8-72a0bb27df8c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget) + 0.1 * np.sin(self.function_evaluations)  # New dynamic mutation scaling factor\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic mutation scaling factor to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 64, "fitness": 0.8842102247596729, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.040. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.9387043799347426, 0.869724476783899, 0.844201817560377], "final_y": [0.1773246117119125, 0.19793446179253305, 0.2109646139859942]}, "mutation_prompt": null}
{"id": "35863f00-4945-40e3-bc1d-bae8d58d1627", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        # Modified line to enhance diversity\n        return np.random.uniform(lb, ub) + (ub - np.random.uniform(lb, ub)) * np.random.uniform(0, 1, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance solution diversity by updating the hybrid opposition population initialization.", "configspace": "", "generation": 65, "fitness": 0.781895973949626, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.040. And the mean value of best solutions found was 0.235 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.7445587469920587, 0.8376520396754527, 0.7634771351813665], "final_y": [0.251751692069187, 0.20930380704310347, 0.2434408523920354]}, "mutation_prompt": null}
{"id": "2e6ac343-0690-40fd-b012-aa677dede0fd", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) + 0.1  # Introduced modification here\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduced adaptive dynamic crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.7859888088736362, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.071. And the mean value of best solutions found was 0.239 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8766989206014429, 0.7033953726982973, 0.7778721333211684], "final_y": [0.20023071588844743, 0.2761921055432581, 0.23925249112480407]}, "mutation_prompt": null}
{"id": "ce2e8f5a-f9f5-49ac-9ad5-4db769d970fd", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        control_factor = 0.5 * (np.random.rand() + 0.5)  # New control factor for enhanced adaptability\n        adaptive_weight = (1 - self.function_evaluations / self.budget) * control_factor\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Incorporate a control factor to dynamically adjust the weighting factor in mutation for enhanced adaptability.", "configspace": "", "generation": 67, "fitness": 0.6524415870277338, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.652 with standard deviation 0.082. And the mean value of best solutions found was 0.309 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.7475348078797179, 0.5467433816242925, 0.6630465715791909], "final_y": [0.2558782422563155, 0.3713232669279377, 0.29880077531403293]}, "mutation_prompt": null}
{"id": "24013b0d-6117-4192-8ae4-019ea97c6f71", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(12, budget // 5)  # Changed from 10 to 12\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Slightly increase the population size to enhance diversity and exploration capacity.", "configspace": "", "generation": 68, "fitness": 0.7613097137442235, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.095. And the mean value of best solutions found was 0.248 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.6422111752257557, 0.8757761319387973, 0.7659418340681174], "final_y": [0.3134298421743149, 0.19209501281131225, 0.23897773275451106]}, "mutation_prompt": null}
{"id": "193f51a5-a8da-491b-b24e-038e0ed4ac7d", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) * (1 + np.sin(np.pi * self.function_evaluations / self.budget)) / 2  # Enhanced dynamic control with scaling factor\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic scaling factor for crossover rate to further enhance adaptation over budget progression.", "configspace": "", "generation": 69, "fitness": 0.8988380919293425, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.025. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8987512585566119, 0.8684042379830909, 0.929358779248325], "final_y": [0.17881269599519334, 0.18536892772312985, 0.17132605893703667]}, "mutation_prompt": null}
{"id": "d5eff7c6-ac8c-4983-9af2-e5af20b6d400", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - (self.function_evaluations / self.budget) ** 2)  # Adjusted adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance mutation strategy by adjusting the adaptive weighting mechanism for better exploration.", "configspace": "", "generation": 70, "fitness": 0.8993384697757728, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.019. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.9100239554233958, 0.9157863502795054, 0.8722051036244172], "final_y": [0.18708973920505978, 0.1844356374632261, 0.20094722004640164]}, "mutation_prompt": null}
{"id": "c1c51a05-632d-47e3-8ce8-205b1cd066c6", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)  # Original line\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce dynamic population size scaling for better adaptation to budget constraints and problem complexity.", "configspace": "", "generation": 71, "fitness": 0.9011664714430486, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.905668864609582, 0.8917709919640396, 0.9060595577555242], "final_y": [0.1887811675395703, 0.19342316452149, 0.18710557495000457]}, "mutation_prompt": null}
{"id": "f6dee9bb-ea1c-4ffa-9dbd-15066f37a3ed", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population_size = min(10, self.budget // 5) + int((self.budget - self.function_evaluations) // 100)  # Dynamic adjustment\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic population size to improve diversity and search adaptability.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {}, "mutation_prompt": null}
{"id": "87208ead-fac1-4007-b6fb-581fafd3a079", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.55, CR=0.9):  # Adjusted mutation factor F to 0.55\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Slightly adjust the mutation factor to enhance convergence speed while maintaining exploration.", "configspace": "", "generation": 73, "fitness": 0.8679749945015983, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.045. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.8628091465801435, 0.9255297602566953, 0.815586076667956], "final_y": [0.20491982575798573, 0.1782890938558287, 0.2221835676995667]}, "mutation_prompt": null}
{"id": "006ecbe1-933a-41c8-ac2b-a57a8a0b478e", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))  # Modified line\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)  # Added exponential cooling adjustment\n        adaptive_weight = (1 - self.function_evaluations / self.budget)  # New adaptive weighting mechanism\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)  # Dynamic control parameter\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            # Adjust the population size dynamically based on the budget remaining\n            self.population_size = min(10, max(3, int(10 * (1 - self.function_evaluations / self.budget))))\n\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic population size adjustment mechanism to enhance adaptability during the optimization process.", "configspace": "", "generation": 74, "fitness": 0.7567702041985566, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.757 with standard deviation 0.029. And the mean value of best solutions found was 0.251 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.747373554696142, 0.7268114497974313, 0.7961256081020962], "final_y": [0.25472892968129335, 0.2656495513107946, 0.23261528958766642]}, "mutation_prompt": null}
{"id": "1543104d-7c66-4675-b7f4-0a1372216169", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < 0.05:  # New reinitialization strategy\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance diversity and maintain balance by incorporating a new random reinitialization strategy for stagnated individuals.", "configspace": "", "generation": 75, "fitness": 0.9463014984149156, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "91ef7fa4-3a02-46d6-9838-cfdc5edc7aa3", "metadata": {"aucs": [0.9367506301644929, 0.9586913256129646, 0.9434625394672891], "final_y": [0.16528733050736555, 0.1654936524359304, 0.16522725631859647]}, "mutation_prompt": null}
{"id": "34bb618d-1c8e-4e5e-9c23-4e6421ee6323", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance convergence by adjusting reinitialization probability based on fitness variance.", "configspace": "", "generation": 76, "fitness": 0.9473600781439205, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.011. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1543104d-7c66-4675-b7f4-0a1372216169", "metadata": {"aucs": [0.9427467873088358, 0.9365968006201469, 0.9627366465027788], "final_y": [0.16592070966143446, 0.1742680183570151, 0.16515949849742595]}, "mutation_prompt": null}
{"id": "4bf46894-2464-4cd1-965f-939e7c676612", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) + 0.05  # Slightly increase dynamic_CR\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve convergence by slightly increasing the dynamic crossover rate as function evaluations approach the budget.", "configspace": "", "generation": 77, "fitness": 0.909630503100589, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.027. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "34bb618d-1c8e-4e5e-9c23-4e6421ee6323", "metadata": {"aucs": [0.9197452054666353, 0.9363923101093583, 0.8727539937257733], "final_y": [0.16715412551278952, 0.1654179836525349, 0.17163115603766455]}, "mutation_prompt": null}
{"id": "290a1c89-93e2-4f36-b709-874561a268f9", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness), 0.25):  # Adjusted reinitialization probability cap\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve diversity and exploration by increasing the reinitialization probability cap.", "configspace": "", "generation": 78, "fitness": 0.9473600781439205, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.011. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "34bb618d-1c8e-4e5e-9c23-4e6421ee6323", "metadata": {"aucs": [0.9427467873088358, 0.9365968006201469, 0.9627366465027788], "final_y": [0.16592070966143446, 0.1742680183570151, 0.16515949849742595]}, "mutation_prompt": null}
{"id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by adjusting the reinitialization probability dynamically based on fitness variance and median.", "configspace": "", "generation": 79, "fitness": 0.9513833434637863, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "34bb618d-1c8e-4e5e-9c23-4e6421ee6323", "metadata": {"aucs": [0.9465794290450061, 0.9438867408843564, 0.9636838604619965], "final_y": [0.1671408957349778, 0.1681496923992618, 0.16512148020272455]}, "mutation_prompt": null}
{"id": "6a4dd9c1-1a2c-4d6d-8715-237707ca02b7", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        top_variance = np.var(self.population[:int(self.population_size * 0.2)], axis=0)  # Adjusted line\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * (1 + top_variance) * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by dynamically adjusting mutation scaling based on the variance of the top-performing solutions.", "configspace": "", "generation": 80, "fitness": 0.5479896285246927, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.548 with standard deviation 0.067. And the mean value of best solutions found was 0.355 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.64230808477752, 0.5084499750055551, 0.49321082579100317], "final_y": [0.3134298421743149, 0.3992702095910784, 0.35192015489783157]}, "mutation_prompt": null}
{"id": "626bfa42-6acf-4d54-97ec-3d119cce1157", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        noise = np.random.normal(0, 0.01, self.dim)  # Added noise to mutation\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c]) + noise\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) + 0.1  # Adjusted crossover probability\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance diversity and adaptability by incorporating noise in mutation and adaptive crossover probability.", "configspace": "", "generation": 81, "fitness": 0.8742972410835815, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.024. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.8437960112734547, 0.9026674882083239, 0.8764282237689662], "final_y": [0.16819511535907872, 0.17058977734182723, 0.1680433288350911]}, "mutation_prompt": null}
{"id": "4f44aa75-5d37-47ad-b30a-e97b24ffc9e3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        diversity = np.std(self.population)\n        adaptive_CR = self.CR * (1 - diversity / (diversity + 1e-9))  # Adjusted for diversity\n        cross_points = np.random.rand(self.dim) < adaptive_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive crossover mechanism using population diversity to improve convergence in a limited change scope.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {}, "mutation_prompt": null}
{"id": "2288414e-272a-4af8-af1a-67dacfc1add4", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        neighborhood_size = max(2, self.population_size // 4)  # Adjust neighborhood size\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Utilize adaptive neighborhood size in mutation to improve convergence and diversity dynamically.", "configspace": "", "generation": 83, "fitness": 0.9513833434637863, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9465794290450061, 0.9438867408843564, 0.9636838604619965], "final_y": [0.1671408957349778, 0.1681496923992618, 0.16512148020272455]}, "mutation_prompt": null}
{"id": "1c916cc7-9aee-491a-8ea2-e158e9bc293b", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.mean(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by adjusting the reinitialization probability dynamically based on fitness variance and mean.", "configspace": "", "generation": 84, "fitness": 0.9384599667390358, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.022. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9260524160902712, 0.9690870202128944, 0.9202404639139415], "final_y": [0.1671350704712523, 0.16511818828674185, 0.16594245794632267]}, "mutation_prompt": null}
{"id": "2b0af974-e51b-454f-81b8-286591e66be4", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        historical_factor = np.mean(np.abs(self.population - np.roll(self.population, 1, axis=0)), axis=0)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget) * (1 + historical_factor)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        avg_improvement = np.mean(np.diff(np.sort(np.unique(self.population, axis=0), axis=0), axis=0))\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) * (1 / (1 + avg_improvement))\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improved adaptive exploration-exploitation balance by introducing nonlinear mutation and adaptive crossover probability based on historical improvements.", "configspace": "", "generation": 85, "fitness": 0.5784486925418274, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.578 with standard deviation 0.053. And the mean value of best solutions found was 0.324 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.64230808477752, 0.5799056130708724, 0.5131323797770899], "final_y": [0.3134298421743149, 0.2860200536745331, 0.3740298441169019]}, "mutation_prompt": null}
{"id": "e87faa67-d021-4716-9494-9f61c301d026", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.exp(np.std(fitness)) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by adapting reinitialization probability using a smoothed exponential function of fitness variance.", "configspace": "", "generation": 86, "fitness": 0.8956046696948512, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.017. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9196865006333051, 0.883134378834494, 0.8839931296167546], "final_y": [0.17494423978138218, 0.16698556140785414, 0.17820013569763693]}, "mutation_prompt": null}
{"id": "ead2f886-9420-45b0-a6dc-cc3dfa21c055", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Introduced diversity awareness in mutation\n        diversity_factor = np.std(self.population) / (np.mean(self.population) + 1e-9)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) * (1 + diversity_factor)\n        adaptive_weight = (1 - self.function_evaluations / self.budget) * (1 + diversity_factor)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        # Enhanced dynamic crossover with diversity factor\n        diversity_factor = np.std(self.population) / (np.mean(self.population) + 1e-9)\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget) * (1 + diversity_factor)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive crossover and mutation based on population diversity to enhance convergence and escape local optima.", "configspace": "", "generation": 87, "fitness": 0.7121461496189966, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.712 with standard deviation 0.114. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.6566846768360872, 0.8706386115724922, 0.6091151604484102], "final_y": [0.26005482968782323, 0.17665313267089355, 0.2003953341464697]}, "mutation_prompt": null}
{"id": "bc0e5905-68e9-4c0a-9465-43b14461f94b", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, ub = bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9) * np.exp(-0.01 * self.function_evaluations), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve fitness variance-based random reinitialization by introducing exponential decay to its influence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('too many values to unpack (expected 2)').", "error": "ValueError('too many values to unpack (expected 2)')", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {}, "mutation_prompt": null}
{"id": "fe0a8d74-7190-4be7-a7fd-61d0c23c1c3a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.7) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.07 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Fine-tune the exploration-exploitation trade-off by optimizing mutation and reinitialization strategies.", "configspace": "", "generation": 89, "fitness": 0.9333134102589868, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.014. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9312671605180224, 0.9517739651939964, 0.9168991050649415], "final_y": [0.16732528740250807, 0.166361303346365, 0.16613201520886345]}, "mutation_prompt": null}
{"id": "5eb0e42c-dd9d-43c5-a5c8-27a35d7caba0", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.num_populations = 3  # Added line\n        self.populations = []     # Added line\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * np.random.uniform(0.5, 1.5)  # Changed line for more variability\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.populations[0][a] + adaptive_F * adaptive_weight * (self.populations[0][b] - self.populations[0][c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.populations = [self.initialize_population(bounds) for _ in range(self.num_populations)]  # Changed line\n        self.function_evaluations = 0\n\n        fitness_lists = [np.array([func(ind) for ind in pop]) for pop in self.populations]  # Added line\n        self.function_evaluations += sum(len(fitness) for fitness in fitness_lists)  # Changed line\n\n        best_fitness = np.min([np.min(fitness) for fitness in fitness_lists])  # Changed line\n        best_idx = np.argmin([np.min(fitness) for fitness in fitness_lists])  # Added line\n        best_pop = self.populations[np.argmin([np.min(fitness) for fitness in fitness_lists])]  # Added line\n        \n        best_individual = best_pop[best_idx % self.population_size]  # Added line\n\n        while self.function_evaluations < self.budget:\n            for pop_idx in range(self.num_populations):  # Changed line\n                for i in range(self.population_size):\n                    if self.function_evaluations >= self.budget:\n                        break\n\n                    target = self.populations[pop_idx][i]  # Changed line\n                    mutant = self.mutate(i, bounds)\n                    trial = self.crossover(target, mutant)\n\n                    target, target_fitness = self.select(target, trial, func)\n                    self.populations[pop_idx][i] = target  # Changed line\n                    fitness_lists[pop_idx][i] = target_fitness  # Changed line\n                    self.function_evaluations += 1\n\n                    if target_fitness < best_fitness:\n                        best_fitness = target_fitness\n                        best_individual = target\n                    elif np.random.rand() < min(0.05 * np.std(fitness_lists[pop_idx]) / (np.median(fitness_lists[pop_idx]) + 1e-9), 0.2):\n                        self.populations[pop_idx][i] = self.random_reinitialize(bounds)  # Changed line\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Integrate adaptive mutation scaling and multi-population strategies to enhance diversity and convergence.", "configspace": "", "generation": 90, "fitness": 0.8010906300512431, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.040. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.7861426941174139, 0.7612994106136197, 0.8558297854226957], "final_y": [0.1718547930630019, 0.23656854438568442, 0.18784183868537985]}, "mutation_prompt": null}
{"id": "eda3b5e2-0282-45d5-bc0a-b988ed2532ea", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**2) * np.exp(-self.function_evaluations / (2*self.budget))\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.1):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Incorporate a non-linear dynamic scaling factor and improved selective reinitialization strategy to enhance convergence. ", "configspace": "", "generation": 91, "fitness": 0.9174600397589625, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.015. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.914764935582834, 0.9365133272465647, 0.9011018564474887], "final_y": [0.16657878627912137, 0.16792164830957612, 0.17317627476983144]}, "mutation_prompt": null}
{"id": "8e379f19-351b-4a6a-9174-c52fb73762d9", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.1 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance reinitialization chance by modifying the reinit probability formula to better adapt to fitness variance and median.", "configspace": "", "generation": 92, "fitness": 0.9353091502901303, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9286723473446233, 0.9297579894476914, 0.9474971140780761], "final_y": [0.16545309769424144, 0.16623896357988022, 0.16532272804642956]}, "mutation_prompt": null}
{"id": "95b03505-81c8-4a68-8fcc-113f25d929f3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget) * (1 + 0.1 * np.std(self.population))  # Changed line\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploration by dynamically adjusting mutation factor based on iteration progress and fitness diversity.", "configspace": "", "generation": 93, "fitness": 0.6489674066591412, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.649 with standard deviation 0.031. And the mean value of best solutions found was 0.208 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.6601521582959222, 0.6068946042310572, 0.6798554574504441], "final_y": [0.22868304887450575, 0.20993468400701443, 0.18623986778434187]}, "mutation_prompt": null}
{"id": "bf5645b1-5b80-4fdc-9a75-c5c808adbf73", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c]) + adaptive_F * (best_individual - self.population[a]) # Best individual influence\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Use best individual influence in mutation step for improved convergence.", "configspace": "", "generation": 94, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_individual' is not defined\").", "error": "NameError(\"name 'best_individual' is not defined\")", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {}, "mutation_prompt": null}
{"id": "a474f0c1-4f37-4135-9d4c-34cb251eb546", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.1 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Enhance exploitation by increasing reinitialization probability based on the fitness variance to median ratio beyond a threshold.", "configspace": "", "generation": 95, "fitness": 0.9353091502901303, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9286723473446233, 0.9297579894476914, 0.9474971140780761], "final_y": [0.16545309769424144, 0.16623896357988022, 0.16532272804642956]}, "mutation_prompt": null}
{"id": "ed426089-02d1-4c8a-81a8-b105fb5d5de1", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + (adaptive_F + np.std(self.population[b] - self.population[c])) * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Improve exploitation by adjusting mutation strategy based on fitness improvement.", "configspace": "", "generation": 96, "fitness": 0.5420686788964993, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.542 with standard deviation 0.078. And the mean value of best solutions found was 0.339 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.64230808477752, 0.5304428563049495, 0.45345509560702835], "final_y": [0.3134298421743149, 0.36051857961261713, 0.34271783087691177]}, "mutation_prompt": null}
{"id": "e8cef11a-94f5-4377-bb4f-fafab5fbfba2", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(self.population) / (np.mean(self.population) + 1e-9)\n        adaptive_F = self.F * diversity_factor * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Further refine the exploration-exploitation balance by introducing adaptive mutation scaling based on population diversity indicators.", "configspace": "", "generation": 97, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {}, "mutation_prompt": null}
{"id": "e8cdcf15-7908-44a0-bb52-e3b3e4a512ed", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        convergence_rate = 1 - self.function_evaluations / self.budget\n        adaptive_F = self.F * np.exp(-diversity) * convergence_rate  # New dynamic adaptive factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Refine exploration by incorporating a dynamic mutation scaling factor based on fitness diversity and convergence progress.", "configspace": "", "generation": 98, "fitness": 0.6801187327962103, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.680 with standard deviation 0.041. And the mean value of best solutions found was 0.260 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.6537189366952088, 0.7376516835095741, 0.6489855781838483], "final_y": [0.29389123321314015, 0.20305414422223622, 0.2825469985196165]}, "mutation_prompt": null}
{"id": "d36fbb9d-3166-4187-89d7-4a594f9ef5a6", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.population_size = min(10, budget // 5)\n        self.min_population_size = 5\n        self.population = None\n        self.function_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def opposition_based_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + ub - self.population\n\n    def hybrid_opposition_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        midpoint = (lb + ub) / 2\n        return lb + ub - np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.function_evaluations / self.budget)**0.5) * np.exp(-self.function_evaluations / self.budget)\n        adaptive_weight = (1 - self.function_evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * adaptive_weight * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.function_evaluations / self.budget)\n        cross_points = np.random.rand(self.dim) < dynamic_CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        f_target = func(target)\n        f_trial = func(trial)\n        if f_trial < f_target:\n            return trial, f_trial\n        else:\n            return target, f_target\n\n    def random_reinitialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, self.dim)\n    \n    def adaptive_population_control(self, fitness):\n        diversity = np.std(fitness)\n        entropy = -np.sum((fitness / np.sum(fitness)) * np.log(fitness / np.sum(fitness) + 1e-9))\n        if diversity < 0.1 and entropy < 1.0 and self.population_size > self.min_population_size:\n            self.population_size -= 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        opposition_population = self.opposition_based_population(bounds)\n        hybrid_opposition_population = self.hybrid_opposition_population(bounds)\n        self.population = np.vstack((self.population, opposition_population, hybrid_opposition_population))\n        self.function_evaluations = 0\n\n        fitness = np.array([func(ind) for ind in self.population])\n        self.function_evaluations += len(self.population)\n\n        best_idx = np.argmin(fitness)\n        best_individual = self.population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.function_evaluations < self.budget:\n            self.adaptive_population_control(fitness)\n            for i in range(self.population_size):\n                if self.function_evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, bounds)\n                trial = self.crossover(target, mutant)\n\n                target, target_fitness = self.select(target, trial, func)\n                self.population[i] = target\n                fitness[i] = target_fitness\n                self.function_evaluations += 1\n\n                if target_fitness < best_fitness:\n                    best_fitness = target_fitness\n                    best_individual = target\n                elif np.random.rand() < min(0.05 * np.std(fitness) / (np.median(fitness) + 1e-9), 0.2):  # Adjusted reinitialization probability\n                    self.population[i] = self.random_reinitialize(bounds)\n\n        return best_individual", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive population size and enhanced reinitialization using fitness diversity and entropy to boost exploration.", "configspace": "", "generation": 99, "fitness": 0.9513833434637863, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c3e15cc9-cbfa-4a22-bf07-56137c302393", "metadata": {"aucs": [0.9465794290450061, 0.9438867408843564, 0.9636838604619965], "final_y": [0.1671408957349778, 0.1681496923992618, 0.16512148020272455]}, "mutation_prompt": null}
