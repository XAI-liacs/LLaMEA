{"id": "8e727bae-f980-44cb-a136-3840f0ac022e", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = self.measure()\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < self.mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "A novel \"Quantum-Inspired Evolutionary Algorithm\" (QIEA) combining principles of quantum computing with evolutionary strategies to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.031955686207194134, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.032 with standard deviation 0.001. And the mean value of best solutions found was 19.143 (0. is the best) with standard deviation 0.158.", "error": "", "parent_id": null, "metadata": {"aucs": [0.03153949815942547, 0.03301800745004646, 0.03130955301211047], "final_y": [19.101935634796845, 18.972523661638423, 19.35323518626795]}, "mutation_prompt": null}
{"id": "fb7daef5-c011-4301-af52-a4b12631ee0d", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = self.measure()\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < self.mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improved Quantum-Inspired EA with a dynamic population size for better search space exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.06142947602475309, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.061 with standard deviation 0.000. And the mean value of best solutions found was 10.279 (0. is the best) with standard deviation 0.127.", "error": "", "parent_id": "8e727bae-f980-44cb-a136-3840f0ac022e", "metadata": {"aucs": [0.060778835379285634, 0.061930602184290695, 0.06157899051068294], "final_y": [10.434885243398588, 10.123642676978253, 10.278098560091097]}, "mutation_prompt": null}
{"id": "5b964229-b9ae-4fa4-867d-86787e19c029", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < self.mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improved offspring generation by using a Gaussian distribution for more balanced exploration.", "configspace": "", "generation": 2, "fitness": 0.09551487686046863, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.003. And the mean value of best solutions found was 4.384 (0. is the best) with standard deviation 0.663.", "error": "", "parent_id": "fb7daef5-c011-4301-af52-a4b12631ee0d", "metadata": {"aucs": [0.09260954258047271, 0.0999460914754483, 0.09398899652548487], "final_y": [4.931151139649033, 3.451584703274525, 4.768701444468835]}, "mutation_prompt": null}
{"id": "0f262522-74dd-47a9-88e5-8be08636207f", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced exploration by dynamic mutation based on fitness variance.", "configspace": "", "generation": 3, "fitness": 0.19487905451698517, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.195 with standard deviation 0.015. And the mean value of best solutions found was 0.515 (0. is the best) with standard deviation 0.157.", "error": "", "parent_id": "5b964229-b9ae-4fa4-867d-86787e19c029", "metadata": {"aucs": [0.18105516972584068, 0.18805318827478357, 0.21552880555033127], "final_y": [0.7147424217762223, 0.500698948839984, 0.3309576866498723]}, "mutation_prompt": null}
{"id": "9ecee55f-5434-4028-b67c-bd84afc3bcff", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n\n        # Map offspring to real values within bounds, adapting scale by fitness diversity\n        fitness_diversity = np.std(self.fitness)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1)) * (1 + 0.1 * fitness_diversity)\n\n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive offspring scaling based on fitness diversity to enhance local exploitation.", "configspace": "", "generation": 4, "fitness": 0.0, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.000 with standard deviation 0.000. And the mean value of best solutions found was inf (0. is the best) with standard deviation nan.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.0, 0.0, 0.0], "final_y": [Infinity, Infinity, Infinity]}, "mutation_prompt": null}
{"id": "7e794f0e-deeb-4129-879a-8923f7e32467", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        # Local search on the best solution\n        best_idx = np.argmin(self.fitness)\n        real_values[best_idx] = np.clip(best_solution + np.random.normal(0, 0.05, self.dim), lb, ub)\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance exploitation by introducing local search on the best solution during evolutionary process.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_solution' is not defined\").", "error": "NameError(\"name 'best_solution' is not defined\")", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {}, "mutation_prompt": null}
{"id": "7c0a7be6-38d6-4697-9dcd-15b2226815d5", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1 * np.std(self.population), real_values[mutation_mask].shape)  # Adaptive based on diversity\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Quantum-inspired EA with adaptive scaling based on population diversity.", "configspace": "", "generation": 6, "fitness": 0.11493252032775832, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.019. And the mean value of best solutions found was 2.174 (0. is the best) with standard deviation 1.559.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.10866589909823765, 0.14113213650422263, 0.09499952538081469], "final_y": [2.016196911151669, 0.3474947498610052, 4.157692214401258]}, "mutation_prompt": null}
{"id": "7d3b92b2-6b35-42e1-89df-eccbace6d280", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * offspring  # Adjusted mapping to improve exploration\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced exploration by dynamic mutation based on fitness variance with strategic offspring scaling.", "configspace": "", "generation": 7, "fitness": 0.08780219207339372, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.001. And the mean value of best solutions found was 4.655 (0. is the best) with standard deviation 0.174.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.08921877576182757, 0.0863127193082125, 0.08787508115014109], "final_y": [4.627806511889092, 4.88024030988557, 4.457248116129248]}, "mutation_prompt": null}
{"id": "1a62e064-4107-4dfa-88c0-574027b2ee28", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance / (1 + np.exp(-fitness_variance))  # Sigmoid adjustment\n\n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Minor adaptation of the mutation rate calculation, incorporating a sigmoid function to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.13628885652855813, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.136 with standard deviation 0.001. And the mean value of best solutions found was 0.662 (0. is the best) with standard deviation 0.152.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.13611641655302487, 0.13533967535929303, 0.13741047767335646], "final_y": [0.8749541873868885, 0.5297502225571826, 0.581894765254637]}, "mutation_prompt": null}
{"id": "a06892d7-5e5b-4355-9924-f66c84ba3cf9", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.population_size = self.base_population_size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Levy flight mutation\n        levy_step = np.random.standard_cauchy(size=real_values.shape)\n        levy_mutation = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[levy_mutation] += levy_step[levy_mutation]\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def adapt_population_size(self):\n        \"\"\"Adapt population size based on budget utilization.\"\"\"\n        used_budget_ratio = self.budget / self.base_population_size\n        self.population_size = self.base_population_size + int(used_budget_ratio * 10)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            self.adapt_population_size()\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced exploration using adaptive population size and a Lévy flight mechanism for mutation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {}, "mutation_prompt": null}
{"id": "76ab017e-e471-4aa2-b6f4-fe3d4d766e1b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance and iteration progress\n        fitness_variance = np.var(self.fitness)\n        progress_factor = 1 - (sum(self.fitness < np.inf) / self.budget)  # Progress based\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * progress_factor\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Incorporate adaptive adjustment of the mutation rate based on current iteration progress.", "configspace": "", "generation": 10, "fitness": 0.1809141509063851, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.181 with standard deviation 0.013. And the mean value of best solutions found was 0.516 (0. is the best) with standard deviation 0.131.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.19790974659670413, 0.16683698935802838, 0.17799571676442283], "final_y": [0.3377687919437084, 0.650287129975075, 0.5587788983853448]}, "mutation_prompt": null}
{"id": "a93a508e-849d-44e5-84e3-885bba73735d", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        improvement_rate = np.mean(np.diff(np.sort(self.fitness)))\n        mutation_scale = 0.1 if improvement_rate > 0.01 else 0.05\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, mutation_scale, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Adjust mutation scale based on the population's improvement rate to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.09095959263381444, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.009. And the mean value of best solutions found was 5.377 (0. is the best) with standard deviation 1.137.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.08162751177879868, 0.10272788046424175, 0.0885233856584029], "final_y": [6.6900060476472545, 3.917743555717179, 5.523758325691826]}, "mutation_prompt": null}
{"id": "85c0df03-47e1-40ea-8f5c-bfa2ab6b1e9b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            fitness_factor = 1 + 0.05 * (self.fitness[i] - np.min(self.fitness))  # Adaptivity\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01 * fitness_factor)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01 * fitness_factor)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced exploration by dynamic mutation based on fitness variance with adaptive quantum probability adjustment.", "configspace": "", "generation": 12, "fitness": 0.11530813953441654, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.003. And the mean value of best solutions found was 2.992 (0. is the best) with standard deviation 0.157.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.11128791115283199, 0.1149315012105584, 0.11970500623985925], "final_y": [3.1943469742467303, 2.969868704567002, 2.812274207876716]}, "mutation_prompt": null}
{"id": "15ec6147-52a4-4259-bca0-be71f33495dd", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        adaptive_variance = 0.1 * (1 - np.min(self.fitness) / (np.max(self.fitness) + 1e-9))  # Adaptive scaling\n        real_values[mutation_mask] += np.random.normal(0, adaptive_variance, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Integrate adaptive scaling for mutation variance to enhance local search.", "configspace": "", "generation": 13, "fitness": 0.06442224835192123, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.064 with standard deviation 0.001. And the mean value of best solutions found was 9.016 (0. is the best) with standard deviation 0.371.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.06478887968452218, 0.0650433092625653, 0.06343455610867621], "final_y": [9.467996898353112, 9.021651360552363, 8.559647477679645]}, "mutation_prompt": null}
{"id": "efeee755-7a48-49fd-b3bc-6cb41849f211", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation with adaptive scaling based on improvement rate\n        improvement_rate = np.mean(self.fitness) - np.min(self.fitness)\n        mutation_scale = 0.1 if improvement_rate < 0.01 else 0.05\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, mutation_scale, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced convergence by introducing adaptive mutation scaling based on fitness improvement rate.", "configspace": "", "generation": 14, "fitness": 0.1522109327685572, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.152 with standard deviation 0.011. And the mean value of best solutions found was 0.861 (0. is the best) with standard deviation 0.160.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.15945483044723263, 0.16047829047112716, 0.1366996773873118], "final_y": [0.8872313593539355, 0.6527676113612085, 1.042322741981862]}, "mutation_prompt": null}
{"id": "7d4bf242-9d09-4cc6-b5a3-66ab64f8f73b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.05 * fitness_variance  # Adjusted scaling factor\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improved variance-based mutation by integrating dynamic scaling.", "configspace": "", "generation": 15, "fitness": 0.12630023998999948, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.126 with standard deviation 0.017. And the mean value of best solutions found was 2.531 (0. is the best) with standard deviation 1.026.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.14788475417276092, 0.12388008601391132, 0.10713587978332617], "final_y": [1.259810388923765, 2.5596727046182424, 3.773153769420174]}, "mutation_prompt": null}
{"id": "5b593f28-c07d-455f-ba5b-0ed58e851639", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        scale = 0.1 + 0.05 * np.std(self.fitness)  # Adaptive Gaussian scale\n        offspring = np.clip(np.random.normal(loc=self.q, scale=scale), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improved convergence by adaptive Gaussian scale in quantum-inspired offspring generation.", "configspace": "", "generation": 16, "fitness": 0.0, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.000 with standard deviation 0.000. And the mean value of best solutions found was inf (0. is the best) with standard deviation nan.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.0, 0.0, 0.0], "final_y": [Infinity, Infinity, Infinity]}, "mutation_prompt": null}
{"id": "e4451298-f0be-4790-865a-b234a1e173a9", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        scale_factor = 0.2 / (1 + np.exp(-0.1 * self.population_size))  # Adaptive scaling\n        offspring = np.clip(np.random.normal(loc=self.q, scale=scale_factor), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improved offspring generation strategy with adaptive Gaussian distribution scaling.", "configspace": "", "generation": 17, "fitness": 0.16708351970644952, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.167 with standard deviation 0.009. And the mean value of best solutions found was 0.837 (0. is the best) with standard deviation 0.205.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.17361673105078923, 0.15461623198786867, 0.17301759608069067], "final_y": [0.6807868163604003, 1.1262880043852244, 0.703497328894738]}, "mutation_prompt": null}
{"id": "73ad7e65-d358-4b42-b48c-60e9c3b965f0", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        improvement_rate = np.mean(self.fitness) / (np.min(self.fitness) + 1e-9)\n        dynamic_mutation_rate = self.mutation_rate + 0.05 * fitness_variance * improvement_rate\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced quantum-inspired algorithm with adaptive mutation scaling based on fitness improvement rate.", "configspace": "", "generation": 18, "fitness": 0.1128457482425923, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.007. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.081.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.11704642675143095, 0.11905031294337354, 0.10244050503297242], "final_y": [0.156461216783442, 0.3419067063863739, 0.1900767850842164]}, "mutation_prompt": null}
{"id": "8b6dfeef-3ef6-4b26-acac-2115ff369421", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate * (1 / (1 + fitness_variance))  # Inverse scaling\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refined dynamic mutation by scaling it with the inverse of fitness variance for enhanced convergence stability.", "configspace": "", "generation": 19, "fitness": 0.09297703195102669, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.093 with standard deviation 0.002. And the mean value of best solutions found was 3.894 (0. is the best) with standard deviation 0.297.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.09366468690836205, 0.0952805634694932, 0.08998584547522481], "final_y": [4.003715940596711, 3.4882499031748093, 4.1908303697426685]}, "mutation_prompt": null}
{"id": "401fee1f-996f-494a-b8d4-14ba23543cc0", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.03 * budget))  # Increased dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhanced exploration by dynamic mutation based on fitness variance with adaptive population scaling. ", "configspace": "", "generation": 20, "fitness": 0.134428548837749, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.134 with standard deviation 0.022. And the mean value of best solutions found was 1.824 (0. is the best) with standard deviation 0.664.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.12351145776964456, 0.11482166443661679, 0.1649525243069856], "final_y": [2.2043676841286746, 2.3768552183354985, 0.8905020998767368]}, "mutation_prompt": null}
{"id": "cc96c1f2-b237-4493-b670-d7d3ff1d3f8c", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Mutation\n        improvement_factor = np.abs(self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-10)\n        mutation_mask = np.random.rand(*real_values.shape) < (dynamic_mutation_rate * improvement_factor)\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introducing adaptive mutation scaled by fitness improvement to enhance exploration.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,2) (20,) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,2) (20,) ')", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {}, "mutation_prompt": null}
{"id": "24b6363b-b012-47f9-9c0a-7e92c1404be7", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  # Dynamic population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  # Quantum probabilities\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def measure(self):\n        \"\"\"Measure operation in quantum computing to collapse states.\"\"\"\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        \"\"\"Update quantum probabilities based on the best solution.\"\"\"\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + 0.01)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - 0.01)\n\n    def evolutionary_process(self, lb, ub):\n        \"\"\"Perform evolutionary operations.\"\"\"\n        # Quantum-inspired offspring generation\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)  # Gaussian-based measure\n        \n        # Map offspring to real values within bounds\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        # Dynamic mutation rate based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n        \n        # Adaptive scaling factor for mutation\n        improvement_rate = (np.min(self.fitness) - np.mean(self.fitness)) / np.std(self.fitness)\n        scaling_factor = 1.0 + 0.2 * improvement_rate\n        \n        # Mutation\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += scaling_factor * np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  # Ensure within bounds\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            # Selection: Replace if offspring are better\n            better_indices = new_fitness < self.fitness\n            self.population[better_indices] = new_population[better_indices]\n            self.fitness[better_indices] = new_fitness[better_indices]\n\n            # Update quantum probabilities\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance mutation with adaptive scaling based on fitness improvement rate.", "configspace": "", "generation": 22, "fitness": 0.16726566197174988, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.167 with standard deviation 0.010. And the mean value of best solutions found was 0.575 (0. is the best) with standard deviation 0.321.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.1547507240010052, 0.16750667743576553, 0.17953958447847895], "final_y": [1.0044507120480117, 0.48667727880430683, 0.23421073713670998]}, "mutation_prompt": null}
{"id": "335160e0-4aac-480f-833a-1b3000088a88", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1  # Fraction of top solutions to preserve\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05  # adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Incorporate adaptive learning rates for quantum probabilities and incorporate elitism to preserve top solutions.", "configspace": "", "generation": 23, "fitness": 0.2010610936938998, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.201 with standard deviation 0.015. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.130.", "error": "", "parent_id": "0f262522-74dd-47a9-88e5-8be08636207f", "metadata": {"aucs": [0.22071798180055247, 0.18461950575879738, 0.19784579352234954], "final_y": [0.14757202662217128, 0.4527518187392816, 0.22360977202287005]}, "mutation_prompt": null}
{"id": "3e4e55a8-39bb-40df-8029-6f30674fc2ea", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1  # Fraction of top solutions to preserve\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 * (1 - np.std(self.fitness) / np.mean(self.fitness))  # adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - np.std(self.fitness) / np.mean(self.fitness))\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce self-adaptive adjustment of mutation and learning rates based on fitness convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.1686239013162081, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.169 with standard deviation 0.010. And the mean value of best solutions found was 0.981 (0. is the best) with standard deviation 0.229.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.1791456504377531, 0.15500365968069962, 0.17172239383017163], "final_y": [0.7515497808399607, 1.2937163003864551, 0.8964808677636735]}, "mutation_prompt": null}
{"id": "b6a447c0-dc8f-4481-9e0d-8db3cc6d2e7c", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1  # Fraction of top solutions to preserve\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)\n        learning_rate = 0.05 + 0.05 * fitness_variance  # adaptive learning rate with variance\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve exploration by adjusting quantum probability learning dynamically based on fitness variance.", "configspace": "", "generation": 25, "fitness": 0.11781356568213135, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.118 with standard deviation 0.015. And the mean value of best solutions found was 3.160 (0. is the best) with standard deviation 0.959.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.11391019672537561, 0.1377890403904396, 0.10174145993057881], "final_y": [3.270202915276568, 1.9345836930556914, 4.276240973850355]}, "mutation_prompt": null}
{"id": "ee206bc7-c36d-4009-a935-6e97f49cdae1", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1  # Fraction of top solutions to preserve\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05  # adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate * (1 + 0.1 * fitness_variance)  # Adaptive mutation adjustment\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive learning for mutation rate based on fitness improvement to enhance exploration.", "configspace": "", "generation": 26, "fitness": 0.10789871470195922, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.008. And the mean value of best solutions found was 3.444 (0. is the best) with standard deviation 0.693.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.11022483686365869, 0.09767808089909169, 0.11579322634312728], "final_y": [3.2255247526592123, 4.380225213720254, 2.7259103161326625]}, "mutation_prompt": null}
{"id": "bb8df0b1-69bb-404f-a795-faa5a931a8a1", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.base_population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.base_population_size, self.dim))\n        self.fitness = np.full(self.base_population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)\n        learning_rate = 0.05 + 0.1 * fitness_variance\n        for i in range(self.base_population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        current_population_size = self.base_population_size + int(0.05 * self.budget)\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1) \n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.base_population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive population size and dynamic learning rates for quantum probabilities based on fitness variance.", "configspace": "", "generation": 27, "fitness": 0.09188612876973101, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.004. And the mean value of best solutions found was 5.190 (0. is the best) with standard deviation 0.437.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.08880660217289449, 0.09686822003581652, 0.08998356410048203], "final_y": [5.629483440334691, 4.594510761766089, 5.346410399029462]}, "mutation_prompt": null}
{"id": "5f509afd-a483-4d57-bcfb-bcd9e5c4b987", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(12, int(0.02 * budget))  # Adjusted population size\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)\n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        cosine_factor = np.cos(np.linspace(0, np.pi, self.population_size))\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate * cosine_factor[i])\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def chaotic_perturbation(self, values, lb, ub):\n        perturbation = 0.01 * (ub - lb) * np.sin(100 * values) \n        return np.clip(values + perturbation, lb, ub)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n        real_values = self.chaotic_perturbation(real_values, lb, ub)  # Apply chaotic perturbation\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum probabilities using cosine-based adaptation and integrate a chaotic perturbation strategy to avoid local optima.", "configspace": "", "generation": 28, "fitness": 0.18338409056601992, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.183 with standard deviation 0.016. And the mean value of best solutions found was 0.588 (0. is the best) with standard deviation 0.190.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.1696381726112094, 0.17431269966546414, 0.20620139942138627], "final_y": [0.782779065953809, 0.6494388465098613, 0.3306347545186161]}, "mutation_prompt": null}
{"id": "dc86ec72-4045-47c0-b146-01d773945253", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by adjusting mutation rate based on the best solution's fitness.", "configspace": "", "generation": 29, "fitness": 0.20536720360473434, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.003. And the mean value of best solutions found was 0.284 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "335160e0-4aac-480f-833a-1b3000088a88", "metadata": {"aucs": [0.20913852062725546, 0.20533750908919401, 0.20162558109775353], "final_y": [0.24421596459290462, 0.2796809402259969, 0.32742437306502514]}, "mutation_prompt": null}
{"id": "b4721d9e-a5b5-49c1-807e-cc107a1cc88b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n        self.no_improvement_count = 0  # Line 1: Adding a counter for convergence stalling\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            if self.fitness[best_idx] == np.min(self.fitness):  # Line 2: Check for improvement\n                self.no_improvement_count += 1\n            else:\n                self.no_improvement_count = 0\n            \n            if self.no_improvement_count > 5:  # Reinitialize if convergence stalls\n                self.initialize_population(lb, ub)\n                self.no_improvement_count = 0\n                \n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired evolutionary algorithm by introducing diversity maintenance through random reinitialization when convergence stalls.", "configspace": "", "generation": 30, "fitness": 0.15246853930863322, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.152 with standard deviation 0.014. And the mean value of best solutions found was 1.449 (0. is the best) with standard deviation 0.408.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.14893207665020958, 0.13739873267950087, 0.17107480859618918], "final_y": [1.5038441778144351, 1.9188717920645513, 0.9241942469409912]}, "mutation_prompt": null}
{"id": "8b37f783-3519-47a4-8fda-ec59e2cf3a30", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution, convergence_speed):\n        learning_rate = 0.05 + 0.1 * convergence_speed  # Adapt learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.05 + 0.15 * (1 - best_fitness), real_values[mutation_mask].shape)  # Guided mutation\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        previous_best = np.inf\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            convergence_speed = abs(previous_best - self.fitness[best_idx]) / previous_best\n            previous_best = self.fitness[best_idx]\n            self.update_quantum_probabilities(best_solution, convergence_speed)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance Quantum-Inspired EA by incorporating adaptive learning rates and a guided mutation strategy based on convergence speed.", "configspace": "", "generation": 31, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "70f8cfe9-7784-4d68-833e-3e63890e8dd4", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n        \n        mutation_scale = max(0.1, min(0.5, 0.1 + fitness_variance))  # Adjusted mutation scale\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, mutation_scale, real_values[mutation_mask].shape)  # Applied mutation scale\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired evolutionary algorithm by enhancing population diversity through adaptive mutation scale based on fitness variance.", "configspace": "", "generation": 32, "fitness": 0.13496328395179127, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.135 with standard deviation 0.005. And the mean value of best solutions found was 1.466 (0. is the best) with standard deviation 0.757.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1354199782183957, 0.1406440346486696, 0.12882583898830857], "final_y": [1.8509114632877284, 0.4087851426477294, 2.1378189378553687]}, "mutation_prompt": null}
{"id": "3c34737d-a4d7-454e-9210-f84b70fd4a26", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.15 * fitness_variance * (1 - best_fitness)  # Adjusted line.\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by refining the dynamic mutation rate calculation to further exploit the fitness variance.", "configspace": "", "generation": 33, "fitness": 0.09854059943616474, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.099 with standard deviation 0.005. And the mean value of best solutions found was 4.610 (0. is the best) with standard deviation 0.533.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09190660277908824, 0.0987601376288143, 0.10495505790059168], "final_y": [5.298936184388005, 4.530529249914782, 4.001156103602925]}, "mutation_prompt": null}
{"id": "2d49bd77-e90a-454b-9c9a-f968ee57baf8", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line\n        dynamic_learning_rate = 0.05 + 0.1 * fitness_variance  # Modified line\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + dynamic_learning_rate)  # Modified line\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - dynamic_learning_rate)  # Modified line\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by dynamically adjusting learning rate based on fitness variance.", "configspace": "", "generation": 34, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "b951354d-5b35-4134-b689-cf571b9bd5a8", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity = np.std(self.population, axis=0)  # Calculate diversity across the population\n        learning_rate = 0.05 + 0.1 * np.mean(diversity)  # Adjust learning rate based on diversity\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired EA by incorporating adaptive quantum probability updating based on population diversity.", "configspace": "", "generation": 35, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "7d89121c-caa5-43bb-8af1-a0939c0e7e12", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            elite_indices = best_indices[:int(self.elite_fraction * self.population_size)]  # Added line for elitism\n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce elitism by preserving a fraction of the best solutions directly into the next generation for maintaining diversity.", "configspace": "", "generation": 36, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "a9aaf75b-309c-4fa5-8322-05503824f679", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity = np.std(self.population, axis=0)  # Calculating population diversity\n        learning_rate = 0.05 + 0.05 * np.mean(diversity)  # Making learning rate adaptive based on diversity\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the quantum-inspired evolutionary algorithm by introducing adaptive quantum probability adjustment based on population diversity.", "configspace": "", "generation": 37, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "aa304eca-605e-4ed1-8fe3-6081f6d4ccfb", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        fitness_variance = np.var(self.fitness)  # New line to calculate fitness variance for adaptive learning\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate * (1 + fitness_variance))  # Adapt learning rate\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate * (1 + fitness_variance))  # Adapt learning rate\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n\n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n\n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by using adaptive learning rate in quantum probability updates to improve convergence.", "configspace": "", "generation": 38, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "6616279d-a075-41ab-aa65-0b6c34308be2", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line to calculate fitness variance for dynamic learning rate.\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Modified line to dynamically adjust learning rate.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by dynamically adjusting the learning rate based on fitness variance.", "configspace": "", "generation": 39, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "1312f18c-8072-49af-94fb-34f448185621", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        diversity_scale = 0.1 + 0.1 * np.std(self.population)  # Adjust mutation scale based on diversity\n        offspring = np.clip(np.random.normal(loc=self.q, scale=diversity_scale), 0, 1)  # Updated line\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance mutation diversity by introducing adaptive scale parameters based on population diversity.", "configspace": "", "generation": 40, "fitness": 0.08386070410461159, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.084 with standard deviation 0.007. And the mean value of best solutions found was 4.427 (0. is the best) with standard deviation 1.284.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.07560083345075519, 0.09256799364323698, 0.08341328521984259], "final_y": [5.345066830896336, 2.6108858853013883, 5.32383013654848]}, "mutation_prompt": null}
{"id": "7ce1c7d7-beed-4b91-8f0d-ad55103cc150", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        fitness_variance = np.var(self.fitness)\n        self.population_size = max(10, int(self.population_size * (1 + 0.1 * fitness_variance)))  # Dynamic population size update\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by dynamically adjusting population size based on fitness variance.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "0bfa341d-09c2-4b24-9d5f-db92d661bc85", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)\n        learning_rate = 0.01 + 0.04 * fitness_variance  # Changed line to adjust learning rate dynamically.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by dynamically adjusting learning rate based on fitness variance.", "configspace": "", "generation": 42, "fitness": 0.11268085747045005, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.016. And the mean value of best solutions found was 3.581 (0. is the best) with standard deviation 1.344.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09076596535167936, 0.1281377274615364, 0.1191388795981344], "final_y": [5.456470989298568, 2.3743065508366956, 2.9117003537546835]}, "mutation_prompt": null}
{"id": "9a3cd3fe-2b19-4056-b501-aab29d5521b2", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_improvement = np.mean(self.fitness) - np.min(self.fitness)\n        dynamic_learning_rate = 0.05 + 0.1 * fitness_improvement\n        \n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + dynamic_learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - dynamic_learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by integrating adaptive learning rates for quantum probability updates based on fitness improvements.", "configspace": "", "generation": 43, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "df5fca71-f7fd-4fb9-961f-fd27b0b841b1", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))\n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)\n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        avg_fitness = np.mean(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness / avg_fitness)  # Updated line\n        \n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve the dynamic mutation rate by considering both fitness variance and the ratio of current best fitness to average fitness.", "configspace": "", "generation": 44, "fitness": 0.11446334902355826, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.019. And the mean value of best solutions found was 3.430 (0. is the best) with standard deviation 1.187.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.10079205761170751, 0.10184338987746933, 0.14075459958149794], "final_y": [4.326010584539333, 4.212466718800095, 1.7522233849144684]}, "mutation_prompt": null}
{"id": "448fa524-8fd5-4799-8223-84b34c20a6a0", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n        \n        # Adaptive population size\n        self.population_size = max(10, int(self.population_size * (1 + 0.1 * (best_fitness - np.mean(self.fitness)))))\n\n        # Adaptive differential mutation factor\n        mutation_factor = 0.8 + 0.2 * (1 - best_fitness)\n        mutation_mask = np.random.rand(*real_values.shape) < (dynamic_mutation_rate * mutation_factor)\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Incorporate adaptive population size and differential mutation factor based on convergence rate in quantum-inspired evolutionary algorithm.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "a27f4400-6815-4431-bb88-a5f6b941b32c", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        best_fitness = np.min(self.fitness)  # Dynamically adjust learning rate based on best fitness.\n        learning_rate = 0.05 * (1 - best_fitness)\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by dynamically adjusting both mutation rate and learning rate to enhance exploration and convergence.", "configspace": "", "generation": 46, "fitness": 0.06127324721644556, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.061 with standard deviation 0.014. And the mean value of best solutions found was 10.992 (0. is the best) with standard deviation 3.235.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.0787138791891836, 0.04504600536852854, 0.060059857091624536], "final_y": [7.1630783399655185, 15.075347433122728, 10.737494492337694]}, "mutation_prompt": null}
{"id": "162690b8-a787-4eec-86fe-8cb7c64b005e", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 * (1 - np.mean(self.fitness))  # Changed line: adaptive learning rate based on fitness.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the quantum-inspired evolutionary algorithm by implementing adaptive learning rates for both quantum probabilities and mutation rate.", "configspace": "", "generation": 47, "fitness": 0.09175666787909975, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.453 (0. is the best) with standard deviation 1.092.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08816606354154843, 0.08240051184241926, 0.10470342825333157], "final_y": [5.782452321849942, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "e50dd6ba-93ce-4de4-a9b9-9a82bfdbfb46", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity = np.mean(np.std(self.population, axis=0))  # Population diversity\n        learning_rate = 0.05 * (1 + diversity)  # Adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by adding elitism and adaptive learning rate based on population diversity.", "configspace": "", "generation": 48, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "dcd44bc0-74f3-4118-88f0-286f67acc25f", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.05 * np.random.rand()  # Changed line to introduce dynamic learning rates.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n        \n        elite_indices = np.argsort(self.fitness)[:int(self.population_size * self.elite_fraction)]\n        self.elites = self.population[elite_indices]  # Changed line to include adaptive elite selection.\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the quantum-inspired EA by introducing dynamic learning rates and adaptive elite selection.", "configspace": "", "generation": 49, "fitness": 0.10229953129702318, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.102 with standard deviation 0.002. And the mean value of best solutions found was 4.194 (0. is the best) with standard deviation 0.184.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09978170534431541, 0.10241346029342258, 0.10470342825333157], "final_y": [4.430092533827097, 4.169571495112289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "1fef5818-c11a-4b05-bbc8-be45f7a2921e", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        adaptive_factor = np.random.uniform(0.9, 1.1)  # changed line to introduce adaptive adjustment\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate * adaptive_factor)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate * adaptive_factor)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive quantum probability adjustment to enhance exploration in quantum-inspired evolutionary algorithm.", "configspace": "", "generation": 50, "fitness": 0.10764762668263805, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.010. And the mean value of best solutions found was 3.648 (0. is the best) with standard deviation 0.800.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.11012017695402943, 0.09446625549327703, 0.1183564476006077], "final_y": [3.4009642285460084, 4.728576710049143, 2.8155107406024737]}, "mutation_prompt": null}
{"id": "9e9b73a7-92ea-434d-85db-ba670ee0ebdf", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # New line to calculate fitness variance for dynamic learning rate.\n        learning_rate = max(0.01, 0.1 * fitness_variance)  # Dynamic learning rate based on fitness variance.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by setting dynamic learning rate for updating quantum probabilities based on fitness variance.", "configspace": "", "generation": 51, "fitness": 0.08461103396866483, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.085 with standard deviation 0.008. And the mean value of best solutions found was 5.994 (0. is the best) with standard deviation 0.956.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.07687870458524859, 0.0810648874378681, 0.09588950988287781], "final_y": [6.922134645855567, 6.381429151089702, 4.677512995983432]}, "mutation_prompt": null}
{"id": "2835a2cc-2a1c-46f6-84c3-196d2b9dce0b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n            # Update elite fraction based on improvement in fitness over time\n            self.elite_fraction = max(0.05, min(0.2, self.elite_fraction * (1 + (np.std(self.fitness) / np.mean(self.fitness)))))\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by introducing adaptive elite fraction based on convergence rate to improve diversity and exploration.", "configspace": "", "generation": 52, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "7fde9387-0649-4bae-a121-c82f7ef2dfaa", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.rand(self.dim)\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n\n        for i in range(0, self.population_size, 2):\n            if i+1 < self.population_size:\n                child1 = self.crossover(real_values[i], real_values[i+1])\n                child2 = self.crossover(real_values[i+1], real_values[i])\n                real_values[i], real_values[i+1] = child1, child2\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the evolutionary process by adding crossover with dynamic mutation rate adjustment.", "configspace": "", "generation": 53, "fitness": 0.12752974343609283, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.128 with standard deviation 0.012. And the mean value of best solutions found was 1.150 (0. is the best) with standard deviation 0.675.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.13662296246331196, 0.1098695720574695, 0.13609669578749706], "final_y": [0.3965127937323302, 2.0342627177584554, 1.018424503268681]}, "mutation_prompt": null}
{"id": "061cea69-9f48-433e-8fa0-cae548d0781a", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n            # Preserving the best solutions across generations\n            elite_count = int(self.elite_fraction * self.population_size)\n            elites_indices = np.argsort(self.fitness)[:elite_count]\n            self.elites = self.population[elites_indices]\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by introducing elitism to preserve the best solutions across generations for improved convergence.", "configspace": "", "generation": 54, "fitness": 0.14611900980701598, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.146 with standard deviation 0.033. And the mean value of best solutions found was 1.386 (0. is the best) with standard deviation 0.927.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.10531652329320484, 0.146445181271329, 0.1865953248565141], "final_y": [2.557948390449175, 1.310467108037199, 0.2905821396752921]}, "mutation_prompt": null}
{"id": "71101a76-d7f9-49e7-898f-83c7ccaba901", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):  # Modified line for adaptive learning rate.\n        learning_rate = 0.05 + 0.05 * np.var(self.fitness)  # Change made here\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by incorporating adaptive learning rates based on the variance of the fitness values.", "configspace": "", "generation": 55, "fitness": 0.17055628598682004, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.171 with standard deviation 0.007. And the mean value of best solutions found was 0.629 (0. is the best) with standard deviation 0.280.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.17255306080979904, 0.1775662217306322, 0.1615495754200289], "final_y": [0.5829854786686359, 0.3124556712190916, 0.9930286782821001]}, "mutation_prompt": null}
{"id": "b732c8e2-bb96-4756-8326-c8194715c5fe", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        diversity_degree = np.std(real_values, axis=0).mean() # Calculate population diversity\n        dynamic_population_size = int(self.population_size * (1 + diversity_degree)) # Adjust population size\n        dynamic_population_size = min(dynamic_population_size, self.budget - 10) \n        \n        mutation_mask = np.random.rand(*real_values.shape) < self.mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values[:dynamic_population_size]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by introducing adaptive population size and elite strategy based on diversity metrics.", "configspace": "", "generation": 56, "fitness": 0.20315548768220912, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.203 with standard deviation 0.022. And the mean value of best solutions found was 0.376 (0. is the best) with standard deviation 0.306.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.22654311704621088, 0.2090684235356427, 0.17385492246477374], "final_y": [0.07260891755244987, 0.2600267567609931, 0.7958518859806042]}, "mutation_prompt": null}
{"id": "7fd9ecb0-f6c2-409b-b992-5a23c4d265d7", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # New line to calculate fitness variance.\n        learning_rate = 0.05 + 0.05 * fitness_variance  # Modified line for adaptive learning rate.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm with adaptive learning rate based on fitness variance.", "configspace": "", "generation": 57, "fitness": 0.16721719660348633, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.167 with standard deviation 0.006. And the mean value of best solutions found was 1.010 (0. is the best) with standard deviation 0.133.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.16493722361249719, 0.16120218123668084, 0.17551218496128096], "final_y": [1.048489437906137, 1.149476196966171, 0.8318107845639116]}, "mutation_prompt": null}
{"id": "bf99c6c5-5fd0-417e-a3af-64f8fdde6be1", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n        self.elite_fraction = 0.1 + 0.1 * (1 - best_fitness)  # Dynamically adjust elite fraction based on best fitness.\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by dynamically adjusting both mutation rate and elite fraction based on the best fitness.", "configspace": "", "generation": 58, "fitness": 0.09446205851027352, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.094 with standard deviation 0.004. And the mean value of best solutions found was 5.054 (0. is the best) with standard deviation 0.460.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08904122631121092, 0.09520395843401974, 0.09914099078558991], "final_y": [5.662854647970263, 4.947761182659003, 4.552085967134917]}, "mutation_prompt": null}
{"id": "9f162b06-e68c-4521-8304-58314b42d734", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        adaptive_noise = np.random.normal(0, fitness_variance, real_values[mutation_mask].shape)  # Change 1\n        real_values[mutation_mask] += adaptive_noise  # Change 2\n        np.clip(real_values, lb, ub, out=real_values)\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance mutation diversity by introducing adaptive Gaussian noise based on the fitness variance to balance exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "efb2d83a-bc85-4547-8406-0b6ef52936bf", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < (dynamic_mutation_rate * np.random.rand())  # Modified line\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance offspring generation in QuantumInspiredEA by modifying mutation mask for improved exploration.", "configspace": "", "generation": 60, "fitness": 0.1044367359865559, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.005. And the mean value of best solutions found was 3.990 (0. is the best) with standard deviation 0.473.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.11031197122964942, 0.09792589623992543, 0.10507234049009284], "final_y": [3.432356443771499, 4.5892199448263895, 3.948449668890778]}, "mutation_prompt": null}
{"id": "5a308366-d207-4662-9cd2-57d9625c52b4", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.elite_fraction = 0.1 + 0.4 * (np.std(self.fitness) / (np.max(self.fitness) - np.min(self.fitness))) # Change to dynamically adjust elite fraction\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired EA by dynamically adjusting the elite fraction based on the population's fitness diversity.", "configspace": "", "generation": 61, "fitness": 0.09903004388604757, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.099 with standard deviation 0.007. And the mean value of best solutions found was 4.298 (0. is the best) with standard deviation 0.730.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.10655405776976368, 0.08990823387336011, 0.1006278400150189], "final_y": [3.519647153514653, 5.274169583493807, 4.099205485009446]}, "mutation_prompt": null}
{"id": "9eb9cf45-737a-419e-9696-921429488304", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        # Adaptive crossover\n        offspring = np.clip(self.q + np.random.normal(0, 0.1 * np.std(self.q)), 0, 1)\n\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        # Enhanced mutation strategy\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1 * dynamic_mutation_rate, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by incorporating adaptive crossover and enhanced mutation strategy based on population diversity.", "configspace": "", "generation": 62, "fitness": 0.047404184596838816, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.047 with standard deviation 0.000. And the mean value of best solutions found was 14.323 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.047404184596838816, 0.047404184596838816, 0.047404184596838816], "final_y": [14.323138954034944, 14.323138954034944, 14.323138954034944]}, "mutation_prompt": null}
{"id": "c631275c-d261-4de3-bba9-9415c22edfa7", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * np.log(1 + fitness_variance) * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance mutation rate adaptation using logarithmic scaling based on fitness variance.", "configspace": "", "generation": 63, "fitness": 0.08885455484892264, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 5.646 (0. is the best) with standard deviation 0.423.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08436867289473216, 0.09221693632186279, 0.089978055330173], "final_y": [6.2183854244959145, 5.207673453263591, 5.513081478341395]}, "mutation_prompt": null}
{"id": "bfd15b10-fdca-4438-9cc4-03707a388134", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.1 * np.var(self.q)  # Adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the quantum-inspired evolutionary algorithm by introducing adaptive learning rates and a preservation mechanism for elite solutions.", "configspace": "", "generation": 64, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "96f2ab1f-93eb-43e0-b63b-e03acb24adbc", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.95, self.q[i, j] + learning_rate * 1.1)  # Adjusting probability update\n                else:\n                    self.q[i, j] = max(0.05, self.q[i, j] - learning_rate * 0.9)  # Adjusting probability update\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.05, real_values[mutation_mask].shape)  # Adjusting mutation magnitude\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the Quantum-inspired EA by introducing adaptive quantum probability and mutation adjustment based on dynamic fitness landscapes.", "configspace": "", "generation": 65, "fitness": 0.10374106850729618, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.007. And the mean value of best solutions found was 4.102 (0. is the best) with standard deviation 0.578.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09857378614448808, 0.09951257342190367, 0.11313684595549678], "final_y": [4.561988098067105, 4.457321547453513, 3.2862221233271054]}, "mutation_prompt": null}
{"id": "e20faf5c-67ae-4902-8a76-84c2b6e3d89b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        fitness_variance = np.var(self.fitness)\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1 * (1 + fitness_variance)), 0, 1)  # Line 1 changed\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by incorporating adaptive scaling in the evolutionary process based on fitness variance.", "configspace": "", "generation": 66, "fitness": 0.0, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.000 with standard deviation 0.000. And the mean value of best solutions found was inf (0. is the best) with standard deviation nan.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.0, 0.0, 0.0], "final_y": [Infinity, Infinity, Infinity]}, "mutation_prompt": null}
{"id": "309eb20c-ddab-48e5-bc4a-b05c90a58baf", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.05), 0, 1)  # Changed line: Reduced scale for finer adjustments.\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.05, real_values[mutation_mask].shape)  # Changed line: Reduced step size for mutations.\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by incorporating self-adaptive offspring scaling and mutation step size to boost convergence.", "configspace": "", "generation": 67, "fitness": 0.09282862157628657, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.093 with standard deviation 0.003. And the mean value of best solutions found was 5.189 (0. is the best) with standard deviation 0.446.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08797842660277921, 0.09544293360804856, 0.09506450451803194], "final_y": [5.818616849819655, 4.847657150204983, 4.9009464084227305]}, "mutation_prompt": null}
{"id": "aa5a9d9a-891f-46e0-84d7-eead67d087f0", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        fitness_variance = np.var(self.fitness)  # Added line to adjust learning rate based on fitness variance.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate * (1 + fitness_variance))  # Modified line.\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate * (1 + fitness_variance))  # Modified line.\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by dynamically adjusting both mutation rate and learning rate for quantum probability updates based on fitness variance.", "configspace": "", "generation": 68, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "0c72cae7-0f11-4b09-9509-31f03ca6607c", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.95, self.q[i, j] + learning_rate)  # Change 1\n                else:\n                    self.q[i, j] = max(0.05, self.q[i, j] - learning_rate)  # Change 2\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        diversity = np.mean(np.std(self.population, axis=0))  # Change 3\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness) + 0.05 * diversity\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Fine-tune quantum probabilities and improve mutation adaptiveness by incorporating population diversity metrics.", "configspace": "", "generation": 69, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "0e0f731c-4459-477f-ae6e-2601326cecfe", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.1 * (1 - np.min(self.fitness))  # Adapt learning rate based on fitness.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, (ub - lb) * 0.05, real_values[mutation_mask].shape)  # Boundary-aware mutation.\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the Quantum-Inspired Evolutionary Algorithm by incorporating adaptive learning rates and boundary-aware mutation.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 2 with shape (2,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 2 with shape (2,).')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "9314215b-0a83-41d9-a1f1-70876d1c5266", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        top_k = int(self.elite_fraction * self.population_size)\n        elite_solutions = self.population[np.argsort(self.fitness)[:top_k]]  # New line to select top solutions as elites\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n\n        return np.vstack((real_values, elite_solutions))  # New line to include elites in the offspring\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance exploitation by introducing elitism and adjusting quantum probability based on top solutions.", "configspace": "", "generation": 71, "fitness": 0.16321277226609368, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.163 with standard deviation 0.035. And the mean value of best solutions found was 1.014 (0. is the best) with standard deviation 0.686.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.13498980424532525, 0.14266579187684014, 0.21198272067611568], "final_y": [1.8509114632877284, 1.0208710807929469, 0.16943196604611244]}, "mutation_prompt": null}
{"id": "6435a835-c665-419a-855b-b1b848417461", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line to calculate fitness variance.\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Adjusted learning rate based on fitness variance.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by adapting quantum probability update learning rate based on fitness variance.", "configspace": "", "generation": 72, "fitness": 0.09355966075684978, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.094 with standard deviation 0.009. And the mean value of best solutions found was 5.121 (0. is the best) with standard deviation 1.002.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09030932812996051, 0.08433730468878364, 0.10603234945180517], "final_y": [5.176943752798026, 6.3189695058073285, 3.8664763534759534]}, "mutation_prompt": null}
{"id": "23a9c4ee-df4f-4bbb-8a94-f43c1dc6baa3", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n\n            elite_count = int(self.elite_fraction * self.population_size * (1 + fitness_variance))  # Changed line\n            elites = best_indices[:elite_count]  # Changed line\n\n            self.population = combined_population[elites]  # Changed line\n            self.fitness = combined_fitness[elites]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by introducing adaptive elite selection based on fitness variance.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'fitness_variance' is not defined\").", "error": "NameError(\"name 'fitness_variance' is not defined\")", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "e96e717a-5a13-49d6-a6d4-28ff9c7a8a5d", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity = np.mean(np.std(self.population, axis=0))  # Added to measure population diversity\n        adaptive_learning_rate = 0.05 * (1 + diversity)  # Adaptive learning rate adjusted based on diversity\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + adaptive_learning_rate)  # Applied adaptive learning rate\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - adaptive_learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive learning rate based on population diversity to enhance convergence in quantum-inspired evolutionary algorithm.", "configspace": "", "generation": 74, "fitness": 0.1269755106615953, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.127 with standard deviation 0.012. And the mean value of best solutions found was 1.823 (0. is the best) with standard deviation 1.229.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1108825724785305, 0.13887006493257092, 0.13117389457368445], "final_y": [3.405815943410225, 0.4087851426477294, 1.6555436431452253]}, "mutation_prompt": null}
{"id": "10625d7b-37cb-4316-865d-c24bdb4be832", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)\n        learning_rate = 0.05 + 0.01 * fitness_variance  # Adjusted learning rate based on fitness variance.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by adjusting learning rate based on fitness variance to improve optimization.", "configspace": "", "generation": 75, "fitness": 0.10998500169172942, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.014. And the mean value of best solutions found was 3.507 (0. is the best) with standard deviation 1.177.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09146974693211152, 0.11263540617730272, 0.12584985196577403], "final_y": [5.123229090247418, 3.041441470276996, 2.3550448798164743]}, "mutation_prompt": null}
{"id": "8ee06c38-aeda-4aaf-8241-baf0b25c405f", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n        self.previous_best_fitness = np.inf  # Added line to track previous best fitness.\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        fitness_improvement = max(0, self.previous_best_fitness - best_fitness) / self.previous_best_fitness  # Calculate improvement.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness) + 0.05 * fitness_improvement  # Adjust mutation rate.\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n            self.previous_best_fitness = self.fitness[best_idx]  # Update previous best fitness.\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the adaptive mutation rate by incorporating fitness improvement over generations in QuantumInspiredEA.", "configspace": "", "generation": 76, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "9fc2ac0d-9cbe-402b-bfe4-fcf86a1c1375", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.01 * np.std(self.fitness)  # Adjusted learning rate based on fitness std\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refined Quantum-Inspired EA by incorporating adaptive learning rate and enhanced initialization for improved search space exploration.", "configspace": "", "generation": 77, "fitness": 0.12391940690960153, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.124 with standard deviation 0.031. And the mean value of best solutions found was 3.088 (0. is the best) with standard deviation 1.739.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08987181098845198, 0.11642259683740963, 0.16546381290294299], "final_y": [5.26214895377282, 2.996173869765765, 1.005361454210095]}, "mutation_prompt": null}
{"id": "7c3fe179-9ac8-4e6e-9b8d-dee45851b0c5", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        fitness_ranks = np.argsort(np.argsort(self.fitness))  # Rank solutions based on fitness\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                target_prob = 1 - (fitness_ranks[i] / self.population_size)\n                self.q[i, j] = self.q[i, j] * (1 - learning_rate) + target_prob * learning_rate\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired evolutionary algorithm by using fitness rank-based probability updates instead of relying solely on the best solution.", "configspace": "", "generation": 78, "fitness": 0.1621012092185419, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.162 with standard deviation 0.023. And the mean value of best solutions found was 1.068 (0. is the best) with standard deviation 0.537.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1947796246256892, 0.1480706505424848, 0.14345335248745172], "final_y": [0.3151338506309305, 1.3564371575579641, 1.532561671232286]}, "mutation_prompt": null}
{"id": "10417c15-942f-45aa-adce-f4f6d716789b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Dynamic learning rate adjustment\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n\n            elite_size = max(1, int(self.elite_fraction * len(best_indices)))\n            self.elites = combined_population[best_indices[:elite_size]]  # Adaptive elite retention\n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce adaptive elite retention and dynamic learning rate to enhance exploration and exploitation balance in the quantum-inspired evolutionary algorithm.", "configspace": "", "generation": 79, "fitness": 0.16769938817211963, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.168 with standard deviation 0.007. And the mean value of best solutions found was 0.757 (0. is the best) with standard deviation 0.068.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1651764107547089, 0.1605107991559257, 0.1774109546057243], "final_y": [0.8521741476563369, 0.7150089997773732, 0.703209579032134]}, "mutation_prompt": null}
{"id": "37c30e86-4b6c-4337-b364-0617f2d4eb7b", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by adjusting mutation rate based on the best solution's fitness.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.20913852062725546, 0.20533750908919401, 0.20162558109775353], "final_y": [0.24421596459290462, 0.2796809402259969, 0.32742437306502514]}, "mutation_prompt": null}
{"id": "e2f1e4e0-0b6b-4eda-9aba-9dfdf89eeb8c", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            # Preserve elite solutions\n            self.population[0] = best_solution\n            self.fitness[0] = self.fitness[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce elite solution preservation to improve convergence by ensuring best-performing solutions are retained.", "configspace": "", "generation": 81, "fitness": 0.1655428770315328, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.166 with standard deviation 0.017. And the mean value of best solutions found was 1.094 (0. is the best) with standard deviation 0.348.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1558982354906766, 0.1889703791630153, 0.15176001644090653], "final_y": [1.2620011956924202, 0.6098116331467717, 1.4108809037659098]}, "mutation_prompt": null}
{"id": "bd3ece55-c9f7-49da-bc52-272e6a132326", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line to calculate fitness variance.\n        adaptive_learning_rate = 0.05 + 0.1 * fitness_variance  # Adjusted learning rate based on fitness variance.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + adaptive_learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - adaptive_learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n\n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by introducing adaptive learning rate based on current best fitness variance.", "configspace": "", "generation": 82, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "dbd6de4c-273c-48b7-8749-155b78315a7a", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity = np.mean(np.std(self.population, axis=0))  # Added line: calculate diversity\n        learning_rate = 0.05 * (1 + diversity)  # Updated line: adjust learning rate based on diversity\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired evolutionary algorithm by dynamically adjusting learning rate based on solution diversity.", "configspace": "", "generation": 83, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "ea3b7e14-629d-49af-ad61-92086a0e14ee", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.1 * (np.argmin(self.fitness) / self.budget)  # Adaptive learning rate based on progress\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum-inspired EA by using adaptive learning rate based on fitness improvement trends.", "configspace": "", "generation": 84, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "e7977335-8298-4345-8e50-4944a6c94735", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n        \n        # Modified lines start here\n        learning_rates = 0.01 + 0.09 * (self.fitness - best_fitness) / (np.max(self.fitness) - best_fitness)\n        mutation_mask = np.random.rand(*real_values.shape) < (dynamic_mutation_rate * learning_rates[:, None])\n        # Modified lines end here\n\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Adapt mutation strategy by introducing fitness-based learning rates and dynamic mutation scaling.", "configspace": "", "generation": 85, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "27c18b33-9492-4b12-8bf1-50fcb4210b54", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.05), 0, 1)  # Adjusted scale for stability\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        elite_diversity = np.std(self.population[:int(self.elite_fraction * self.population_size)], axis=0)  # Consider elite diversity\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness) * (1 + np.mean(elite_diversity))  # Adjust mutation rate\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine adaptive mutation rate by incorporating elite diversity and improve offspring generation stability.", "configspace": "", "generation": 86, "fitness": 0.09282862157628657, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.093 with standard deviation 0.003. And the mean value of best solutions found was 5.189 (0. is the best) with standard deviation 0.446.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08797842660277921, 0.09544293360804856, 0.09506450451803194], "final_y": [5.818616849819655, 4.847657150204983, 4.9009464084227305]}, "mutation_prompt": null}
{"id": "d301c2e3-5f0b-4d90-b957-64d29f139597", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.95, self.q[i, j] + learning_rate / 2)  # Adjusted line\n                else:\n                    self.q[i, j] = max(0.05, self.q[i, j] - learning_rate / 2)  # Adjusted line\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.2 * fitness_variance * (1 - best_fitness)  # Adjusted line\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired evolutionary algorithm by improving mutation rate dynamics and probability update to enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.1182814440961315, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.118 with standard deviation 0.009. And the mean value of best solutions found was 2.932 (0. is the best) with standard deviation 0.607.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.1055443785116228, 0.12768526953891635, 0.12161468423785537], "final_y": [3.7605554626331457, 2.3248307626522964, 2.709324102736088]}, "mutation_prompt": null}
{"id": "9223d85f-4658-4d9e-9e57-dd5be586e668", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # New line for adaptive learning rate\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Updated line for adaptive learning\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Introduce an adaptive learning rate for quantum probability updates based on fitness variance to enhance convergence.", "configspace": "", "generation": 88, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "9dabafe4-8441-4ce4-8f46-7486868bfbc1", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n\n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            self.population_size = max(10, int(0.02 * (self.budget - eval_count)))  # Changed line\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine QuantumInspiredEA by introducing adaptive population size to improve diversity and convergence.", "configspace": "", "generation": 89, "fitness": 0.10779793860249327, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.009. And the mean value of best solutions found was 3.098 (0. is the best) with standard deviation 0.405.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09902215046004337, 0.10469547093569675, 0.11967619441173971], "final_y": [3.1534964215560657, 3.5643691465845735, 2.5762700416420494]}, "mutation_prompt": null}
{"id": "b684b675-a676-426e-a406-82d64ae405ec", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)\n\n        # Dynamically adjust population size\n        self.population_size = max(10, int(0.02 * budget) + int(fitness_variance * 100))\n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance Quantum-Inspired EA by adjusting population size dynamically based on fitness variance.", "configspace": "", "generation": 90, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'budget' is not defined\").", "error": "NameError(\"name 'budget' is not defined\")", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "aac24349-6d22-4f3d-a22a-a4efb4b0a00e", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line for adaptive learning rate.\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Modified line to make learning rate adaptive.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness) \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by incorporating an adaptive learning rate based on fitness variance.", "configspace": "", "generation": 91, "fitness": 0.12309815431306044, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.123 with standard deviation 0.013. And the mean value of best solutions found was 1.912 (0. is the best) with standard deviation 1.344.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.10645402558603734, 0.1380310874189552, 0.1248093499341888], "final_y": [3.6719330632882006, 0.4087851426477294, 1.6555436431452253]}, "mutation_prompt": null}
{"id": "06608086-418b-460a-8368-761880463e62", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05 + 0.5 * (1 - np.min(self.fitness))  # Adaptive learning rate\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            elite_count = max(1, int(self.elite_fraction * self.population_size))  # Dynamic elite count\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the QuantumInspiredEA by incorporating adaptive learning rates and dynamic elite selection to improve convergence.", "configspace": "", "generation": 92, "fitness": 0.05653851180241668, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.057 with standard deviation 0.006. And the mean value of best solutions found was 11.777 (0. is the best) with standard deviation 1.656.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.05965714159768032, 0.048097739061827904, 0.06186065474774183], "final_y": [10.913669758551286, 14.093411490080442, 10.323471988722478]}, "mutation_prompt": null}
{"id": "de3c0c0c-8429-4fda-8e6c-a78af7726f7a", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Changed line to use dynamic learning rate.\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Changed line to introduce dynamic component.\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Improve quantum-inspired evolutionary algorithm by dynamically adjusting learning rate based on fitness variance.", "configspace": "", "generation": 93, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "9faba593-5f5e-429d-a01c-fbe4f6061316", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n        \n        # Adjust population size based on fitness variance\n        self.population_size = int(max(10, self.population_size * (1 + 0.05 * fitness_variance)))\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by dynamically adjusting population size based on fitness variance for improved exploration-exploitation balance.", "configspace": "", "generation": 94, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {}, "mutation_prompt": null}
{"id": "1415e2cf-ca57-4919-9c16-656f44a888b5", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness) * 0.5  # Adjust mutation dynamics\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def crowding_distance(self, fitness):  # New helper function for diversity preservation\n        population_size = fitness.size\n        distances = np.zeros(population_size)\n        sorted_indices = np.argsort(fitness)\n        max_fitness, min_fitness = fitness[sorted_indices[-1]], fitness[sorted_indices[0]]\n        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n\n        for i in range(1, population_size - 1):\n            distances[sorted_indices[i]] = (fitness[sorted_indices[i + 1]] - fitness[sorted_indices[i - 1]]) / (max_fitness - min_fitness)\n        \n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            crowding_dist = self.crowding_distance(combined_fitness)  # Use crowding distance\n            best_indices = np.lexsort((crowding_dist, combined_fitness))[:self.population_size]  # Use crowding distance for selection\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Refine quantum-inspired EA by enhancing dynamic mutation strategy and employing diversity preservation via crowding distance.", "configspace": "", "generation": 95, "fitness": 0.12756274401970738, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.128 with standard deviation 0.012. And the mean value of best solutions found was 2.465 (0. is the best) with standard deviation 0.673.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.13536090874108997, 0.13636794264366414, 0.11095938067436806], "final_y": [2.0123062584417633, 1.9658761371104527, 3.4160932625302265]}, "mutation_prompt": null}
{"id": "e3185afe-5be9-4c78-8855-d1740b9b6872", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        diversity_measure = np.mean(np.var(self.population, axis=0))  # Calculate diversity\n        learning_rate = 0.05 + 0.1 * diversity_measure  # Adjust learning rate based on diversity\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance the quantum-inspired EA by dynamically adjusting learning rate based on population diversity.", "configspace": "", "generation": 96, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "f8bffa1a-7f2f-4a55-8216-c51733e57c27", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.base_population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n        self.evaluation_improvement_threshold = 0.02  # New line to control dynamic population\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.base_population_size, self.dim))\n        self.fitness = np.full(self.base_population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.base_population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.base_population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            if np.min(combined_fitness) < np.min(self.fitness) - self.evaluation_improvement_threshold:  # Change condition to adjust population size\n                self.base_population_size = min(2 * self.base_population_size, int(0.1 * self.budget))  # Adjust population size dynamically\n\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by adapting population size dynamically based on fitness improvement.", "configspace": "", "generation": 97, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
{"id": "242e7cb9-1007-40bf-af95-ea53ae8ec9f6", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        fitness_variance = np.var(self.fitness)  # Added line for dynamic learning rate\n        learning_rate = 0.05 + 0.1 * fitness_variance  # Changed line for dynamic learning rate adjustment\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  # Changed line to adjust mutation rate based on best fitness.\n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance quantum evolutionary algorithm by employing dynamic learning rates based on fitness variance.", "configspace": "", "generation": 98, "fitness": 0.09193720251623834, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.009. And the mean value of best solutions found was 5.280 (0. is the best) with standard deviation 1.067.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.08870766745296421, 0.08240051184241926, 0.10470342825333157], "final_y": [5.26214895377282, 6.595636494488289, 3.981929821764699]}, "mutation_prompt": null}
{"id": "821807ab-ab48-494e-9d9d-40e36b0dd644", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(0.02 * budget))  \n        self.mutation_rate = 0.1\n        self.q = np.full((self.population_size, dim), 0.5)  \n        self.elite_fraction = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n        self.elites = []\n\n    def measure(self):\n        return np.where(np.random.rand(*self.q.shape) < self.q, 1, 0)\n\n    def update_quantum_probabilities(self, best_solution):\n        learning_rate = 0.05\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if self.population[i, j] == best_solution[j]:\n                    self.q[i, j] = min(0.9, self.q[i, j] + learning_rate)\n                else:\n                    self.q[i, j] = max(0.1, self.q[i, j] - learning_rate)\n\n    def evolutionary_process(self, lb, ub):\n        offspring = np.clip(np.random.normal(loc=self.q, scale=0.1), 0, 1)\n        real_values = lb + (ub - lb) * (offspring / (self.q.shape[1] - 1))\n        fitness_variance = np.var(self.fitness)\n        \n        best_fitness = np.min(self.fitness)  \n        dynamic_mutation_rate = self.mutation_rate + 0.1 * fitness_variance * (1 - best_fitness)\n\n        mutation_mask = np.random.rand(*real_values.shape) < dynamic_mutation_rate\n        real_values[mutation_mask] += np.random.normal(0, 0.1, real_values[mutation_mask].shape)\n        np.clip(real_values, lb, ub, out=real_values)  \n\n        return real_values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            new_population = self.evolutionary_process(lb, ub)\n            new_fitness = np.apply_along_axis(func, 1, new_population)\n            eval_count += len(new_fitness)\n\n            combined_population = np.vstack((self.population, new_population))\n            combined_fitness = np.hstack((self.fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            \n            self.population = combined_population[best_indices]\n            self.fitness = combined_fitness[best_indices]\n            \n            elite_variance = np.var(self.fitness[:int(self.elite_fraction * self.population_size)])  # Added line\n            best_idx = np.argmin(self.fitness)\n            best_solution = self.population[best_idx]\n            self.update_quantum_probabilities(best_solution)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "name": "QuantumInspiredEA", "description": "Enhance QuantumInspiredEA by incorporating an adaptive elite preservation mechanism based on variance of top solutions.", "configspace": "", "generation": 99, "fitness": 0.09993096000054431, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.005. And the mean value of best solutions found was 4.451 (0. is the best) with standard deviation 0.435.", "error": "", "parent_id": "dc86ec72-4045-47c0-b146-01d773945253", "metadata": {"aucs": [0.09721206850549813, 0.0962749372044075, 0.10630587429172733], "final_y": [4.705410287797641, 4.80900016512552, 3.8392577994813872]}, "mutation_prompt": null}
