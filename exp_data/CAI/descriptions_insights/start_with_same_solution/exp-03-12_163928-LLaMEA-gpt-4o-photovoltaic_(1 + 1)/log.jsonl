{"id": "de9074c9-466e-408d-b32e-7be5be207cee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Integrates dynamic inertia weight and nonlinear social influence to improve convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.9197998232758864, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "de9074c9-466e-408d-b32e-7be5be207cee", "metadata": {"aucs": [0.9121656164822428, 0.9190826303754778, 0.9281512229699387], "final_y": [0.11757313867440167, 0.11622172457209146, 0.11180086375215315]}, "mutation_prompt": null}
{"id": "20432a72-ed75-4261-ae42-7258ac6cc311", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor  # Modified line\n            social_coeff = 1.3 * np.exp(-0.4 * adaptive_factor)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < 0.3:  # New sampling strategy\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)  # Modified line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Swarm-Sampling Algorithm (HSSA): Combines adaptive swarm dynamics with random sampling for enhanced exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8053208223141829, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.015. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "metadata": {"aucs": [0.7843913580830524, 0.8119009917181259, 0.8196701171413703], "final_y": [0.1586329516982764, 0.15049260914702223, 0.14803001826258966]}, "mutation_prompt": null}
{"id": "34eb8b1c-0d8e-4a63-9a4e-b4b4ff9da378", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * np.cos(adaptive_factor * np.pi / 2)  # Changed line\n            social_coeff = 1.5 * np.sin(adaptive_factor * np.pi / 2)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates nonlinear temporal adaptation of cognitive and social coefficients for improved search space exploration.", "configspace": "", "generation": 3, "fitness": 0.8619316870009905, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.031. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "metadata": {"aucs": [0.8460941154752599, 0.9052412920322045, 0.8344596534955074], "final_y": [0.12490651551573762, 0.11525878520766208, 0.14299015331811227]}, "mutation_prompt": null}
{"id": "c27a2901-a683-42ad-971d-a92db9300875", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.elite_size = max(1, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        learning_rate = 0.1  # Added line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_rate  # Modified line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n\n            elite_indices = np.argsort(personal_best_value)[:self.elite_size]  # Added line\n            elite_swarm = personal_best[elite_indices]  # Added line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adjust learning rate based on elite performance\n            elite_values = np.array([func(x) for x in elite_swarm])  # Added line\n            learning_rate = np.mean(elite_values) / np.max(elite_values)  # Added line\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a variable learning rate and an elite set strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9170589710364968, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "metadata": {"aucs": [0.9105897188200907, 0.9155110258724295, 0.9250761684169704], "final_y": [0.11744296731748116, 0.11622643917771358, 0.11186081000738946]}, "mutation_prompt": null}
{"id": "66f52599-1c5d-429d-b891-5cf8a496ac54", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  \n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified line\n            social_coeff = 1.5 * np.exp(-0.3 * adaptive_factor)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent with dynamic cognitive coefficient and improved social influence.", "configspace": "", "generation": 5, "fitness": 0.8992676526284233, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.026. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "metadata": {"aucs": [0.8635904835870948, 0.9258485895116071, 0.9083638847865678], "final_y": [0.13188708128733573, 0.11190504324834194, 0.11561734899406062]}, "mutation_prompt": null}
{"id": "ced0d943-3964-46a3-8c25-986c356254b4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence: Introduces a local neighborhood influence factor to refine convergence and explore the search space more efficiently.", "configspace": "", "generation": 6, "fitness": 0.9347132817433489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "788ec1b9-d3a9-4cd9-a76f-ea97748f1be6", "metadata": {"aucs": [0.9381259651798637, 0.930298422923407, 0.9357154571267757], "final_y": [0.10987787470939236, 0.11164940620935748, 0.11001439706245719]}, "mutation_prompt": null}
{"id": "33f5e74c-91cf-4e96-9e3c-d4fa383d0426", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                convergence_acceleration = 1 + 0.5 * (1 - adaptive_factor)  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += convergence_acceleration * self.velocity[i]  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a convergence acceleration factor to dynamically adjust the velocity, enhancing exploitation in later stages.", "configspace": "", "generation": 7, "fitness": 0.9243846466147484, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9269908247421929, 0.9206244464587304, 0.925538668643322], "final_y": [0.10987364683520306, 0.11621727969038786, 0.11371809510260644]}, "mutation_prompt": null}
{"id": "707f2d90-ba58-475d-98f5-2066073a9485", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized Adaptive Swarm Gradient Descent with Dynamic Personal Best Influence: Introduces an adaptive factor to adjust personal best influence for better convergence.", "configspace": "", "generation": 8, "fitness": 0.9347132817433489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9381259651798637, 0.930298422923407, 0.9357154571267757], "final_y": [0.10987787470939236, 0.11164940620935748, 0.11001439706245719]}, "mutation_prompt": null}
{"id": "8d19482b-c0d9-409e-bfaf-30577c491d61", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                self.neighborhood_size = max(2, int((1 - adaptive_factor) * self.population_size))  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic neighborhood size that adapts based on the evaluation progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.928553677190504, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9367075565991461, 0.9213049715673278, 0.927648503405038], "final_y": [0.10997033654469679, 0.11622676967155121, 0.11356762070491044]}, "mutation_prompt": null}
{"id": "4594fe54-c11d-4c97-8b46-8e1ad941a58a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n            \n            self.neighborhood_size = max(2, int((self.population_size // 5) * (0.5 + 0.5 * adaptive_factor)))  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive neighborhood size adjustment based on the convergence state to further enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.9276927589472206, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.934466314441508, 0.9208613022638721, 0.9277506601362817], "final_y": [0.11063625053226134, 0.11626960608881132, 0.11378781160660578]}, "mutation_prompt": null}
{"id": "76235963-ec7d-4ee5-9d15-1c7562f81f97", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = np.random.uniform(1.2, 1.8) * np.exp(-0.5 * adaptive_factor)  # Modified line\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Stochastic Social Coefficient Adjustment: Incorporates a stochastic element into the social coefficient for further exploration efficiency.", "configspace": "", "generation": 11, "fitness": 0.920872707962383, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.019. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8974009970984198, 0.9222367133005263, 0.9429804134882028], "final_y": [0.12094712755040082, 0.11621702536222944, 0.10965443986312873]}, "mutation_prompt": null}
{"id": "dd7a67a8-df5b-40f4-abb8-4f0871fa386d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.05  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n\n                if np.random.rand() < self.mutation_rate:  # Added line\n                    mutation_vector = np.random.uniform(-1, 1, self.dim)  # Added line\n                    self.velocity[i] += adaptive_factor * mutation_vector  # Added line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm with Directional Mutation introduces a mutation strategy based on gradient estimation to improve exploration and avoid local optima.", "configspace": "", "generation": 12, "fitness": 0.9232961853637729, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9302589376369259, 0.9109462082008852, 0.9286834102535073], "final_y": [0.11164528486651382, 0.11648036225335434, 0.1122146192562371]}, "mutation_prompt": null}
{"id": "491ec980-a66c-4314-b8b3-0d9f7a352752", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.base_neighborhood_size = max(2, self.population_size // 5)  # Modified line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_size = self.base_neighborhood_size + np.random.randint(-1, 2)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)  # Modified line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Randomized Neighborhood Size: Introduces a dynamic neighborhood size to balance exploration and exploitation efficiently.", "configspace": "", "generation": 13, "fitness": 0.9115547276106252, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.021. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8828473660452393, 0.9184813554216164, 0.9333354613650197], "final_y": [0.1256726822907609, 0.11491297268138012, 0.11256247130656494]}, "mutation_prompt": null}
{"id": "13b1f63b-4dac-4f8d-b182-22d274817fb6", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.chaotic_map = np.random.rand(self.population_size, self.dim)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce chaos to velocities (4 changes)\n            self.chaotic_map = (3.999 * self.chaotic_map * (1 - self.chaotic_map))  # Modified line\n            chaotic_influence = 0.2 * (self.chaotic_map - 0.5)  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    chaotic_influence[i])  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "MultiScaleAdaptiveSwarmGradientDescent", "description": "Multi-Scale Adaptive Swarm Gradient Descent with Chaos-Induced Exploration: Integrates chaotic dynamics to enhance exploitation and exploration balance in adaptive swarm mechanisms.", "configspace": "", "generation": 14, "fitness": 0.8486116076342247, "feedback": "The algorithm MultiScaleAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.079. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8867694835629782, 0.7389858211792176, 0.9200795181604785], "final_y": [0.12436412858460522, 0.1797640067899562, 0.1147931491431553]}, "mutation_prompt": null}
{"id": "b3eb897d-8361-4293-9e9b-21ce8cbb8f32", "solution": "import numpy as np\n\nclass HybridSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.crowding_distance = 0.1  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    self.crowding_distance * (np.random.rand() - 0.5))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "HybridSwarmGradientDescent", "description": "Hybrid Swarm Gradient Descent with Adaptive Inertia and Crowding Distance: Combines adaptive inertia weight and crowding distance mechanism to balance exploration and exploitation effectively.", "configspace": "", "generation": 15, "fitness": 0.9248498932376338, "feedback": "The algorithm HybridSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9179714848186254, 0.9181296184195158, 0.9384485764747601], "final_y": [0.11283883537582895, 0.1162227789488689, 0.11017701790255852]}, "mutation_prompt": null}
{"id": "0c59d9f3-11d1-4dbc-b26f-5b30267f06ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * np.tanh(local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence, enhanced by introducing a sigmoid function for more refined velocity updates.", "configspace": "", "generation": 16, "fitness": 0.9100641832365927, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.026. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.874095762096875, 0.9208584209929668, 0.935238366619936], "final_y": [0.12779621395406116, 0.11623102056578516, 0.1114845311951903]}, "mutation_prompt": null}
{"id": "516b345e-14ad-485f-bb37-1156efb3d178", "solution": "import numpy as np\nfrom scipy.stats import qmc\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        sobol = qmc.Sobol(d=self.dim, scramble=True)  # Changed line\n        swarm = lb + (ub - lb) * sobol.random(self.population_size)  # Changed line\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Initialization for Diverse Coverage: Introduces a Sobol sequence for swarm initialization to improve exploration and coverage of the search space.", "configspace": "", "generation": 17, "fitness": 0.8963660163619616, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.022. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9124220170267607, 0.9110790569920084, 0.8655969750671155], "final_y": [0.11740507753285834, 0.11689726707803683, 0.11867347122530858]}, "mutation_prompt": null}
{"id": "52f7a2c1-9f67-4e9c-b942-483895059b4b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        phase_switch = self.budget // 2  # Added line\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                if evaluations < phase_switch:  # Added line\n                    exploration_coeff = 0.1 * np.random.random(self.dim)  # Added line\n                else:  # Added line\n                    exploration_coeff = 0.01 * np.random.random(self.dim)  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    exploration_coeff)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dual-phase search strategy combining global exploration and local exploitation with adaptive coefficients for refined convergence.", "configspace": "", "generation": 18, "fitness": 0.9168429899498945, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9002424754424201, 0.9171401803982733, 0.9331463140089905], "final_y": [0.11771713993633093, 0.11282791848173557, 0.11049826539834284]}, "mutation_prompt": null}
{"id": "bfcc6fc7-1643-4fa8-9d7e-39dd43c04bb3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.5 * adaptive_factor  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Increased Neighborhood Influence: Adjusts local influence coefficient for improved exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.9288836421921195, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9285649152677515, 0.9240153711994141, 0.9340706401091927], "final_y": [0.1109813716831689, 0.11621691189201522, 0.1101547710401285]}, "mutation_prompt": null}
{"id": "fcd507cb-c934-4d60-8309-94ccc0175440", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            self.neighborhood_size = max(2, int(self.population_size * adaptive_factor))  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic neighborhood size scaling with the budget to enhance local exploration capability.", "configspace": "", "generation": 20, "fitness": 0.9166789718420075, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9103140599751038, 0.912182329307742, 0.9275405262431771], "final_y": [0.11628162254143515, 0.11658020835122995, 0.11158967154765853]}, "mutation_prompt": null}
{"id": "0027be12-be2c-4fb2-9fa8-a4df0db6f92b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Change: Adaptive neighborhood size\n            adaptive_neighborhood_size = max(2, int(self.neighborhood_size * adaptive_factor))\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, adaptive_neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive neighborhood size based on current evaluation to balance exploration and exploitation dynamically.", "configspace": "", "generation": 21, "fitness": 0.9276927589472206, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.934466314441508, 0.9208613022638721, 0.9277506601362817], "final_y": [0.11063625053226134, 0.11626960608881132, 0.11378781160660578]}, "mutation_prompt": null}
{"id": "475b734a-9f38-46dd-887a-749306bb3ce2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * np.cos(adaptive_factor * np.pi)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic inertia weight adjustment using cosine function to enhance convergence adaptability.", "configspace": "", "generation": 22, "fitness": 0.8577287630104783, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.025. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8373751616459031, 0.8423644250702428, 0.8934467023152888], "final_y": [0.12410879511427475, 0.12401236412150107, 0.11373714133605328]}, "mutation_prompt": null}
{"id": "f1e6804b-934d-4e6d-a5c1-aa1edc4e4897", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor  # Changed line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Enhanced Cognitive Coefficient: Adjusts the cognitive coefficient to increase exploration capabilities dynamically.", "configspace": "", "generation": 23, "fitness": 0.9291964414029077, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9361690436907917, 0.9170872990976249, 0.9343329814203064], "final_y": [0.10972150603468545, 0.11622986537469804, 0.1118489089983491]}, "mutation_prompt": null}
{"id": "af9ee570-66f7-4b5a-a1b5-2c68fef6db6a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations % (self.budget // 10) == 0:  # Added line for reinitialization\n                    global_best = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Enhanced Exploration: Introduces a random reinitialization of global best for improved exploration in stagnation.", "configspace": "", "generation": 24, "fitness": 0.8776004055781366, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.019. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8956945067999957, 0.8521374813051025, 0.8849692286293115], "final_y": [0.12425357792531033, 0.13948635520979558, 0.12796552083784896]}, "mutation_prompt": null}
{"id": "db54621e-8b21-4525-9750-bfa87fee1860", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.1  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Mutation step\n                if np.random.rand() < self.mutation_rate:  # Added line\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)  # Added line\n                    swarm[i] += mutation_vector  # Added line\n                    swarm[i] = np.clip(swarm[i], lb, ub)  # Added line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Diversity-Enhancing Mutation: Integrates a mutation strategy to maintain population diversity, improving exploration and convergence in complex landscapes.", "configspace": "", "generation": 25, "fitness": 0.9142073863493775, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.031. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8707889266939486, 0.9326898447663945, 0.9391433875877891], "final_y": [0.12664064635718697, 0.11171475590549595, 0.11005724831527064]}, "mutation_prompt": null}
{"id": "256e7b17-0c73-43a0-aa61-527fea53b902", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n            exploration_factor = 0.1 * np.exp(-3 * adaptive_factor)  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3, r4 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    exploration_factor * r4)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Exploration Control: Introduces a decaying random exploration factor to better balance exploration and exploitation over iterations.", "configspace": "", "generation": 26, "fitness": 0.9284537782116488, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9362954558335291, 0.915808652590973, 0.9332572262104443], "final_y": [0.10964562821246804, 0.11185187000271035, 0.11020908461599122]}, "mutation_prompt": null}
{"id": "ea50af32-0f0c-4155-b6f3-17231c286f28", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2  # Modified line\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * (adaptive_factor + 0.1)  # Modified line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Tuned Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence and Nonlinear Damping for Enhanced Convergence.", "configspace": "", "generation": 27, "fitness": 0.92679022671489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.934615001055506, 0.9167947591381013, 0.9289609199510628], "final_y": [0.10963243487778473, 0.11625773847020293, 0.11358733373164998]}, "mutation_prompt": null}
{"id": "ff6fbef8-8fa0-40e0-9214-6c2f53d22533", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * adaptive_factor  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with Time-Varying Inertia Weight to improve convergence speed and accuracy.", "configspace": "", "generation": 28, "fitness": 0.8752015281387622, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.896680761164932, 0.8548879309056152, 0.8740358923457392], "final_y": [0.11125954875659427, 0.12206716098035675, 0.12431103022026468]}, "mutation_prompt": null}
{"id": "95cc6eb8-bd89-4e17-a911-da3dc2d7cdce", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                # Modified line for energy-based velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -np.abs(global_best - personal_best[i]), np.abs(global_best - personal_best[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence and Energy-Based Velocity Clamping: Introduces energy-based velocity clamping to maintain exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.8683125451106749, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.025. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8729184720190377, 0.8361356361770116, 0.8958835271359756], "final_y": [0.1314905519542805, 0.14507730306725541, 0.12469219811204368]}, "mutation_prompt": null}
{"id": "92cd7f24-8471-49cc-9b63-c181e45f2df7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * np.exp(0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Time-Varying Cognitive and Social Coefficients: Adjusts cognitive and social coefficients dynamically to enhance convergence and exploration balance.", "configspace": "", "generation": 30, "fitness": 0.9232611697141749, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.008. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9293774740665428, 0.912624780468224, 0.9277812546077582], "final_y": [0.11004197319841602, 0.11201982953526335, 0.11247648667935162]}, "mutation_prompt": null}
{"id": "73b5a251-db41-4ac4-94b5-6a4f023dcf25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        momentum = np.zeros((self.population_size, self.dim))  # Added line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) + momentum[i]  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence and Momentum: Introduces a momentum term to enhance solution convergence speed and precision.", "configspace": "", "generation": 31, "fitness": 0.9347132817433489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9381259651798637, 0.930298422923407, 0.9357154571267757], "final_y": [0.10987787470939236, 0.11164940620935748, 0.11001439706245719]}, "mutation_prompt": null}
{"id": "61832d48-26f3-4431-b9d0-7458357190ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * np.exp(-0.5 * adaptive_factor)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Enhanced Inertia Weight Decay: Improves convergence by introducing exponential decay in inertia weight adaptation.", "configspace": "", "generation": 32, "fitness": 0.9229420906404767, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9252189070475778, 0.916545676875267, 0.9270616879985851], "final_y": [0.11311696368148083, 0.11624910530419763, 0.11293014907432142]}, "mutation_prompt": null}
{"id": "d711c781-da07-4cb3-915b-e82048103424", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * np.std(personal_best_value) / np.mean(personal_best_value)  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent by dynamically updating the inertia weight based on the population's diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 33, "fitness": 0.8718349264473771, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.026. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8677635774959271, 0.8421964235474599, 0.9055447782987444], "final_y": [0.12658120879047863, 0.1368763551033334, 0.11689577401827211]}, "mutation_prompt": null}
{"id": "4e3602d8-56e8-4d9b-8921-f6e8dcbd897c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                scaling_factor = 0.9 + 0.1 * np.random.random()  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) * scaling_factor  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive learning rate to enhance convergence precision and exploration efficiency.", "configspace": "", "generation": 34, "fitness": 0.9123695144004268, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.016. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.892163067552045, 0.9139480219503192, 0.9309974536989161], "final_y": [0.12207132725693237, 0.11245947101452392, 0.11240211266368905]}, "mutation_prompt": null}
{"id": "15d79658-6603-4159-a017-753c3ec3373a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                mutation = np.random.normal(0, 0.1, self.dim)  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) + mutation\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a mutation mechanism in velocity update to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 35, "fitness": 0.9187181132821219, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9293024748400682, 0.9116574645493076, 0.9151944004569897], "final_y": [0.10975632507700539, 0.11628392420690581, 0.11724220506916638]}, "mutation_prompt": null}
{"id": "fc8b96a3-6695-43e4-9c93-da6b6a41b116", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n            \n            # Dynamic learning rate adjustment\n            learning_rate = 0.1 + 0.8 * (1 - adaptive_factor)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm with Dynamic Learning Rate Adjustment: Introduces a dynamic learning rate adjustment factor to fine-tune exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.8576690423982267, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8387558000488813, 0.8714565986804831, 0.8627947284653157], "final_y": [0.1129869832825725, 0.12279537869359802, 0.1149064070834187]}, "mutation_prompt": null}
{"id": "6fc85509-c098-494f-85b4-1ade92033e41", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Changed line (adaptive neighborhood size)\n            self.neighborhood_size = max(2, int(self.population_size * adaptive_factor))  \n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive neighborhood size to dynamically adjust exploration and exploitation based on the convergence stage.", "configspace": "", "generation": 37, "fitness": 0.9166789718420075, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9103140599751038, 0.912182329307742, 0.9275405262431771], "final_y": [0.11628162254143515, 0.11658020835122995, 0.11158967154765853]}, "mutation_prompt": null}
{"id": "105c8095-e62e-44b3-8d97-8fbb69a54c4a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Introduced random reinitialization for exploration\n                if np.random.rand() < 0.05:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                    self.velocity[i] = np.zeros(self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a random reinitialization step to enhance exploration of the search space in Adaptive Swarm Gradient Descent.", "configspace": "", "generation": 38, "fitness": 0.9094727345453303, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8998431372689332, 0.9096091714287866, 0.918965894938271], "final_y": [0.11738226740857449, 0.11691668378900577, 0.11388081365772462]}, "mutation_prompt": null}
{"id": "e633953d-789d-4864-a023-7688d0e5e133", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        restart_frequency = self.budget // 5  # Added line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations % restart_frequency == 0:  # Added line\n                    swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Added line\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm with Dynamic Neighborhood Influence and Iterative Restarts: Introduces periodic restarts to diversify exploration and refine convergence efficiently.", "configspace": "", "generation": 39, "fitness": 0.9213284758441677, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9287343184154702, 0.9171230167544979, 0.918128092362535], "final_y": [0.11360891524346761, 0.11586455177363664, 0.11496451611695602]}, "mutation_prompt": null}
{"id": "b8bcc33a-abb8-4ddf-a2dc-fc118c6bd733", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * np.exp(-0.5 * adaptive_factor)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Exponential Decay Strategy: Introduces an exponential decay factor to improve exploration-exploitation balance in the search process.", "configspace": "", "generation": 40, "fitness": 0.9229420906404767, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9252189070475778, 0.916545676875267, 0.9270616879985851], "final_y": [0.11311696368148083, 0.11624910530419763, 0.11293014907432142]}, "mutation_prompt": null}
{"id": "a78cf0cd-3eb6-4909-8d99-6117605e2a91", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = np.clip(0.9 - 0.5 * adaptive_factor, 0.4, 0.9)  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Dynamic Inertia Weight Clipping: Introduces clipping on inertia weight to maintain its effects within a controlled range for improved convergence stability.", "configspace": "", "generation": 41, "fitness": 0.9347132817433489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9381259651798637, 0.930298422923407, 0.9357154571267757], "final_y": [0.10987787470939236, 0.11164940620935748, 0.11001439706245719]}, "mutation_prompt": null}
{"id": "de16148f-ad23-4c91-9e70-7f6b48513dcd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Changed line\n            self.neighborhood_size = max(2, int(self.population_size * (1 - adaptive_factor)))\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved local influence by adjusting neighborhood size dynamically based on convergence rate.", "configspace": "", "generation": 42, "fitness": 0.928553677190504, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9367075565991461, 0.9213049715673278, 0.927648503405038], "final_y": [0.10997033654469679, 0.11622676967155121, 0.11356762070491044]}, "mutation_prompt": null}
{"id": "ffabb831-850a-4ede-a20a-306e3a384e1d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * (0.5 + adaptive_factor)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by modifying the inertia weight formula to dynamically adapt more aggressively based on the evaluation progress.", "configspace": "", "generation": 43, "fitness": 0.8584265114669579, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8540433250508197, 0.8446021199246152, 0.8766340894254387], "final_y": [0.11894002921570879, 0.12739518452920573, 0.1140572601045241]}, "mutation_prompt": null}
{"id": "030eeaa1-7a74-41f7-9d6e-d038136b133a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.3 * adaptive_factor  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent by recalibrating the inertia weight calculation for enhanced balancing between exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.9076593682094659, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8987751102018674, 0.9062483486245353, 0.9179546458019954], "final_y": [0.11604592462227514, 0.11702939774186571, 0.11228904474363399]}, "mutation_prompt": null}
{"id": "3f51b784-6631-4501-a4bf-4f63c1bb8dfd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            self.neighborhood_size = max(2, int(self.population_size * adaptive_factor))  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a dynamic neighborhood size adjustment mechanism based on evaluations to enhance local exploration.", "configspace": "", "generation": 45, "fitness": 0.9166789718420075, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9103140599751038, 0.912182329307742, 0.9275405262431771], "final_y": [0.11628162254143515, 0.11658020835122995, 0.11158967154765853]}, "mutation_prompt": null}
{"id": "db0a989f-77e0-4ae4-b46d-6564d1633e39", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                momentum = 0.1  # Added line\n                self.velocity[i] = (momentum * self.velocity[i] +  # Modified line\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a momentum factor into velocity updates for smoother convergence and enhanced exploration.", "configspace": "", "generation": 46, "fitness": 0.9169589763456526, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9042928447862082, 0.9176135674558663, 0.9289705167948834], "final_y": [0.12060801863688841, 0.11685430725952173, 0.11213561784162285]}, "mutation_prompt": null}
{"id": "b0d7b499-7e9b-40ff-94b4-f03b2f7c3750", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - (0.5 + 0.1 * np.random.random()) * adaptive_factor  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced random inertia weight decay for enhanced adaptive behavior and better convergence.", "configspace": "", "generation": 47, "fitness": 0.9217158216430731, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.017. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8985268650801435, 0.9278627706388111, 0.9387578292102646], "final_y": [0.1209753753509627, 0.11240098058897341, 0.10999497381106016]}, "mutation_prompt": null}
{"id": "c8d98d87-ebfa-41bc-b9ea-02fc69c425cb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor + 0.1 * np.random.rand()\n            cognitive_coeff = (1.5 + 0.5 * np.random.rand()) * adaptive_factor\n            social_coeff = (1.5 + 0.5 * np.random.rand()) * np.exp(-0.5 * adaptive_factor)\n            local_coeff = (0.4 + 0.2 * np.random.rand()) * adaptive_factor  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Randomized Adaptive Coefficients: Introduces stochastic variations in the adaptive coefficients to balance exploration and exploitation dynamically.", "configspace": "", "generation": 48, "fitness": 0.9117173297450222, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.017. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.890220300304173, 0.9303541615858171, 0.9145775273450765], "final_y": [0.12133676552581973, 0.11300883370733239, 0.1139645263804886]}, "mutation_prompt": null}
{"id": "3cc2b00a-84f2-4ce8-8c23-b94d829c15b3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * np.random.uniform(0.9, 1.1) * adaptive_factor  # Modified line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Randomized Learning Factors: Introduces randomized learning coefficients to enhance exploration and avoid premature convergence.", "configspace": "", "generation": 49, "fitness": 0.9239076466526975, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9105737394185145, 0.923143289652799, 0.9380059108867792], "final_y": [0.11711639533770313, 0.11256894779868021, 0.11003461316034824]}, "mutation_prompt": null}
{"id": "5a3a1bb2-1e84-49a6-86ae-c9862cb0b3ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                mutation_vector = np.random.uniform(lb, ub, self.dim) # Added line\n                self.velocity[i] += 0.1 * (mutation_vector - swarm[i]) # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced Velocity Clamping and Differential Mutation to enhance convergence speed and solution diversity.", "configspace": "", "generation": 50, "fitness": 0.8664774754053735, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.020. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.8871376087424085, 0.839907361285308, 0.872387456188404], "final_y": [0.12125227554874163, 0.12568623560664527, 0.12435182068020612]}, "mutation_prompt": null}
{"id": "51c402f8-6bec-4a47-93ef-17484d44fda6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            mutation_rate = 0.1 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + mutation_rate * np.random.normal(size=self.dim)  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce Adaptive Mutation Rate for Enhanced Exploration in ASGD.", "configspace": "", "generation": 51, "fitness": 0.9181935901111343, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9255035754737482, 0.9143309151265143, 0.9147462797331406], "final_y": [0.10965196838315816, 0.11623080130975894, 0.1171365486133088]}, "mutation_prompt": null}
{"id": "4f990b8e-7705-485a-bd22-d52e59e32250", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        momentum = 0.1  # Added line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (momentum * self.velocity[i] +  # Modified line\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implements a momentum term in the velocity update to improve convergence speed and stability.", "configspace": "", "generation": 52, "fitness": 0.9169589763456526, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9042928447862082, 0.9176135674558663, 0.9289705167948834], "final_y": [0.12060801863688841, 0.11685430725952173, 0.11213561784162285]}, "mutation_prompt": null}
{"id": "32eb0535-fe56-4ceb-aa51-d1c301d82212", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = (1.5 - 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor  # Added line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]  # Added line\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Neighborhood Influence and Time-Varying Learning Coefficients: Implements time-varying cognitive and social coefficients to balance exploration and exploitation.", "configspace": "", "generation": 53, "fitness": 0.9183069612772465, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9105954204339592, 0.913137724459544, 0.9311877389382366], "final_y": [0.11691455835482534, 0.11623552970907003, 0.11235509896867657]}, "mutation_prompt": null}
{"id": "5083f945-1b65-4d4f-8eb8-2a14efafbb45", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor \n            \n            # Changed line\n            dynamic_neighborhood_size = max(2, int(self.neighborhood_size * (1 - adaptive_factor))) \n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, dynamic_neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic neighborhood size adjustment based on convergence to adapt exploration and exploitation phases effectively.", "configspace": "", "generation": 54, "fitness": 0.9276927589472206, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.934466314441508, 0.9208613022638721, 0.9277506601362817], "final_y": [0.11063625053226134, 0.11626960608881132, 0.11378781160660578]}, "mutation_prompt": null}
{"id": "eda75165-839c-47dd-be5c-e1609ac311b4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                exploration_factor = 0.1 * (np.random.random(self.dim) - 0.5)  # Added line\n                \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    exploration_factor)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a random exploration factor to enhance diversity and prevent premature convergence in Adaptive Swarm Gradient Descent.", "configspace": "", "generation": 55, "fitness": 0.916858785851067, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.9071841062743217, 0.9142788355851492, 0.92911341569373], "final_y": [0.11699324931474919, 0.11626439246037301, 0.11070939777284217]}, "mutation_prompt": null}
{"id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic population size reduction mechanism to enhance convergence speed while maintaining solution quality.", "configspace": "", "generation": 56, "fitness": 0.9348048391521558, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ced0d943-3964-46a3-8c25-986c356254b4", "metadata": {"aucs": [0.938375838548408, 0.9303347004535799, 0.9357039784544795], "final_y": [0.1096507154823324, 0.11164911075154604, 0.1100232677180415]}, "mutation_prompt": null}
{"id": "6aaa540a-5965-463d-b07b-30b4a67e7ad6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            mutation_strength = 0.1 * adaptive_factor  # Adaptive mutation strength\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) + mutation_strength * np.random.randn(self.dim)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates adaptive mutation strategy for enhanced exploration and fine-tuning while maintaining dynamic population size reduction.", "configspace": "", "generation": 57, "fitness": 0.9181557261152841, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9283694168606631, 0.9105706844419988, 0.9155270770431904], "final_y": [0.10984259904214588, 0.11623005009022325, 0.11736617840219055]}, "mutation_prompt": null}
{"id": "c28f2001-cde1-4ebc-87a5-c9ab68dff2c2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + np.random.normal(0, 0.1, self.dim) # Added line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and exploitation by integrating a mutation mechanism and adaptive inertia weight, improving solution robustness and quality.", "configspace": "", "generation": 58, "fitness": 0.8536670260899931, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.840992491061774, 0.8423558503973791, 0.8776527368108263], "final_y": [0.13019525561811796, 0.13697363319177236, 0.11388933285252312]}, "mutation_prompt": null}
{"id": "7513fcbb-c560-4796-a76f-ff939bf95309", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor * (1 + 0.5 * np.sin(evaluations * np.pi / self.budget))\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by incorporating a dynamic inertia weight adjustment and local search strategy.", "configspace": "", "generation": 59, "fitness": 0.8804447329958914, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8926562110186855, 0.8602654047324277, 0.888412583236561], "final_y": [0.1163056226671636, 0.12095228336963748, 0.11412759446354015]}, "mutation_prompt": null}
{"id": "d8abcdde-899e-4caa-9c5a-709b95d0e0c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                # Dynamic mutation mechanism\n                if np.random.rand() < self.mutation_probability:\n                    mutation_strength = adaptive_factor * (ub - lb) / 10\n                    swarm[i] += mutation_strength * np.random.normal(size=self.dim)\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a dynamic mutation mechanism inspired by evolutionary strategies to enhance exploration and adaptation.", "configspace": "", "generation": 60, "fitness": 0.9010956632096955, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8891288265472534, 0.8943870409361456, 0.9197711221456877], "final_y": [0.12405519273061172, 0.12370929294961752, 0.11241921920978604]}, "mutation_prompt": null}
{"id": "96bca60a-685b-4ffb-84d2-b1723798b772", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Adjusted inertia weight to nonlinear form for improved exploration-exploitation\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**2\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            # Modified local coefficient calculation for better local search\n            local_coeff = 0.4 + (0.6 * adaptive_factor)\n\n            # Dynamic reduction and adjustment in neighborhood size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                # Adjust neighborhood size dynamically\n                self.neighborhood_size = max(2, int(self.neighborhood_size * 0.9))\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive neighborhood size adjustment and nonlinear inertia weight for enhanced exploitation-exploration balance.", "configspace": "", "generation": 61, "fitness": 0.9125569539777736, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.014. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9123533131065154, 0.8955469001335158, 0.9297706486932896], "final_y": [0.11305147378671021, 0.1198843974759326, 0.11248173331210942]}, "mutation_prompt": null}
{"id": "8c1ff7f8-1c9e-43e2-9b9a-836637a43429", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor)  # Variable inertia weight\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Adaptively increased\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a variable inertia weight mechanism and adaptive learning coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.9151909702719218, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9225655860546081, 0.9079368939378046, 0.9150704308233522], "final_y": [0.11223282472135543, 0.11755314106537296, 0.11709825270450036]}, "mutation_prompt": null}
{"id": "f2bd97c2-18b9-4751-b3e1-835d23c19cbb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.1  # Added mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < self.mutation_rate:  # Introduce mutation operator\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation_vector, lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a mutation operator inspired by genetic algorithms to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 63, "fitness": 0.9127415400019251, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9089853704254851, 0.8987664086010304, 0.9304728409792602], "final_y": [0.11694260997170947, 0.12133534324011452, 0.11223976265621594]}, "mutation_prompt": null}
{"id": "32022f21-fcb8-415f-a2a9-3fcc553a82bb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3, r4 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                # Mutation factor is introduced here\n                mutation_factor = 0.01 * (ub - lb) * r4\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) + mutation_factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances the convergence speed by dynamically adjusting the velocity calculation and introducing a mutation factor to escape local optima.", "configspace": "", "generation": 64, "fitness": 0.8931695093020798, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.005. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8921663851025766, 0.8882280804497142, 0.8991140623539488], "final_y": [0.12003372375195376, 0.12096197333894809, 0.12235215299950952]}, "mutation_prompt": null}
{"id": "46a9557b-52dc-470b-a8e1-02b1399b045d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor  # Increased cognitive influence\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Mutation for diversity\n                if np.random.rand() < 0.1:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by increasing cognitive influence and introducing a mutation mechanism for diversity maintenance.", "configspace": "", "generation": 65, "fitness": 0.9119625719125674, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.032. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8681647928908922, 0.9259965894259252, 0.9417263334208847], "final_y": [0.12659789022543844, 0.11165214236739229, 0.10966927670010496]}, "mutation_prompt": null}
{"id": "99f39289-68b6-4056-a832-427b65716429", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 4)  # Adjusted neighborhood reduction\n        self.velocity_modulation_factor = 0.1  # New factor for velocity modulation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                # Apply velocity modulation\n                self.velocity[i] *= 1 + self.velocity_modulation_factor * adaptive_factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and exploitation balance by introducing adaptive neighborhood size and velocity modulation.", "configspace": "", "generation": 66, "fitness": 0.9205366088954144, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9128797937414899, 0.9174739521204932, 0.9312560808242605], "final_y": [0.11685567595399726, 0.11623543007969483, 0.11232176634083257]}, "mutation_prompt": null}
{"id": "6c9f8c65-fd82-41d5-ab54-fe5e74216476", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Compute swarm diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (1 + diversity)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                # Adaptive neighborhood size\n                neighborhood_indices = np.random.choice(self.population_size, max(2, self.neighborhood_size - i % 3), replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence speed and diversity by introducing a dynamic inertia weight adjustment based on swarm diversity and an adaptive neighborhood approach.", "configspace": "", "generation": 67, "fitness": 0.771983826603182, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.035. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8130764446322007, 0.7744448027419062, 0.7284302324354393], "final_y": [0.15272621214991677, 0.16802302736141417, 0.18690237040961932]}, "mutation_prompt": null}
{"id": "f9c593ce-1a9c-4b40-b561-27c374ccf53d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * (0.5 ** (evaluations / self.budget))  # Decay-based inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Hybrid mutation strategy\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    swarm[i] = 0.5 * (swarm[i] + mutation_vector)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances the adaptive swarm algorithm with a decay-based inertia weight and hybrid mutation strategy for improved exploration and exploitation balance.", "configspace": "", "generation": 68, "fitness": 0.8637123879136958, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.023. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8772447585081457, 0.8820307145159724, 0.8318616907169694], "final_y": [0.12254996177527311, 0.11692416508956072, 0.14061819705788103]}, "mutation_prompt": null}
{"id": "4fbb6c61-9032-44f3-9890-63a4ef0b2867", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            convergence_acceleration = 0.5 * np.log(1 + evaluations)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) * convergence_acceleration\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances solution quality by adapting velocity with an additional convergence acceleration factor.", "configspace": "", "generation": 69, "fitness": 0.7981333985274818, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.008. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.7996089219439089, 0.7879617027580452, 0.8068295708804913], "final_y": [0.15776132192482628, 0.16276761829205533, 0.1552123883723624]}, "mutation_prompt": null}
{"id": "20fdd65a-7867-4f8d-9db1-15da9c2e5535", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.diversity_threshold = 0.1  # Line 1 changed\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Dynamic population size reduction based on diversity\n            diversity = np.std(swarm)  # Line 2 changed\n            if diversity < self.diversity_threshold:  # Line 3 changed\n                self.population_size = max(5, int(self.population_size * 0.85))  # Line 4 changed\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates an adaptive exploration-exploitation strategy using a dynamic diversity measure to balance search efforts.", "configspace": "", "generation": 70, "fitness": 0.9347132817433489, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9381259651798637, 0.930298422923407, 0.9357154571267757], "final_y": [0.10987787470939236, 0.11164940620935748, 0.11001439706245719]}, "mutation_prompt": null}
{"id": "de561c21-e832-450c-90c8-c90575685750", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.momentum = 0.1  # New line added for momentum\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (self.momentum * self.velocity[i] +  # Modified line with momentum\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces momentum to swarm velocity updates for enhanced convergence stability and solution quality.", "configspace": "", "generation": 71, "fitness": 0.9170821487778141, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9042330742754708, 0.9181274848760863, 0.928885887181885], "final_y": [0.12065737867841508, 0.1165075085962094, 0.11219306583649191]}, "mutation_prompt": null}
{"id": "31c270a8-df8e-4bc0-844e-1ac1d568f3bb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * (1 - np.exp(-5 * (global_best_value - prev_global_best_value)))\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic inertia weight adjustment based on convergence rate to improve solution exploration and exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.9262627108722229, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.928198586486233, 0.913011167471547, 0.9375783786588889], "final_y": [0.11235525675206037, 0.11690384362254391, 0.1101384508173805]}, "mutation_prompt": null}
{"id": "e34a89c7-5efa-42a7-ad8b-7eb442cfd57a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.8 * adaptive_factor  # Adjusted\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.85))  # Adjusted\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            # Adjust neighborhood size based on progress\n            self.neighborhood_size = max(2, int(self.population_size * adaptive_factor))  # Adjusted\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive inertia weight and neighborhood size adjustment based on convergence rate to improve exploitation in later stages.", "configspace": "", "generation": 73, "fitness": 0.9023279465574935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.026. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9014560416764464, 0.8703500929481642, 0.9351777050478697], "final_y": [0.12055020791781978, 0.1296780341566055, 0.11217548239498065]}, "mutation_prompt": null}
{"id": "4c609e9e-61fa-402e-9557-aeddcbcb6e61", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                # Add velocity clamping mechanism\n                self.velocity[i] = np.clip(self.velocity[i], -0.1*(ub-lb), 0.1*(ub-lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a velocity clamping mechanism to prevent excessive step sizes, enhancing stability in convergence.", "configspace": "", "generation": 74, "fitness": 0.9158166882063581, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.015. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8945074232495961, 0.9225259396588813, 0.930416701710597], "final_y": [0.11687980394843056, 0.11252118492535079, 0.1104071286562639]}, "mutation_prompt": null}
{"id": "1bcbe1fc-5d98-419b-9593-749dad86d775", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Adjust neighborhood influence dynamically\n            self.neighborhood_size = int(max(2, self.population_size * adaptive_factor))\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                # Use a dynamic learning rate\n                lr = adaptive_factor * (1.0 + np.random.uniform(0.0, 0.5))\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i])) * lr\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by incorporating a dynamic learning rate and iteratively adjusting neighborhood influence.", "configspace": "", "generation": 75, "fitness": 0.9004285331989273, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.027. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8692296560740631, 0.8968066174470389, 0.93524932607568], "final_y": [0.12958142494801905, 0.12076681132436073, 0.11089433689164141]}, "mutation_prompt": null}
{"id": "aa96db44-40a9-479c-9944-8acd6eb4bede", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0 * (1 - adaptive_factor) # Changed line: Adjusted social coefficient\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive social coefficient to enhance information sharing among particles based on convergence progress.", "configspace": "", "generation": 76, "fitness": 0.9015254891212138, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9039770411833469, 0.8968899679859437, 0.9037094581943512], "final_y": [0.11684032989888882, 0.11070816654802118, 0.11241668234312718]}, "mutation_prompt": null}
{"id": "31f02b06-420f-46f4-a5bb-8a3fa6911ac9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        improvement_threshold = 1e-5\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Enhanced dynamic population size strategy\n            if evaluations / self.budget > 0.5 and (global_best_value - np.mean(personal_best_value)) < improvement_threshold:\n                self.population_size = max(5, int(self.population_size * 0.8))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "AdaptiveSwarmGradientDescent with an enhanced dynamic population management strategy based on convergence rate for improved solution quality.", "configspace": "", "generation": 77, "fitness": 0.934697914436109, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.003. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9380367997837032, 0.9303340086360657, 0.9357229348885581], "final_y": [0.10980520895018309, 0.11166273795493764, 0.11000980428744833]}, "mutation_prompt": null}
{"id": "faa9ecfd-bfc1-46dc-bb80-18cc815f0dc2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations < self.budget and np.random.rand() < 0.1:\n                    additional_solution = np.random.uniform(lb, ub, self.dim)\n                    additional_value = func(additional_solution)\n                    evaluations += 1\n                    if additional_value < global_best_value:\n                        global_best = additional_solution\n                        global_best_value = additional_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a hybrid strategy combining swarm intelligence with local search to enhance global exploration and local exploitation.", "configspace": "", "generation": 78, "fitness": 0.9129080709081262, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9090985397834095, 0.898612069773803, 0.9310136031671661], "final_y": [0.11695849618164078, 0.12132951718523521, 0.11158404735527416]}, "mutation_prompt": null}
{"id": "8562738d-901d-47ed-b2f3-3735424cf05c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                # Apply mutation and crossover\n                if np.random.rand() < self.crossover_rate:\n                    partner = np.random.choice(self.population_size)\n                    offspring = np.where(np.random.rand(self.dim) < 0.5, swarm[i], swarm[partner])\n                    offspring += self.mutation_rate * np.random.normal(size=self.dim)\n                    offspring = np.clip(offspring, lb, ub)\n                    f_value = func(offspring)\n                else:\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        local_coeff * r3 * (local_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n                    f_value = func(swarm[i])\n\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances swarm convergence by incorporating an evolutionary strategy with adaptive mutation and crossover rates.", "configspace": "", "generation": 79, "fitness": 0.8614817247842721, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.022. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.843901395422721, 0.8474058633781354, 0.8931379155519601], "final_y": [0.13483107749710033, 0.13885373315882044, 0.12187902784700066]}, "mutation_prompt": null}
{"id": "0f490708-24ce-43e6-851f-e20ad6ecbb49", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor  # Changed coefficient from 1.5 to 2.0\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing dynamic adaptation of cognitive and social coefficients based on evaluation progress.", "configspace": "", "generation": 80, "fitness": 0.9254777037022507, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9284845100743724, 0.9188302730832314, 0.9291183279491486], "final_y": [0.11179897866519295, 0.11624248790313785, 0.11360129902344618]}, "mutation_prompt": null}
{"id": "b932f2c1-c4ac-495d-9991-0f16f609e6df", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_factor = 0.1  # Mutation factor for exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                # Mutation-based exploration\n                mutation = self.mutation_factor * np.random.normal(size=self.dim)\n                swarm[i] += self.velocity[i] + mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances global exploration by introducing a mutation-based mechanism to prevent premature convergence.", "configspace": "", "generation": 81, "fitness": 0.9179393993720674, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9250370281563152, 0.9141029330621858, 0.9146782368977009], "final_y": [0.10993123123979542, 0.11622962272419712, 0.11741984832436525]}, "mutation_prompt": null}
{"id": "463541cf-218b-4bba-9e2e-bee8450270e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.cos(adaptive_factor * np.pi)  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                mutation = 0.1 * np.random.randn(self.dim) * adaptive_factor  # Changed line\n                swarm[i] += mutation  # Changed line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by incorporating an adaptive mutation strategy and improving inertia weight calculation for better exploration and exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.8914842646046628, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.023. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8822237913386628, 0.8685194582995363, 0.9237095441757892], "final_y": [0.12191561831594433, 0.12315954166762022, 0.11061528971719914]}, "mutation_prompt": null}
{"id": "08d8a016-c908-45cc-adef-d66e9f660ec3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                if np.random.rand() < 0.3:\n                    leader = local_best\n                else:\n                    leader = global_best\n                \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (leader - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances solution exploration by introducing a non-linear dynamic inertia weight and variable leader mechanism to improve convergence efficiency.", "configspace": "", "generation": 83, "fitness": 0.8723784156886768, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.005. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.879166067985972, 0.8688596582268857, 0.869109520853173], "final_y": [0.11629700820671818, 0.12089463764884323, 0.12822131963904404]}, "mutation_prompt": null}
{"id": "45a49f20-bd8c-4677-b47e-89a00e56da75", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + (global_best_value - np.mean(personal_best_value)) / (np.std(personal_best_value) + 1e-9))  # Changed line\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by integrating a dynamic cognitive coefficient adjustment based on the relative performance of the swarm.", "configspace": "", "generation": 84, "fitness": 0.8569341997072905, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.036. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8135212318854326, 0.9021886348862259, 0.8550927323502129], "final_y": [0.15256707833391914, 0.12038532238227995, 0.1380100082440453]}, "mutation_prompt": null}
{"id": "e0511679-8ea3-4694-8e49-1cb8f2bbd0d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.8 * np.exp(-0.4 * adaptive_factor)\n            local_coeff = 0.5 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] += 0.1 * np.random.randn(self.dim)  # Improved local exploration\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "An enhanced dynamic particle velocity strategy and improved local exploration to boost convergence speed and solution refinement.", "configspace": "", "generation": 85, "fitness": 0.9297727166708422, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.008. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9330887711023372, 0.9185468109458196, 0.9376825679643701], "final_y": [0.11060066804315605, 0.1124691004403563, 0.11001379985386006]}, "mutation_prompt": null}
{"id": "2e45bc37-22ba-4196-8750-3f29d52f8e17", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Increased adaptability\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            elite_solution_index = np.argmin(personal_best_value)\n            elite_solution = personal_best[elite_solution_index]  # Preserve elite solution\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n                    \n            swarm[elite_solution_index] = elite_solution  # Ensure elite solution is preserved\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates elite solution preservation and adaptive dynamic coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.9199468649943148, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.019. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9407821629838412, 0.8943714939172167, 0.9246869380818862], "final_y": [0.10974167915428568, 0.1231761110785855, 0.11357712514120544]}, "mutation_prompt": null}
{"id": "61c12467-c8c3-4e19-9bc6-7cc442548b3c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * adaptive_factor  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                # Dynamic neighborhood size adjustment\n                self.neighborhood_size = max(2, self.population_size // 4)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic neighborhood size and adaptive inertia weight for enhanced exploration and convergence.", "configspace": "", "generation": 87, "fitness": 0.8723659132515257, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.015. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8895979442456416, 0.8527693285915068, 0.8747304669174287], "final_y": [0.11847768240227674, 0.12573469965073536, 0.12413354472934301]}, "mutation_prompt": null}
{"id": "06abe83a-5071-4ead-ba05-6f57e650dc91", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            mutation_rate = 0.1 * adaptive_factor  # Adaptive mutation rate\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                # Apply mutation to velocity\n                mutation_vector = np.random.normal(0, mutation_rate, self.dim)\n                self.velocity[i] += mutation_vector\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates adaptive mutation in velocity to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 88, "fitness": 0.9181557261152841, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9283694168606631, 0.9105706844419988, 0.9155270770431904], "final_y": [0.10984259904214588, 0.11623005009022325, 0.11736617840219055]}, "mutation_prompt": null}
{"id": "1f2a34e1-3c62-4cdf-8a05-2626e6c4896a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                perturbation = 0.05 * (ub - lb) * np.random.randn(self.dim) * adaptive_factor  # Added\n                swarm[i] += self.velocity[i] + perturbation  # Modified\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive learning coefficients and a stochastic perturbation mechanism to enhance exploration and exploitation balance.  ", "configspace": "", "generation": 89, "fitness": 0.9152040341638493, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9222015759920201, 0.9045119765355187, 0.9188985499640091], "final_y": [0.11210506361760875, 0.11405211268948923, 0.11349073234492546]}, "mutation_prompt": null}
{"id": "4f5f1ad0-683a-4b1f-83e1-878756efad6b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                mutation = 0.1 * np.random.normal(size=self.dim)\n                swarm[i] += self.velocity[i] + mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration by introducing a mutation mechanism and adaptive learning rates for improved solution diversity and convergence.", "configspace": "", "generation": 90, "fitness": 0.911109705870737, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.023. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9173711899821954, 0.8804337572368536, 0.9355241703931619], "final_y": [0.11715883179649789, 0.1266762725355004, 0.11021129725184764]}, "mutation_prompt": null}
{"id": "e8878437-e7e3-4678-be4c-c98a677bd21f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3, r4 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                # Adjust velocity computation with an exploration term\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]) +\n                                    0.1 * r4 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances the exploration-exploitation balance by introducing a velocity adjustment term and dynamic neighborhood selection to improve convergence.", "configspace": "", "generation": 91, "fitness": 0.7961981261551369, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.007. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8019330707605505, 0.785685921098964, 0.8009753866058957], "final_y": [0.15006585683760032, 0.15979769984220416, 0.1531482933801387]}, "mutation_prompt": null}
{"id": "ad875228-178c-44cd-85ea-8f7af7b651b3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implements an adaptive inertia weight to enhance convergence by dynamically balancing exploration and exploitation.", "configspace": "", "generation": 92, "fitness": 0.8639252037875301, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8867950195524443, 0.8477715485738823, 0.857209043236264], "final_y": [0.12286385579829728, 0.127221220609685, 0.13173066306563097]}, "mutation_prompt": null}
{"id": "997ca74b-edfa-4388-b1b3-8b523915434f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                # Stochastic escape mechanism\n                if np.random.random() < 0.1:\n                    self.velocity[i] = np.random.uniform(-1, 1, self.dim) * (ub - lb)\n                else:\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration by incorporating a stochastic escape mechanism to avoid premature convergence and diversify the search space.", "configspace": "", "generation": 93, "fitness": 0.9028653931000048, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9038926251543707, 0.9244586293895961, 0.8802449247560475], "final_y": [0.11629825619655898, 0.1119688351647401, 0.12697152757034103]}, "mutation_prompt": null}
{"id": "59505217-df11-4d07-b576-a27a800589ba", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                # Change: Make neighborhood size adaptive based on evaluations.\n                self.neighborhood_size = max(2, int(self.population_size * (1 - adaptive_factor)))\n\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive neighborhood size to enhance exploration-exploitation balance in swarm optimization.", "configspace": "", "generation": 94, "fitness": 0.9285655231854574, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9368404205278583, 0.9212422505319305, 0.9276138984965832], "final_y": [0.10986174216327527, 0.11624319828599627, 0.11361015195798707]}, "mutation_prompt": null}
{"id": "562c14ea-6f82-4e38-a7c1-ce7018debdcb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            mutation_probability = 0.1 * adaptive_factor  # Added mutation probability\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                # Apply mutation\n                if np.random.rand() < mutation_probability:\n                    swarm[i] += np.random.normal(0, (ub - lb) * 0.1, self.dim)\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a mutation-based exploration mechanism to enhance diversity and prevent premature convergence in swarm dynamics.", "configspace": "", "generation": 95, "fitness": 0.9033403228945701, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8883130518962531, 0.895802286294044, 0.925905630493413], "final_y": [0.1244546592676905, 0.12371200566267804, 0.11216947054018234]}, "mutation_prompt": null}
{"id": "84388102-0225-4921-9faf-57be47e597d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.5 * adaptive_factor  # Reduced starting value for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances the algorithm by fine-tuning the inertia weight reduction strategy for better convergence.", "configspace": "", "generation": 96, "fitness": 0.9193758412540382, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9132087231732895, 0.9182190525052, 0.9266997480836252], "final_y": [0.11702356391023305, 0.11622235501038491, 0.11250619556900476]}, "mutation_prompt": null}
{"id": "52778d8c-ce1f-4dc9-ac24-83e535fea061", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.momentum = np.ones(self.dim)  # Added momentum vector\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            # Introduce dynamic reduction in population size\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                \n                # Update momentum: new line\n                self.momentum = 0.9 * self.momentum + 0.1 * (self.velocity[i])**2\n                \n                # Adjust velocity: new line\n                swarm[i] += self.velocity[i] * np.clip(self.momentum, 0.9, 1.1)\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive momentum mechanism for improved exploration and convergence with reduced stagnation risk.", "configspace": "", "generation": 97, "fitness": 0.9257631157830256, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9329402490450733, 0.9208078698171058, 0.9235412284868976], "final_y": [0.11044221205815963, 0.11621755954633695, 0.11301972521911141]}, "mutation_prompt": null}
{"id": "92f83b28-8a38-49eb-acd9-7a3507bd2a4e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(swarm, axis=0).mean()\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * (1 - 0.5 * diversity)\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + diversity)\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor) * (1 - diversity)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates dynamic inertia and learning coefficients adaptation based on solution diversity to enhance convergence and exploration balance.", "configspace": "", "generation": 98, "fitness": 0.722101763274328, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.722 with standard deviation 0.037. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.6782316552725818, 0.76890311738062, 0.7191705171697818], "final_y": [0.20976455073767897, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "3d9cf8f2-c4e0-409f-a126-def88d39088d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.1  # Added for adaptive mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n            mutation_strength = self.mutation_rate * adaptive_factor  # Adaptive mutation\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + mutation_strength * np.random.randn(self.dim)  # Mutation effect\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates adaptive mutation and selective elitism to enhance exploration and exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.9181162510055266, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.9254700753438421, 0.9143915064552002, 0.914487171217538], "final_y": [0.10963331890961425, 0.11622024108973783, 0.11743608453855059]}, "mutation_prompt": null}
{"id": "b37e42e9-0b4e-4cd3-a0ce-07492ed3943d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.exp(-0.5 * adaptive_factor)\n            local_coeff = 0.4 * adaptive_factor\n\n            if evaluations / self.budget > 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_value[neighborhood_indices])]]\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    local_coeff * r3 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < self.mutation_rate:\n                    swarm[i] += np.random.normal(0, adaptive_factor, self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing adaptive mutation and crossover strategies to exploit diverse solutions.", "configspace": "", "generation": 100, "fitness": 0.9126647044238682, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.031. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8f2aca1c-b9fe-429d-b731-d6df6c657bbb", "metadata": {"aucs": [0.8688271171799034, 0.928846405755706, 0.9403205903359951], "final_y": [0.12653881066695027, 0.11171491877500195, 0.10999320780689414]}, "mutation_prompt": null}
