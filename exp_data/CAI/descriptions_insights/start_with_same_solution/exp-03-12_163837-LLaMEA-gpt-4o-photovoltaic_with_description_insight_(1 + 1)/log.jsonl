{"id": "f0588b34-7601-4de2-b873-e46ff2a7d13d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "79f86064-32dd-4ff1-89fc-baba729c5882", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation for exploration\n                if np.random.rand() < 0.1 * adaptive_factor:  # Changed line\n                    mutation_strength = (ub - lb) * 0.1 * adaptive_factor\n                    swarm[i] += np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces adaptive mutation for better exploration at the beginning and convergence at the end.", "configspace": "", "generation": 1, "fitness": 0.8214621235152094, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.018. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f0588b34-7601-4de2-b873-e46ff2a7d13d", "metadata": {"aucs": [0.7975361928559398, 0.8252265125726213, 0.8416236651170671], "final_y": [0.15322517000333358, 0.14300181508189447, 0.11950838668508201]}, "mutation_prompt": null}
{"id": "3518ce12-b45c-4d12-b554-03ae10b34cdb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic adjustment of the cognitive coefficient to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8400610827424543, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.029. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f0588b34-7601-4de2-b873-e46ff2a7d13d", "metadata": {"aucs": [0.8048273095523992, 0.8397541977311189, 0.8756017409438449], "final_y": [0.13736602354031646, 0.13306782928905914, 0.12798991601303]}, "mutation_prompt": null}
{"id": "76bf9703-90a9-49d2-b8d1-dbc861c5fdc6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Dynamic adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) with dynamic social coefficient to further improve exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.7912357963036035, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.022. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3518ce12-b45c-4d12-b554-03ae10b34cdb", "metadata": {"aucs": [0.76089796203029, 0.8102960708298267, 0.8025133560506938], "final_y": [0.15392139289854723, 0.1449993135808153, 0.13878079340209737]}, "mutation_prompt": null}
{"id": "a92af07f-e109-4e3f-a697-1927d9879678", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) with dynamic social coefficient for improved global optimization balance.", "configspace": "", "generation": 4, "fitness": 0.8599889977024526, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3518ce12-b45c-4d12-b554-03ae10b34cdb", "metadata": {"aucs": [0.8331279825123752, 0.871793019513259, 0.8750459910817238], "final_y": [0.1296843409474372, 0.1269430417235914, 0.1172766647432818]}, "mutation_prompt": null}
{"id": "2c9086bf-7b4a-4e10-8d0e-3b04815e967c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor * np.random.uniform(0.8, 1.2)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) with improved velocity update and dynamic social coefficient for superior balance in global optimization.", "configspace": "", "generation": 5, "fitness": 0.8229119823845794, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.023. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a92af07f-e109-4e3f-a697-1927d9879678", "metadata": {"aucs": [0.8050440014963992, 0.8089125170909051, 0.8547794285664342], "final_y": [0.13555121660071612, 0.15033905335164066, 0.1270104087094297]}, "mutation_prompt": null}
{"id": "1f175118-50da-47ca-9a6b-3d369f55920d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                global_convergence_factor = 0.5 * np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    global_convergence_factor * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Augmented Adaptive Swarm Gradient Descent (AASGD) with improved velocity update by incorporating global convergence factor.", "configspace": "", "generation": 6, "fitness": 0.831606951329038, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.022. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a92af07f-e109-4e3f-a697-1927d9879678", "metadata": {"aucs": [0.8056156844988516, 0.8601623940353929, 0.8290427754528695], "final_y": [0.14994834245079058, 0.1290097093229855, 0.13586204322596296]}, "mutation_prompt": null}
{"id": "2f88479f-7301-4c91-b588-6c95df7392ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration-exploitation balance by fine-tuning the inertia weight's adaptive range.", "configspace": "", "generation": 7, "fitness": 0.8673275813187954, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.016. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a92af07f-e109-4e3f-a697-1927d9879678", "metadata": {"aucs": [0.8459285707606999, 0.8717149284631586, 0.8843392447325278], "final_y": [0.12602291909057373, 0.12518104645258055, 0.11828374579343426]}, "mutation_prompt": null}
{"id": "fc223f07-5c71-4eaa-80f6-51d8e145273c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.75, 1.5)  # Adjusted range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly adjusted cognitive coefficient range for better exploration-exploitation balance in adaptive swarm gradient descent.", "configspace": "", "generation": 8, "fitness": 0.8627104143717107, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8537082154317623, 0.8447145994080595, 0.8897084282753103], "final_y": [0.11920182309485905, 0.1297420892283201, 0.1129653645069153]}, "mutation_prompt": null}
{"id": "4fde64c4-3aac-418b-910c-ac59fec4e182", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia weight adaptation for better convergence balance.", "configspace": "", "generation": 9, "fitness": 0.8599889977024526, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8331279825123752, 0.871793019513259, 0.8750459910817238], "final_y": [0.1296843409474372, 0.1269430417235914, 0.1172766647432818]}, "mutation_prompt": null}
{"id": "af37f3d0-5273-4ab6-8438-1b0c91b1b221", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.0 + 0.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Fine-tuned dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced balance in swarm dynamics through fine-tuned cognitive coefficient adaptation.", "configspace": "", "generation": 10, "fitness": 0.8641070556481041, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.022. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8418581926827904, 0.8562538158515831, 0.8942091584099386], "final_y": [0.12861229950553676, 0.12437397488666202, 0.11631708258872298]}, "mutation_prompt": null}
{"id": "4cd3ed32-c312-495d-8bc9-8a5aa32d046d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, dim))  # Initialize velocity with random values\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm diversity through improved velocity initialization for better global exploration.", "configspace": "", "generation": 11, "fitness": 0.8264263969783453, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.025. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8096081430500215, 0.8077247896363045, 0.8619462582487101], "final_y": [0.14401826126741557, 0.1279763821383857, 0.11954787754575491]}, "mutation_prompt": null}
{"id": "a6f6424a-3e37-40fc-be38-a3f250749bba", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * np.random.uniform(0.4, 1.6)  # Added stochastic component\n            social_coeff = 1.5 * np.random.uniform(0.4, 1.6)  # Added stochastic component\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a stochastic component in cognitive and social coefficients for better diversity and escape from local optima.", "configspace": "", "generation": 12, "fitness": 0.8521839498051141, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.020. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8296075778627451, 0.8495030459460213, 0.8774412256065757], "final_y": [0.12238885108114872, 0.13712356526291392, 0.11677899744129616]}, "mutation_prompt": null}
{"id": "8672dbb9-0968-496a-9649-210e1095ff36", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Increased dynamic adjustment\n            social_coeff = 2.0 * adaptive_factor  # Increased social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global exploration by adjusting cognitive and social coefficients for better solution diversity.", "configspace": "", "generation": 13, "fitness": 0.8299774980059347, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.032. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.8723379805533832, 0.7966637097009684, 0.8209308037634526], "final_y": [0.12225804253348638, 0.14997316396443805, 0.14135678566531695]}, "mutation_prompt": null}
{"id": "b2f100d5-8983-4a2a-82ed-ed4538c4101c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay for adaptive factor\n            inertia_weight = 0.6 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive coefficients using a nonlinear decay for better convergence in high-dimensional spaces.", "configspace": "", "generation": 14, "fitness": 0.8304599686432695, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.029. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.7997017768273942, 0.8227063839935888, 0.8689717451088261], "final_y": [0.1337216744270313, 0.1271394736524617, 0.12311429362758941]}, "mutation_prompt": null}
{"id": "93e0660d-156e-40ec-a016-d9ef397d97fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            diversity = np.mean(np.std(swarm, axis=0))  # Calculate diversity of the swarm\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5) * (1 + diversity)  # Adjusted with diversity\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration-exploitation balance by dynamically adjusting social and cognitive coefficients based on swarm diversity.", "configspace": "", "generation": 15, "fitness": 0.7756121184211824, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.012. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.7925713929399787, 0.76890311738062, 0.7653618449429483], "final_y": [0.1599780801572831, 0.1702433386818767, 0.17127079934461265]}, "mutation_prompt": null}
{"id": "2d95a2b2-11fe-4726-bdc0-f364a514ac62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced variable inertia weight decay to improve convergence towards global optimum.", "configspace": "", "generation": 16, "fitness": 0.9171535892840099, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2f88479f-7301-4c91-b588-6c95df7392ef", "metadata": {"aucs": [0.9065606625688925, 0.9146416742957184, 0.9302584309874189], "final_y": [0.11866743510777555, 0.11656129929865977, 0.11269638414636063]}, "mutation_prompt": null}
{"id": "64b7a66f-9869-4ed8-80b0-6cb47e0bf8ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5) * (0.5 + 0.5*adaptive_factor)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor * (0.5 + 0.5*adaptive_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive cognitive and social coefficients decay to improve convergence towards global optimum.", "configspace": "", "generation": 17, "fitness": 0.9068034417439866, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.018. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2d95a2b2-11fe-4726-bdc0-f364a514ac62", "metadata": {"aucs": [0.9103616939353165, 0.8837511830709178, 0.9262974482257251], "final_y": [0.1172958493310845, 0.12506043606461903, 0.11344493234384068]}, "mutation_prompt": null}
{"id": "cce5b341-57c8-4ee8-9982-a48abbc1dc5a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n            learning_factor = 0.1 * (1 - adaptive_factor)  # New line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    learning_factor)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update by introducing a learning factor to improve swarm adaptability and balance exploration-exploitation.", "configspace": "", "generation": 18, "fitness": 0.9162838301629505, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2d95a2b2-11fe-4726-bdc0-f364a514ac62", "metadata": {"aucs": [0.9065323403787804, 0.9072274673478574, 0.9350916827622137], "final_y": [0.11883326035994457, 0.11987633211089999, 0.11041122009859938]}, "mutation_prompt": null}
{"id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm exploration by dynamically adjusting the cognitive coefficient for better convergence.", "configspace": "", "generation": 19, "fitness": 0.9178247215208405, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2d95a2b2-11fe-4726-bdc0-f364a514ac62", "metadata": {"aucs": [0.9019273960999117, 0.9187640444334166, 0.932782724029193], "final_y": [0.11728682975556648, 0.11658220844698175, 0.11038081898163021]}, "mutation_prompt": null}
{"id": "dccaaad7-869d-43fe-9f5f-9b430cef6c7c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 / (1 + np.exp(evaluations * 10 / self.budget - 5))  # Sigmoid function for adaptive factor\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by introducing a sigmoid adaptive factor for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.9173261297412746, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9003254771676393, 0.9204127609561091, 0.9312401511000752], "final_y": [0.11961891025095506, 0.11624731913598707, 0.1121643533352501]}, "mutation_prompt": null}
{"id": "4c3ea365-96df-4f68-a4e2-5a3b17976d4a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Change: Update swarm[i]'s upper bound based on global_best's proximity to func bounds\n                swarm[i] = np.clip(swarm[i] + self.velocity[i], lb, np.minimum(ub, global_best + 0.1 * (ub - lb)))\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Further enhances the swarm's exploration by incorporating a dynamic max boundary adjustment based on the current global best's proximity to the function bounds.", "configspace": "", "generation": 21, "fitness": 0.9031489860539571, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.029. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8621273156602934, 0.9199937370650155, 0.9273259054365621], "final_y": [0.13102445351935832, 0.11621984683684339, 0.11356280441839017]}, "mutation_prompt": null}
{"id": "6f79a010-94c2-4cb2-9b91-a0da8881582e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by refining inertia weight adaptation for improved optimization.", "configspace": "", "generation": 22, "fitness": 0.849661759690588, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.012. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8522327391355593, 0.8626557510772936, 0.834096788858911], "final_y": [0.12093937154761347, 0.12033509956423749, 0.12640747361560978]}, "mutation_prompt": null}
{"id": "1717bd97-2ccc-4021-ae61-63512ef1c688", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by adjusting the inertia weight decay for optimized convergence.", "configspace": "", "generation": 23, "fitness": 0.9142136794330229, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9141030049418198, 0.9015595320770532, 0.9269785012801954], "final_y": [0.11857509727436244, 0.12142277410247626, 0.11311740108023116]}, "mutation_prompt": null}
{"id": "56488d2a-5b10-4169-b05b-86e065c5e9d7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor**2  # Refined social coefficient adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm adaptability by refining social coefficient adjustment for more efficient convergence.", "configspace": "", "generation": 24, "fitness": 0.9109534261676372, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.914841182328145, 0.890350610317538, 0.9276684858572284], "final_y": [0.11682811232337498, 0.12386656079163649, 0.11350280564628712]}, "mutation_prompt": null}
{"id": "90b6f504-e016-4ab8-a61d-9fc1e96128ad", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        success_rate = 0.5  # Initial success rate for dynamic adjustment\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor * success_rate  # Adjusted social coefficient based on success rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    success_rate = min(success_rate + 0.01, 1.0)  # Increase success rate on improvement\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            success_rate = max(success_rate - 0.01, 0.1)  # Decrease success rate when no improvement\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by adapting social coefficient based on success rate of iterations.", "configspace": "", "generation": 25, "fitness": 0.8970139721986805, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.034. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8493796093414, 0.9167014249092259, 0.9249608823454157], "final_y": [0.13549359088619695, 0.11621945083823171, 0.1135640921706873]}, "mutation_prompt": null}
{"id": "c7499faa-9cf5-423e-872e-6a2564249b55", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic range adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by refining the social coefficient adaptability using a dynamic range.", "configspace": "", "generation": 26, "fitness": 0.8981399685622296, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8783357454383025, 0.8980830883466094, 0.9180010719017767], "final_y": [0.1135706993271649, 0.11626236572541127, 0.11498693171403296]}, "mutation_prompt": null}
{"id": "067914f6-b908-4b5e-8da1-77729e97bebb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.7 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by refining dynamic coefficient adjustments for improved global convergence.", "configspace": "", "generation": 27, "fitness": 0.9137371317482832, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9126263013282054, 0.8990935463967717, 0.9294915475198724], "final_y": [0.11196144956466136, 0.1196305099044731, 0.11156060237262277]}, "mutation_prompt": null}
{"id": "8ba6304f-7e2c-4e17-a6af-222177fd97b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 3.0)  # Dynamic adjustment with enhanced randomness\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by introducing a random factor to the cognitive coefficient for improved convergence.", "configspace": "", "generation": 28, "fitness": 0.9091120883989925, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8948888992223856, 0.9099135052942112, 0.9225338606803807], "final_y": [0.11778072118761329, 0.11634892872673697, 0.11215904665108667]}, "mutation_prompt": null}
{"id": "c5dd33f3-31d5-409d-853e-35f91d8e5eee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                new_velocity = (inertia_weight * self.velocity[i] +\n                                cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = 0.7 * self.velocity[i] + 0.3 * new_velocity  # Blending new velocity with existing\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced global exploration by refining the swarm's position update mechanism for improved convergence.", "configspace": "", "generation": 29, "fitness": 0.8732096430637676, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.033. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8281937030296547, 0.8833393961990621, 0.9080958299625859], "final_y": [0.1426331951245975, 0.12423931336701999, 0.11552100886579364]}, "mutation_prompt": null}
{"id": "273e9047-9387-4fa8-a2c2-3b9b811ebd5d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)  # Dynamic adjustment\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                \n                # Random restart mechanism\n                if evaluations % (self.budget // 10) == 0:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm dynamics by incorporating a random restart mechanism to escape local optima and improve global exploration.", "configspace": "", "generation": 30, "fitness": 0.9161799588912363, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9152858697347752, 0.9140424457517603, 0.9192115611871735], "final_y": [0.11276721102439591, 0.11831001669302676, 0.11446282279558273]}, "mutation_prompt": null}
{"id": "fe21cb4c-4718-4bfe-b66e-c7732ed5a8b4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Changed adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0) \n            social_coeff = 1.7 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Periodic local search refinement\n            if evaluations % (self.population_size * 5) == 0:  # Conduct local search periodically\n                for j in range(self.population_size):\n                    refined_solution = self.local_search(personal_best[j], func, lb, ub)\n                    refined_value = func(refined_solution)\n                    evaluations += 1\n                    if refined_value < personal_best_value[j]:\n                        personal_best[j] = refined_solution\n                        personal_best_value[j] = refined_value\n                        if refined_value < global_best_value:\n                            global_best = refined_solution\n                            global_best_value = refined_value\n\n        return global_best, global_best_value\n\n    def local_search(self, position, func, lb, ub):  # New local search function\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim) * (ub - lb)\n        new_position = np.clip(position + perturbation, lb, ub)\n        return new_position", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence using adaptive inertia and periodic local search refinements.", "configspace": "", "generation": 31, "fitness": 0.9105960650193982, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9130752334603627, 0.9019835987400886, 0.9167293628577432], "final_y": [0.11330074804834955, 0.11951476750694223, 0.11366092959090013]}, "mutation_prompt": null}
{"id": "c3fe6bb7-8f37-4dc6-8e5d-7aeddaf6497d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * np.sin(np.pi * adaptive_factor)  # Layered adaptive range\n            cognitive_coeff = 2.0 * adaptive_factor * np.cos(np.pi * adaptive_factor / 2)  # Layered dynamic adjustment\n            social_coeff = 2.0 * adaptive_factor * np.sin(np.pi * adaptive_factor / 2)  # Layered adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by incorporating a layered adaptive strategy for inertia, cognitive, and social coefficients.", "configspace": "", "generation": 32, "fitness": 0.8335300533380575, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.026. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8003413098447015, 0.8357458198138291, 0.8645030303556418], "final_y": [0.1541598949128774, 0.13914783680224818, 0.1253707316496372]}, "mutation_prompt": null}
{"id": "aa13625b-8771-4b33-bd8f-b60dd3af6f78", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_adapt_rate = np.ones(dim)  # Add layer-wise adaptive rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.0)\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                modular_factor = np.random.uniform(0.8, 1.2, self.dim)  # Modular influence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * modular_factor\n                swarm[i] += self.velocity[i] * self.layer_adapt_rate  # Apply adaptive learning rates\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    self.layer_adapt_rate *= 0.99  # Reduce learning rate if improvement\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate layer-wise adaptive learning rates and modular structure detection to improve convergence and robustness.", "configspace": "", "generation": 33, "fitness": 0.8909081969511125, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.010. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.8919316133014216, 0.8777650647539863, 0.9030279127979296], "final_y": [0.12427891942197922, 0.12964842384012332, 0.12031288694962572]}, "mutation_prompt": null}
{"id": "da14c5e3-4417-40e4-9ef8-54429f097700", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by adjusting cognitive and social coefficients for improved balance between exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.921338671941515, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "475b24f4-10e5-4fe5-9f86-21e5af593210", "metadata": {"aucs": [0.9209734104009053, 0.9182338232240546, 0.9248087821995853], "final_y": [0.11300762721382562, 0.11621692293328234, 0.11357019306122307]}, "mutation_prompt": null}
{"id": "ba7f441e-c7b5-4a2f-8877-88ceb6c00c1d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.05 * np.random.randn(self.dim))  # Added local search term\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by adjusting the velocity update mechanism to include local search for increased precision.", "configspace": "", "generation": 35, "fitness": 0.890737558620787, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.013. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.9079966760287768, 0.8856814691687703, 0.8785345306648137], "final_y": [0.11602373603914484, 0.12361157694968805, 0.12552095496925164]}, "mutation_prompt": null}
{"id": "608dfbb9-8683-4226-addc-b1f94c1e226c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 3.0)  # Increased upper range for randomness\n            social_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Introduced variability in social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized swarm convergence by refining velocity calculation with enhanced random coefficients for better solution space exploration.", "configspace": "", "generation": 36, "fitness": 0.8961235360484977, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.8893700618951487, 0.8861602689454912, 0.9128402773048534], "final_y": [0.12013141648770365, 0.12343860846756416, 0.1152730660975555]}, "mutation_prompt": null}
{"id": "3101d40e-26ff-4c64-9c80-b1e407a4e4e7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Adjusted inertia weight to improve exploration\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)\n            social_coeff = 1.7 * adaptive_factor  # Adjusted social coefficient for better convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia and social factors to increase exploration and convergence efficiency.", "configspace": "", "generation": 37, "fitness": 0.9058002398312316, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.9100798099696253, 0.8915324549908311, 0.9157884545332383], "final_y": [0.11230910508508363, 0.12268576635063999, 0.11374032328716621]}, "mutation_prompt": null}
{"id": "f37855b8-c645-4e22-a785-156b487eef82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Adjusted adaptive factor for cognitive coefficient\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust cognitive coefficient adaptation to further enhance exploration early in the optimization process.", "configspace": "", "generation": 38, "fitness": 0.8989084732070219, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.8913246068795702, 0.891987369993996, 0.9134134427474997], "final_y": [0.11892357225500405, 0.11640859525240954, 0.11392759171284994]}, "mutation_prompt": null}
{"id": "8a521d70-ca8a-4be8-9fe4-5067dc8669dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        momentum = np.zeros(self.dim)  # Initialize momentum\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with momentum\n                if f_value < global_best_value:\n                    momentum = 0.1 * (swarm[i] - global_best)  # Add momentum term\n                    global_best = swarm[i] + momentum\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved global best update strategy by introducing a momentum term to enhance convergence speed.", "configspace": "", "generation": 39, "fitness": 0.909228314093497, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.8935370924190628, 0.9172160587388964, 0.9169317911225321], "final_y": [0.11882650969153086, 0.11621784103486454, 0.11228403784890961]}, "mutation_prompt": null}
{"id": "0fc2b32b-a720-4826-8787-9d65d8474b87", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.8 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Slightly increased range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined convergence by enhancing dynamic adjustment of cognitive coefficient to improve global search.", "configspace": "", "generation": 40, "fitness": 0.9023262128548407, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.8911356106847537, 0.9070029133529182, 0.9088401145268504], "final_y": [0.11708183316966758, 0.11637628345745588, 0.11383294910900632]}, "mutation_prompt": null}
{"id": "483491da-19aa-44d9-a8da-faaf7b9d0889", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Adjusted social coefficient with randomness\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by dynamically adjusting inertia weight and coefficients to improve exploration and exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.8679409622850572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.014. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.84788320847092, 0.8775266407543358, 0.8784130376299155], "final_y": [0.1310997117241114, 0.12261434745751632, 0.12372777771867949]}, "mutation_prompt": null}
{"id": "ca3ddcac-dad3-4b32-b0ba-88f0b14b675e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.5, 3.0)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm adaptability by fine-tuning randomness in cognitive coefficient for enhanced exploration.", "configspace": "", "generation": 42, "fitness": 0.9030622729911838, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.8976504998656293, 0.8970203789365051, 0.9145159401714171], "final_y": [0.11742116198903985, 0.11754347038139323, 0.114205380033498]}, "mutation_prompt": null}
{"id": "7f88d383-0a2d-447b-8f46-672c29a66d7b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                personal_best_influence = 0.5 + 0.5 * adaptive_factor  # Dynamic personal best memory factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) * personal_best_influence +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by introducing a dynamic personal best memory factor to adaptively balance exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.9210403376263909, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.9234812958208078, 0.9167165782362017, 0.9229231388221633], "final_y": [0.109847001572829, 0.11623015216992205, 0.11378479722825563]}, "mutation_prompt": null}
{"id": "d26743e0-0fcb-4793-a374-76c4b637e1ac", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted adaptive range for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Dynamic adjustment with higher range\n            social_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  # Increased range for social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence by dynamically adjusting social coefficients with an increased upper range, ensuring a better balance between exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.8679409622850572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.014. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.84788320847092, 0.8775266407543358, 0.8784130376299155], "final_y": [0.1310997117241114, 0.12261434745751632, 0.12372777771867949]}, "mutation_prompt": null}
{"id": "97dfc132-2e4e-401b-9c94-ebd48113f73d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)  \n            social_coeff = 1.5 * adaptive_factor * np.sum(np.abs(np.diff(swarm, axis=0))) / self.population_size  # Modularity-based adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined swarm dynamics by adapting cognitive and social coefficients based on layer modularity detection for improved optimization.", "configspace": "", "generation": 45, "fitness": 0.7266351137955954, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.727 with standard deviation 0.032. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.6918317068363844, 0.76890311738062, 0.7191705171697818], "final_y": [0.20241640769719016, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "cb797153-40a7-4456-b359-ef3974ee3d71", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = (0.9 - 0.5 * adaptive_factor) * (1 + 0.1 * (global_best_value / np.mean(personal_best_value)))  # Change: Adjusted inertia weight with feedback\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(1.0, 2.5)\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined swarm convergence by dynamically adjusting inertia weight based on personal and global performance metrics for enhanced optimization precision.", "configspace": "", "generation": 46, "fitness": 0.9117428404410785, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "da14c5e3-4417-40e4-9ef8-54429f097700", "metadata": {"aucs": [0.903260908520531, 0.9135647566648051, 0.9184028561378995], "final_y": [0.11408179674187857, 0.1162958175724148, 0.1146551304294059]}, "mutation_prompt": null}
