{"id": "5668017c-921c-40a6-b745-d905802546df", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "b50c2c9d-5ff0-4c68-b86d-efcaaaf06077", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # Adjust social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by introducing a dynamic adjustment of social and cognitive coefficients based on current swarm diversity.", "configspace": "", "generation": 1, "fitness": 0.8663471603354983, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.011. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5668017c-921c-40a6-b745-d905802546df", "metadata": {"aucs": [0.8773176273556984, 0.850840852338634, 0.8708830013121627], "final_y": [0.12062956953314119, 0.1279479105204394, 0.12176387535068922]}, "mutation_prompt": null}
{"id": "bc695246-8373-4b59-8f09-8512ea41a91f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # Adjust social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply layer-wise annealing factor to velocity for refined exploration\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve Adaptive Swarm Gradient Descent by incorporating a layer-wise annealing strategy for velocity update to encourage gradual exploration refinement.", "configspace": "", "generation": 2, "fitness": 0.8920324145473217, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b50c2c9d-5ff0-4c68-b86d-efcaaaf06077", "metadata": {"aucs": [0.9117836199829712, 0.8797792231693151, 0.8845344004896789], "final_y": [0.11340073615360946, 0.12426253996464576, 0.11576972833609145]}, "mutation_prompt": null}
{"id": "d311f924-b5e8-4873-8a76-f26cceda88ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95\n        self.diversity_threshold = 0.1  # Added diversity threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                diversity = np.std(swarm) / np.mean(swarm)\n                if diversity < self.diversity_threshold:\n                    self.velocity[i] += 0.5 * r3 * (lb + ub) / 2  # Add stochastic exploration\n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by employing a dynamic diversity-driven exploration strategy and integrating a stochastic layer variation to improve convergence.", "configspace": "", "generation": 3, "fitness": 0.8496145716787202, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "bc695246-8373-4b59-8f09-8512ea41a91f", "metadata": {"aucs": [0.8505687122978856, 0.8678542878635765, 0.8304207148746986], "final_y": [0.1321559610893075, 0.12202319470687151, 0.13880623054805685]}, "mutation_prompt": null}
{"id": "bc7f47b7-0497-4fed-869d-fadc6cc880c2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + np.std(personal_best_value))  # Modified cognitive coefficient\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # Adjust social coefficient\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 10) == 0 and evaluations < self.budget * 0.8:\n                self.population_size = min(self.population_size + 1, self.budget // self.dim)\n                self.velocity = np.vstack((self.velocity, np.zeros((1, self.dim))))\n                new_position = np.random.uniform(lb, ub, self.dim)\n                swarm = np.vstack((swarm, new_position))\n                personal_best = np.vstack((personal_best, new_position))\n                personal_best_value = np.append(personal_best_value, func(new_position))\n                evaluations += 1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply layer-wise annealing factor to velocity for refined exploration\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by introducing dynamic population resizing and adaptive cognitive coefficients to improve exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8800207253804363, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.031. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "bc695246-8373-4b59-8f09-8512ea41a91f", "metadata": {"aucs": [0.9122723211460667, 0.8897334323605376, 0.8380564226347047], "final_y": [0.11340224693952505, 0.1152669788634264, 0.13097679947076712]}, "mutation_prompt": null}
{"id": "d7b79e54-f734-4ad0-ac2d-7d251f632ed4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            # Dynamic annealing adjustment based on swarm diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            dynamic_annealing_factor = self.layer_annealing_factor + 0.05 * diversity\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply dynamic layer-wise annealing factor\n                self.velocity[i] *= dynamic_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by introducing a dynamic layer-wise annealing factor that adapts based on swarm diversity to improve convergence. ", "configspace": "", "generation": 5, "fitness": 0.7559931373143791, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.756 with standard deviation 0.016. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "bc695246-8373-4b59-8f09-8512ea41a91f", "metadata": {"aucs": [0.7501206367045785, 0.7783711877975195, 0.7394875874410393], "final_y": [0.177192064998687, 0.16650923155768194, 0.1820843300794327]}, "mutation_prompt": null}
{"id": "13927695-607b-4e25-bed9-c31606b60d9c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # Adjust social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation_factor = np.random.normal(loc=0, scale=0.1, size=self.dim)  # Dynamic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)  # Add mutation factor\n                \n                # Apply layer-wise annealing factor to velocity for refined exploration\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by introducing a dynamic layer-wise mutation strategy for velocity to improve exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8939216826945241, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bc695246-8373-4b59-8f09-8512ea41a91f", "metadata": {"aucs": [0.8962545625374165, 0.8757704865598648, 0.9097399989862907], "final_y": [0.11275072589049917, 0.1256170835787559, 0.11315308290215775]}, "mutation_prompt": null}
{"id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by incorporating a layer-wise adaptive inertia weight and a chaotic map for dynamic exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.8995930408976993, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "13927695-607b-4e25-bed9-c31606b60d9c", "metadata": {"aucs": [0.892907807222486, 0.9052235735034262, 0.9006477419671858], "final_y": [0.11759852775929946, 0.11553768390935659, 0.11703543211952072]}, "mutation_prompt": null}
{"id": "cd94b1f3-bb8a-4e47-803b-40775a7f7b09", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.mean(chaotic_sequence)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 * chaotic_sequence.mean() / np.mean(swarm)  # Changed to chaotic interaction\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent by incorporating a dynamic cognitive coefficient and leveraging a chaotic sequence for both cognitive and social interactions.", "configspace": "", "generation": 8, "fitness": 0.7283317590784324, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.728 with standard deviation 0.033. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.6929597507583846, 0.7728650093071308, 0.7191705171697818], "final_y": [0.1967785106641713, 0.1677367068866945, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "dcb84b55-769e-493a-9d9d-9cc5b96815b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * adaptive_factor / (np.std(swarm) + 1e-9)  # Change social coefficient to avoid division by small mean\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent is enhanced by refining social coefficient calculation and chaotic sequence initialization for improved exploration.", "configspace": "", "generation": 9, "fitness": 0.7455705102345438, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.746 with standard deviation 0.021. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.7466273777910126, 0.7708615296427771, 0.7192226232698417], "final_y": [0.1718807627351695, 0.1694100216825315, 0.19100753486856104]}, "mutation_prompt": null}
{"id": "426f6d81-861d-4c51-a2d9-3fcd2d1e013a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    1.5 * r2 * (global_best - swarm[i]) +  # Adjusted social_coeff to fixed value\n                                    mutation_factor)\n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine Adaptive Swarm Gradient Descent by introducing layer-specific inertia weights and strategic use of chaotic maps for improved exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8810225822238876, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.017. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8890277669524683, 0.8578850993721616, 0.8961548803470332], "final_y": [0.11938792335018922, 0.1206743036101755, 0.11196894830016157]}, "mutation_prompt": null}
{"id": "b760abb7-6cdc-43e1-9095-d47efa4daed5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < 0.02:  # 2% chance of random restart\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce random restarts with a small probability to enhance exploration and avoid local optima.", "configspace": "", "generation": 11, "fitness": 0.889236100552946, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8735720433999621, 0.8879230766807482, 0.9062131815781278], "final_y": [0.12261118419499151, 0.11876660603103417, 0.11529694330274465]}, "mutation_prompt": null}
{"id": "cf20e7a8-dfbf-47eb-aefb-5122c17904ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i]  # Increased chaotic mutation factor impact\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Increase the mutation_factor's impact by adjusting its scaling factor for enhanced exploration.", "configspace": "", "generation": 12, "fitness": 0.8884105008764553, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.015. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8990305844921497, 0.8676089557514913, 0.8985919623857248], "final_y": [0.11422179670159927, 0.12558167632085238, 0.11821149083313476]}, "mutation_prompt": null}
{"id": "3d25bbcf-c4f3-4118-8a0e-42194f76b753", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.std(swarm)  # Decaying cognitive coeff based on variance\n            social_coeff = 1.5 * (1 + np.std(personal_best)) / np.mean(swarm)  # Dynamic social coeff\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decaying cognitive coefficient and dynamic social coefficient based on variance to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8016621320097279, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.028. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8382644671845744, 0.7971040654774244, 0.7696178633671852], "final_y": [0.1425792879918899, 0.1590308412591216, 0.16935403520918046]}, "mutation_prompt": null}
{"id": "2ad123a7-4bae-4b0b-93d9-fde7c7f33552", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                temperature_factor = 1.0 - (evaluations / self.budget)  # New line: Temperature-based factor\n                self.velocity[i] *= self.layer_annealing_factor * temperature_factor  # Updated line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a temperature-based annealing factor in the swarm's velocity update to further enhance exploration and convergence.", "configspace": "", "generation": 14, "fitness": 0.884024457652461, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.015. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8661724662720877, 0.8834831676705263, 0.9024177390147688], "final_y": [0.13137185111905492, 0.1254382952761378, 0.11712301555724158]}, "mutation_prompt": null}
{"id": "2bfb3c6c-5501-4e8f-aaee-e4e0ca2bc536", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # swapped with social_coeff\n            social_coeff = 1.5 * adaptive_factor  # swapped with cognitive_coeff\n\n            for i in range(self.population_size):\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)\n                mutation_factor = 0.1 * chaotic_sequence[i]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic cognitive and social coefficients by adapting them based on iteration progress and swarm diversity to improve exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.8828008460610149, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8698539920253752, 0.8700699571545442, 0.9084785890031253], "final_y": [0.12593247146937703, 0.12295708285967477, 0.11125796717841197]}, "mutation_prompt": null}
{"id": "8056e3f3-d441-4c1e-b097-22add700e0aa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * np.std(swarm) / np.mean(swarm)  # Dynamically adjusted cognitive coefficient\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine Adaptive Swarm Gradient Descent by adjusting the cognitive coefficient dynamically based on the population diversity to enhance exploration in diverse regions.", "configspace": "", "generation": 16, "fitness": 0.8798687387035461, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.008. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8693019723036375, 0.8896842852249542, 0.8806199585820467], "final_y": [0.1285805437052363, 0.11901102356430893, 0.12012095631038344]}, "mutation_prompt": null}
{"id": "c5db38dc-9582-4148-8509-2d3f0d028efc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * chaotic_sequence[i] * self.velocity[i] +  # Chaotic inertia\n                                    cognitive_coeff * np.random.random(self.dim) * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance adaptive exploration with chaotic inertia and diverse cognitive influence to improve convergence and solution quality.", "configspace": "", "generation": 17, "fitness": 0.8610419290219893, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.014. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8499792330347747, 0.8804606947904207, 0.8526858592407722], "final_y": [0.1381088164425035, 0.1286113256517556, 0.13554562127719205]}, "mutation_prompt": null}
{"id": "eee23e88-661e-4aba-ad26-d9213faab740", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear inertia weight update for more adaptive exploration-exploitation trade-off.", "configspace": "", "generation": 18, "fitness": 0.8974003859840575, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.9093792144860099, 0.8808433009791686, 0.9019786424869939], "final_y": [0.11336143312087499, 0.12556935961418791, 0.1173960538273291]}, "mutation_prompt": null}
{"id": "a5ac8b46-f977-4705-8a00-c1c5ecd65eea", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 4.0  # Modified chaos parameter for improved exploration\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i]  # Use chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with improved chaotic sequence generation for enhanced exploration.", "configspace": "", "generation": 19, "fitness": 0.8887581040075996, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.9009763972983729, 0.8796724302915535, 0.8856254844328725], "final_y": [0.11213535194163504, 0.1238301747195153, 0.12148594785718703]}, "mutation_prompt": null}
{"id": "c9d37d6d-488b-4275-9cd5-6e7a2c53e8b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine Adaptive Swarm Gradient Descent by enhancing chaotic mutation factor with adaptive scaling for better exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.9000397403848691, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6db2e908-bf3b-4b71-9018-64c6f5a84a98", "metadata": {"aucs": [0.8924368749149236, 0.9056751007445627, 0.9020072454951212], "final_y": [0.11797649573935387, 0.11462753371933088, 0.1161130956494727]}, "mutation_prompt": null}
{"id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.05 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent enhanced by incorporating periodic chaotic velocity perturbations to improve convergence.", "configspace": "", "generation": 21, "fitness": 0.9004722027323142, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.004. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c9d37d6d-488b-4275-9cd5-6e7a2c53e8b6", "metadata": {"aucs": [0.8951583154739262, 0.9042772115564766, 0.90198108116654], "final_y": [0.11641457864544735, 0.11549539146254695, 0.11612325070715923]}, "mutation_prompt": null}
{"id": "91ff2f14-4a3f-4dec-b549-d2317d8dbdfc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor ** 2  # Modified cognitive coefficient\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.05 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent by introducing a dynamic cognitive coefficient based on the evaluation progress to enhance convergence efficiency.", "configspace": "", "generation": 22, "fitness": 0.8974833306240376, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "metadata": {"aucs": [0.8988089390146936, 0.9017915093218429, 0.8918495435355763], "final_y": [0.11463353200020632, 0.11681991016125737, 0.11964896734567398]}, "mutation_prompt": null}
{"id": "b82989b4-4ad6-4794-bfb0-1e158a2154c0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.8  # Adjusted logistic map parameter for improved exploration\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.3 * adaptive_factor  # Modified inertia weight for better balance\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.05 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with optimized inertia weight and chaotic logistic map parameters for improved convergence.", "configspace": "", "generation": 23, "fitness": 0.8976143706866356, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "metadata": {"aucs": [0.9132906031451794, 0.8917559009435956, 0.8877966079711317], "final_y": [0.11207560906927228, 0.12095777549344766, 0.11288466504561345]}, "mutation_prompt": null}
{"id": "b54c734a-f4b3-4313-a92d-22e5dd2abcb5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % max(5, int(25 * adaptive_factor)) == 0:  # Dynamic perturbation frequency\n                    self.velocity[i] += 0.05 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with dynamic chaotic perturbation frequency for enhanced convergence.", "configspace": "", "generation": 24, "fitness": 0.8995813696049693, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "metadata": {"aucs": [0.892318045458754, 0.9033713279982449, 0.903054735357909], "final_y": [0.11805007263184764, 0.11643437841322879, 0.11545651129566725]}, "mutation_prompt": null}
{"id": "a9f4dca7-a800-42ce-9b06-aff8866b9c17", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm) + 0.1 * adaptive_factor  # Modified social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.05 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with variable social coefficients based on convergence trends for improved exploration-exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.8992657029148571, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "metadata": {"aucs": [0.8871263123917789, 0.9153282372665632, 0.8953425590862294], "final_y": [0.11546416966108142, 0.11245191563512136, 0.11635858290706536]}, "mutation_prompt": null}
{"id": "3e41248d-0bc5-49ff-9ad8-86a6fbb25c94", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent using improved chaotic perturbation for better convergence.", "configspace": "", "generation": 26, "fitness": 0.9018330480089491, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a89ab452-b111-4f96-99fb-1b2b92b0f2fd", "metadata": {"aucs": [0.8943396843611318, 0.9084757393453073, 0.9026837203204083], "final_y": [0.11680386788578712, 0.11370649473131811, 0.11575318665116952]}, "mutation_prompt": null}
{"id": "c7132c72-b41a-4b2a-aee0-c60c1a5d13bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n\n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    chaotic_scale = 0.05 * chaotic_sequence[i] * adaptive_factor  # Changed perturbation factor\n                    self.velocity[i] += chaotic_scale  # Updated dynamic velocity scaling\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic velocity scaling based on chaotic sequence.", "configspace": "", "generation": 27, "fitness": 0.9004722027323142, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.004. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e41248d-0bc5-49ff-9ad8-86a6fbb25c94", "metadata": {"aucs": [0.8951583154739262, 0.9042772115564766, 0.90198108116654], "final_y": [0.11641457864544735, 0.11549539146254695, 0.11612325070715923]}, "mutation_prompt": null}
{"id": "c337b655-6f88-4e8c-a55a-eff925750388", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 4.0  # Changed logistic_mu to enhance chaos\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with enhanced chaotic logistic mapping for better exploration.", "configspace": "", "generation": 28, "fitness": 0.8879985269003049, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.009. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3e41248d-0bc5-49ff-9ad8-86a6fbb25c94", "metadata": {"aucs": [0.8990762156203073, 0.8775076688633756, 0.8874116962172323], "final_y": [0.11378399736876488, 0.1253647091214103, 0.11994500657510898]}, "mutation_prompt": null}
{"id": "8c57af59-4e7c-4b21-929f-1ae08df2e370", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.1 * chaotic_sequence[i] * adaptive_factor  # Use chaotic mutation factor with adaptive scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 5 == 0:  # Increased frequency of periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with chaotic perturbation and increased perturbation frequency for improved convergence.", "configspace": "", "generation": 29, "fitness": 0.9005309447114521, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.003. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3e41248d-0bc5-49ff-9ad8-86a6fbb25c94", "metadata": {"aucs": [0.8960350394781516, 0.9035834290194095, 0.9019743656367956], "final_y": [0.1156159895224127, 0.11710787027074743, 0.11628747772607995]}, "mutation_prompt": null}
{"id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with enhanced chaotic mutation for better exploration.", "configspace": "", "generation": 30, "fitness": 0.9025061854853375, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3e41248d-0bc5-49ff-9ad8-86a6fbb25c94", "metadata": {"aucs": [0.8999369741508543, 0.9032729504914472, 0.9043086318137108], "final_y": [0.1123691784371722, 0.11757037268516546, 0.1152157419037857]}, "mutation_prompt": null}
{"id": "f448f1a9-e019-4911-8e68-86a1c90f5543", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            # Dynamically adjust logistic_mu\n            logistic_mu = 3.5 + 0.4 * np.sin(np.pi * evaluations / self.budget)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic logistic map parameters for improved exploration and adaptive velocity adjustment.", "configspace": "", "generation": 31, "fitness": 0.9012863204192737, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.9093733965898186, 0.8931461717344027, 0.9013393929335999], "final_y": [0.11373518095471125, 0.11769253750599051, 0.11707096709386833]}, "mutation_prompt": null}
{"id": "4a03e2d9-8f9b-4d95-90c0-784a913b95e7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.98  # Adjusted annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.2 * chaotic_sequence[i] * adaptive_factor  # Further increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm with Optimized Chaotic Perturbation and Dynamic Layer Annealing.", "configspace": "", "generation": 32, "fitness": 0.8802294415161801, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.87578064890267, 0.8894614432710025, 0.875446232374868], "final_y": [0.1249070409568388, 0.11655146335969624, 0.1175316314959799]}, "mutation_prompt": null}
{"id": "2c329f0b-0809-48b7-b202-8337928bb8a9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor  # Updated cognitive coefficient\n            social_coeff = 1.7 * np.std(swarm) / np.mean(swarm)  # Updated social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with increased cognitive and social coefficients for better convergence.", "configspace": "", "generation": 33, "fitness": 0.8977578541017208, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.8954196088577691, 0.8971105712581395, 0.9007433821892539], "final_y": [0.11251514223210524, 0.1160545692798235, 0.11680411610620667]}, "mutation_prompt": null}
{"id": "7023d1aa-2735-4de1-9f82-d762467e4d50", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.95  # Modified logistic map parameter\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with updated logistic map parameters for improved chaotic exploration.", "configspace": "", "generation": 34, "fitness": 0.8858841338906958, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.866451088621192, 0.8849593181873036, 0.9062419948635914], "final_y": [0.12917983606628636, 0.11922928029202928, 0.11555863687074053]}, "mutation_prompt": null}
{"id": "491b9a5b-2416-4233-ba91-ed4efeaf503b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.95  # Modified logistic map parameter\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Modified mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved chaotic mutation parameters for better exploration and convergence.", "configspace": "", "generation": 35, "fitness": 0.8741704940825991, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.028. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.8647011678592589, 0.8458456656535275, 0.9119646487350109], "final_y": [0.12933752960758405, 0.13501957904869943, 0.1127935424249581]}, "mutation_prompt": null}
{"id": "9ca00dea-2b15-41db-8c55-a8972c2e6110", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved chaotic mutation tuning for exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.8946173411073269, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.9035902224500895, 0.882242931659178, 0.8980188692127131], "final_y": [0.1118589390660758, 0.11689475030677277, 0.11795522782098189]}, "mutation_prompt": null}
{"id": "72cfa682-95fd-4623-b633-4299aa5190db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and mutation influence for improved convergence.", "configspace": "", "generation": 37, "fitness": 0.9059675507853339, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6d5cb67a-5134-44f4-8147-f74bc60d4e44", "metadata": {"aucs": [0.9037923169103736, 0.9059212936985952, 0.9081890417470329], "final_y": [0.111091472483407, 0.11677334518666127, 0.11300054330119269]}, "mutation_prompt": null}
{"id": "96ff212b-aa25-438c-aebc-0a040813df81", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                # Change 1: Dynamic velocity scaling based on adaptive factor\n                self.velocity[i] *= (1 + 0.05 * adaptive_factor)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and dynamic velocity scaling for improved convergence.", "configspace": "", "generation": 38, "fitness": 0.885885840267238, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.012. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8693856520872825, 0.8966663269698713, 0.8916055417445605], "final_y": [0.11671838245707422, 0.11829343395230318, 0.11770237969767161]}, "mutation_prompt": null}
{"id": "e114c1c0-6f98-4e51-9a94-902a8d57f89a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 8 == 0:\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor * np.sin(evaluations)  # Periodic scaling\n\n                self.velocity[i] *= self.layer_annealing_factor * (1 + 0.01 * adaptive_factor)  # Adaptive annealing factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced periodic chaotic velocity scaling and adaptive layer annealing for enhanced convergence.", "configspace": "", "generation": 39, "fitness": 0.9036872859575634, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8939213894357396, 0.9118829718639584, 0.9052574965729923], "final_y": [0.11282799787594189, 0.11307090890564397, 0.11492590747927323]}, "mutation_prompt": null}
{"id": "31109e31-c4f0-44a4-b282-b37700efd84a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 6 == 0:  # Modify periodic chaotic perturbation frequency\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity scaling and dynamic chaotic perturbation to improve convergence rate.", "configspace": "", "generation": 40, "fitness": 0.8945529745569312, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8986244991696416, 0.8819025651857939, 0.9031318593153581], "final_y": [0.11344324649579873, 0.11697452996612612, 0.11579017460908392]}, "mutation_prompt": null}
{"id": "7a08c142-51ab-4c2e-b87b-fc39f3dec101", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.6 * np.std(swarm) / np.mean(swarm)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate layer-adaptive inertia and velocity scaling for improved convergence stability.", "configspace": "", "generation": 41, "fitness": 0.8858512537049418, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8738348735926709, 0.8779508453337386, 0.9057680421884162], "final_y": [0.12558554116635334, 0.12593612571458634, 0.11633313995718364]}, "mutation_prompt": null}
{"id": "abad974b-d702-4189-adb8-92a177161f95", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.3 * adaptive_factor  # Modified inertia weight  (line 1 change)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.19 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor (line 2 change)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update with adaptive chaotic mutation and inertia tuning for better convergence.", "configspace": "", "generation": 42, "fitness": 0.8923337488436087, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8976435418504702, 0.8773655170030054, 0.9019921876773503], "final_y": [0.11199557236228219, 0.11693712466431327, 0.11551463608555446]}, "mutation_prompt": null}
{"id": "6086393a-e566-43b0-96d6-e1367ffbdb5e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence with dynamic logistic_mu\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n                logistic_mu += 0.0005  # New change: dynamic logistic_mu adjustment\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic layer annealing and chaotic mapping to enhance convergence and solution robustness.", "configspace": "", "generation": 43, "fitness": 0.8918445868351244, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.019. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8672108170877957, 0.8948446183368979, 0.9134783250806796], "final_y": [0.12806732529076825, 0.12143166823658225, 0.11570693642575003]}, "mutation_prompt": null}
{"id": "af7b5b76-9d85-40e0-927a-2087577a4bce", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor  # Changed from 1.5 to 2.0\n            social_coeff = 1.7 * np.std(swarm) / np.mean(swarm)  # Changed from 1.5 to 1.7\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic exploration with adaptive cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 44, "fitness": 0.8826510096876076, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.017. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8624863191857557, 0.8806593675684743, 0.9048073423085924], "final_y": [0.11340978422593895, 0.11800134271988905, 0.11152294226495807]}, "mutation_prompt": null}
{"id": "0322ea66-b8f2-4c96-ae32-174c3b7c8b66", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.20 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive chaotic mutation and refined perturbation for enhanced convergence stability.", "configspace": "", "generation": 45, "fitness": 0.8924063062884912, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9007388261450702, 0.873965410342759, 0.9025146823776443], "final_y": [0.11356544820756265, 0.11944731410642906, 0.11613353514758051]}, "mutation_prompt": null}
{"id": "3c1013d6-40cb-4abf-a947-93c1efbc36c2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= (self.layer_annealing_factor ** (evaluations / self.budget))  # Gradual annealing\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced stepwise adaptive annealing for gradual velocity reduction to enhance convergence stability.", "configspace": "", "generation": 46, "fitness": 0.882121443047421, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8646399043072382, 0.8893575750707702, 0.8923668497642543], "final_y": [0.12023877471694411, 0.11949018296761149, 0.11725347285588661]}, "mutation_prompt": null}
{"id": "9550259c-6fcb-4b52-96e6-c89194d4c4ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.93  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.8 * np.std(swarm) / np.mean(swarm)  # Enhanced social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive chaotic perturbation with enhanced social influence and damping factor for improved convergence.", "configspace": "", "generation": 47, "fitness": 0.887968629768487, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.004. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8865717277683328, 0.8839845935781995, 0.893349567958929], "final_y": [0.11216050952166479, 0.12301489065330806, 0.11818497313067033]}, "mutation_prompt": null}
{"id": "cf7f777a-d074-4519-9a40-58c9e4fd624e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) * adaptive_factor  # Progressive velocity reduction\n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbations with progressive velocity reduction for improved exploitation.", "configspace": "", "generation": 48, "fitness": 0.8876267988648813, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.019. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.864394443564161, 0.8878726101284917, 0.9106133429019909], "final_y": [0.13143946815270136, 0.12449412245529712, 0.1156337345974705]}, "mutation_prompt": null}
{"id": "6cd99af5-0425-4e2f-b55d-e81b6c5d5b18", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.99  # Adjusted logistic map parameter for more chaos\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Augmented chaotic perturbation frequency and adaptive logistic sequence for enhanced convergence.", "configspace": "", "generation": 49, "fitness": 0.8913383169196752, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8995281645684465, 0.8861889249264244, 0.8882978612641546], "final_y": [0.11545637916930074, 0.11776347714474344, 0.1147244491336532]}, "mutation_prompt": null}
{"id": "075bc748-824c-4507-93fe-8699c8f10954", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 10 == 0:  # Adjusted periodic chaotic perturbation\n                    self.velocity[i] += 0.2 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved velocity update by enhancing chaotic perturbation frequency with a novel periodic update mechanism.", "configspace": "", "generation": 50, "fitness": 0.8981304859122572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.903861849832054, 0.8818573427147156, 0.9086722651900019], "final_y": [0.11109105978820577, 0.11714355063103465, 0.11271760541593578]}, "mutation_prompt": null}
{"id": "95d19d34-e6ea-4e9e-babd-3305cbb46514", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 5 == 0:  # Adjust perturbation period for better exploration\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence speed through enhanced velocity update and chaos perturbation scheduling.", "configspace": "", "generation": 51, "fitness": 0.8926460222854017, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8941634417918674, 0.8824165566860426, 0.901358068378295], "final_y": [0.11690859164113288, 0.1169246265863011, 0.11625013977191911]}, "mutation_prompt": null}
{"id": "a8721d50-5943-4122-aee2-1685a382137f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 7 == 0:  # Add periodic chaotic perturbation, changed from 8 to 7\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor, changed from 0.1 to 0.12\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and mutation influence for improved convergence through dynamic logistic map adjustment.", "configspace": "", "generation": 52, "fitness": 0.9037796786117944, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.904250554363045, 0.9042733135431991, 0.9028151679291392], "final_y": [0.11096936563760884, 0.11771517716436286, 0.11565648531629369]}, "mutation_prompt": null}
{"id": "877086ed-9c10-4bb0-a4e2-09930f81edab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.9 + 0.05 * np.random.rand()  # Changed to adaptive annealing factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 5 == 0:  # Changed periodic perturbation frequency\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive layer annealing factor and enhanced chaotic perturbation frequency for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.8774206069127706, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.047. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.895497565741733, 0.8128589364897082, 0.9239053185068704], "final_y": [0.12006604715001656, 0.14467911032471736, 0.11293618213138878]}, "mutation_prompt": null}
{"id": "73f8d77b-41ce-442c-985d-b8bd3c6127d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * np.std(swarm) / np.mean(swarm)  # Adjust based on diversity\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 7 == 0:  # Adjust frequency for perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increase perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation and velocity adjustment based on diversity for optimal convergence.", "configspace": "", "generation": 54, "fitness": 0.8824495305933452, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.004. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8810168841256124, 0.8880895290680101, 0.878242178586413], "final_y": [0.12262549658440602, 0.11944650022039494, 0.11860978916425835]}, "mutation_prompt": null}
{"id": "fba883dd-a096-49ae-ba79-9f10549b7c53", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Adjusted perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved local refinement by adjusting velocity and mutation factor dynamically.", "configspace": "", "generation": 55, "fitness": 0.905741322867179, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9037413578506724, 0.9052288569245799, 0.9082537538262848], "final_y": [0.11112804696581902, 0.11726488631814125, 0.1129751310656073]}, "mutation_prompt": null}
{"id": "0384a2dd-ecad-4048-8427-5c1d533659c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tuned chaotic perturbation and enhanced exploration through adaptive velocity scaling.", "configspace": "", "generation": 56, "fitness": 0.8904442891051322, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9004138386720368, 0.8707457671695908, 0.9001732614737686], "final_y": [0.11379335618129771, 0.12100701823004945, 0.11675392288272313]}, "mutation_prompt": null}
{"id": "1cd3d076-2208-44d6-a735-b6eba598c484", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic influence on mutation and periodic perturbations for better global exploration.", "configspace": "", "generation": 57, "fitness": 0.8924063062884912, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9007388261450702, 0.873965410342759, 0.9025146823776443], "final_y": [0.11356544820756265, 0.11944731410642906, 0.11613353514758051]}, "mutation_prompt": null}
{"id": "04023faf-7247-4811-9e3c-3803751ec313", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * (1 - chaotic_sequence.mean()) * adaptive_factor  # Change 1: Use chaos in inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Change 2: Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced chaos-enhanced inertia weight adaptation using logistic map to improve exploration-exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.8909138826474924, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8707634762154521, 0.8883845994941999, 0.9135935722328251], "final_y": [0.124978040921366, 0.12187892393639477, 0.11522602314633879]}, "mutation_prompt": null}
{"id": "38323f02-7607-40e0-90c0-0f34f122e0fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = (0.17 + 0.05 * adaptive_factor) * chaotic_sequence[i] * adaptive_factor # Adaptive mutation scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Enhanced perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation scaling and enhanced chaotic perturbation for refined convergence.  ", "configspace": "", "generation": 59, "fitness": 0.8830901559259966, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.026. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9006842093980909, 0.8466073377253458, 0.9019789206545531], "final_y": [0.11348594962688696, 0.12953835289133153, 0.11645921896861966]}, "mutation_prompt": null}
{"id": "c201e8d0-cb66-4c17-8cc4-9e5b52884689", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.93  # Adjusted annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor * adaptive_factor) # Further amplify mutation factor\n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Further refined chaotic influence on velocity and layer annealing for enhanced convergence.", "configspace": "", "generation": 60, "fitness": 0.8928718441483734, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8818340558340295, 0.9030186485931117, 0.8937628280179789], "final_y": [0.11803465579854933, 0.1161354952668806, 0.11668034928820392]}, "mutation_prompt": null}
{"id": "5f1a4ccd-9f36-414f-9f9b-32c4d4937f65", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor  # Modified inertia weight decay\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.15 * chaotic_sequence[i] * adaptive_factor  # Adjusted mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia weight decay and adaptive mutation factor for improved exploration and exploitation balance.", "configspace": "", "generation": 61, "fitness": 0.9005915667429375, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8960106305568163, 0.8965117469382672, 0.909252322733729], "final_y": [0.11921799342737849, 0.12181726263085368, 0.11381008307860951]}, "mutation_prompt": null}
{"id": "09881e72-35e2-4ce7-885e-f2caf36c1dc1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n\n                if evaluations % 8 == 0:\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n\n                self.velocity[i] *= self.layer_annealing_factor\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and mutation influence with improved adaptive diversity for better convergence.", "configspace": "", "generation": 62, "fitness": 0.9059444149599742, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9038671278091899, 0.9057111155926261, 0.9082550014781068], "final_y": [0.11098446353765834, 0.117272601784845, 0.1128746194324568]}, "mutation_prompt": null}
{"id": "ad3d7a1c-63de-40f4-ac7a-84de3d7b5415", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.3 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia weight and perturbation strategy for better convergence and solution diversity.", "configspace": "", "generation": 63, "fitness": 0.9020751292863425, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8986941068610628, 0.9015120163740905, 0.9060192646238743], "final_y": [0.1118482726033545, 0.1140485368189813, 0.11360508218432575]}, "mutation_prompt": null}
{"id": "e71df078-e40e-4a95-83d4-9e9d6d3959dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (global_best_value / np.mean(personal_best_value))  # Adaptive cognitive coefficient\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive cognitive coefficient based on global performance for enhanced convergence.", "configspace": "", "generation": 64, "fitness": 0.8697756379518582, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.008. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.875170284579165, 0.8581530127708377, 0.8760036165055718], "final_y": [0.12627338402234023, 0.12816886668303273, 0.12531827344661783]}, "mutation_prompt": null}
{"id": "050bdb7c-3a41-4a0d-aa2b-1a41e7182f04", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.95  # Adjusted logistic map parameter\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined chaotic sequence adjustment and increased population size for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.8862433561803008, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8718559671384473, 0.8651349630817902, 0.9217391383206652], "final_y": [0.12181249918550874, 0.1273416784933119, 0.11159238981880482]}, "mutation_prompt": null}
{"id": "ba179045-92d5-4c49-a75f-02b0b66414aa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                influence_factor = 0.5 * np.exp(-0.5 * evaluations / self.budget)  # New influence factor based on convergence history\n                swarm[i] += self.velocity[i] * (1 + influence_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a new influence factor for personal best update based on convergence history to enhance solution quality.", "configspace": "", "generation": 66, "fitness": 0.8816613653589022, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8811689212789232, 0.8772874135620861, 0.8865277612356971], "final_y": [0.11157848863247677, 0.12070519471629293, 0.113314540916443]}, "mutation_prompt": null}
{"id": "409c6cb8-da9c-4daf-93e0-852086a045db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor  # Slightly increased cognitive coefficient\n            social_coeff = 1.3 * np.std(swarm) / np.mean(swarm)  # Slightly decreased social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic adjustment of cognitive and social coefficients for enhanced exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.8689698712768804, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.029. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.835719439323344, 0.8639777516492749, 0.9072124228580221], "final_y": [0.13814440241251758, 0.12827988335344276, 0.1131378059725121]}, "mutation_prompt": null}
{"id": "74843b2c-3347-411d-b824-714747762c63", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * (1 / (evaluations + 1))  # Adaptive mutation scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive mutation rate scaling based on the inverse of evaluations for enhanced convergence. ", "configspace": "", "generation": 68, "fitness": 0.9005948532822505, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8952323428016444, 0.9017509038622661, 0.9048013131828408], "final_y": [0.11408712082781047, 0.11506960400319799, 0.11481678916209881]}, "mutation_prompt": null}
{"id": "65554eb3-3405-4dee-a7ce-e23db68a211e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.2 + 0.3 * np.std(swarm) / np.mean(swarm)  # Dynamic scaling of social coeff\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic social coefficient scaling with adaptive learning for enhanced multi-layered photonic structure optimization.", "configspace": "", "generation": 69, "fitness": 0.8805815891063727, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8692290847878643, 0.876941544950819, 0.895574137580435], "final_y": [0.11261617311615069, 0.12252577662474395, 0.11235609680906167]}, "mutation_prompt": null}
{"id": "8dcc9b25-8c29-4fe5-9417-e2473bd7a08e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor * (1 + 0.05 * chaotic_sequence[i]))  # Dynamic mutation scaling\n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate chaotic learning rate adjustment and dynamic mutation scaling for enhanced convergence.", "configspace": "", "generation": 70, "fitness": 0.9036661331682588, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9038797501051136, 0.9052136081403312, 0.9019050412593317], "final_y": [0.11106822128600025, 0.1172752400595991, 0.1162499298517401]}, "mutation_prompt": null}
{"id": "f76cd191-4c72-495f-9f68-f1316e67fe5e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor * (1 + 0.05 * adaptive_factor)  # Adaptive annealing\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive layer annealing based on evaluation ratio for enhanced convergence dynamics.", "configspace": "", "generation": 71, "fitness": 0.885885840267238, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.012. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8693856520872825, 0.8966663269698713, 0.8916055417445607], "final_y": [0.11671838245707422, 0.11829343395230318, 0.11770237969767161]}, "mutation_prompt": null}
{"id": "fb8576c5-5aa6-4710-9a41-185e3ff8e22e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.3 * adaptive_factor  # Modified inertia weight for better exploration\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia weight and adaptive chaotic mutation for improved exploration and convergence.", "configspace": "", "generation": 72, "fitness": 0.8905169765258917, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8962313554376444, 0.8734599999658348, 0.9018595741741962], "final_y": [0.1125031766908392, 0.11798767423873613, 0.11590940248309745]}, "mutation_prompt": null}
{"id": "4b3fc9b9-994a-454c-ad09-5215d6dc3721", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * np.std(swarm) / (np.mean(swarm) + 1e-6)  # Enhanced adaptive cognitive influence\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic chaotic perturbation and adaptive cognitive influence for improved convergence.", "configspace": "", "generation": 73, "fitness": 0.8753422189008799, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.011. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8851544868142924, 0.8607730902759116, 0.8800990796124357], "final_y": [0.11759555594119553, 0.1304535715754307, 0.11754460631462094]}, "mutation_prompt": null}
{"id": "bd0b5428-53b2-4f9f-9f05-d36ecee68755", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor * np.sin(evaluations)  # Changed line 1\n                self.velocity[i] = np.clip(  # Changed line 2\n                    inertia_weight * self.velocity[i] +\n                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                    social_coeff * r2 * (global_best - swarm[i]) +\n                    mutation_factor,\n                    -0.1, 0.1)  # Velocity clamping with dynamic range\n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporating adaptive mutation scaling with dynamic velocity clamping to enhance convergence and robustness.", "configspace": "", "generation": 74, "fitness": 0.7220383210781706, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.722 with standard deviation 0.039. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.6760956728835655, 0.7704593835149132, 0.7195599068360327], "final_y": [0.2101140331008865, 0.16941866600601063, 0.19083654977798836]}, "mutation_prompt": null}
{"id": "79280297-e13b-4f67-81c6-028365a3f13f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive mutation scaling and enhanced chaotic perturbation to refine convergence.", "configspace": "", "generation": 75, "fitness": 0.8924063062884912, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9007388261450702, 0.873965410342759, 0.9025146823776443], "final_y": [0.11356544820756265, 0.11944731410642906, 0.11613353514758051]}, "mutation_prompt": null}
{"id": "b86355f7-f05f-4081-9dec-73555ba01462", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor * (1 + 0.1 * adaptive_factor)  # Change 1\n                swarm[i] += self.velocity[i] \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic velocity scaling based on evaluation progress to enhance convergence stability.", "configspace": "", "generation": 76, "fitness": 0.8819804392859029, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.020. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8540191528343359, 0.8964501673032719, 0.8954719977201007], "final_y": [0.12549958426447727, 0.11516054826150313, 0.11424048152512645]}, "mutation_prompt": null}
{"id": "73c17a7a-d042-4156-bffc-24b45f856f14", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.5 + 0.4 * (1 - evaluations / self.budget)  # Adjusted logistic map parameter\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor)\n                \n                if evaluations % 8 == 0:\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive global exploration with variable logistic map parameters for improved convergence.", "configspace": "", "generation": 77, "fitness": 0.8987993843522334, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8869027450589676, 0.905714392726285, 0.9037810152714474], "final_y": [0.1183614774261853, 0.11393661275233513, 0.11617165079169645]}, "mutation_prompt": null}
{"id": "ad58b441-6117-4c95-a9af-ba2ce7c874be", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= (self.layer_annealing_factor + 0.02)  # Slightly adjust annealing factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation with adaptive annealing and mutation factors for improved convergence.", "configspace": "", "generation": 78, "fitness": 0.8913527267549424, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8823668891487204, 0.8830377840598448, 0.9086535070562621], "final_y": [0.12204058035064735, 0.12174677783330956, 0.11569876827334702]}, "mutation_prompt": null}
{"id": "c2649ff1-9f94-41b6-90ed-c3eacbd4f00d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor * np.random.uniform(-1, 1)) # Modified chaotic mutation factor\n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * np.random.uniform(-1, 1) # Enhanced perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive chaotic perturbation to enhance exploitation and exploration balance.", "configspace": "", "generation": 79, "fitness": 0.8839362491447589, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.017. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8646111877000457, 0.8808482146952353, 0.9063493450389957], "final_y": [0.126840823564763, 0.12277168218085655, 0.11233808167365966]}, "mutation_prompt": null}
{"id": "b37b067d-7b8b-4a73-8669-b74364cb47bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.2 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive chaotic mutation for enhanced convergence and exploration.", "configspace": "", "generation": 80, "fitness": 0.9031558522815247, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9043216433371188, 0.9052754267670601, 0.8998704867403948], "final_y": [0.11078092823694563, 0.1174617930791666, 0.1165050259970043]}, "mutation_prompt": null}
{"id": "bcd11dd7-b15d-4f00-a032-f21a2595185a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                logistic_mu = 3.5 + 0.4 * adaptive_factor  # Changed line for dynamic logistic_mu\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic logistic map parameter for enhanced chaotic behavior to improve convergence.", "configspace": "", "generation": 81, "fitness": 0.8905388346479609, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8657518331492863, 0.8995618434393129, 0.9063028273552836], "final_y": [0.12758217826245666, 0.11820538505557276, 0.11388864631818651]}, "mutation_prompt": null}
{"id": "b0c9c0dd-c6e7-4a52-9534-1ee1d7872ada", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.18 * chaotic_sequence[i] * adaptive_factor  # Slightly increased chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 7 == 0:  # Reduced interval for chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined chaotic perturbation and adaptive mutation to enhance exploration and convergence.", "configspace": "", "generation": 82, "fitness": 0.903778496751014, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9041855991096289, 0.906012633769191, 0.9011372573742218], "final_y": [0.11100542650315781, 0.11679588647905814, 0.11538975186956857]}, "mutation_prompt": null}
{"id": "24b5f781-2228-406d-9f0b-5c749523f578", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    mutation_factor *= np.sin(evaluations / self.budget * np.pi)  # Dynamic perturbation adjustment\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.layer_annealing_factor = 0.95 + 0.05 * np.sin(evaluations / self.budget * np.pi)  # Dynamic layer annealing\n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic layer annealing factor and adaptive mutation perturbation for improved convergence.", "configspace": "", "generation": 83, "fitness": 0.9043658103684106, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.004. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9062964903264711, 0.9084265837064049, 0.8983743570723558], "final_y": [0.11264024015966667, 0.11644941302823275, 0.11837973603815777]}, "mutation_prompt": null}
{"id": "d36cba73-9ca1-4940-8139-2ce50a98d3be", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.45 * adaptive_factor  # Modified inertia weight for better exploration\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.18 * chaotic_sequence[i] * adaptive_factor  # Slightly increased chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive inertia and chaotic mutation for improved convergence precision.", "configspace": "", "generation": 84, "fitness": 0.8777186555349497, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.005. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8797415193933997, 0.8714608036685768, 0.8819536435428725], "final_y": [0.12007406136557341, 0.1227663368357722, 0.11946162173947372]}, "mutation_prompt": null}
{"id": "00ed6e9e-2c77-419a-9e31-162a99af5553", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / (np.mean(swarm) + 1e-5)  # Updated to include small constant\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive social coefficient using population diversity to improve convergence stability.", "configspace": "", "generation": 85, "fitness": 0.9059675488632589, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.903792319845819, 0.9059212874760414, 0.9081890392679164], "final_y": [0.11109147252888563, 0.11677334620357016, 0.11300054790649428]}, "mutation_prompt": null}
{"id": "9d3de322-1fc3-4052-8e69-07f2227adc46", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and mutation influence for improved convergence with periodic velocity reset.  ", "configspace": "", "generation": 86, "fitness": 0.9059675507853339, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9037923169103736, 0.9059212936985952, 0.9081890417470329], "final_y": [0.111091472483407, 0.11677334518666127, 0.11300054330119269]}, "mutation_prompt": null}
{"id": "f91e4640-25f9-47e9-a9b1-72a4790a3c97", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm) * adaptive_factor  # Adaptively scale social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 9 == 0:  # Refine chaotic perturbation frequency\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive social coefficient scaling and refine chaotic perturbation for improved convergence.", "configspace": "", "generation": 87, "fitness": 0.8740983825433708, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.026. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8823711698460788, 0.8384594839262871, 0.9014644938577464], "final_y": [0.12160216301806714, 0.14161371287994196, 0.11695940202235555]}, "mutation_prompt": null}
{"id": "e84823b8-c6a5-48ed-9c5a-24c539138ee5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Adjusted chaotic mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 5 == 0:  # Adjusted chaotic perturbation frequency\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm convergence by adjusting chaotic perturbation frequency and mutation factor.", "configspace": "", "generation": 88, "fitness": 0.8972173399014216, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9037530505335452, 0.8818403248350556, 0.9060586443356643], "final_y": [0.11156979272151035, 0.11726511971143949, 0.11406913261074891]}, "mutation_prompt": null}
{"id": "0bad2574-95da-49dd-bb5e-ec7e9dc3a90e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 6 == 0:  # Add more frequent periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic sequence integration for increased convergence speed and solution accuracy.", "configspace": "", "generation": 89, "fitness": 0.8945529745569312, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8986244991696416, 0.8819025651857939, 0.9031318593153581], "final_y": [0.11344324649579873, 0.11697452996612612, 0.11579017460908392]}, "mutation_prompt": null}
{"id": "b1d0f833-ad7a-4a15-a2e2-9b273169138e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 4) == 0:  # Dynamic population size adjustment\n                self.population_size = min(50, self.population_size + 5)\n                self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n                swarm = np.resize(swarm, (self.population_size, self.dim))\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency and mutation influence with dynamic population size for improved convergence.", "configspace": "", "generation": 90, "fitness": 0.9059675507853339, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9037923169103736, 0.9059212936985952, 0.9081890417470329], "final_y": [0.111091472483407, 0.11677334518666127, 0.11300054330119269]}, "mutation_prompt": null}
{"id": "4c665c89-6683-41e6-9bf5-44926f0ed6a8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.12 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation frequency, mutation influence, and adaptive local learning rates for improved convergence.", "configspace": "", "generation": 91, "fitness": 0.905741322867179, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9037413578506724, 0.9052288569245799, 0.9082537538262848], "final_y": [0.11112804696581902, 0.11726488631814125, 0.1129751310656073]}, "mutation_prompt": null}
{"id": "11d66252-d4b0-43ef-ab94-8b9ed6d68bcb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.3 * adaptive_factor  # Adjusted cognitive coefficient\n            social_coeff = 1.7 * np.std(swarm) / np.mean(swarm)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhancing balance in cognitive and social coefficients for improved convergence dynamics.", "configspace": "", "generation": 92, "fitness": 0.888023686546561, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8797836507536103, 0.8879133917312589, 0.8963740171548138], "final_y": [0.11985563261208998, 0.11930353205911959, 0.11690354199771491]}, "mutation_prompt": null}
{"id": "ea126fbb-49ec-4616-9e28-71bc5db7dc1b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(personal_best_value) / np.mean(personal_best_value)  # Changed to use fitness diversity\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * (1 - adaptive_factor)  # Adjusted to use static mutation factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a dynamic social coefficient and adaptive mutation factor based on the fitness diversity to improve convergence.", "configspace": "", "generation": 93, "fitness": 0.8590608619664225, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.011. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8715668192859558, 0.8442662201162424, 0.8613495464970693], "final_y": [0.1267764392788836, 0.14079941937758345, 0.12243674736117105]}, "mutation_prompt": null}
{"id": "78b8bad0-66fc-48d0-baa4-2800e9b2b37b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.2 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update with adaptive chaotic perturbation for improved convergence.", "configspace": "", "generation": 94, "fitness": 0.9031558522815247, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9043216433371188, 0.9052754267670601, 0.8998704867403948], "final_y": [0.11078092823694563, 0.1174617930791666, 0.1165050259970043]}, "mutation_prompt": null}
{"id": "d393ae4f-3a83-45c2-812c-979a2339b5d8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.3 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.18 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Subtle enhancement of chaotic mutation and inertia for better exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.9019641484771764, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8979713412950187, 0.9021146669448343, 0.9058064371916763], "final_y": [0.11131996303152081, 0.11536568418823023, 0.11385849516986124]}, "mutation_prompt": null}
{"id": "1342fb07-e9c0-453a-ae49-9c07f553cb8e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Altered mutation factor for enhanced exploration\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic swarm with improved mutation dynamics for superior exploration and convergence.", "configspace": "", "generation": 96, "fitness": 0.8958168392824276, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9034610038532439, 0.8814035731045398, 0.9025859408894994], "final_y": [0.1119726704734787, 0.11746051767346011, 0.1151646133570976]}, "mutation_prompt": null}
{"id": "83f447bc-07dd-4808-a923-5fb03688875d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * np.sin(adaptive_factor * np.pi)  # Changed from adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic dynamic adaptation and mutation influence for improved convergence.", "configspace": "", "generation": 97, "fitness": 0.8981110210087003, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9039478715559096, 0.8892455466513995, 0.9011396448187919], "final_y": [0.11334008723148281, 0.12073073117359934, 0.11439610006663192]}, "mutation_prompt": null}
{"id": "007ec27b-b011-4774-a0f8-af61743b8afb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.2 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.15 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced chaotic perturbation and adaptive learning rate for improved global exploration and convergence.", "configspace": "", "generation": 98, "fitness": 0.8924063062884912, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.9007388261450702, 0.873965410342759, 0.9025146823776443], "final_y": [0.11356544820756265, 0.11944731410642906, 0.11613353514758051]}, "mutation_prompt": null}
{"id": "f824a558-581f-404a-b26b-841c2d1a2c58", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm)\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    1.6 * social_coeff * r2 * (global_best - swarm[i]) + \n                                    mutation_factor)  # Modified social coefficient\n\n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive social learning with a modified chaotic influence for enhanced solution convergence.", "configspace": "", "generation": 99, "fitness": 0.8836164578261098, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.022. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8796299316055772, 0.8590179572173606, 0.9122014846553912], "final_y": [0.11843428216831986, 0.1269894012520929, 0.1128036905775831]}, "mutation_prompt": null}
{"id": "759900cd-1ddc-4fbc-8038-9942b4f4c718", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_annealing_factor = 0.95  # Added annealing factor for velocity damping per layer\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Logistic map parameters for chaotic sequence\n        chaotic_sequence = np.random.rand(self.population_size)\n        logistic_mu = 3.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * np.std(swarm) / np.mean(swarm) * adaptive_factor  # Improved adjustment\n\n            for i in range(self.population_size):\n                # Update chaotic sequence\n                chaotic_sequence[i] = logistic_mu * chaotic_sequence[i] * (1 - chaotic_sequence[i])\n\n                r1, r2 = chaotic_sequence[i], np.random.random(self.dim)  # Use chaotic r1\n                mutation_factor = 0.17 * chaotic_sequence[i] * adaptive_factor  # Use enhanced chaotic mutation factor \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_factor) \n                \n                if evaluations % 8 == 0:  # Add periodic chaotic perturbation\n                    self.velocity[i] += 0.1 * chaotic_sequence[i] * adaptive_factor  # Increased perturbation factor\n                \n                self.velocity[i] *= self.layer_annealing_factor * adaptive_factor  # Adaptive velocity scaling\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n        \n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive velocity scaling and improved social coefficient adjustment for better convergence.", "configspace": "", "generation": 100, "fitness": 0.8768729796293111, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.025. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "72cfa682-95fd-4623-b633-4299aa5190db", "metadata": {"aucs": [0.8647511523618906, 0.8539600355292455, 0.9119077509967971], "final_y": [0.132022193458613, 0.1358499380669913, 0.1160736991002187]}, "mutation_prompt": null}
