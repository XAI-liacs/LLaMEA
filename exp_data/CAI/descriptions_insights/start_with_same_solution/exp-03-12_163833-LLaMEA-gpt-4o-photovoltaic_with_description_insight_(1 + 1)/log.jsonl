{"id": "40def39d-e28a-4646-978d-2bd19be4392e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "f4a5c654-d656-4bad-a697-e1372c6e6c4e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce dynamic learning rate\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces a dynamic learning rate to improve convergence in noisy environments.", "configspace": "", "generation": 1, "fitness": 0.8581560307548685, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.014. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "40def39d-e28a-4646-978d-2bd19be4392e", "metadata": {"aucs": [0.8402035168580464, 0.8613102502371399, 0.8729543251694187], "final_y": [0.1327826148719905, 0.12887628843031007, 0.12510238940292162]}, "mutation_prompt": null}
{"id": "6508f2b3-1d4a-405f-9faf-9e52d175bb13", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce dynamic learning rate\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.momentum[i] = 0.3 * self.momentum[i] + self.velocity[i]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.9 * self.momentum[i])\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Momentum Swarm Gradient Descent (AMSGD): Introduces momentum to velocity update, fostering better convergence by leveraging past gradients.", "configspace": "", "generation": 2, "fitness": 0.8004514160526375, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.043. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "f4a5c654-d656-4bad-a697-e1372c6e6c4e", "metadata": {"aucs": [0.7422503766940827, 0.8154763272816161, 0.8436275441822136], "final_y": [0.17998363982917642, 0.15238267618319568, 0.14189381882568097]}, "mutation_prompt": null}
{"id": "ee5cf221-d7e9-4b8b-bfb4-ca855504993e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.modular_layers = np.random.choice([0, 1], size=dim, p=[0.8, 0.2])\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= self.modular_layers\n\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modular Layered Swarm Descent (MLSD): Adds modular layer detection and robustness metrics to enhance optimization in high-dimensional environments.", "configspace": "", "generation": 3, "fitness": 0.7218444295774006, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.722 with standard deviation 0.034. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f4a5c654-d656-4bad-a697-e1372c6e6c4e", "metadata": {"aucs": [0.7074476360173828, 0.7691609423787643, 0.6889247103360545], "final_y": [0.1951399045923088, 0.1702433386818767, 0.20449581522725002]}, "mutation_prompt": null}
{"id": "57ca28c1-8ee2-4963-8fd6-d15d73773478", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n\n            # Adjust population size dynamically\n            self.population_size = int((10 + 2 * np.sqrt(self.dim)) * adaptive_factor) + 1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with adaptive population size for efficient resource utilization and enhanced convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "f4a5c654-d656-4bad-a697-e1372c6e6c4e", "metadata": {}, "mutation_prompt": null}
{"id": "743e17e0-e031-4bed-8729-a6d7f0aca28b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce dynamic learning rate\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved inertia weight adaptation for better exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8758495220833326, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.015. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f4a5c654-d656-4bad-a697-e1372c6e6c4e", "metadata": {"aucs": [0.8552888452089311, 0.8799143661071442, 0.8923453549339223], "final_y": [0.1327158707775976, 0.12575146868717801, 0.12055627922308065]}, "mutation_prompt": null}
{"id": "f631927c-14cf-45a9-9519-b9153e0b4a6b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.subpop_size = self.population_size // 2  # New attribute for subpopulation size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        def subpop_refine(subpop, velocity):  # Refine subpopulation\n            inertia_weight = 0.9\n            cognitive_coeff = 1.5\n            social_coeff = 1.5\n            for i in range(self.subpop_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               cognitive_coeff * r1 * (personal_best[i] - subpop[i]) +\n                               social_coeff * r2 * (global_best - subpop[i]))\n                subpop[i] += velocity[i]\n                subpop[i] = np.clip(subpop[i], lb, ub)\n                f_value = func(subpop[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = subpop[i]\n                    personal_best_value[i] = f_value\n                if f_value < global_best_value:\n                    global_best = subpop[i]\n                    global_best_value = f_value\n                if evaluations >= self.budget:\n                    break\n            return evaluations\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            dynamic_lr = 0.1 + 0.5 * adaptive_factor\n            subpop = swarm[:self.subpop_size].copy()\n            evaluations = subpop_refine(subpop, self.velocity[:self.subpop_size])\n\n            for i in range(self.subpop_size, self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (0.9 * adaptive_factor * self.velocity[i] +\n                                    1.5 * adaptive_factor * r1 * (personal_best[i] - swarm[i]) +\n                                    1.5 * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic subpopulation adaptation and multi-phase strategy for robust solution refinement.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'global_best' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'global_best' where it is not associated with a value\")", "parent_id": "743e17e0-e031-4bed-8729-a6d7f0aca28b", "metadata": {}, "mutation_prompt": null}
{"id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a modified dynamic learning rate for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8881170299261099, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.024. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "743e17e0-e031-4bed-8729-a6d7f0aca28b", "metadata": {"aucs": [0.8540088362700671, 0.9084056887013777, 0.9019365648068849], "final_y": [0.13263608224162915, 0.11626047111253779, 0.1179597130872777]}, "mutation_prompt": null}
{"id": "e337d893-4d7d-4f62-b563-81effcb5a78c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(0.5 * np.pi * adaptive_factor)  # Hierarchical inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # More focus on social component as search progresses\n\n            dynamic_lr = 0.05 + 0.25 * np.sin(0.5 * np.pi * adaptive_factor) + 0.2 * adaptive_factor  # Hierarchical dynamic learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced hierarchical adaptation in inertia weight and dynamic learning rate for enhanced global exploration and local refinement.", "configspace": "", "generation": 8, "fitness": 0.8726281391593417, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "metadata": {"aucs": [0.8514390481462204, 0.898465125925233, 0.8679802434065718], "final_y": [0.1267647227681491, 0.11897350336013379, 0.12309304580554092]}, "mutation_prompt": null}
{"id": "9f142d97-bace-49fb-8f89-29993225cf39", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Enhance swarm diversity by introducing random perturbations\n        perturbation_intensity = 0.1 * (ub - lb)\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 * adaptive_factor + 0.3  # Adjusted inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7\n\n            # Layer-wise adaptive learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor * (1 - 0.5 * np.random.rand())\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Introduce perturbation to enhance exploration\n                perturbation = perturbation_intensity * np.random.randn(self.dim)\n                swarm[i] += dynamic_lr * self.velocity[i] + perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leveraging diversity-enhanced swarm dynamics and layer-wise adaptive learning rates for improved high-dimensional optimization performance.", "configspace": "", "generation": 9, "fitness": 0.8262247089659557, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "metadata": {"aucs": [0.8295308005785169, 0.8132952707304969, 0.8358480555888536], "final_y": [0.13623267176488585, 0.14977608112969243, 0.14126017069681607]}, "mutation_prompt": null}
{"id": "fd4ecb50-ec7a-4614-89a3-884bcbfb4371", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.95 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor  # Modified cognitive coefficient\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with modified inertia weight and cognitive coefficients for improved exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.8681066127678517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.031. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "metadata": {"aucs": [0.8251567559250713, 0.8844687454282494, 0.8946943369502348], "final_y": [0.13784967443937957, 0.1238089047181754, 0.1150989210234934]}, "mutation_prompt": null}
{"id": "04e81285-ccbc-428b-92cd-7c04d554f77f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        # Reduced population size to improve computational resources allocation\n        self.population_size = 8 + int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dimension-dependent initialization for improved diversity\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = np.exp(-evaluations / self.budget)\n            inertia_weight = 0.7 * adaptive_factor + 0.3  # Adjusted inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 2.0\n\n            dynamic_lr = 0.1 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with dimension-dependent initialization and enhanced exploration-exploitation balance for superior convergence.", "configspace": "", "generation": 11, "fitness": 0.8585693064723782, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.014. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "metadata": {"aucs": [0.839047513783366, 0.865183466534047, 0.8714769390997216], "final_y": [0.1378114796822676, 0.12039742456040659, 0.12751969100758254]}, "mutation_prompt": null}
{"id": "dd2babe6-9484-4476-b630-b9ab241136d0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive velocity scaling based on historical convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8885808093688716, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.031. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f7ea0127-48b2-43a2-b987-04caf0f6055d", "metadata": {"aucs": [0.844687851875948, 0.9151727317041202, 0.9058818445265471], "final_y": [0.13506470969739703, 0.11211111878643665, 0.11611433780738656]}, "mutation_prompt": null}
{"id": "e83914c6-0e8c-44e7-8246-6adb3bd0c600", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * np.random.random()  # Stochastic inertia component\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Increase social influence\n\n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, int(self.population_size * 0.1))\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic neighborhood learning and stochastic inertia to improve exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8363739807486481, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.011. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dd2babe6-9484-4476-b630-b9ab241136d0", "metadata": {"aucs": [0.849910065231765, 0.8224259041526965, 0.8367859728614828], "final_y": [0.12257852364518607, 0.13642162555093917, 0.12723256369909075]}, "mutation_prompt": null}
{"id": "ec6a6990-187d-444a-b8e9-a4108d00da25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.chaos_factor = 0.5 * np.random.rand(self.population_size, dim)  # Added for chaos injection\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 * adaptive_factor + 0.2  # Adjusted inertia weight\n            cognitive_coeff = 1.4 * adaptive_factor\n            social_coeff = 1.6  # Adjusted social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                chaos_influence = self.chaos_factor[i] * (2 * np.random.rand(self.dim) - 1)  # Chaos term\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    chaos_influence)  # Added chaos influence\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm dynamics with adaptive chaos injection and multi-layered exploration-exploitation balance for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.7743374912197991, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.045. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "dd2babe6-9484-4476-b630-b9ab241136d0", "metadata": {"aucs": [0.7478687680820199, 0.7371389658991412, 0.8380047396782362], "final_y": [0.17440771434821223, 0.17596292740324293, 0.1353106590364066]}, "mutation_prompt": null}
{"id": "a73bf8a9-b35a-4464-9828-cc611443411a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor**2  # Changed to exponential decay\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance dynamic learning rate by introducing exponential decay to improve convergence speed and precision.", "configspace": "", "generation": 15, "fitness": 0.8779659084651109, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.028. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "dd2babe6-9484-4476-b630-b9ab241136d0", "metadata": {"aucs": [0.8407049380852587, 0.9085220018785698, 0.8846707854315042], "final_y": [0.13661351965884605, 0.11475351310992388, 0.12198460050924953]}, "mutation_prompt": null}
{"id": "77de2fb7-8904-4de4-8f8f-1a8e0731b1f6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.learning_rates = np.full((self.population_size, dim), 0.1)  # Layer-wise learning rates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * self.learning_rates[i] * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive local search\n                if evaluations % 10 == 0:\n                    local_search = swarm[i] + 0.01 * np.random.normal(size=self.dim)\n                    local_search = np.clip(local_search, lb, ub)\n                    local_f_value = func(local_search)\n                    evaluations += 1\n                    if local_f_value < personal_best_value[i]:\n                        swarm[i] = local_search\n                        f_value = local_f_value\n                    else:\n                        f_value = func(swarm[i])\n                        evaluations += 1\n                else:\n                    f_value = func(swarm[i])\n                    evaluations += 1\n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate layer-wise learning rates and adaptive local search to enhance convergence in high-dimensional spaces.", "configspace": "", "generation": 16, "fitness": 0.8657861274441793, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.011. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "dd2babe6-9484-4476-b630-b9ab241136d0", "metadata": {"aucs": [0.8521356325740268, 0.8782661237691383, 0.8669566259893731], "final_y": [0.13373540373790838, 0.12501337297217086, 0.1280197129635282]}, "mutation_prompt": null}
{"id": "802e2832-c9bf-4970-96e9-a396118db5fe", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 1) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a convergence-enhancing factor to dynamically adjust the inertia weight for improved balance in exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.9044625722120422, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.008. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dd2babe6-9484-4476-b630-b9ab241136d0", "metadata": {"aucs": [0.9018329082422484, 0.8967527539549253, 0.9148020544389529], "final_y": [0.11851693518826212, 0.12297279254346627, 0.11500740502747275]}, "mutation_prompt": null}
{"id": "b7588054-00df-4184-801a-a8790a6997b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 1) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            \n            # Introduce hierarchy-based interactions\n            layer_interaction = np.sin(np.linspace(0, np.pi, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * layer_interaction * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * layer_interaction * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptively tuned hierarchy-based layer interactions for enhanced convergence and robustness.", "configspace": "", "generation": 18, "fitness": 0.7601732357333087, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.038. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "802e2832-c9bf-4970-96e9-a396118db5fe", "metadata": {"aucs": [0.725170449207053, 0.8136310072224722, 0.7417182507704011], "final_y": [0.1860625684424485, 0.15215633540243667, 0.17824592877385959]}, "mutation_prompt": null}
{"id": "e40c4b35-a2b1-4f1b-aff1-f3f60dea1c9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        \n        # Phase control variables\n        phase1_end = int(0.3 * self.budget)\n        phase2_end = int(0.7 * self.budget)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 1) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Adjust dynamic learning rate and velocity scale based on phase\n            if evaluations < phase1_end:\n                dynamic_lr = 0.1 + 0.4 * adaptive_factor\n                velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            else:\n                dynamic_lr = 0.01 + 0.2 * adaptive_factor\n                velocity_scale = 0.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] + \n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) + \n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust population size after phase 2\n            if evaluations > phase2_end and self.population_size < 2 * self.initial_population_size:\n                self.population_size += 2\n                self.velocity = np.vstack((self.velocity, np.zeros((2, self.dim))))\n                swarm = np.vstack((swarm, np.random.uniform(lb, ub, (2, self.dim))))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a multi-phase search strategy that adapts exploration and exploitation by varying population sizes and mutation effects.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "802e2832-c9bf-4970-96e9-a396118db5fe", "metadata": {}, "mutation_prompt": null}
{"id": "14114a57-7d9f-41e6-857f-46bf75f92389", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance inertia weight adaptability by refining the convergence-enhancing factor to improve exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.9047505113656932, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.003. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "802e2832-c9bf-4970-96e9-a396118db5fe", "metadata": {"aucs": [0.9034620567030949, 0.9014973389159162, 0.9092921384780682], "final_y": [0.11818440137971697, 0.1207851241696265, 0.11436302978839108]}, "mutation_prompt": null}
{"id": "5beaec7e-834f-4109-92a2-734f08303ba0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3  # Introducing multiple swarms\n        self.population_size = (10 + 2 * int(np.sqrt(dim))) // self.num_swarms\n        self.velocity = np.zeros((self.num_swarms, self.population_size, dim))\n        self.hierarchical_learning_rate = 0.1  # New hierarchical learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [np.random.uniform(lb, ub, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best = [swarm.copy() for swarm in swarms]\n        personal_best_value = [np.array([func(x) for x in swarm]) for swarm in swarms]\n        global_best = min((pb[np.argmin(pv)] for pb, pv in zip(personal_best, personal_best_value)), key=func)\n        global_best_value = func(global_best)\n\n        evaluations = sum(map(len, personal_best_value))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for swarm_idx in range(self.num_swarms):\n                for i in range(self.population_size):\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[swarm_idx][i] = (inertia_weight * self.velocity[swarm_idx][i] +\n                                                   cognitive_coeff * r1 * (personal_best[swarm_idx][i] - swarms[swarm_idx][i]) +\n                                                   social_coeff * r2 * (global_best - swarms[swarm_idx][i]))\n                    swarms[swarm_idx][i] += velocity_scale * dynamic_lr * self.velocity[swarm_idx][i]\n                    swarms[swarm_idx][i] = np.clip(swarms[swarm_idx][i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarms[swarm_idx][i])\n                    evaluations += 1\n                    if f_value < personal_best_value[swarm_idx][i]:\n                        personal_best[swarm_idx][i] = swarms[swarm_idx][i]\n                        personal_best_value[swarm_idx][i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarms[swarm_idx][i]\n                        global_best_value = f_value\n\n                    if evaluations >= self.budget:\n                        break\n\n                # Hierarchical learning between swarms\n                for other_swarm_idx in range(self.num_swarms):\n                    if other_swarm_idx != swarm_idx:\n                        for i in range(self.population_size):\n                            diff = personal_best[other_swarm_idx][i] - personal_best[swarm_idx][i]\n                            swarms[swarm_idx][i] += self.hierarchical_learning_rate * diff\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a modular multi-swarm approach with hierarchical learning to improve convergence and solution diversity.", "configspace": "", "generation": 21, "fitness": 0.8835506324403276, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "14114a57-7d9f-41e6-857f-46bf75f92389", "metadata": {"aucs": [0.846539160956645, 0.8925827960722134, 0.9115299402921242], "final_y": [0.13182387173854693, 0.12212576714025025, 0.11490416522218505]}, "mutation_prompt": null}
{"id": "ef639ed8-fb8c-4fc1-9636-ff514f1e28d0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            # Updated social coefficient with time-varying factor\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a time-varying acceleration coefficient for improved balance between exploration and exploitation. ", "configspace": "", "generation": 22, "fitness": 0.8649749695720534, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.032. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "14114a57-7d9f-41e6-857f-46bf75f92389", "metadata": {"aucs": [0.8215944326882971, 0.8957545034152277, 0.8775759726126356], "final_y": [0.14199781700881153, 0.12381899900019167, 0.12829193270093098]}, "mutation_prompt": null}
{"id": "d20ad2f2-0867-452d-ad8d-fa6b1898b7db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.layer_increment = dim // 3  # Gradually increase layers\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        current_dim = self.layer_increment\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor) ** 2\n\n            if evaluations > self.budget // 2:  # Adaptive local search\n                local_search_radius = (ub - lb) * (0.1 * adaptive_factor)\n            else:\n                local_search_radius = (ub - lb) * 0.2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Apply local search in a reduced dimension\n                search_dim = min(current_dim, self.dim)\n                swarm[i, :search_dim] += velocity_scale * dynamic_lr * self.velocity[i, :search_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            current_dim = min(self.dim, current_dim + self.layer_increment)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a layer-by-layer optimization approach with adaptive local search to improve modular structure detection and refinement.", "configspace": "", "generation": 23, "fitness": 0.8991875619777919, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.004. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14114a57-7d9f-41e6-857f-46bf75f92389", "metadata": {"aucs": [0.8938264411795427, 0.9004972883047356, 0.9032389564490978], "final_y": [0.12067881341085773, 0.11868537440353077, 0.11530581915207982]}, "mutation_prompt": null}
{"id": "3a38459d-3175-41a6-96a1-0006bf972d26", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a layer-adaptive feedback mechanism and stochastic velocity adjustment for enhanced exploration.", "configspace": "", "generation": 24, "fitness": 0.9155565393625466, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "14114a57-7d9f-41e6-857f-46bf75f92389", "metadata": {"aucs": [0.892494566652285, 0.9269353016425184, 0.9272397497928363], "final_y": [0.12392383551613873, 0.11270166491784084, 0.11360231646780639]}, "mutation_prompt": null}
{"id": "ff339db2-542f-43aa-ba7f-796acf96b240", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Nonlinear dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * np.sin(np.pi * adaptive_factor / 2)\n\n            # Enhanced adaptive velocity scaling\n            velocity_scale = 1 + 0.6 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing a nonlinear dynamic scaling factor and improving adaptive velocity adjustments.", "configspace": "", "generation": 25, "fitness": 0.9077067070126156, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8874302257154622, 0.9122431963475782, 0.9234466989748064], "final_y": [0.12513148096546978, 0.11736514642421803, 0.11274065996452654]}, "mutation_prompt": null}
{"id": "f9e8a0b0-f5b3-4f59-8f3b-0eacd20197e9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  \n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  \n            cognitive_coeff = 1.6 * adaptive_factor + 0.1 * np.random.rand()  # Slight randomness added\n            social_coeff = 1.8 - 0.1 * np.random.rand()  # Slight randomness added\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Introduce a self-adaptive mutation mechanism\n                if np.random.rand() < 0.1:\n                    mutation_step = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    swarm[i] += mutation_step\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance adaptive exploration by refining cognitive-social balance and introducing a self-adaptive mutation mechanism.", "configspace": "", "generation": 26, "fitness": 0.8929478083291702, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.030. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8567291326611725, 0.8910563435280766, 0.9310579487982616], "final_y": [0.12834937834601168, 0.11975908055107665, 0.113205311990075]}, "mutation_prompt": null}
{"id": "fc6bf441-8304-4f06-b2d3-58d9892ded5b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            noise_threshold = 0.01 + 0.1 * adaptive_factor  # New line for adaptive noise handling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Implement layer-wise perturbation (mutation) - New line\n                if np.random.rand() < noise_threshold:\n                    layer_mutation = np.random.normal(scale=0.1, size=self.dim)\n                    swarm[i] += layer_mutation\n\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive noise handling and layer-wise mutation to enhance solution robustness and exploration.", "configspace": "", "generation": 27, "fitness": 0.900747609156662, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8878201205462508, 0.8874926776055053, 0.9269300293182298], "final_y": [0.12416337152644852, 0.1251327893048455, 0.1130504080348248]}, "mutation_prompt": null}
{"id": "d3b0b16b-328b-4b4d-9032-6b21909a486c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Add small random perturbations to enhance exploration\n                swarm[i] += np.random.normal(0, 0.01, self.dim) * adaptive_factor\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine swarm diversity by adding random perturbations to avoid premature convergence.", "configspace": "", "generation": 28, "fitness": 0.8923036057837844, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.898297451148129, 0.8845890410218644, 0.8940243251813595], "final_y": [0.11820896452508856, 0.12396032993426587, 0.11873614141911071]}, "mutation_prompt": null}
{"id": "c8a62696-bd49-4c36-b848-8d8cbe8c06ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 * adaptive_factor  # Introduce an adaptive social coefficient\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient to enhance information sharing among particles for improved exploration and convergence.", "configspace": "", "generation": 29, "fitness": 0.9050772235725227, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8820934109151788, 0.9099913689992, 0.9231468908031893], "final_y": [0.12567330560242007, 0.11736054879259805, 0.1154911959958278]}, "mutation_prompt": null}
{"id": "2a969ab0-a30a-4ee3-8081-9a1440e06992", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 + 0.2 * adaptive_factor  # Introduce environmental feedback\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                transition_factor = np.sin(evaluations / self.budget * np.pi)  # Add dynamic layer transition\n                swarm[i] += transition_factor * velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance adaptive swarm with environmental feedback and dynamic layer transition for improved convergence.", "configspace": "", "generation": 30, "fitness": 0.8711285871822666, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.035. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8214423170896709, 0.897499245017322, 0.894444199439807], "final_y": [0.13987744486820197, 0.1179915847671048, 0.11783764285064502]}, "mutation_prompt": null}
{"id": "17cf74bb-1bbd-4f13-a43b-97d066a72948", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                \n                # Gradient approximation for local search enhancement\n                if evaluations < self.budget:\n                    grad_approx = (func(swarm[i] + 1e-5) - f_value) / 1e-5\n                    swarm[i] -= 0.01 * grad_approx * (swarm[i] - global_best)\n                    evaluations += 1\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a local search routine based on gradient approximation to enhance convergence towards optimal solutions.", "configspace": "", "generation": 31, "fitness": 0.8924065865115542, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.024. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8591810729336281, 0.902536244239118, 0.9155024423619164], "final_y": [0.13229048398776544, 0.11664622481470599, 0.1145718217840499]}, "mutation_prompt": null}
{"id": "3a5022d2-a463-4276-900a-c90c067accdc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.swarm_clusters = 2 + int(np.log2(dim))  # New: Number of swarm clusters\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified inertia weight\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified cognitive coefficient\n            social_coeff = 2.0 - 0.5 * adaptive_factor  # Modified social coefficient\n\n            dynamic_lr = 0.1 + 0.4 * adaptive_factor  # Modified dynamic learning rate\n\n            velocity_scale = 1 + 0.3 * (1 - adaptive_factor)**1.5  # Adjusted scaling\n\n            # New stochasticity and local exploration\n            cluster_indices = np.random.choice(self.swarm_clusters, self.population_size)\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.swarm_clusters)\n\n            for i in range(self.population_size):\n                cluster_index = cluster_indices[i]\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[cluster_index]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration using adaptive multi-swarm dynamics with tailored stochasticity and dynamic feedback to refine convergence. ", "configspace": "", "generation": 32, "fitness": 0.8897155119676802, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.012. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8893214138252927, 0.8756227270387528, 0.9042023950389948], "final_y": [0.11652671507039802, 0.12247246044297766, 0.11533482799696348]}, "mutation_prompt": null}
{"id": "85fa9720-da41-427f-93d1-90912f8fd518", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.local_search_scale = 0.1  # New parameter for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Local search enhancement\n                if f_value < global_best_value:\n                    neighborhood = np.random.uniform(-self.local_search_scale, self.local_search_scale, self.dim)\n                    potential_best = np.clip(global_best + neighborhood * adaptive_factor, lb, ub)\n                    potential_best_value = func(potential_best)\n                    evaluations += 1\n                    if potential_best_value < f_value:\n                        swarm[i] = potential_best\n                        f_value = potential_best_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptively refine local search with dynamic neighborhood shrinking and historical best guidance for enhanced convergence.", "configspace": "", "generation": 33, "fitness": 0.8910477052180586, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8805905480525724, 0.8759623254173314, 0.9165902421842722], "final_y": [0.12525734118632992, 0.12778006285753574, 0.11616393060736918]}, "mutation_prompt": null}
{"id": "71522841-1863-4fbf-b49b-d0f3e1eb4ed9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            # Utilizing the elite swarm members' guidance\n            elite_swarm = personal_best[np.argsort(personal_best_value)[:self.population_size // 2]]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * np.mean(elite_swarm, axis=0))  # Elite guidance term\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize elite swarm members' guidance to refine adaptive feedback and improve solution convergence.", "configspace": "", "generation": 34, "fitness": 0.8056253104674244, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.018. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8128129725124502, 0.7809671196287673, 0.8230958392610557], "final_y": [0.15255031757855397, 0.1653852649254266, 0.14817893610404842]}, "mutation_prompt": null}
{"id": "58a088d1-b22d-4458-98f8-c84cceb5d960", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor + 0.1 * (1 - adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor)  # Adjusted social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by introducing momentum-inspired velocity adaptation and dynamic layer adjustment in the swarm.", "configspace": "", "generation": 35, "fitness": 0.9140810088775088, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8891602269260651, 0.9249660987836275, 0.9281167009228338], "final_y": [0.12471323276656221, 0.1135693909749258, 0.11367824487057188]}, "mutation_prompt": null}
{"id": "ea039e22-cf51-4800-ae9e-58f14e28b7af", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            # Integrate adaptive momentum\n            momentum = 0.9 - 0.7 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (momentum * self.velocity[i] + \n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce localized perturbation\n                perturbation = np.random.normal(0, 0.01, self.dim) * (ub - lb) * adaptive_factor\n                swarm[i] += perturbation\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine convergence dynamics by integrating adaptive momentum and localized perturbations for improved solution stability and exploration.", "configspace": "", "generation": 36, "fitness": 0.8621342845657479, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.019. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8400813755890661, 0.8856288358055606, 0.8606926423026169], "final_y": [0.14015445044896435, 0.12594345828094378, 0.13492866574650442]}, "mutation_prompt": null}
{"id": "267ae52f-a679-4022-a3c0-1cc8123a9f82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor * (1 + 0.5 * np.sin(evaluations * np.pi / self.budget))  # Modified cognitive coefficient\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by adjusting the cognitive coefficient using a dynamic scaling based on the budget.", "configspace": "", "generation": 37, "fitness": 0.9095163104096894, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8873956943177418, 0.9139551856446264, 0.9271980512667001], "final_y": [0.12550225348530875, 0.11656037868176528, 0.11338342277425073]}, "mutation_prompt": null}
{"id": "e0bbe659-f6c3-4fd2-b187-49f146e8dd94", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Adapt layer scalability and introduce noise-resilient mutation\n                mutation = np.random.normal(0, 0.1, self.dim) * adaptive_factor\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + mutation\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive layer scalability and noise-resilient mutation for improved exploration.", "configspace": "", "generation": 38, "fitness": 0.8962037757636208, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.9178267368465719, 0.8850458723309583, 0.8857387181133319], "final_y": [0.11014662901363714, 0.12372390172716485, 0.12139618791115947]}, "mutation_prompt": null}
{"id": "fb281caa-4e9a-4a33-8984-cfed9273d3a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * 1.02  # Slight modification to inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine the inertia weight to improve convergence dynamics in layer-adaptive swarm optimization.", "configspace": "", "generation": 39, "fitness": 0.9105121546700671, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.013. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8914611511659847, 0.9210592605508731, 0.9190160522933436], "final_y": [0.12390998048561974, 0.11572300505162691, 0.11531478579616827]}, "mutation_prompt": null}
{"id": "1337c75e-4335-443f-88dd-9535c523fa20", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 + 0.2 * adaptive_factor  # Introduce a dynamic interaction coefficient\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            # Layer-sensitive scaling for enhanced adaptation\n            layer_scale = 1 + 0.3 * (self.dim / self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] * layer_scale\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global exploration by integrating a dynamic interaction coefficient and refine adaptive learning with a layer-sensitive scaling.", "configspace": "", "generation": 40, "fitness": 0.8995401517041604, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8844127792734956, 0.8980974886262838, 0.9161101872127015], "final_y": [0.12332447132514279, 0.12013399292710103, 0.11392002848733429]}, "mutation_prompt": null}
{"id": "9ea38a1f-18dc-4e07-a746-b448788f8935", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n\n            noise_reduction_factor = 0.9 + 0.1 * adaptive_factor  # New noise reduction mechanism\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] * noise_reduction_factor  # Adjusted velocity scaling\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive noise handling by introducing a noise reduction mechanism and adjusted velocity scaling for smoother convergence.", "configspace": "", "generation": 41, "fitness": 0.9144506267112048, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.892264467433703, 0.9229165310442293, 0.928170881655682], "final_y": [0.12406605837964335, 0.11462388391022016, 0.11361954081425385]}, "mutation_prompt": null}
{"id": "47ecc358-de6b-4192-8492-af9c723924c3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 * (1 - adaptive_factor)  # Dynamic social learning control\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Apply small perturbation to enhance exploration\n                swarm[i] += np.random.normal(0, 0.01, self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing a perturbation mechanism and dynamic social learning control.", "configspace": "", "generation": 42, "fitness": 0.8168480299148829, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.012. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8233972294333101, 0.8276432526819075, 0.7995036076294311], "final_y": [0.1334413217864192, 0.14177007069448255, 0.1388955563058375]}, "mutation_prompt": null}
{"id": "c10475c9-e2e0-4e89-bd8d-75a8e3dcec94", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Individual-based adaptive velocity scaling\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor**2)  # Changed line for individual-based adaptation\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce individual-based adaptive velocity scaling to refine convergence in Adaptive Swarm Gradient Descent.", "configspace": "", "generation": 43, "fitness": 0.9112410012899707, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.889444344280689, 0.9187351147874668, 0.9255435448017559], "final_y": [0.12459655019856009, 0.11440635464466287, 0.11271012025277416]}, "mutation_prompt": null}
{"id": "f7ee3551-c621-4349-9c7b-bd2346945b91", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)  # New convergence-enhancing factor\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor  # Modified inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Introduce modified dynamic learning rate\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n\n            # Adaptive velocity scaling based on historical convergence rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            # Stochastic velocity adjustment\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            # Layer-based perturbation\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and convergence by introducing layer-based perturbations and adaptive inertia adjustment.", "configspace": "", "generation": 44, "fitness": 0.9157759300206889, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3a38459d-3175-41a6-96a1-0006bf972d26", "metadata": {"aucs": [0.8926286329278388, 0.9261886983263606, 0.9285104588078676], "final_y": [0.1238348942590457, 0.112826094686868, 0.11349609806329197]}, "mutation_prompt": null}
{"id": "54b91567-8905-4378-8890-23da7296299f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            # Adjusted dynamic learning rate\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n\n            # Adaptive velocity scaling\n            velocity_scale = 1 + 0.6 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            # Layer-based perturbation with adaptive involvement\n            perturbation_factor = 0.12 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Modified swarm update with selective local search\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and convergence by incorporating adaptive perturbation and selective local search based on convergence trends.", "configspace": "", "generation": 45, "fitness": 0.9003631675932428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f7ee3551-c621-4349-9c7b-bd2346945b91", "metadata": {"aucs": [0.8854372276535984, 0.8930976055429775, 0.9225546695831522], "final_y": [0.12548429690875784, 0.12366918405365268, 0.11426812741646908]}, "mutation_prompt": null}
{"id": "f6993bf4-07db-402d-8567-ab1df7fa2828", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.1 + 0.4 * adaptive_factor  # Adjusted dynamic learning rate\n\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.2 * np.sin(np.pi * evaluations / self.budget)  # Adjusted perturbation factor\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm adaptation by modifying perturbations and dynamic learning rates based on evaluations for improved convergence.", "configspace": "", "generation": 46, "fitness": 0.9154970510583821, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.017. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f7ee3551-c621-4349-9c7b-bd2346945b91", "metadata": {"aucs": [0.8910748389841099, 0.9269385885641397, 0.9284777256268966], "final_y": [0.12432072407727868, 0.11272121888151665, 0.11347516447500505]}, "mutation_prompt": null}
{"id": "3621090d-55ea-4d36-a763-7095e13aea92", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  # Introduce momentum factor\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce momentum-based velocity adjustment and dynamic inertia adjustment to enhance convergence.", "configspace": "", "generation": 47, "fitness": 0.9159872060884298, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f7ee3551-c621-4349-9c7b-bd2346945b91", "metadata": {"aucs": [0.8928007107670043, 0.9267524316838693, 0.9284084758144155], "final_y": [0.12376615182673034, 0.1125669447098081, 0.11353865698782539]}, "mutation_prompt": null}
{"id": "04c355fc-0b75-404b-8f43-a564d8b20f38", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.5 * adaptive_factor  # Modified cognitive coefficient\n            social_coeff = 2.0  # Modified social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget) + \\\n                                  0.05 * (np.random.rand(self.dim) - 0.5)  # Added diversity-focused perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by modifying the velocity update rule and adding a diversity-focused perturbation mechanism.", "configspace": "", "generation": 48, "fitness": 0.8991849721902169, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.8722726052174827, 0.9075285005628239, 0.9177538107903439], "final_y": [0.11959337218484312, 0.11998862195441151, 0.11555593145524468]}, "mutation_prompt": null}
{"id": "35628348-54f9-4d61-91c8-6165e220e5d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  # Introduce momentum factor\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)**2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance velocity update by incorporating a nonlinear perturbation for improved exploration.", "configspace": "", "generation": 49, "fitness": 0.9150513066673601, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.8923215838383315, 0.9262738798258473, 0.9265584563379016], "final_y": [0.12399441595732485, 0.11287433651895273, 0.11376657728344686]}, "mutation_prompt": null}
{"id": "87163eaf-09df-410d-9e49-274eb250d9b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 + 0.2 * adaptive_factor  # Change 1: Dynamic increment\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget) + 0.05 * adaptive_factor  # Change 2: Additional perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic acceleration coefficients and perturbations to enhance exploration and convergence efficiency.", "configspace": "", "generation": 50, "fitness": 0.9107058592013448, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.022. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.8813257914243345, 0.9157537637593962, 0.9350380224203038], "final_y": [0.1267432244383827, 0.11678093608868356, 0.1114494371533874]}, "mutation_prompt": null}
{"id": "0edb7799-2f05-458d-b2ef-1cd13ef3fb43", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.1, self.population_size)  # Reduced randomness range\n\n            perturbation_factor = 0.05 * np.sin(2 * np.pi * evaluations / self.budget)  # Reduced perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive convergence pressure and noise reduction for enhanced solution refinement.", "configspace": "", "generation": 51, "fitness": 0.8986910874922444, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.8728935765574926, 0.9129868448151534, 0.9101928411040869], "final_y": [0.12785818082107892, 0.1176082398127839, 0.11746183600713023]}, "mutation_prompt": null}
{"id": "f7c29b8c-79a4-4bf2-8119-c630b4f0b3fe", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor * np.var(personal_best_value) # Change 1\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n            elite_index = np.argmin(personal_best_value) # Change 2\n            if evaluations >= self.budget:\n                break\n\n        return personal_best[elite_index], personal_best_value[elite_index] # Change 3", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the existing algorithm by introducing dynamic learning rate scaling based on the function's variance and incorporating an elitism strategy for robust convergence.", "configspace": "", "generation": 52, "fitness": 0.7906637930635784, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.025. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.7893082622706244, 0.8224860090978314, 0.7601971078222791], "final_y": [0.15443315470065588, 0.1442804659215896, 0.16788682528662702]}, "mutation_prompt": null}
{"id": "527a1dd0-f4fd-4628-a814-1f5eda1b9250", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 * convergence_factor  # Modified line: Introduce adaptive scaling\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  # Introduce momentum factor\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive social coefficient scaling based on convergence to enhance exploration and exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.8954733664768817, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.004. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.9014604790705631, 0.8909768221785528, 0.893982798181529], "final_y": [0.11597251008202736, 0.12379254278796081, 0.12037340303025945]}, "mutation_prompt": null}
{"id": "435423e7-8f71-491a-a045-6e1525190298", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(4 * np.pi * evaluations / self.budget)  # Modified perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive perturbation with a sinusoidal component and integrate exploration-exploitation balance for improved convergence.", "configspace": "", "generation": 54, "fitness": 0.9100978990839009, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.8919431346802946, 0.9116586279370473, 0.9266919346343607], "final_y": [0.12408547656976954, 0.11685678575942537, 0.11378559455450499]}, "mutation_prompt": null}
{"id": "70d6a425-0d25-4a86-8d68-16f376004761", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                \n                diversity_factor = 0.2 * np.random.uniform(-1, 1, self.dim) * adaptive_factor  \n                swarm[i] += diversity_factor  \n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and exploit gradual layering for improved convergence.", "configspace": "", "generation": 55, "fitness": 0.893071059439995, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.015. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.886431578628097, 0.9133267499739866, 0.8794548497179014], "final_y": [0.12390024686620016, 0.11652144856134716, 0.12419192209657592]}, "mutation_prompt": null}
{"id": "8179e364-bc02-430f-a170-da6730734759", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)  # Sinusoidal adaptive inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  # Introduce momentum factor\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a sinusoidal adaptive inertia weight for enhanced global exploration and convergence.", "configspace": "", "generation": 56, "fitness": 0.9227859289234703, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3621090d-55ea-4d36-a763-7095e13aea92", "metadata": {"aucs": [0.9244356606640571, 0.9209708512991345, 0.9229512748072195], "final_y": [0.11416613528377473, 0.11538001105835205, 0.11350819377766452]}, "mutation_prompt": null}
{"id": "4cd1a677-86d9-45eb-b674-0bf696542dc3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Dynamic social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a sinusoidal adaptive inertia weight with dynamic social coefficient adjustment for improved convergence.", "configspace": "", "generation": 57, "fitness": 0.9188360778489596, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.024. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.9286569699149035, 0.8854944523350144, 0.9423568112969607], "final_y": [0.11305834647736446, 0.12588116475077804, 0.11072618609801432]}, "mutation_prompt": null}
{"id": "5a3f738d-7cee-4ff6-b8ef-2f8ea7edb9d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8 + 0.2 * adaptive_factor  # Adaptive social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n            personal_best_perturb = 0.05 * np.random.randn(self.population_size, self.dim)  # Personal best perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] + personal_best_perturb[i] - swarm[i]) +  # Apply perturbation\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic personal best perturbation and adaptive social coefficient for improved exploration and convergence.", "configspace": "", "generation": 58, "fitness": 0.9020735475704861, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.889684146192742, 0.8820124300819799, 0.934524066436736], "final_y": [0.12166588445991033, 0.12599482274623586, 0.11221525407996125]}, "mutation_prompt": null}
{"id": "9912ac93-51b4-4446-967a-0ef1c67d4c79", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)  # Sinusoidal adaptive inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  # Introduce momentum factor\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                crossover_rate = 0.5 * (1 + np.cos(2 * np.pi * evaluations / self.budget))  # Dynamic crossover mutation\n                mutation_factor = np.random.normal(0, 0.1, self.dim) * crossover_rate  # Apply mutation\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor + mutation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance local search refinement and adaptive exploration using a dynamic crossover mutation strategy.", "configspace": "", "generation": 59, "fitness": 0.9041508763109406, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.8926974218201371, 0.9041304172362042, 0.9156247898764805], "final_y": [0.12208729588151024, 0.11947059332216026, 0.11493090599659961]}, "mutation_prompt": null}
{"id": "4a77ea11-6333-43fa-b18c-f117a5477ecc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n            \n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce random momentum scaling for better diversity and convergence in swarm movement.", "configspace": "", "generation": 60, "fitness": 0.9227859289234703, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.9244356606640571, 0.9209708512991345, 0.9229512748072195], "final_y": [0.11416613528377473, 0.11538001105835205, 0.11350819377766452]}, "mutation_prompt": null}
{"id": "a5fbbb99-2778-46d3-afe9-b330af51ccd0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)  \n            cognitive_coeff = 1.6 * adaptive_factor + 0.4 * np.random.random()  # Dynamic cognitive coefficient\n            social_coeff = 1.8 * (0.5 + np.random.random())  # Dynamic social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85  \n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by incorporating dynamic cognitive and social coefficients with stochastic momentum.", "configspace": "", "generation": 61, "fitness": 0.8960786186538678, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.8798299909726821, 0.8858618966055989, 0.9225439683833225], "final_y": [0.12302877288065273, 0.12537796065934648, 0.11389480678920083]}, "mutation_prompt": null}
{"id": "9eb2ef7b-efc0-4e37-accd-8204b01a7b51", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Dynamic cognitive coefficient\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim))  # Layer-wise perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic cognitive coefficient and layer-wise perturbation to enhance convergence and exploration.", "configspace": "", "generation": 62, "fitness": 0.9228072661823354, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8179e364-bc02-430f-a170-da6730734759", "metadata": {"aucs": [0.9250141832755656, 0.9250801524660099, 0.9183274628054305], "final_y": [0.1138385243554112, 0.11401578247181243, 0.1149663810525674]}, "mutation_prompt": null}
{"id": "f3356261-3a4e-435f-ba98-07dd9caddbef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.4 * (adaptive_factor ** 0.7)  # Modified dynamic cognitive coefficient\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                crossover_mask = np.random.rand(self.dim) < 0.1  # Multi-layer crossover mask\n                swarm[i] = np.where(crossover_mask, global_best, swarm[i])  # Apply crossover\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine dynamic components and introduce multi-layer crossover to enhance exploration and convergence.", "configspace": "", "generation": 63, "fitness": 0.9020817195720575, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9eb2ef7b-efc0-4e37-accd-8204b01a7b51", "metadata": {"aucs": [0.8981142594734761, 0.8859666382292757, 0.922164261013421], "final_y": [0.1202090256864975, 0.12593987529302741, 0.1145774194713437]}, "mutation_prompt": null}
{"id": "fdf59790-8f94-4970-ae3c-2054154193d5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.05 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim))  # Adjusted perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                adaptive_noise = np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Added noise\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor + adaptive_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by introducing adaptive noise and dynamic boundary adjustments.", "configspace": "", "generation": 64, "fitness": 0.9037773025062722, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9eb2ef7b-efc0-4e37-accd-8204b01a7b51", "metadata": {"aucs": [0.8929687468618058, 0.9018896798058478, 0.9164734808511626], "final_y": [0.1222167336242439, 0.12002904551131788, 0.11448453769435019]}, "mutation_prompt": null}
{"id": "d5bb6953-bd5b-4030-b9f2-06d1cc6599bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Dynamic cognitive coefficient\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a decaying perturbation effect to enhance exploration precision over time.", "configspace": "", "generation": 65, "fitness": 0.9229004183754294, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9eb2ef7b-efc0-4e37-accd-8204b01a7b51", "metadata": {"aucs": [0.9248400142293092, 0.925368528229705, 0.9184927126672744], "final_y": [0.1139408422046454, 0.1138611327253487, 0.11492077192663985]}, "mutation_prompt": null}
{"id": "2668d948-ad65-4216-ae9c-8c390c96cef3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Dynamic cognitive coefficient\n\n            # Adjust social influence based on diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            social_coeff = 1.8 * (1 + 0.2 * diversity)  \n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances swarm cohesion by dynamically adjusting social influence based on population diversity.", "configspace": "", "generation": 66, "fitness": 0.7900826387660637, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.014. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d5bb6953-bd5b-4030-b9f2-06d1cc6599bf", "metadata": {"aucs": [0.802543558005024, 0.7978457606214482, 0.7698585976717188], "final_y": [0.1522728003899091, 0.1455322975533191, 0.16710474533497377]}, "mutation_prompt": null}
{"id": "12fb1dfc-8df8-4e27-9305-ccaa825d52ec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5) \n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor)  # Increased social influence\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor * velocity_scale  # Scaled perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive perturbation scaling and momentum for improved convergence precision.", "configspace": "", "generation": 67, "fitness": 0.9226755612159924, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d5bb6953-bd5b-4030-b9f2-06d1cc6599bf", "metadata": {"aucs": [0.925876880931416, 0.9254531469297467, 0.9166966557868146], "final_y": [0.11365232055614316, 0.11415143588083332, 0.116132342487412]}, "mutation_prompt": null}
{"id": "c8050165-0bd0-4ca6-a1b7-279d13562a5f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Dynamic cognitive coefficient\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbor_indices = np.random.choice(self.population_size, size=3, replace=False)\n                neighborhood_best = min(neighbor_indices, key=lambda idx: personal_best_value[idx])\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.3 * (personal_best[neighborhood_best] - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implements a dynamic neighborhood search to improve local refinements and convergence speed.", "configspace": "", "generation": 68, "fitness": 0.8952873849101683, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d5bb6953-bd5b-4030-b9f2-06d1cc6599bf", "metadata": {"aucs": [0.8782322000643656, 0.89596230043436, 0.9116676542317792], "final_y": [0.1270926401211624, 0.12153011964467819, 0.11764702988770559]}, "mutation_prompt": null}
{"id": "25ff8a66-cfe9-4830-8d08-153bbb284a24", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Dynamic cognitive coefficient\n            social_coeff = 1.8\n\n            # Changed line\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a decaying perturbation effect, with a refined dynamic learning rate to enhance exploration precision over time.", "configspace": "", "generation": 69, "fitness": 0.9234710580917493, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d5bb6953-bd5b-4030-b9f2-06d1cc6599bf", "metadata": {"aucs": [0.9202732631802124, 0.9180591659183116, 0.9320807451767238], "final_y": [0.11597619740081733, 0.11554150441490685, 0.1132475747625481]}, "mutation_prompt": null}
{"id": "baa4323b-175a-4ca6-8696-357c77e5528e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.3)  # Adjusted cognitive coefficient\n            social_coeff = 1.8\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.15 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Adjusted perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and exploitation balance by dynamically adapting the perturbation and cognitive coefficients based on convergence rates.", "configspace": "", "generation": 70, "fitness": 0.9210664298203103, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "25ff8a66-cfe9-4830-8d08-153bbb284a24", "metadata": {"aucs": [0.9205998044568826, 0.9106373513585132, 0.9319621336455353], "final_y": [0.1158652489942078, 0.11815239765371988, 0.11328602942753685]}, "mutation_prompt": null}
{"id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a layering adaptive heuristic to enhance stability and convergence with an improved cognitive-social interaction balance.", "configspace": "", "generation": 71, "fitness": 0.9252653883889459, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "25ff8a66-cfe9-4830-8d08-153bbb284a24", "metadata": {"aucs": [0.9289238921672373, 0.9039168626081542, 0.9429554103914463], "final_y": [0.11226438414664897, 0.12145731416498484, 0.11057510205033516]}, "mutation_prompt": null}
{"id": "b4412afa-514a-44c5-8f0e-1969bc2c5d9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + adaptive_factor**2 * 0.85  # Modified adaptive velocity scaling\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.cos(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Improved perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive velocity scaling and improved perturbation to refine search efficiency and convergence.", "configspace": "", "generation": 72, "fitness": 0.9005496208427596, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.8993411112005776, 0.881150907193962, 0.9211568441337392], "final_y": [0.11991467251722698, 0.12716337810177636, 0.11603858706824277]}, "mutation_prompt": null}
{"id": "d57264bb-c181-45ac-9735-a15fc0ef0a3a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.1 - 0.1 * adaptive_factor  # Modified social coefficient\n\n            dynamic_lr = 0.07 + 0.5 * adaptive_factor  # Adjusted dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive local search and perturbation control for enhanced convergence and solution refinement.", "configspace": "", "generation": 73, "fitness": 0.9128467292525869, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.020. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.8944673231599768, 0.9039299059777075, 0.9401429586200767], "final_y": [0.12342923077848877, 0.12002417751992334, 0.11016553410979202]}, "mutation_prompt": null}
{"id": "e8b1dcc1-e3a6-4cc3-9cdc-e9c2a482768b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)  # Time-varying social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]  # Added neighborhood search around global_best\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence dynamics by introducing time-varying coefficients and strategic neighborhood search.", "configspace": "", "generation": 74, "fitness": 0.919135954688338, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.9125008742663865, 0.9061202267173947, 0.9387867630812328], "final_y": [0.11709698130311619, 0.11988329048299895, 0.11098867472463236]}, "mutation_prompt": null}
{"id": "518c3bb9-b81b-4463-94a4-677c76752374", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)  # Chaotic velocity scale\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * adaptive_factor * np.sin(2 * np.pi * (evaluations / self.budget) ** 2)  # Adaptive perturbation scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces chaotic inertia and adaptive perturbation scaling to enhance exploration and stability.", "configspace": "", "generation": 75, "fitness": 0.8968352170312485, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.029. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.891862948563176, 0.863624657301183, 0.9350180452293865], "final_y": [0.12397741107725269, 0.13364065894155408, 0.11256931460240338]}, "mutation_prompt": null}
{"id": "d6c9a595-ac66-4435-9ad4-a99869b2eb33", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            local_perturbation = 0.05 * (np.random.random(self.dim) - 0.5) * adaptive_factor  # Dynamic local search\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += (velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + \n                             perturbation_factor + local_perturbation)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic local search perturbation to explore around the current best solutions, enhancing global convergence and solution robustness.", "configspace": "", "generation": 76, "fitness": 0.914099450108985, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.9134949670817872, 0.8984655485235706, 0.9303378347215968], "final_y": [0.1144902269793987, 0.12341671182644198, 0.11341756011453508]}, "mutation_prompt": null}
{"id": "0ce1d9ec-1014-42bf-94f7-824e739917fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0 * adaptive_factor  # Updated social coefficient with decay\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a decay factor into the social coefficient to better balance exploration and exploitation.", "configspace": "", "generation": 77, "fitness": 0.9082894063890873, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.022. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.8989307721978018, 0.8875346144272387, 0.9384028325422212], "final_y": [0.12209783930943763, 0.1248128495136791, 0.11140585106812684]}, "mutation_prompt": null}
{"id": "1ae3d499-dc44-43f9-9833-178256bad994", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * (np.sin(2 * np.pi * evaluations / self.budget) + 0.1)\n            cognitive_coeff = 1.2 * (adaptive_factor ** 0.5)  # Refined cognitive coefficient\n            social_coeff = 2.5  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refines cognitive-social dynamics and perturbs inertia weight to enhance convergence and solution quality.", "configspace": "", "generation": 78, "fitness": 0.9153034161138852, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.9097550005518367, 0.9087079196804067, 0.9274473281094121], "final_y": [0.11823598329752316, 0.1201045760042253, 0.11516557702495989]}, "mutation_prompt": null}
{"id": "8c5d6aea-eb5f-4560-9c83-fc9e2fb9477c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            population_size = int(self.initial_population_size * (1 - evaluations / self.budget)) + 5  # Dynamic population size\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.initial_population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(population_size):  # Iterate only over the dynamic population size\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces dynamic population size adjustment and improved velocity update to enhance exploration and exploitation balance.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {}, "mutation_prompt": null}
{"id": "46ebc056-42ac-4da5-8267-71ae18956aff", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)  # Dynamic social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Decaying perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic social coefficient modulation to better balance exploration-exploitation trade-offs.", "configspace": "", "generation": 80, "fitness": 0.9054412534562171, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.870233839264375, 0.9203136005032863, 0.9257763206009898], "final_y": [0.13012454029220633, 0.11636307264362278, 0.11257041112343735]}, "mutation_prompt": null}
{"id": "96bf738a-d30f-4ec5-aaa5-784e46013ce9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.cos(np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  \n            social_coeff = 1.8 + 0.2 * np.sin(np.pi * evaluations / self.budget)  # Dynamic social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  \n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)\n\n            perturbation_factor = 0.1 * np.sin(2 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates dynamic adaptive inertia and social coefficients to enhance exploration-exploitation balance.", "configspace": "", "generation": 81, "fitness": 0.9017451087469407, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.021. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.8760913109334687, 0.9014378205995178, 0.9277061947078352], "final_y": [0.1280409100655583, 0.12084143312778117, 0.11340172354733635]}, "mutation_prompt": null}
{"id": "0836d990-1b41-484c-9b41-70dd8795b69e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.15 * np.sin(2.5 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Modified perturbation formula\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and convergence balance by modifying stochastic factor dynamics and refining perturbation strategies.", "configspace": "", "generation": 82, "fitness": 0.9264743934235121, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e6a6ea02-9244-425d-abeb-4efdd685d1c6", "metadata": {"aucs": [0.9272215763016832, 0.914191611633811, 0.9380099923350419], "final_y": [0.11327522757125941, 0.11664431765207361, 0.11125324835447081]}, "mutation_prompt": null}
{"id": "e5150039-b2b0-48dc-ab38-3f7b3786d97b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)\n            perturbation_factor = 0.15 * np.sin(2.5 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n\n            if evaluations > self.budget * 0.5:  # Dynamic swarm size adjustment\n                self.population_size = 5 + int(np.sqrt(dim))\n\n            noise_handling_factor = np.random.normal(0, 0.1, self.dim) * adaptive_factor  # Advanced noise handling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor + noise_handling_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic swarm size and advanced noise handling to improve convergence in noisy environments.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "0836d990-1b41-484c-9b41-70dd8795b69e", "metadata": {}, "mutation_prompt": null}
{"id": "9584d4b0-2b4a-4efa-a020-c6e9aa1f6b7f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**3 * 0.85  # Adjusted exponent for velocity scale\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.15 * np.sin(2.5 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Modified perturbation formula\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic adjustment to the velocity scale for better adaptive control.", "configspace": "", "generation": 84, "fitness": 0.9235378492866565, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0836d990-1b41-484c-9b41-70dd8795b69e", "metadata": {"aucs": [0.9273729760456424, 0.9058469645437955, 0.9373936072705312], "final_y": [0.11322924817355451, 0.11968499672751043, 0.11155471184844223]}, "mutation_prompt": null}
{"id": "66710183-f1fc-44ed-a6a6-f788c503a95f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.5:  # Introduce dynamic layer count strategy\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic layer count strategy and improved perturbation for better convergence.", "configspace": "", "generation": 85, "fitness": 0.9264836161803238, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0836d990-1b41-484c-9b41-70dd8795b69e", "metadata": {"aucs": [0.9273715844086641, 0.9128257161499443, 0.939253547982363], "final_y": [0.11329927900327796, 0.11715084451857394, 0.1108757848931945]}, "mutation_prompt": null}
{"id": "75ad1c99-2aad-40ed-90ba-b5e48aa329ec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor  # Refined inertia weight\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)\n\n            perturbation_factor = 0.03 * np.sin(4.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Adjusted perturbation factor\n\n            if evaluations > self.budget * 0.5:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine the inertia weight and perturbation factor to enhance convergence speed and stability.", "configspace": "", "generation": 86, "fitness": 0.9043085949640122, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.013. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "66710183-f1fc-44ed-a6a6-f788c503a95f", "metadata": {"aucs": [0.8921952154644085, 0.898917702182946, 0.9218128672446819], "final_y": [0.12229809233328459, 0.11899461823180679, 0.11313095052516409]}, "mutation_prompt": null}
{"id": "e1d342ef-dc25-4292-b0f2-5c2988d120fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**2 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor * (1.5 - adaptive_factor)\n\n            if evaluations > self.budget * 0.5:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive perturbation scaling and improved local refinement for enhanced convergence.", "configspace": "", "generation": 87, "fitness": 0.9264598304359751, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "66710183-f1fc-44ed-a6a6-f788c503a95f", "metadata": {"aucs": [0.9267806859416018, 0.9128068890902562, 0.9397919162760673], "final_y": [0.11354109471020635, 0.11715471783719011, 0.11070503950567234]}, "mutation_prompt": null}
{"id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tune the dynamic layer count trigger and refine velocity scaling for enhanced convergence precision.", "configspace": "", "generation": 88, "fitness": 0.9285364122511498, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "66710183-f1fc-44ed-a6a6-f788c503a95f", "metadata": {"aucs": [0.9296479801696927, 0.9131798316818449, 0.9427814249019116], "final_y": [0.11271427438603898, 0.11696108831052054, 0.11116174807130996]}, "mutation_prompt": null}
{"id": "9f591e7a-33e3-4343-8514-f67070494b93", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.1  # Updated social coefficient to increase convergence pressure\n\n            dynamic_lr = 0.055 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1.1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Further adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.8, 1.3, self.population_size)  # Expanded stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by optimizing velocity scaling and introducing exploration adjustments.", "configspace": "", "generation": 89, "fitness": 0.9156495346203846, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.023. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.8893132188612143, 0.9128611196997323, 0.9447742653002072], "final_y": [0.12526660046118443, 0.11737009372052276, 0.11046761107301939]}, "mutation_prompt": null}
{"id": "135e691d-f89b-4b05-9a30-851f5952a16c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.45 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.45 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.35:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploitation-exploration balance by refining learning rate and inertia dynamics.", "configspace": "", "generation": 90, "fitness": 0.9240792322055263, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.018. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9300897788751958, 0.8992144087954975, 0.942933508945886], "final_y": [0.11268871202491859, 0.12135769120115969, 0.11027301977687332]}, "mutation_prompt": null}
{"id": "57c193a7-7575-4658-8d3a-192a2474f70b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85\n            stochastic_factor = np.random.uniform(0.95, 1.25, self.population_size)  # Refined stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n            \n            if evaluations > self.budget * 0.4:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i] * (1 - adaptive_factor * 0.1):  # Dynamic convergence threshold\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic convergence threshold and refine the stochastic factor range for improved exploitation near the global best.", "configspace": "", "generation": 91, "fitness": 0.9110256469600819, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9004767829416742, 0.8919515743773028, 0.9406485835612689], "final_y": [0.12274528310208332, 0.12525563640728998, 0.11180783718548293]}, "mutation_prompt": null}
{"id": "67f74109-d154-4470-8cc0-7e40a207057e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim) + 0.5) * adaptive_factor  # Improved perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and convergence speed by introducing a dynamic inertia weight adjustment and improved perturbation effect.", "configspace": "", "generation": 92, "fitness": 0.9246192654218293, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9297285087921671, 0.9040453491099479, 0.940083938363373], "final_y": [0.1123305757256341, 0.12010395218350245, 0.11097690438858854]}, "mutation_prompt": null}
{"id": "715117b6-78df-4799-99d4-9e8bd3f11c89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.8 * 0.9  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.8, 1.4, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.1 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.35:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and control velocity scaling dynamically to improve exploration and convergence accuracy.", "configspace": "", "generation": 93, "fitness": 0.9273722092222144, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9164170913999214, 0.9206851836976998, 0.9450143525690219], "final_y": [0.11626277313812883, 0.11675913430070572, 0.11044440868105487]}, "mutation_prompt": null}
{"id": "c9503240-e60f-4a95-92b2-560987d5e042", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.4 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.8, 1.2, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the AdaptiveSwarmGradientDescent by modifying velocity scaling and stochastic factor to improve convergence.", "configspace": "", "generation": 94, "fitness": 0.9256571684870473, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.017. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9293337081311588, 0.9038449324460682, 0.9437928648839151], "final_y": [0.11213445059704286, 0.1214925980862982, 0.11028633998514614]}, "mutation_prompt": null}
{"id": "cb4a8719-0388-43ee-9b7d-4b9f1f2925b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Refined cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive inertia weight and updated cognitive coefficient for enhanced exploration and convergence in AdaptiveSwarmGradientDescent.", "configspace": "", "generation": 95, "fitness": 0.9073130717939559, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9167419627778984, 0.8967557945766009, 0.9084414580273685], "final_y": [0.11300102786575938, 0.12066211349305556, 0.11772457690224081]}, "mutation_prompt": null}
{"id": "d53133a9-ef0d-4a92-965e-b0a0a70727ca", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.cos(2 * np.pi * evaluations / self.budget)  # Modified cosine adjustment\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor * np.cos(evaluations / self.budget)  # Modified perturbation scaling\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic inertia weight adjustment and selective perturbation scaling to enhance adaptive convergence.", "configspace": "", "generation": 96, "fitness": 0.9003898954414106, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.009. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.8885150140846787, 0.901567285151739, 0.911087387087814], "final_y": [0.12413061926235658, 0.1207604956096131, 0.11843999755543866]}, "mutation_prompt": null}
{"id": "54d70108-4c04-493e-b0e6-4eea0cf00ac6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.75 * adaptive_factor + 0.25) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget) \n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)  # Dynamic cognitive coefficient\n            social_coeff = 2.0  # Updated social coefficient\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor  # Refined dynamic learning rate\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85  # Adjusted velocity scaling\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)  # Adjusted stochastic range\n\n            perturbation_factor = 0.08 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Further refined perturbation formula\n\n            if evaluations > self.budget * 0.4:  # Fine-tuned dynamic layer count trigger\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence speed and solution quality by adjusting inertia weight dynamics and refining perturbation strategy.", "configspace": "", "generation": 97, "fitness": 0.9243131157761689, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9239791977858216, 0.9098469759873363, 0.9391131735553492], "final_y": [0.11424645556543445, 0.11823249504081934, 0.11093370622963061]}, "mutation_prompt": null}
{"id": "7c73f966-e3c0-4391-9813-ddefcb056031", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.9 * adaptive_factor + 0.1) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)  # Adjusted inertia weight\n            cognitive_coeff = 1.8 * (adaptive_factor ** 0.5)  # Refined cognitive coefficient\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)\n\n            perturbation_factor = 0.05 * np.sin(3.5 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor  # Adjusted perturbation timing\n\n            if evaluations > self.budget * 0.4:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine the inertia and cognitive coefficients and introduce dynamic perturbation timing for improved convergence and robustness.", "configspace": "", "generation": 98, "fitness": 0.9232401168229997, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.023. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.9323923891525183, 0.8917879249949356, 0.945540036321545], "final_y": [0.11231384233696262, 0.12468931526811089, 0.1103671849775103]}, "mutation_prompt": null}
{"id": "0ff8a0c3-3d8a-4261-9316-3db19d54c3e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0 * adaptive_factor  # Made social coefficient adaptive\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85\n            stochastic_factor = np.random.uniform(0.9, 1.3, self.population_size)\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n\n            if evaluations > self.budget * 0.4:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive social and inertia coefficients to enhance exploratory and exploitative balance.", "configspace": "", "generation": 99, "fitness": 0.909942083778085, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.8884426920161068, 0.9095800345480509, 0.9318035247700975], "final_y": [0.12181430817120353, 0.11609963563460257, 0.11083360379579821]}, "mutation_prompt": null}
{"id": "aed0be26-61a7-47f6-92e3-3a6afbadf91e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = np.cos(np.pi * evaluations / (2 * self.budget))  # Enhanced adaptive factor\n            convergence_factor = np.log10(evaluations + 10) / np.log10(self.budget)\n            inertia_weight = (0.85 * adaptive_factor + 0.15) * convergence_factor * np.sin(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * (adaptive_factor ** 0.4)\n            social_coeff = 2.0\n\n            dynamic_lr = 0.05 + 0.5 * adaptive_factor\n            velocity_scale = 1 + 0.5 * (1 - adaptive_factor)**1.75 * 0.85\n            stochastic_factor = np.random.uniform(0.8, 1.4, self.population_size)  # Refined stochastic range\n\n            perturbation_factor = 0.05 * np.sin(3.0 * np.pi * evaluations / (self.budget * self.dim)) * adaptive_factor\n\n            if evaluations > self.budget * 0.4:\n                self.dim = min(self.dim + 1, len(swarm[0]))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += velocity_scale * dynamic_lr * self.velocity[i] * stochastic_factor[i] + perturbation_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance adaptive factor dynamics and refine stochastic factors for improved convergence.", "configspace": "", "generation": 100, "fitness": 0.9266174070693461, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dd7c2cf-c467-4960-a3a0-e08b31704d7a", "metadata": {"aucs": [0.922380809472775, 0.922412857525635, 0.9350585542096288], "final_y": [0.11462838418244714, 0.11629296396766264, 0.1124216818913889]}, "mutation_prompt": null}
