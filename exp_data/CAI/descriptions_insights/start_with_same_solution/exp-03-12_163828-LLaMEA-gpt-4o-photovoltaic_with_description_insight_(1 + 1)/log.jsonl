{"id": "6e462010-18ee-4a39-86a8-e3d710e901f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "5f475ae5-c583-4f01-9471-cd3f6f62d443", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = adaptive_factor * 0.1  # Introduced adaptive learning rates\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD): Introduces adaptive learning rates to improve convergence speed and accuracy.", "configspace": "", "generation": 1, "fitness": 0.8521688117916343, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6e462010-18ee-4a39-86a8-e3d710e901f7", "metadata": {"aucs": [0.8459450241126427, 0.8332350789928331, 0.8773263322694272], "final_y": [0.1250913902239117, 0.138657474987245, 0.1201170021418081]}, "mutation_prompt": null}
{"id": "05528e51-6f79-46a7-8f95-264c03d14f7e", "solution": "import numpy as np\n\nclass MultiModalAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate_decay = 0.99 ** (evaluations / self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = adaptive_factor * 0.1 * learning_rate_decay\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "MultiModalAdaptiveSwarmGradientDescent", "description": "Multi-modal Adaptive Swarm Gradient Descent (MM-ASGD): Enhances exploration by incorporating multi-modal search features and learning rate decay.", "configspace": "", "generation": 2, "fitness": 0.8376916626076722, "feedback": "The algorithm MultiModalAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.005. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5f475ae5-c583-4f01-9471-cd3f6f62d443", "metadata": {"aucs": [0.8363616011779026, 0.8319405887599076, 0.8447727978852064], "final_y": [0.13232747976840376, 0.1426931026971595, 0.13100337879602153]}, "mutation_prompt": null}
{"id": "7d6638ee-379e-48b2-83f9-1c7d91d8c32e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Modified to enhance exploration\n            cognitive_coeff = 2.0 * adaptive_factor  # Adjusted for balanced exploration\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = adaptive_factor * 0.15  # Increased for better convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, 0.01, self.dim)  # Added noise for diversity\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with enhanced exploration and diversity maintenance for robust convergence.", "configspace": "", "generation": 3, "fitness": 0.8741897005832121, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5f475ae5-c583-4f01-9471-cd3f6f62d443", "metadata": {"aucs": [0.8403018205871327, 0.9062089939748446, 0.8760582871876589], "final_y": [0.13549531295245687, 0.11446794466693866, 0.11737395117841165]}, "mutation_prompt": null}
{"id": "e4f7b513-2312-48ed-a1a4-6aff035a8bbd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.local_refinement = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.6 * adaptive_factor  \n            cognitive_coeff = 2.5 * adaptive_factor  \n            social_coeff = 1.8\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = adaptive_factor * 0.1  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if self.local_refinement:\n                    layer_noise = np.random.normal(0, 0.005, self.dim)\n                    swarm[i] += layer_noise\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Adaptive Swarm Gradient Descent with Layer-wise Exploration and Local Refinement for Enhanced Convergence.", "configspace": "", "generation": 4, "fitness": 0.834214750559589, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.011. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7d6638ee-379e-48b2-83f9-1c7d91d8c32e", "metadata": {"aucs": [0.8449720576991173, 0.8387057214190627, 0.8189664725605872], "final_y": [0.13459024866746572, 0.14089473163442878, 0.14614367002545192]}, "mutation_prompt": null}
{"id": "495452d1-9c15-439a-bf29-4272fa0e9ea3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Adjusted to optimize exploration\n            cognitive_coeff = 1.8 * adaptive_factor  # Balanced for better exploration\n            social_coeff = 1.7  # Slightly higher to improve global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size  # Layer-wise adaptation\n                learning_rate = 0.2 * adaptive_factor * (1 + layer_adaptation)  # Increased for dynamic convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor, self.dim)  # Dynamic noise for stability\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with layer-wise dynamic adaptation and noise-resilient convergence.", "configspace": "", "generation": 5, "fitness": 0.9103177391203886, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7d6638ee-379e-48b2-83f9-1c7d91d8c32e", "metadata": {"aucs": [0.9135563555928572, 0.899559264955711, 0.9178375968125975], "final_y": [0.11541291781545726, 0.12048035422805814, 0.11563519591948279]}, "mutation_prompt": null}
{"id": "54d4cd51-6e4a-40e9-8b8a-33aa437f38eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.7\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size\n                learning_rate = 0.2 * adaptive_factor * (1.2 + layer_adaptation)  # Hierarchical learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise_adaptive = self.noise_factor * (1 - adaptive_factor)  # Dynamic noise\n                noise = np.random.normal(0, noise_adaptive, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hierarchical Adaptive Swarm Gradient Descent with layer-specific learning rates and dynamic adaptive noise for enhanced convergence and robustness.", "configspace": "", "generation": 6, "fitness": 0.9017821028014622, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "495452d1-9c15-439a-bf29-4272fa0e9ea3", "metadata": {"aucs": [0.9063755607915291, 0.8831846904792765, 0.9157860571335806], "final_y": [0.11694802292546524, 0.12341094867264157, 0.11487300844598347]}, "mutation_prompt": null}
{"id": "33473ad2-adec-4083-9938-97521e36295d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * adaptive_factor\n            cognitive_coeff = 1.9 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size \n                learning_rate = 0.3 * adaptive_factor * (1 + layer_adaptation)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise_scale = self.noise_factor * (1 - layer_adaptation)\n                noise = np.random.normal(0, noise_scale, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized Adaptive Swarm Gradient Descent with dynamic noise scaling and intelligent local search for enhanced convergence.", "configspace": "", "generation": 7, "fitness": 0.8975011296441258, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "495452d1-9c15-439a-bf29-4272fa0e9ea3", "metadata": {"aucs": [0.8863333446075852, 0.890048104698802, 0.9161219396259901], "final_y": [0.12266223338599458, 0.12219906900473831, 0.11352783999356575]}, "mutation_prompt": null}
{"id": "44b32e5f-e029-4e5e-a1ae-95d5a201bf54", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n        self.perturbation_rate = 0.05  # Added for dynamic perturbations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.7\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size\n                learning_rate = 0.2 * adaptive_factor * (1 + layer_adaptation)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 + adaptive_factor), self.dim)\n                perturbation = np.random.normal(0, self.perturbation_rate * layer_adaptation, self.dim)\n                swarm[i] += noise + perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Adaptive Swarm with Dynamic Layer-wise Perturbation and Robustness-Enhanced Noise Control.", "configspace": "", "generation": 8, "fitness": 0.8736658894509786, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "495452d1-9c15-439a-bf29-4272fa0e9ea3", "metadata": {"aucs": [0.8405180905840175, 0.9075893877498242, 0.872890190019094], "final_y": [0.1290392098533032, 0.11771314918830034, 0.1231487384168598]}, "mutation_prompt": null}
{"id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Adjusted to optimize exploration\n            cognitive_coeff = 1.8 * adaptive_factor  # Balanced for better exploration\n            social_coeff = 1.7  # Slightly higher to improve global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size  # Layer-wise adaptation\n                learning_rate = 0.2 * adaptive_factor * (1 + layer_adaptation)  # Increased for dynamic convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Refined noise with decay\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with refined noise factor decay for better stability and convergence.", "configspace": "", "generation": 9, "fitness": 0.9103202996940724, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "495452d1-9c15-439a-bf29-4272fa0e9ea3", "metadata": {"aucs": [0.9136122460881773, 0.899574928636732, 0.917773724357308], "final_y": [0.1153890581132897, 0.12048234666295898, 0.1156828863562217]}, "mutation_prompt": null}
{"id": "43de6b27-e744-4704-bda0-3a9e5c656182", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Adjusted for balance\n            cognitive_coeff = 1.9 * adaptive_factor  # Enhanced exploration\n            social_coeff = 1.6  # Reduced for better local tuning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size  # Layer-wise adaptation\n                learning_rate = 0.25 * adaptive_factor * (1 + layer_adaptation)  # More dynamic\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 - adaptive_factor), self.dim)  # Enhanced modulation\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Dynamic Layered Swarm Optimization with adaptive exploration-exploitation balance and enhanced noise modulation for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.8942611465314615, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.012. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.8784241761025888, 0.8960901081124508, 0.9082691553793452], "final_y": [0.12169189705713312, 0.11896493666902552, 0.1141851442181272]}, "mutation_prompt": null}
{"id": "690852df-18ed-4695-aa1e-963cb96e0cbc", "solution": "import numpy as np\n\nclass HybridSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.005  # Reduced initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * adaptive_factor  # Adjusted to optimize exploration\n            cognitive_coeff = 1.5 * adaptive_factor  # Balanced for dynamic exploration\n            social_coeff = 1.5  # Adjusted for improved global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = np.sin(np.pi * i / self.population_size)  # Layer-wise adaptation with variation\n                learning_rate = 0.25 * adaptive_factor * (1 + layer_adaptation)  # Refinement for dynamic convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 - adaptive_factor), self.dim)  # Altered noise with decay\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "HybridSwarmGradientDescent", "description": "Hybrid Swarm Gradient Descent with Adaptive Layerwise Learning for Enhanced Convergence.", "configspace": "", "generation": 11, "fitness": 0.8991361890111026, "feedback": "The algorithm HybridSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.027. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.9139894362957723, 0.8616783794822567, 0.9217407512552788], "final_y": [0.1141574117599784, 0.1332471643977743, 0.11388275298450035]}, "mutation_prompt": null}
{"id": "16d49303-4d44-46f6-94e8-04f9c449a5a5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.4 * adaptive_factor  # Adjusted for dynamic balance\n            cognitive_coeff = 2.0 * adaptive_factor  # Enhanced exploration\n            social_coeff = 1.6  # Improved convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = (i / self.population_size) * adaptive_factor\n                learning_rate = 0.15 + 0.15 * adaptive_factor  # Refined for layered convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (0.5 + adaptive_factor), self.dim)  # Smoothed noise\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Dynamics with Adaptive Exploration and Robustness-Driven Layer Update Strategy for Improved Optimization Performance.", "configspace": "", "generation": 12, "fitness": 0.8944280867973359, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.8764093173832623, 0.8912492876454898, 0.9156256553632555], "final_y": [0.12672184281533594, 0.12208722367662428, 0.11512451014958647]}, "mutation_prompt": null}
{"id": "c151bb2d-8d4d-4318-99b6-4ca3fa43793a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Adjusted for exploration-exploitation balance\n            cognitive_coeff = 2.0 * adaptive_factor  # Enhanced for dynamic exploration\n            social_coeff = 1.8  # Improved global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size\n                learning_rate = 0.25 * adaptive_factor * (1 + layer_adaptation)  # Enhanced for better convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Hierarchical Layered Optimization and Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 13, "fitness": 0.8976970168385371, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.8904203206141403, 0.8800511741809482, 0.9226195557205228], "final_y": [0.11975420921496849, 0.12784166334303682, 0.11230267540406857]}, "mutation_prompt": null}
{"id": "79e201da-c970-4d2e-98ce-fa503fcf36e5", "solution": "import numpy as np\n\nclass AdaptiveHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.015  # Increased initial noise level for broader exploration\n        self.layer_increment = max(1, dim // 10)  # Increment layers dynamically\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        active_dim = self.layer_increment  # Start with fewer active layers\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * adaptive_factor  # Adjusted to optimize exploration\n            cognitive_coeff = 1.5 * adaptive_factor  # Balanced for better exploration\n            social_coeff = 1.9  # Slightly higher to improve global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size  # Layer-wise adaptation\n                learning_rate = 0.25 * adaptive_factor * (1 + layer_adaptation)  # Increased for convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i, :active_dim] += learning_rate * self.velocity[i, :active_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Refined noise with decay\n                swarm[i, :active_dim] += noise[:active_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations % (self.budget // 10) == 0:\n                    active_dim = min(active_dim + self.layer_increment, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveHybridSwarmOptimization", "description": "Adaptive Hybrid Swarm Optimization with Incremental Layering and Robustness-Driven Search for improved convergence and solution robustness.", "configspace": "", "generation": 14, "fitness": 0.7973463287500152, "feedback": "The algorithm AdaptiveHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.024. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.7712008827102046, 0.7911804621912399, 0.829657641348601], "final_y": [0.14924082313355935, 0.1494862490331601, 0.13174881772092029]}, "mutation_prompt": null}
{"id": "4774ae94-6543-4cec-be5a-7287d363e22a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.005  # Reduced initial noise level for precision\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor  # Reduced for stability\n            social_coeff = 1.8  # Increased for enhanced global search\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = np.sqrt(i / self.population_size)  # Non-linear layer adaptation\n                learning_rate = 0.1 * adaptive_factor * (1 + layer_adaptation)  # Adjusted learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Consistent noise\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                \n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Layered Learning Rate Adjustment and Robustness Integration.", "configspace": "", "generation": 15, "fitness": 0.8739381624192264, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.025. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.8397510532804137, 0.8834632812776572, 0.8986001526996082], "final_y": [0.13902815499032128, 0.12388038873060314, 0.11964202222924525]}, "mutation_prompt": null}
{"id": "0d099874-e852-4043-a341-86324db30689", "solution": "import numpy as np\n\nclass SynergisticGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n        self.layer_weights = np.linspace(0.8, 1.2, self.population_size)  # Layer weights for adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * adaptive_factor  # Adjusted to optimize exploration\n            cognitive_coeff = 1.9 * adaptive_factor  # Balanced for better exploration\n            social_coeff = 1.8  # Slightly higher to improve global learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = self.layer_weights[i]  # Enhanced layer adaptation\n                learning_rate = 0.3 * adaptive_factor * layer_adaptation  # Increased for dynamic convergence\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Refined noise with decay\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "SynergisticGradientDescent", "description": "Synergistic Gradient Descent with Multi-Layer Adaptation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8972206684161931, "feedback": "The algorithm SynergisticGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.9133181104499791, 0.8672556874922027, 0.9110882073063974], "final_y": [0.11356549233864488, 0.12930760106063954, 0.11282331711500504]}, "mutation_prompt": null}
{"id": "6cb71892-93a3-4952-abf1-c12fd8005fd4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Increased initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.4 * adaptive_factor  # Adjusted for balanced exploration-exploitation\n            cognitive_coeff = 1.5 * adaptive_factor  # Lowered for improved global learning\n            social_coeff = 1.9  # Increased for enhanced convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = (i + np.random.uniform(0, 0.1)) / self.population_size  # Enhanced layer-wise adaptation\n                learning_rate = 0.25 * adaptive_factor * (1 + layer_adaptation)  # Optimized learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 2), self.dim)  # Refined noise decay\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with adaptive layer-wise learning and noise decay for improved exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.8718291261986498, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.005. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.866099814562137, 0.8716308031437054, 0.8777567608901071], "final_y": [0.1289394873099, 0.1272279701475837, 0.1236987222768614]}, "mutation_prompt": null}
{"id": "3719b88d-21e9-48b7-90e1-09595a994d12", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01  # Initial noise level\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.7\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                layer_adaptation = i / self.population_size\n                learning_rate = 0.2 * adaptive_factor * (1 + layer_adaptation)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise_scale = 0.5 * (1 + np.sin(2 * np.pi * evaluations / self.budget))  # Dynamic noise scaling\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor * noise_scale, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic noise scaling and adaptive velocity update for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.9103152281719437, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.913608649923943, 0.8995699596235402, 0.9177670749683473], "final_y": [0.11538625705427119, 0.12048074936874797, 0.11568420520214429]}, "mutation_prompt": null}
{"id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Introduce a phase change for exploration/exploitation balance\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9  # Adjusted for more effective learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * 0.5 * adaptive_factor, self.dim)  # Reduced noise for stability\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Dual-Phase Adaptive Swarm Gradient Descent with noise-reduced exploration and phase-specific learning coefficients.", "configspace": "", "generation": 19, "fitness": 0.9111539042446147, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "29920f75-1ad7-48b5-805f-dc1df5b5c009", "metadata": {"aucs": [0.9043960455745499, 0.9048339402373301, 0.9242317269219642], "final_y": [0.1177942039485067, 0.12015759554518746, 0.11304287464231777]}, "mutation_prompt": null}
{"id": "67804912-58f8-43fb-974b-710f68aba4c6", "solution": "import numpy as np\n\nclass DynamicPhaseAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n        self.modular_preserve_chance = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 2.0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.random() < self.modular_preserve_chance:\n                    noise = np.random.normal(0, self.noise_factor * 0.3 * adaptive_factor, self.dim)\n                    swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DynamicPhaseAdaptivePSO", "description": "Dynamic Phase-Adaptive Particle Swarm Optimization with modular layer preservation and robust noise handling.", "configspace": "", "generation": 20, "fitness": 0.8772591119802909, "feedback": "The algorithm DynamicPhaseAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.004. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {"aucs": [0.8828751707966067, 0.876558898272657, 0.8723432668716093], "final_y": [0.12588776726767237, 0.12774382715818766, 0.12448611231729523]}, "mutation_prompt": null}
{"id": "d5069da5-288c-416a-aeba-86c71a495836", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # More adaptive inertia\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Enhanced perturbation\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm with adaptive inertia and perturbation for improved exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.8728319269604065, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.029. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {"aucs": [0.8340404145502021, 0.8790710137587955, 0.9053843525722216], "final_y": [0.1375144529546264, 0.12705945358525184, 0.11730002225581948]}, "mutation_prompt": null}
{"id": "24693419-12a0-4fd7-a118-fb544ef8644b", "solution": "import numpy as np\n\nclass EnhancedDualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n        self.global_search_fraction = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9\n\n            dynamic_pop_size = max(2, int(self.initial_population_size * (self.global_search_fraction + (1 - self.global_search_fraction) * evaluations / self.budget)))\n            if dynamic_pop_size != self.population_size:\n                self.population_size = dynamic_pop_size\n                swarm = swarm[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = inertia_weight * self.velocity[i] + cognitive_coeff * r1 * (personal_best[i] - swarm[i]) + social_coeff * r2 * (global_best - swarm[i])\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * 0.5 * adaptive_factor, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedDualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm Gradient Descent with dynamic population resizing and robust local search refinement.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 4 is out of bounds for axis 0 with size 4').", "error": "IndexError('index 4 is out of bounds for axis 0 with size 4')", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {}, "mutation_prompt": null}
{"id": "f43cc7a4-5d94-40f0-b725-62f7ba8925bb", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.005  # Changed noise factor for enhanced stability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Introduce a phase change for exploration/exploitation balance\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9  # Adjusted for more effective learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * 0.5 * adaptive_factor, self.dim)  # Reduced noise for stability\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced noise reduction by optimizing noise factor for stable convergence.", "configspace": "", "generation": 23, "fitness": 0.9111491219166395, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {"aucs": [0.9043776997228609, 0.9048435219620912, 0.9242261440649665], "final_y": [0.1178001983972704, 0.12015405751299435, 0.11304527627751526]}, "mutation_prompt": null}
{"id": "5b70925c-70f0-43a7-8da6-0155d842ba09", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 3 * int(np.sqrt(dim))  # Increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.005  # Reduced noise factor for stability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Earlier phase change\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 2.2 if evaluations < phase_change else 1.2  # Adjusted coefficients\n            social_coeff = 1.2 if evaluations < phase_change else 2.0  # Adjusted coefficients\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.25 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, self.dim)  # Adjusted noise\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with phased learning coefficients and dynamic population size adjustment.", "configspace": "", "generation": 24, "fitness": 0.8340419951746737, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.028. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {"aucs": [0.7967892192567619, 0.8421835246514637, 0.8631532416157957], "final_y": [0.14910181946225676, 0.13799505098909504, 0.12203551615681563]}, "mutation_prompt": null}
{"id": "10f22b7e-f1dd-4bd8-8843-3c896ca861c4", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Introduce a phase change for exploration/exploitation balance\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9  # Adjusted for more effective learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 - adaptive_factor) * 0.5, self.dim)  # Dynamic noise scaling\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm Gradient Descent with dynamic noise scaling based on global convergence progress.", "configspace": "", "generation": 25, "fitness": 0.9112471872286317, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a24fe768-054a-49e5-9dde-32f4899f0ba6", "metadata": {"aucs": [0.9046601266331117, 0.9048504495186702, 0.9242309855341134], "final_y": [0.11765925993788096, 0.12014876527252005, 0.11303549630307652]}, "mutation_prompt": null}
{"id": "bed920a7-3178-409e-96c5-4d6447e3616f", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n        self.layer_increment = int(dim / 4)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3 \n\n        while evaluations < self.budget:\n            if evaluations % phase_change == 0 and evaluations // phase_change < 3:\n                self.dim += self.layer_increment\n                self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n                swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                personal_best = np.resize(personal_best, (self.population_size, self.dim))\n\n            adaptive_factor = (1 - evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.2 * adaptive_factor\n            cognitive_coeff = 2.2 if evaluations < phase_change else 1.4\n            social_coeff = 1.4 if evaluations < phase_change else 1.8  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.2 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 - adaptive_factor), self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Layered Adaptive Swarm with Phase-transition Dynamic Noise and Incremental Dimensionality to Maximize Photonic Structure Optimization.", "configspace": "", "generation": 26, "fitness": 0.8597979826931755, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.035. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "10f22b7e-f1dd-4bd8-8843-3c896ca861c4", "metadata": {"aucs": [0.8194374020905113, 0.8547664157320427, 0.9051901302569727], "final_y": [0.1469532087979546, 0.13652756678658529, 0.11669390237286914]}, "mutation_prompt": null}
{"id": "38e6e770-f3f6-4c9b-942e-6faeea81bc66", "solution": "import numpy as np\n\nclass HybridAdaptiveSwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n        self.gradient_weight = 0.2  # New parameter for gradient influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] + \n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                gradient = np.gradient([func(swarm[i] + np.eye(self.dim)[j] * 1e-5) \n                                        for j in range(self.dim)], 1e-5, axis=0)\n                swarm[i] -= self.gradient_weight * gradient * adaptive_factor  # Incorporating gradient for local refinement\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (1 - adaptive_factor) * 0.5, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "HybridAdaptiveSwarmGradientSearch", "description": "Hybrid Adaptive Swarm with Gradient-Assisted Local Search for improved convergence accuracy and robustness.", "configspace": "", "generation": 27, "fitness": 0.7857806956141148, "feedback": "The algorithm HybridAdaptiveSwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.023. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "10f22b7e-f1dd-4bd8-8843-3c896ca861c4", "metadata": {"aucs": [0.7691047571823328, 0.8176183504744194, 0.7706189791855921], "final_y": [0.13683515818821912, 0.13808253391018355, 0.12846907917922712]}, "mutation_prompt": null}
{"id": "df4ddbc2-89cb-45ef-9dac-ab09ad481b10", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Introduce a phase change for exploration/exploitation balance\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.5 if evaluations < phase_change else 1.9  # Adjusted for more effective learning\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.3 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise_scale = self.noise_factor * (1 - adaptive_factor) * (0.5 if evaluations < phase_change else 0.3)  # Phase-dependent noise scaling\n                noise = np.random.normal(0, noise_scale, self.dim)\n                swarm[i] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm Gradient Descent with phase-dependent noise scaling for improved exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.9112443143869985, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "10f22b7e-f1dd-4bd8-8843-3c896ca861c4", "metadata": {"aucs": [0.904657174147494, 0.9048490855577849, 0.9242266834557167], "final_y": [0.11766493229060615, 0.1201505179812723, 0.11304089320127775]}, "mutation_prompt": null}
{"id": "22a0c8b7-0ef2-4a58-ad3b-9191439d4ddf", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.01\n        self.layer_increment = max(1, dim // 10)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.7 if evaluations < phase_change else 1.8\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.2 + 0.1 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm Gradient Descent with progressive layer-wise complexity and adaptive learning rates for efficient high-dimensional exploration.", "configspace": "", "generation": 29, "fitness": 0.9159987913025218, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "10f22b7e-f1dd-4bd8-8843-3c896ca861c4", "metadata": {"aucs": [0.9165681717012468, 0.9090373210917756, 0.922390881114543], "final_y": [0.1130290417653298, 0.11824054178362964, 0.1126077099119499]}, "mutation_prompt": null}
{"id": "7c5ae9b5-94a6-4f00-b0b1-b49c0d9f2412", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Increased noise factor for better exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.25 + 0.05 * adaptive_factor  # Slightly increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm with Dynamic Noise Scaling and Search Space Reduction for Improved High-Dimensional Exploration and Exploitation Balance.", "configspace": "", "generation": 30, "fitness": 0.9168055956107848, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "22a0c8b7-0ef2-4a58-ad3b-9191439d4ddf", "metadata": {"aucs": [0.9243426688540373, 0.9040552488734761, 0.9220188691048409], "final_y": [0.11164438244901376, 0.11963486585914529, 0.11240317726626925]}, "mutation_prompt": null}
{"id": "dd3860bb-e7db-49f3-8766-38045b5fa7ea", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + int(np.sqrt(dim))  # Adjusted population size for diversity\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.015  # Refined noise factor for smoother exploration\n        self.layer_increment = max(1, dim // 5)  # More incremental for finer adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = np.exp(-evaluations / self.budget)  # Exponential decay for adaptation\n            inertia_weight = 0.7 - 0.05 * adaptive_factor  # Modified inertia for balance\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.5  # Balanced cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Enhanced social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 * adaptive_factor  # Adaptive learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, current_dim)  # Consistent noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Hybrid Incremental Layered Differential Evolution with Enhanced Swarm Intelligence for Optimized Exploration-Exploitation Trade-off in High-Dimensional Photovoltaic Design.", "configspace": "", "generation": 31, "fitness": 0.886358884699983, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.026. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7c5ae9b5-94a6-4f00-b0b1-b49c0d9f2412", "metadata": {"aucs": [0.8499426536141294, 0.9043200935694622, 0.9048139069163572], "final_y": [0.13102854188012691, 0.11820140267399182, 0.1154305957458085]}, "mutation_prompt": null}
{"id": "d41192d2-4f3d-4bb4-b46d-5b69da4b3291", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Increased noise factor for better exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refined Dual-Phase Adaptive Swarm with Enhanced Learning Rate Adaptation for Improved Convergence and Solution Quality.", "configspace": "", "generation": 32, "fitness": 0.9168679520933088, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7c5ae9b5-94a6-4f00-b0b1-b49c0d9f2412", "metadata": {"aucs": [0.9244979964371678, 0.8973579950662205, 0.9287478647765383], "final_y": [0.11178882565712789, 0.11861973665110659, 0.11168625497403106]}, "mutation_prompt": null}
{"id": "437d6979-11c0-40d6-9b95-0aaa44d256c6", "solution": "import numpy as np\n\nclass HybridAdaptiveSwarmGreedyDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Increased population for diversity\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.015  # Reduced noise factor for better exploitation\n        self.layer_increment = max(2, dim // 6)  # Adjusted increment for smoother adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.05 * adaptive_factor  # Adjusted inertia for stability\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5 \n            social_coeff = 1.5 if evaluations < phase_change else 2.0 \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.25 + 0.07 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim) \n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "HybridAdaptiveSwarmGreedyDescent", "description": "Hybrid Dual-Phase Adaptive Swarm and Greedy Layer-wise Descent for Enhanced Global-Local Convergence and Robust Solution Refinement.", "configspace": "", "generation": 33, "fitness": 0.8632680298696872, "feedback": "The algorithm HybridAdaptiveSwarmGreedyDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d41192d2-4f3d-4bb4-b46d-5b69da4b3291", "metadata": {"aucs": [0.841893900648677, 0.883122004630392, 0.8647881843299923], "final_y": [0.12732784696488852, 0.11710668541308722, 0.11594985602050589]}, "mutation_prompt": null}
{"id": "701585f0-ce9d-47b5-a1ae-2f91c26bdc3d", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Increased noise factor for better exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim)  # Dynamic noise scaling\n                layer_noise = np.random.normal(0, self.noise_factor * adaptive_factor, current_dim)  # Added layer-specific perturbation\n                swarm[i][:current_dim] += noise + layer_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced Dual-Phase Adaptive Swarm with Layer-Specific Perturbation for Improved Convergence.", "configspace": "", "generation": 34, "fitness": 0.8873733777248175, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d41192d2-4f3d-4bb4-b46d-5b69da4b3291", "metadata": {"aucs": [0.8669464321989633, 0.8763177253803346, 0.9188559755951546], "final_y": [0.12667785078067573, 0.12203051833027923, 0.11247892133540704]}, "mutation_prompt": null}
{"id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced noise factor adaptation for improved exploration while maintaining solution quality.", "configspace": "", "generation": 35, "fitness": 0.9170037936444864, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d41192d2-4f3d-4bb4-b46d-5b69da4b3291", "metadata": {"aucs": [0.9248744317454227, 0.8973523884703563, 0.92878456071768], "final_y": [0.11122796766027943, 0.11863932507653774, 0.11157743085241545]}, "mutation_prompt": null}
{"id": "8c6a65f9-6db5-451f-8458-0467c29a0476", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise for better exploration\n        self.adaptation_cycle = max(1, dim // 10)  # Adjusted cycle for adaptation\n        self.inertia_range = (0.5, 0.9)  # New range for inertia\n        self.cognitive_coeff_range = (1.5, 2.2)  # New range for cognitive coeff\n        self.social_coeff_range = (1.2, 2.0)  # New range for social coeff\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Updated phase change point\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.adaptation_cycle) + 1) * self.adaptation_cycle)\n            adaptation_factor = 1 - (evaluations / self.budget) ** 0.8  # Modified adaptation curve\n            inertia_weight = self.inertia_range[0] + (self.inertia_range[1] - self.inertia_range[0]) * adaptation_factor\n            cognitive_coeff = self.cognitive_coeff_range[1] if evaluations < phase_change else self.cognitive_coeff_range[0]\n            social_coeff = self.social_coeff_range[0] if evaluations < phase_change else self.social_coeff_range[1]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.1 * adaptation_factor  # Enhanced learning rate dynamics\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptation_factor, current_dim)  # Adapted noise\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced exploration-exploitation balance using dynamic adaptation and control of search parameters.", "configspace": "", "generation": 36, "fitness": 0.9106367583343257, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "metadata": {"aucs": [0.9176611959268102, 0.8944684525244478, 0.9197806265517189], "final_y": [0.1114814904749385, 0.11646248000646975, 0.11344056624442511]}, "mutation_prompt": null}
{"id": "5a96daa7-ad97-40a4-8f77-0f2b9ee34e57", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for better precision\n        self.layer_increment = max(1, dim // 6)  # Adjusted increment for more refined adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Modified phase duration for better adaptation\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.3  # Modified cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.05 * adaptive_factor  # Further increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.6), current_dim)  # Further dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Dynamic Layered Exploration with Noise-Adaptive Swarm and Gradient Refinement for enhanced precision in high-dimensional noisy optimization.", "configspace": "", "generation": 37, "fitness": 0.902061926688393, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.025. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "metadata": {"aucs": [0.8698790740312528, 0.9065749399710782, 0.9297317660628484], "final_y": [0.12885878752989932, 0.11270375056733406, 0.11087656759535292]}, "mutation_prompt": null}
{"id": "2fbf2958-2161-4a1d-ac48-05a84b401bcf", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Enhanced noise factor for robust exploration\n        self.layer_increment = max(1, dim // 6)  # Faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.65 + 0.05 * adaptive_factor  # Refined inertia\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Tuned cognitive for balance\n            social_coeff = 1.5 if evaluations < phase_change else 2.0  # Tuned social for convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.25 + 0.07 * adaptive_factor  # Tuned learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.6), current_dim)  # Adjusted noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "A dual-phase adaptive swarm with enhanced local search via noise robustness and dynamic exploration constraints.", "configspace": "", "generation": 38, "fitness": 0.9122685436158546, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "metadata": {"aucs": [0.9170014003795321, 0.8993663018349387, 0.920437928633093], "final_y": [0.11291004931334359, 0.11875254996314921, 0.11347371521455629]}, "mutation_prompt": null}
{"id": "e2493233-6366-4a45-b3aa-f800b234fcc4", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03\n        self.layer_increment = max(1, dim // 8)\n        self.quantum_probability = 0.1  # Quantum-inspired dynamic for exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4\n            social_coeff = 1.6 if evaluations < phase_change else 1.9\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor\n                \n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                \n                # Quantum-inspired update rule\n                if np.random.random() < self.quantum_probability:\n                    self.velocity[i][:current_dim] += np.random.uniform(-1, 1, current_dim)\n\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 0.5), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveQuantumInspiredSwarmGradientDescent", "description": "Adaptive Quantum-Inspired Swarm Gradient Descent integrates quantum dynamics for enhanced exploration and convergence in high-dimensional noisy problems.", "configspace": "", "generation": 39, "fitness": 0.88508911779128, "feedback": "The algorithm AdaptiveQuantumInspiredSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.008. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "metadata": {"aucs": [0.8817542474601084, 0.8773338097988765, 0.8961792961148549], "final_y": [0.12366856613074517, 0.12067157413207075, 0.11289543806907254]}, "mutation_prompt": null}
{"id": "dac58c82-2530-4086-b729-af647b23390c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduction of adaptive noise factor decay for refined exploration.", "configspace": "", "generation": 40, "fitness": 0.9170707924079485, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5e4225d4-7221-43bd-8091-cda9b75987ec", "metadata": {"aucs": [0.9251896196469741, 0.8973815102210132, 0.9286412473558581], "final_y": [0.11114298127241973, 0.11849553639928934, 0.11175599092572552]}, "mutation_prompt": null}
{"id": "1a2c7022-6b64-4644-bfd6-952314a01ff8", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))  # Increased pop size for diversity\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.015  # Reduced noise factor for finer updates\n        self.layer_increment = max(1, dim // 5)  # Smaller increment for gradual adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Earlier phase transition for quicker convergence\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = np.exp(-evaluations / self.budget)  # Exponential decay for adaptation\n            inertia_weight = 0.5 + 0.2 * adaptive_factor  # Refined inertia for dynamism\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.2  # Refined cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Enhanced social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.1 * adaptive_factor  # Higher learning rate for speed\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 2), current_dim)  # Adjusted noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced multi-phase swarm optimization with adaptive layer growth and noise-resilient updates.", "configspace": "", "generation": 41, "fitness": 0.901168222563484, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.030. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "dac58c82-2530-4086-b729-af647b23390c", "metadata": {"aucs": [0.8588272019862766, 0.9271408061418172, 0.917536659562358], "final_y": [0.13168079647332342, 0.11183921898605953, 0.11213989841527838]}, "mutation_prompt": null}
{"id": "cdac645d-7aa5-4390-88b6-7e1a741527d8", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 8)  # Adjusted increment for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Modified phase change for better transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introducing adaptive phase transition for enhanced exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.9159953198513248, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "dac58c82-2530-4086-b729-af647b23390c", "metadata": {"aucs": [0.9238513001408558, 0.8950077494463144, 0.9291269099668041], "final_y": [0.11181556978166463, 0.11992590137172154, 0.11168644882875722]}, "mutation_prompt": null}
{"id": "e27a1f1b-0ee3-4aa2-a5fd-c16c53e44013", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Adjusted population size for better diversity\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise for precise refinement\n        self.layer_increment = max(1, dim // 7)  # Adjusted increment for gradual complexity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase change for early refinement\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * adaptive_factor  # Adjusted inertia for improved convergence\n            cognitive_coeff = 1.9 if evaluations < phase_change else 1.5  # Balanced cognitive coefficient\n            social_coeff = 1.5 if evaluations < phase_change else 2.0  # Enhanced social influence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.05 * adaptive_factor  # Tuned learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Refined noise factor\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Dynamic hierarchical swarm with adaptive phase adjustments for enhanced exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.876753397504173, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dac58c82-2530-4086-b729-af647b23390c", "metadata": {"aucs": [0.8801783935661891, 0.8632465170544555, 0.8868352818918742], "final_y": [0.11919339976325949, 0.11491726748677511, 0.11278848674137998]}, "mutation_prompt": null}
{"id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 6)  # Adjusted increment for better dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration by adjusting noise factor scaling and layer increment strategy.", "configspace": "", "generation": 44, "fitness": 0.9170839874177191, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dac58c82-2530-4086-b729-af647b23390c", "metadata": {"aucs": [0.9251790594056202, 0.8974170170636134, 0.9286558857839241], "final_y": [0.11114884290868576, 0.11852178406299319, 0.11174612428158692]}, "mutation_prompt": null}
{"id": "04bc6bf7-47c5-4e0a-bfe4-5325681828b3", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for more stable searches\n        self.layer_increment = max(1, dim // 5)  # Adjusted increment for improved exploration-refinement balance\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Modified phase timing\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Refined inertia for better balance\n            cognitive_coeff = 1.8 + 0.3 * adaptive_factor  # Dynamic cognitive coefficient adjustment\n            social_coeff = 2.0 if evaluations < phase_change else 1.5  # Modified social coefficient strategy\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.2 + 0.08 * adaptive_factor  # Refined learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Enhanced noise scaling for robustness\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refine exploration by dynamically adjusting cognitive and social coefficients while integrating robustness metrics for perturbation tolerance.", "configspace": "", "generation": 45, "fitness": 0.8835502834303878, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "metadata": {"aucs": [0.8647860836670793, 0.89668992156574, 0.8891748450583442], "final_y": [0.12570874223733564, 0.12212202298615171, 0.1166284431344703]}, "mutation_prompt": null}
{"id": "ea46f0eb-4612-44f5-98b4-a3328099d9a0", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 6)  # Adjusted increment for better dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration by adjusting noise factor scaling and layer increment strategy.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "metadata": {"aucs": [0.9251790594056202, 0.8974170170636134, 0.9286558857839241], "final_y": [0.11114884290868576, 0.11852178406299319, 0.11174612428158692]}, "mutation_prompt": null}
{"id": "bbbf39ee-c021-4a21-95b3-1886993393f1", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Enhanced noise factor for improved exploration\n        self.layer_increment = max(1, dim // 6)  # Adjusted increment for better dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.1 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tuned cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 1.9  # Tuned social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                perturbation = 0.01 * (ub - lb) * adaptive_factor  # Systematic perturbation\n                swarm[i][:current_dim] += perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce a small systematic perturbation to improve robustness and escape local optima.  ", "configspace": "", "generation": 47, "fitness": 0.8771065854485508, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "metadata": {"aucs": [0.8555539554782182, 0.874542863768748, 0.901222937098686], "final_y": [0.13400670148897864, 0.12911446753228994, 0.1205821773194159]}, "mutation_prompt": null}
{"id": "3a54cca0-ac1d-46b8-8c46-ff14132bf6cf", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03\n        self.layer_increment = max(1, dim // 6)\n        self.local_search_prob = 0.2  # Probability to perform local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.15 * adaptive_factor  # Adjusted inertia for better exploration\n            cognitive_coeff = 2.2 if evaluations < phase_change else 1.3\n            social_coeff = 1.5 if evaluations < phase_change else 2.0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.25 + 0.1 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.random() < self.local_search_prob:  # Local search with noise control\n                    noise = np.random.normal(0, self.noise_factor * 0.5 * adaptive_factor, current_dim)\n                    swarm[i][:current_dim] += noise\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce adaptive local search with noise control and layer-wise dimension expansion to refine the DualPhaseAdaptiveSwarmGradientDescent algorithm.", "configspace": "", "generation": 48, "fitness": 0.8874575529343663, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.016. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "metadata": {"aucs": [0.8651665872260674, 0.8927942648924914, 0.9044118066845404], "final_y": [0.12783004458194724, 0.12437179175280777, 0.11698457578600041]}, "mutation_prompt": null}
{"id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refine exploration and diversity through adaptive noise scaling and dynamic role assignment for enhanced layer navigation.", "configspace": "", "generation": 49, "fitness": 0.9277060857339464, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6df406d4-b918-486f-b9fa-3c45ba79cfed", "metadata": {"aucs": [0.9164909241678844, 0.9282839820197787, 0.9383433510141763], "final_y": [0.11067441436831571, 0.11235388824893666, 0.11021883436333024]}, "mutation_prompt": null}
{"id": "ef3e9c74-ad65-43c2-900b-c21b6046fef6", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        elite_fraction = 0.1  # Introducing elitism\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.2 * adaptive_factor  # Adjusted inertia\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.7 if evaluations < phase_change else 2.0\n\n            elite_size = max(1, int(self.population_size * elite_fraction))\n            elites = np.argsort(personal_best_value)[:elite_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Enhanced noise adaptation\n                if i not in elites:  # Preserve elite solutions\n                    swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration-exploitation balance by introducing elitism and adaptive noise for improved convergence in high-dimensional, noisy landscapes.", "configspace": "", "generation": 50, "fitness": 0.9241406673324742, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9211396265781238, 0.9162122990564487, 0.9350700763628502], "final_y": [0.11273581881131811, 0.1150580972721994, 0.11004334110579661]}, "mutation_prompt": null}
{"id": "046637e6-5742-405d-a4af-74c7960bdd0c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Increased population for diversity\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.04  # Adjusted for improved stability\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        adaptive_reinitialization_point = self.budget // 2  # New reinitialization strategy\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Refined inertia weight\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.6  # Modified cognitive coefficient\n            social_coeff = 1.8 if evaluations < phase_change else 2.1  # Modified social coefficient\n\n            if evaluations == adaptive_reinitialization_point:\n                swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Reinitialization\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.05 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.1), current_dim)  # Enhanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance adaptive swarm behavior with diversified cognitive and social dynamics, incorporating population reinitialization for improved convergence resilience.", "configspace": "", "generation": 51, "fitness": 0.8777268943478301, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.028. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8380993010629343, 0.8952137873082128, 0.8998675946723432], "final_y": [0.13556813371934062, 0.11882941765080302, 0.1136975765217233]}, "mutation_prompt": null}
{"id": "d20bb6bc-7277-489b-abe2-c7d54b09fda6", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * np.clip(self.velocity[i][:current_dim], -adaptive_factor, adaptive_factor)  # Adaptive velocity bounds\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.1), current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce dynamic noise scaling and adaptive velocity bounds for enhanced convergence in high-dimensional noisy spaces.", "configspace": "", "generation": 52, "fitness": 0.7247913764666101, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.725 with standard deviation 0.037. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.681539842710879, 0.770934952029428, 0.7218993346595233], "final_y": [0.20507554239615544, 0.16901690182444706, 0.189164014352321]}, "mutation_prompt": null}
{"id": "1a6d7dab-4dbf-4be3-b187-8213b0759bfd", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Fine-tuned increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Adjusted phase transition for balance\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.2 * adaptive_factor  # Adjusted inertia for stability\n            cognitive_coeff = 2.5 if evaluations < phase_change else 1.8  # Optimized cognitive coefficient\n            social_coeff = 1.5 if evaluations < phase_change else 2.2  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.1 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if evaluations % (self.layer_increment*2) == 0:  # Local refinement step\n                    local_perturbation = np.random.uniform(-0.005, 0.005, current_dim)\n                    swarm[i][:current_dim] += local_perturbation\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, current_dim)  # Dynamic noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by incorporating adaptive layer-based perturbations and local search refinements for targeted performance optimization.", "configspace": "", "generation": 53, "fitness": 0.911108978690964, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9225114328630051, 0.889261346655975, 0.9215541565539119], "final_y": [0.10999348062255698, 0.12317067968098516, 0.109800453192205]}, "mutation_prompt": null}
{"id": "d3b7c15f-18e4-46e3-b8ae-9e9e9a9dcb4d", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.07  # Enhanced noise factor for better exploration\n        self.layer_increment = max(2, dim // 4)  # Modified increment for finer granularity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Tuned inertia for balance\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tweaked cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 2.1  # Tweaked social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Refined noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance solution refinement with adaptive layer engagement and selective noise amplification for optimized navigation.", "configspace": "", "generation": 54, "fitness": 0.9269991524564084, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.012. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9329027344094042, 0.9097448076887015, 0.9383499152711196], "final_y": [0.11109124401995263, 0.11622116033867735, 0.11004568506560031]}, "mutation_prompt": null}
{"id": "5846c5b0-0cff-42e5-b600-97c05640a0f1", "solution": "# Description: Enhance solution quality by integrating adaptive mutation control and elite candidate promotion for improved convergence.\n# Code:\nimport numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = self.population_size\n        phase_change = self.budget // 3\n        elite_fraction = 0.2  # Fraction of elite candidates\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.7 if evaluations < phase_change else 2.0\n\n            num_elites = max(1, int(self.population_size * elite_fraction))\n            sorted_indices = np.argsort(personal_best_value)\n            elite_swarm = swarm[sorted_indices[:num_elites]]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                if i < num_elites:  # Additional promotion for elite candidates\n                    mutation = np.random.normal(0, 0.1 * adaptive_factor, current_dim)\n                    self.velocity[i][:current_dim] += mutation\n\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance solution quality by integrating adaptive mutation control and elite candidate promotion for improved convergence.", "configspace": "", "generation": 55, "fitness": 0.9142016186133383, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.007. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9058555729601658, 0.9150314931784396, 0.9217177897014096], "final_y": [0.11126528665879398, 0.11201190814874995, 0.11208534503169632]}, "mutation_prompt": null}
{"id": "97bd7eec-1f84-42d3-88ab-74583b433ddc", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.06  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 4)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.8 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by integrating adaptive layer tuning and refined noise regulation.", "configspace": "", "generation": 56, "fitness": 0.9203443272392628, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.92029395229191, 0.9010117575864222, 0.9397272718394561], "final_y": [0.11300115536300204, 0.11766091158115832, 0.1100298856041837]}, "mutation_prompt": null}
{"id": "02fa8ab2-83c3-404a-a957-dd99ac8c6160", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 7)  # Enhanced increment for dimension adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Shifted phase transition for balance\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Refined inertia for stability\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.3  # Balanced cognitive coefficient\n            social_coeff = 1.9 if evaluations < phase_change else 2.2  # Balanced social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.1 * adaptive_factor  # Dynamic learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Adjusted noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Integrate adaptive layer incrementing with multi-phase search to improve solution robustness and convergence in high-dimensional photonics optimization.", "configspace": "", "generation": 57, "fitness": 0.9266543362383036, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.009. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9264723194200116, 0.9160032922780725, 0.937487397016827], "final_y": [0.11276942589764938, 0.11390918268968753, 0.110541545848305]}, "mutation_prompt": null}
{"id": "198c15f5-6ad3-480e-9789-b1390e7f7225", "solution": "import numpy as np\n\nclass EnhancedDualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + int(np.sqrt(dim))  # Increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.07  # Refined noise factor for better exploration\n        self.layer_increment = max(2, dim // 4)  # Adjusted increment for finer control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Altered phase transition for quicker adaptation\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Modified inertia for agility\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.3  # Adjusted cognitive coefficient\n            social_coeff = 1.9 if evaluations < phase_change else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Enhanced learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Recalibrated noise\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedDualPhaseSwarmOptimizer", "description": "Enhanced dual-phase swarm optimization with adaptive role balancing and layer-wise refinement for improved absorption.", "configspace": "", "generation": 58, "fitness": 0.9146006361239811, "feedback": "The algorithm EnhancedDualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8996654991469947, 0.9188774704284278, 0.9252589387965211], "final_y": [0.11313951253875187, 0.11445153612391534, 0.11210786756875324]}, "mutation_prompt": null}
{"id": "2df47236-b08d-4b8f-8ffe-416524450c2a", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Modified noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence by adjusting learning rate and noise scaling based on evaluations.", "configspace": "", "generation": 59, "fitness": 0.9227316539089424, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9188348444868527, 0.9254758482501028, 0.923884268989872], "final_y": [0.11321962287304932, 0.11165915477828925, 0.1130587383938374]}, "mutation_prompt": null}
{"id": "c78c00cd-9ab2-4aeb-b166-2f19a9f78102", "solution": "# Description: Introduce hierarchical exploration strategies with adaptive role specialization to enhance convergence and robustness.\nimport numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Adjusted noise factor for enhanced exploration\n        self.layer_increment = max(1, dim // 6)  # Modulated increment for finer dimension control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 4  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Modified inertia for refined control\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Tweaked cognitive coefficient\n            social_coeff = 1.8 if evaluations < phase_change else 2.1  # Enhanced social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.04 * adaptive_factor  # Tuned learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Tailored noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce hierarchical exploration strategies with adaptive role specialization to enhance convergence and robustness.", "configspace": "", "generation": 60, "fitness": 0.9271077255397419, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.013. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.931079745270993, 0.9092378188175029, 0.9410056125307297], "final_y": [0.11109234488948794, 0.11511943588961471, 0.11002032234119952]}, "mutation_prompt": null}
{"id": "f95244b4-3865-41ff-bdc9-e1c5c745c73c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.sub_pop_size = self.population_size // 3  # New: Split population into sub-groups\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Modified noise factor\n        self.layer_increment = max(1, dim // 6)  # Revised increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 4  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - (evaluations / self.budget) ** 0.7  # New: Nonlinear adaptation\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Modified inertia for control\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.3  # Updated cognitive coefficient\n            social_coeff = 2.1 if evaluations < phase_change else 2.3  # Updated social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.07 * adaptive_factor  # Modified learning rate\n                if i % self.sub_pop_size == 0:  # New: Swarm coordination per sub-population\n                    chosen_best = global_best[:current_dim]\n                else:\n                    chosen_best = personal_best[np.random.choice(self.sub_pop_size)][:current_dim]\n                \n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (chosen_best - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Revised noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance global exploration and local exploitation by leveraging adaptive multi-swarm coordination and nonlinear learning dynamics.", "configspace": "", "generation": 61, "fitness": 0.8842496038534812, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.024. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8647447387705633, 0.8703844887698673, 0.917619584020013], "final_y": [0.12520626007612068, 0.11799746114544674, 0.11421603296080007]}, "mutation_prompt": null}
{"id": "d94e7ace-4dcc-48aa-b0aa-1da6b35b2cd7", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.07  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  \n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.8 if evaluations < phase_change else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.45 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance adaptive velocity scaling and noise integration for more effective exploration and convergence.", "configspace": "", "generation": 62, "fitness": 0.9020814976916482, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.029. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8627293151826266, 0.9102336092399348, 0.9332815686523833], "final_y": [0.13043853248758597, 0.11272040093594926, 0.11002807554805305]}, "mutation_prompt": null}
{"id": "c348dad3-1c16-4976-b1fb-943c6878d193", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n        \n        subgroup_size = self.population_size // 2  # New division into subgroups\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Adjusted inertia\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.4  # Modified cognitive coefficient\n            social_coeff = 1.5 if evaluations < phase_change else 1.9  # Modified social coefficient\n            exploration_coeff = 2.1  # New exploration coefficient\n            \n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(current_dim), np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.1 * adaptive_factor  # Adjusted learning rate\n                subgroup_best = personal_best[np.argmin(personal_best_value[:subgroup_size])]  # New subgroup best\n\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]) +\n                                                  exploration_coeff * r3 * (subgroup_best[:current_dim] - swarm[i][:current_dim]))  # New exploration\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * adaptive_factor, current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing dynamic subgroup interactions and phase-based dimension increment for improved convergence.", "configspace": "", "generation": 63, "fitness": 0.8862407616011474, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.042. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8272934649638037, 0.9097692056925595, 0.9216596141470788], "final_y": [0.14229680971439795, 0.11622537811921929, 0.11552413771004155]}, "mutation_prompt": null}
{"id": "ca7b0ca9-6576-4c52-8c71-c6debdfd9895", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.7 if evaluations < phase_change else 2.0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Differential evolution-like mutation\n                mutant_idx = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = swarm[mutant_idx[0]] + 0.8 * (swarm[mutant_idx[1]] - swarm[mutant_idx[2]])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < 0.5, mutant_vector, swarm[i])\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)\n                trial_vector[:current_dim] += noise\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                f_value = func(trial_vector)\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = trial_vector\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = trial_vector\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Integrate differential evolution elements into adaptive swarm to enhance global search and convergence efficiency.", "configspace": "", "generation": 64, "fitness": 0.9014720036698144, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.015. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8800612541724624, 0.91517304167766, 0.9091817151593209], "final_y": [0.12039897834071522, 0.11201485653871446, 0.112116558328623]}, "mutation_prompt": null}
{"id": "e6f10422-03d2-415f-8602-b1dd5055d1af", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        # Changed the population size to be adaptive based on dimension and evaluations\n        self.population_size = 10 + int(np.sqrt(dim)) + (budget // 10000)\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refine exploration and diversity through adaptive noise scaling and dynamic role assignment for enhanced layer navigation by introducing adaptive population size.", "configspace": "", "generation": 65, "fitness": 0.9037659157030586, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8817933296455974, 0.911607849703207, 0.9178965677603715], "final_y": [0.12528377216204478, 0.11195617286460091, 0.11347137530923257]}, "mutation_prompt": null}
{"id": "97f1f63d-39c7-4715-b46b-50d056ee908e", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n        # Use adaptive learning rates per layer\n        self.layer_base_learning_rate = np.ones(dim) * 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5\n            social_coeff = 1.7 if evaluations < phase_change else 2.0\n            \n            # Adjust learning rate dynamically per layer\n            learning_rates = self.layer_base_learning_rate * (1.0 + adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rates[:current_dim] * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce stochastic evaluation to reduce noise effects\n                f_value = func(swarm[i]) + np.random.normal(0, 0.01 * adaptive_factor)\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Integrate adaptive layer-specific learning rates and dynamic role reassignment with stochastic evaluation for enhanced exploration and convergence.", "configspace": "", "generation": 66, "fitness": 0.872820271817918, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.024. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8625229218135446, 0.8498791469183179, 0.9060587467218915], "final_y": [0.12829292749021237, 0.1381466173892817, 0.1166542100784328]}, "mutation_prompt": null}
{"id": "b18d1b20-7517-48dd-93ad-9f11f3ab1ae3", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.06  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration with a slight increase in noise factor to improve diversity and convergence.", "configspace": "", "generation": 67, "fitness": 0.9263732313577825, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9159190634394367, 0.9245393166813338, 0.9386613139525768], "final_y": [0.11100728905264778, 0.11237762481152713, 0.11000770648885327]}, "mutation_prompt": null}
{"id": "37929d53-8e5a-4470-a33d-28f544c3b9b1", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n        self.mutation_prob = 0.1  # Added adaptive mutation probability\n        self.self_adapt_factor = np.ones((self.population_size, dim))  # Self-adaptation factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.2 * adaptive_factor  # Adjusted inertia for better control\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.4  # Adjusted cognitive coefficient\n            social_coeff = 1.6 if evaluations < phase_change else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                if np.random.random() < self.mutation_prob:  # Implementing mutation\n                    self.velocity[i][:current_dim] *= self.self_adapt_factor[i][:current_dim]\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Adjusted noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    self.self_adapt_factor[i][:current_dim] *= 1.05  # Increase self-adaptation factor on improvement\n                else:\n                    self.self_adapt_factor[i][:current_dim] *= 0.95  # Decrease self-adaptation on no improvement\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation by incorporating adaptive mutation and layered self-adaptation for improved convergence.", "configspace": "", "generation": 68, "fitness": 0.9085333567057612, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8855129614253086, 0.9094884071067671, 0.9305987015852079], "final_y": [0.12350106629969981, 0.11623934254916213, 0.1097227821225435]}, "mutation_prompt": null}
{"id": "0a160cd7-1b8e-467b-b2e9-9b71ca2ac77a", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance adaptive dynamics by refining velocity updates and phase transition points for improved convergence.", "configspace": "", "generation": 69, "fitness": 0.9020918427403103, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.026. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9168883560901306, 0.8661022120897971, 0.9232849600410031], "final_y": [0.11469344533666193, 0.12969958425673067, 0.11262306649485898]}, "mutation_prompt": null}
{"id": "a7616a47-c4cf-4049-9fe8-2f91f6633c0c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 2 * int(np.sqrt(dim))  # Increased population for better coverage\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Adjusted noise factor for refined exploration\n        self.layer_increment = max(1, dim // 4)  # Adjusted increment for smoother dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Phase transition adjusted for more exploration\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = (1 - evaluations / self.budget) ** 1.5  # Enhanced adaptive factor\n            inertia_weight = 0.8 - 0.1 * adaptive_factor  # Altered inertia for stability\n            cognitive_coeff = 2.5 if evaluations < phase_change else 1.0  # Varied cognitive coefficient\n            social_coeff = 1.5 if evaluations < phase_change else 2.3  # Varied social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.3 + 0.1 * adaptive_factor  # Adjusted learning rate for faster convergence\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Fine-tuned noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration by combining adaptive particle roles with a dynamic layer-wise improvement strategy for balanced convergence.", "configspace": "", "generation": 70, "fitness": 0.9013145876444102, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9036834895384849, 0.8822475385544742, 0.9180127348402713], "final_y": [0.11316727577418517, 0.12277998384729827, 0.11230398275136588]}, "mutation_prompt": null}
{"id": "1b7e24fe-5171-4a03-b02f-bdc656bfa29f", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.0 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance swarm convergence by refining adaptive noise scaling with a dynamic exponent based on phase transitions.", "configspace": "", "generation": 71, "fitness": 0.9276825392026952, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9164260957777344, 0.9282816034655321, 0.938339918364819], "final_y": [0.11062506479586154, 0.11235936746854824, 0.11020255987845173]}, "mutation_prompt": null}
{"id": "35479c29-b67e-49b5-bce3-8f031bd98c0c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05\n        self.layer_increment = max(1, dim // 5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * np.sin(np.pi * adaptive_factor)  # Dynamic inertia for enhanced exploration\n            cognitive_coeff = 2.1 if evaluations < phase_change else 1.3  # Adjusted coefficients for balance\n            social_coeff = 1.5 if evaluations < phase_change else 2.2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adaptive learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (0.5 + 0.5 * adaptive_factor), current_dim)  # Adaptive perturbation\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia and adaptive perturbation to enhance exploration and convergence of layered structures.", "configspace": "", "generation": 72, "fitness": 0.91945762320641, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9154918793067034, 0.9112893852794668, 0.9315916050330598], "final_y": [0.11175812466302382, 0.11635002031904618, 0.11239481230865467]}, "mutation_prompt": null}
{"id": "6ceef5ab-026d-47b0-ab85-568a9541cdb5", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + int(np.sqrt(dim))  # Adjusted swarm size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Adjusted noise factor for better convergence\n        self.layer_increment = max(1, dim // 4)  # Adjusted increment for finer dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 2  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.2 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 1.8 if evaluations < phase_change else 1.4  # Updated cognitive coefficient\n            social_coeff = 1.5 if evaluations < phase_change else 2.5  # Updated social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.35 + 0.07 * adaptive_factor  # Refined learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.5), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Improved convergence and exploration through adaptive swarm size, noise-induced role dynamics, and phase-specific inertia adjustments.", "configspace": "", "generation": 73, "fitness": 0.845671865728436, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.046. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.8055680760037467, 0.8207815055480377, 0.9106660156335239], "final_y": [0.15030781241320035, 0.14101406692872998, 0.11055205424962322]}, "mutation_prompt": null}
{"id": "f11d628b-76b1-4d85-9891-4ce9dd22d3f4", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Adjusted noise factor for better diversity\n        self.layer_increment = max(1, dim // 5)  # Improved increment for dimension coverage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change = self.budget // 3  # Adjusted phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Enhanced inertia for control\n            cognitive_coeff = 2.2 if evaluations < phase_change else 1.5  # Optimized cognitive coefficient\n            social_coeff = 1.7 if evaluations < phase_change else 2.0  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.4 + 0.05 * adaptive_factor  # Increased learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.3), current_dim)  # Advanced noise scaling\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance local refinement and adaptively shift exploration-exploitation balance for improved layer optimization.", "configspace": "", "generation": 74, "fitness": 0.9228750564795792, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9196959377514435, 0.9149805397147796, 0.9339486919725147], "final_y": [0.11108648608763239, 0.116226677994546, 0.11068070591614465]}, "mutation_prompt": null}
{"id": "ea4f20e5-b258-40e7-ba1b-8fb1faaed7bf", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.3  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 1.9  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence through multi-phase adaptive control and memory-enhanced diversity to improve layer optimization.", "configspace": "", "generation": 75, "fitness": 0.9292072216516359, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e05f926e-165d-4db5-bdce-b50d4fe6ca78", "metadata": {"aucs": [0.9248768496812757, 0.9247373947892683, 0.9380074204843638], "final_y": [0.11060389340720589, 0.1116373473872524, 0.10998992338292168]}, "mutation_prompt": null}
{"id": "28e2ad24-e3bd-471a-9f3b-19a0e26ef5e1", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Adjusted noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.3  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 1.9  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.05 * adaptive_factor  # Adjusted learning rate for improved precision\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Normal noise for stability\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Integrate hybrid noise-driven exploration with precision control to improve convergence and stability in high-dimensional optimization.", "configspace": "", "generation": 76, "fitness": 0.9029300232846897, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ea4f20e5-b258-40e7-ba1b-8fb1faaed7bf", "metadata": {"aucs": [0.8893977687638439, 0.8933240020190911, 0.9260682990711342], "final_y": [0.11802765391880177, 0.12294979963126029, 0.11041352641354474]}, "mutation_prompt": null}
{"id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refine exploration and convergence through enhanced phase transition control and adaptive velocity adjustments.", "configspace": "", "generation": 77, "fitness": 0.9293193220535239, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ea4f20e5-b258-40e7-ba1b-8fb1faaed7bf", "metadata": {"aucs": [0.9244736881576163, 0.9254752316942276, 0.9380090463087277], "final_y": [0.1105984082299527, 0.11164161632748737, 0.1099947402304634]}, "mutation_prompt": null}
{"id": "df2fd1e9-d997-419a-96e1-ba1de6fcceca", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Increased noise factor for better exploration\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.1 * adaptive_factor  # Lower inertia for enhanced adaptability\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.0),  # Modified noise adaptation\n                                           self.noise_factor * (adaptive_factor ** 1.0), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by adjusting noise strategy and inertia weight dynamics for improved adaptability.", "configspace": "", "generation": 78, "fitness": 0.918883269328605, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.022. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8888966253417261, 0.9276999146659046, 0.9400532679781844], "final_y": [0.12085527324782042, 0.11168266355037304, 0.1100297681887269]}, "mutation_prompt": null}
{"id": "f1ff6908-36cb-4e7c-aa59-afaffdfc8f7e", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.75 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.4 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence by refining velocity adaptation and strategically injecting noise for improved exploration.", "configspace": "", "generation": 79, "fitness": 0.9033474899277971, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8910371753727607, 0.9009140061365767, 0.9180912882740538], "final_y": [0.11896086742309242, 0.12063206274102345, 0.11086787750418792]}, "mutation_prompt": null}
{"id": "d8e5e056-2b29-4242-9592-1c88bceb4ff6", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for enhanced precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.65 - 0.1 * adaptive_factor  # Enhanced inertia for improved convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance adaptive mechanisms and convergence through refined inertia and noise factors.", "configspace": "", "generation": 80, "fitness": 0.9109114308751819, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9148465198769166, 0.8947283494969044, 0.923159423251725], "final_y": [0.11295044797133902, 0.12140825371430963, 0.11304381083773196]}, "mutation_prompt": null}
{"id": "01e25fb8-6356-4a14-837c-9ca585994796", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 3  # Adjust for more fine-tuned phase transition\n        phase_change2 = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.4\n            social_coeff = 2.05 if evaluations < phase_change2 else 2.1  # Slight increase for social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.6 + 0.02 * adaptive_factor  # Adjusted learning rate for better exploration\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2),\n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence and exploration by adjusting the learning rate and noise factor adaptively for balanced search behavior.", "configspace": "", "generation": 81, "fitness": 0.8898824194288556, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8581125458013118, 0.896176228624503, 0.9153584838607517], "final_y": [0.13047693851177355, 0.12264067872466478, 0.11446601468958262]}, "mutation_prompt": null}
{"id": "638a5af7-9f55-42ec-a0be-b5f29c047d3c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.4  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.5), \n                                           self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by modifying noise addition and adaptation of the cognitive coefficient.", "configspace": "", "generation": 82, "fitness": 0.9290950861944905, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9244275582133372, 0.9251035175559292, 0.9377541828142055], "final_y": [0.11061024025318833, 0.11167100879082947, 0.11001256257638758]}, "mutation_prompt": null}
{"id": "6b11668f-6e85-4315-b497-f28fbb1e2080", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Adjusted noise factor for better precision\n        self.layer_increment = max(1, dim // 4)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4\n        phase_change2 = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.1 * adaptive_factor  # Adjusted inertia weight for stability\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.3),  # Slightly increased noise factor\n                                           self.noise_factor * (adaptive_factor ** 1.3), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhanced velocity adjustment and noise control for improved exploration and convergence balance.", "configspace": "", "generation": 83, "fitness": 0.9187063655004523, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.022. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8889176592498275, 0.927518284581667, 0.9396831526698621], "final_y": [0.12087790995025305, 0.11167912520714118, 0.11022049670564471]}, "mutation_prompt": null}
{"id": "96ec0d4c-f53e-46da-ae9a-d799456a098f", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 0.8), \n                                           self.noise_factor * (adaptive_factor ** 0.8), np.random.randint(1, current_dim + 1))  # Enhanced noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity with stochastic layer sampling and dynamic noise adaptation.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,) (7,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,) (7,) (10,) ')", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {}, "mutation_prompt": null}
{"id": "79873a8b-1bd6-42dd-85e1-19982e649742", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 1.9 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence by fine-tuning velocity updates and reducing noise factor for improved precision.", "configspace": "", "generation": 85, "fitness": 0.9214642621530947, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9185382328691778, 0.9157633812024977, 0.9300911723876089], "final_y": [0.11069336616782854, 0.11622534051222166, 0.11209270022939766]}, "mutation_prompt": null}
{"id": "eca5530c-6629-48ad-8fc3-c8768c347ce1", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  \n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Adjusted noise factor for exploration\n        self.layer_increment = max(1, dim // 4)  \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  \n        phase_change2 = self.budget // 2  \n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  \n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  \n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.55 + 0.03 * adaptive_factor  # Modified learning rate for balance\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Gaussian noise for precision\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance global and local search balance using adaptive learning rates and refined noise strategies.", "configspace": "", "generation": 86, "fitness": 0.9218111368648582, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9070047750162334, 0.9223159893442849, 0.9361126462340561], "final_y": [0.11686759579006645, 0.11164708288111735, 0.10968275480748158]}, "mutation_prompt": null}
{"id": "c006965a-32f7-4fb3-a0d0-73915fab1707", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.9 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance algorithm efficiency by refining noise adaptation and cognitive coefficient strategy.", "configspace": "", "generation": 87, "fitness": 0.9284091832694413, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.004. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.93037395664068, 0.923414390197175, 0.9314392029704692], "final_y": [0.10999251981007929, 0.11173085709722619, 0.1121279496273101]}, "mutation_prompt": null}
{"id": "ce2f73f4-28e4-4c75-b23d-e8108d9787ff", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 14 + 2 * int(np.sqrt(dim))  # Slightly increased population size for better exploration\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.5),  # Adjusted noise reduction\n                                           self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing dynamic noise reduction and a slightly increased population size for robust exploration.", "configspace": "", "generation": 88, "fitness": 0.911967310449052, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.905700524574737, 0.9031250157265894, 0.9270763910458297], "final_y": [0.11723477372606506, 0.11632699751800601, 0.11056376948617552]}, "mutation_prompt": null}
{"id": "b3982056-c719-489f-b4a5-eaf5c5ba9258", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.5), \n                                           self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Adaptive noise decay\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce adaptive noise decay to enhance convergence precision.", "configspace": "", "generation": 89, "fitness": 0.9293159103122558, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9244467907418429, 0.9254372844135145, 0.9380636557814102], "final_y": [0.11060901196650486, 0.11164060459422764, 0.10998889431263925]}, "mutation_prompt": null}
{"id": "a4289e92-5006-4308-ba4a-c5d532fc6875", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = int(self.budget * 0.3)  # Adjusted phase change\n        phase_change2 = int(self.budget * 0.6)  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.1 * adaptive_factor  # Further lowered inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence by tweaking parameter adaptation and refine phase transition strategy for balanced exploration and exploitation.", "configspace": "", "generation": 90, "fitness": 0.9192466027893528, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.022. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8886614799668997, 0.9279641304168695, 0.9411141979842891], "final_y": [0.12093019646387881, 0.1117046043290646, 0.10999597555693663]}, "mutation_prompt": null}
{"id": "aa8ea877-01e6-4151-9848-634d65fc644c", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for stability\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.1 * adaptive_factor  # Adjusted inertia for improved convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and convergence stability by optimizing inertia weight and noise factor.", "configspace": "", "generation": 91, "fitness": 0.9187065977366159, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.022. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8889218256028606, 0.92751726832252, 0.9396806992844668], "final_y": [0.12086552867316269, 0.11169266348406581, 0.11021871439676778]}, "mutation_prompt": null}
{"id": "7e3f7346-aef6-42d1-9141-ea53012bacdd", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03\n        self.layer_increment = max(1, dim // 4)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4\n        phase_change2 = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.2 * adaptive_factor  # Adjusted inertia for dynamic change\n            cognitive_coeff = 1.5 if evaluations < global_best_value else 1.35  # Dynamic cognitive based on performance\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence through dynamic inertia and cognitive coefficient adaptation based on performance metrics.", "configspace": "", "generation": 92, "fitness": 0.922543643455532, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9183373800966957, 0.9221628779489127, 0.9271306723209871], "final_y": [0.11086490313070618, 0.11232309765702153, 0.11212668344137988]}, "mutation_prompt": null}
{"id": "ef4ea08a-f063-4a3c-abc8-e80238d6d2b9", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Changed noise factor for better balance between exploration and precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance exploration and convergence by adjusting noise factor and dynamic velocity adaptation.", "configspace": "", "generation": 93, "fitness": 0.9284018550540916, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9243506801662517, 0.9240005471363995, 0.9368543378596237], "final_y": [0.11069156804581326, 0.11185274196286787, 0.11004212805777713]}, "mutation_prompt": null}
{"id": "d8424fca-630f-47db-a45d-c8a3aaea9760", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 5)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Normal noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance local search efficiency with adaptive layer transition and refined noise adjustment.", "configspace": "", "generation": 94, "fitness": 0.9025509320959889, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8881164382260336, 0.8953053784295287, 0.9242309796324041], "final_y": [0.11650244427425716, 0.11595628222668708, 0.11002813014732593]}, "mutation_prompt": null}
{"id": "09470df5-0034-4daf-9d14-e71e866431a5", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2) * (current_dim / self.dim), \n                                           self.noise_factor * (adaptive_factor ** 1.2) * (current_dim / self.dim), current_dim)  # Enhanced noise adaptation\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Introduce enhanced noise adaptation based on both evaluation progress and dimensionality to improve solution diversity.", "configspace": "", "generation": 95, "fitness": 0.9293193220535239, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9244736881576163, 0.9254752316942276, 0.9380090463087277], "final_y": [0.1105984082299527, 0.11164161632748737, 0.1099947402304634]}, "mutation_prompt": null}
{"id": "5f2a8d8a-c263-4e82-957e-dfb5dd69643e", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.03  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                differential_perturbation = 0.1 * (global_best - swarm[i]) * adaptive_factor  # New differential perturbation\n                swarm[i][:current_dim] += noise + differential_perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance adaptive exploration and convergence by introducing differential perturbations and dynamic layer scaling.", "configspace": "", "generation": 96, "fitness": 0.9284933546968501, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.008. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9178718860044105, 0.9374565844363489, 0.9301515936497909], "final_y": [0.10983062346570605, 0.10961042415926903, 0.11016165758240282]}, "mutation_prompt": null}
{"id": "78d24807-8237-4849-8c41-366f326db5cd", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05  # Increased noise factor for enhanced diversity\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Gaussian noise for more dynamic exploration\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and exploitation through adjusted noise factor and refined velocity updates.", "configspace": "", "generation": 97, "fitness": 0.9002581807593377, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8887834974645143, 0.8885694077296484, 0.9234216370838505], "final_y": [0.11840407061169933, 0.11714769765443267, 0.11038741231531157]}, "mutation_prompt": null}
{"id": "8bdde503-59c5-47cc-a04f-332b2447c260", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Further reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.8 if evaluations < phase_change1 else 1.35  # Tweaked cognitive coefficient\n            social_coeff = 2.05 if evaluations < phase_change2 else 2.1  # Slightly adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.2), \n                                           self.noise_factor * (adaptive_factor ** 1.2), current_dim)  # Uniform noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence rate by fine-tuning noise factor dynamics and adjusting the social coefficient for improved precision.", "configspace": "", "generation": 98, "fitness": 0.919678707547785, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9108336456725262, 0.9199313524179867, 0.9282711245528423], "final_y": [0.11210924118384213, 0.10970723925202708, 0.1121615037177578]}, "mutation_prompt": null}
{"id": "5667bc1f-dd57-4bb0-a846-7599cf5447d6", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Slightly increased population size\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.02  # Reduced noise factor for precision\n        self.layer_increment = max(1, dim // 4)  # Modified increment for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4  # Introduce additional phase change\n        phase_change2 = self.budget // 2  # Adjusted second phase transition\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.15 * adaptive_factor  # Lower inertia for quicker convergence\n            cognitive_coeff = 1.85 if evaluations < phase_change1 else 1.3  # Tweaked cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor  # Adjusted learning rate\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.uniform(-self.noise_factor * (adaptive_factor ** 1.5), \n                                           self.noise_factor * (adaptive_factor ** 1.5), current_dim)  # Nonlinear noise for diversity\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Enhance convergence speed and solution robustness by refining velocity adjustments and introducing nonlinear noise dynamics.", "configspace": "", "generation": 99, "fitness": 0.9282421704033957, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.9246785368971321, 0.9238645028310812, 0.9361834714819737], "final_y": [0.11019252670929669, 0.11168319921362058, 0.11039698705874768]}, "mutation_prompt": null}
{"id": "b2d314ba-d5bd-4b7f-b008-56a2fe56969b", "solution": "import numpy as np\n\nclass DualPhaseAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.04  # Increased noise factor for enhanced exploration\n        self.layer_increment = max(1, dim // 4)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        phase_change1 = self.budget // 4\n        phase_change2 = self.budget // 2\n\n        while evaluations < self.budget:\n            current_dim = min(self.dim, ((evaluations // self.layer_increment) + 1) * self.layer_increment)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.1 * adaptive_factor\n            cognitive_coeff = 1.9 if evaluations < phase_change1 else 1.35  # Slightly increased cognitive coefficient\n            social_coeff = 2.0 if evaluations < phase_change2 else 2.1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(current_dim), np.random.random(current_dim)\n                learning_rate = 0.5 + 0.03 * adaptive_factor\n                self.velocity[i][:current_dim] = (inertia_weight * self.velocity[i][:current_dim] +\n                                                  cognitive_coeff * r1 * (personal_best[i][:current_dim] - swarm[i][:current_dim]) +\n                                                  social_coeff * r2 * (global_best[:current_dim] - swarm[i][:current_dim]))\n                swarm[i][:current_dim] += learning_rate * self.velocity[i][:current_dim]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                noise = np.random.normal(0, self.noise_factor * (adaptive_factor ** 1.1), current_dim)  # Normal distribution for noise adaptation\n                swarm[i][:current_dim] += noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "DualPhaseAdaptiveSwarmGradientDescent", "description": "Refine exploration by enhancing cognitive diversity and improving noise adaptation techniques.", "configspace": "", "generation": 100, "fitness": 0.909831961763007, "feedback": "The algorithm DualPhaseAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05e754ea-0ac5-4b11-a1d4-1fa097649fbf", "metadata": {"aucs": [0.8989706702292813, 0.8992527270369591, 0.9312724880227802], "final_y": [0.1159225757169019, 0.11677574273323099, 0.1099165951536013]}, "mutation_prompt": null}
