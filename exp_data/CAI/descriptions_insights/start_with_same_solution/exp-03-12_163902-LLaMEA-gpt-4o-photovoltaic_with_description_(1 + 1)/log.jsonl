{"id": "c0cf1cc2-29ef-4877-9f95-ddf92add0fe8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "2f06ca4d-c541-41a5-9ef7-314a42094b84", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic social coefficient adjustment based on exploration-exploitation balance to improve convergence.", "configspace": "", "generation": 1, "fitness": 0.8038003386860915, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.020. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "c0cf1cc2-29ef-4877-9f95-ddf92add0fe8", "metadata": {"aucs": [0.7913517045042786, 0.8314856618081978, 0.7885636497457982], "final_y": [0.15856616082129305, 0.1278073033971484, 0.15547358674618972]}, "mutation_prompt": null}
{"id": "4508acca-333a-45a0-a3d3-d03ecfc94839", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces hybrid velocity update using differential evolution to improve convergence and exploration.", "configspace": "", "generation": 2, "fitness": 0.8344295984992821, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.028. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c0cf1cc2-29ef-4877-9f95-ddf92add0fe8", "metadata": {"aucs": [0.7991290527832564, 0.8373081048161449, 0.8668516378984447], "final_y": [0.14065898522140285, 0.13688312145234316, 0.12137364422809094]}, "mutation_prompt": null}
{"id": "1843e0c9-3760-4998-b4c6-b8584abe09bc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) with adjusted inertia weight for improved convergence and exploration balance.", "configspace": "", "generation": 3, "fitness": 0.8246425833158794, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.017. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4508acca-333a-45a0-a3d3-d03ecfc94839", "metadata": {"aucs": [0.8014559910583832, 0.8311802123579763, 0.8412915465312787], "final_y": [0.1490047248206372, 0.14362665776211758, 0.14316993523807386]}, "mutation_prompt": null}
{"id": "20c70db0-6731-4b46-9637-99f09c3dede7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        # mutation_factor = 0.8\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            mutation_factor = 0.5 + 0.3 * adaptive_factor  # Dynamic mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic mutation factor to improve diversity and enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.8337021865383383, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.016. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "4508acca-333a-45a0-a3d3-d03ecfc94839", "metadata": {"aucs": [0.8172018488310774, 0.8282447636910121, 0.8556599470929251], "final_y": [0.13726773504042056, 0.14806607901533475, 0.12677336464511813]}, "mutation_prompt": null}
{"id": "dc6176b2-980e-4344-9055-a263d1696d08", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces a small stochastic perturbation to the global best to enhance diversity and avoid local optima.", "configspace": "", "generation": 5, "fitness": 0.8670410163171306, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.015. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4508acca-333a-45a0-a3d3-d03ecfc94839", "metadata": {"aucs": [0.8677925580786797, 0.8481806575578379, 0.8851498333148742], "final_y": [0.12005796100441612, 0.12697377446910607, 0.12060338998319409]}, "mutation_prompt": null}
{"id": "6b2657ef-7360-4090-ab48-934a91f0baf4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            mutation_factor = 0.5 + 0.5 * adaptive_factor  # Dynamic mutation factor adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved balance between exploration and exploitation by dynamic mutation factor adjustment.", "configspace": "", "generation": 6, "fitness": 0.862844991452795, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.010. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "dc6176b2-980e-4344-9055-a263d1696d08", "metadata": {"aucs": [0.8618436235819408, 0.8515728039847213, 0.8751185467917229], "final_y": [0.12630300450998488, 0.12903911283074654, 0.11659482358180429]}, "mutation_prompt": null}
{"id": "d09490ea-27e0-4a4c-aec4-638362d69ce4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Adaptive Mutation: Introduces an adaptive mutation factor to improve convergence speed and solution accuracy.", "configspace": "", "generation": 7, "fitness": 0.8718163127537076, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dc6176b2-980e-4344-9055-a263d1696d08", "metadata": {"aucs": [0.8592092840982756, 0.8688400660025202, 0.887399588160327], "final_y": [0.12749572959418742, 0.11891297310659044, 0.1133570738523555]}, "mutation_prompt": null}
{"id": "9108ee41-b0b1-4d51-9c4d-6d879941060c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Adaptive Mutation and Dynamic Adjustment: Adds dynamic adjustment of cognitive coefficient to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.87234408680232, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d09490ea-27e0-4a4c-aec4-638362d69ce4", "metadata": {"aucs": [0.8688132377172262, 0.8558777174841927, 0.8923413052055413], "final_y": [0.11621150014531745, 0.1284324577243089, 0.11501916295466774]}, "mutation_prompt": null}
{"id": "a0134258-8ce6-4156-b5db-cf86a4b0cceb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * (1 - adaptive_factor**2)  # Slight change in decay function\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  \n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  \n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Utilizes an adaptive mutation factor based on a decay function to enhance exploration capabilities. ", "configspace": "", "generation": 9, "fitness": 0.865291747295294, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9108ee41-b0b1-4d51-9c4d-6d879941060c", "metadata": {"aucs": [0.8659985058326971, 0.8571390123520205, 0.8727377237011643], "final_y": [0.12068047530803061, 0.12396573603685745, 0.1167378084061853]}, "mutation_prompt": null}
{"id": "72f113b4-fbc3-474d-877f-40eb7ca21338", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Improved Global Best Stochastic Perturbation: Refines the stochastic perturbation for better global best exploration.", "configspace": "", "generation": 10, "fitness": 0.8746728514268215, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9108ee41-b0b1-4d51-9c4d-6d879941060c", "metadata": {"aucs": [0.8760634392830902, 0.8556951743234458, 0.8922599406739284], "final_y": [0.1166909940236005, 0.1207862990749885, 0.1150887435069543]}, "mutation_prompt": null}
{"id": "bac7e200-b165-436b-b699-81f7301c0a46", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Improved noise-resilient update\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Noise-Resilient Update: Incorporates a noise-resilient update mechanism to improve convergence under noisy conditions.", "configspace": "", "generation": 11, "fitness": 0.87234408680232, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72f113b4-fbc3-474d-877f-40eb7ca21338", "metadata": {"aucs": [0.8688132377172262, 0.8558777174841927, 0.8923413052055413], "final_y": [0.11621150014531745, 0.1284324577243089, 0.11501916295466774]}, "mutation_prompt": null}
{"id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Adaptive Inertia Weight Ceiling: Introduces a dynamic cap for inertia weight based on evaluations for improved convergence stability.", "configspace": "", "generation": 12, "fitness": 0.9017493114134552, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72f113b4-fbc3-474d-877f-40eb7ca21338", "metadata": {"aucs": [0.8860580547053664, 0.9011909691980816, 0.9179989103369175], "final_y": [0.11657540284454049, 0.11727224343598175, 0.11374996941027282]}, "mutation_prompt": null}
{"id": "45ace673-d737-4948-97e4-d38434883672", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor + np.random.normal(0, 0.01)  # Adaptive mutation factor with small random offset\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent by introducing a small random offset to mutation factor for increased exploration.", "configspace": "", "generation": 13, "fitness": 0.8717217050346969, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.017. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8496301513331086, 0.8746693648061241, 0.8908655989648582], "final_y": [0.13479416185053672, 0.12183983224347716, 0.12205851179713134]}, "mutation_prompt": null}
{"id": "959c4814-7f19-4b9f-8044-60539a879260", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i] * (0.5 + 0.5 * adaptive_factor)  # Adaptive velocity scaling\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Improved Exploration Strategy: Introduces chaotic initialization and adaptive velocity scaling for dynamic exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8939249921613087, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.020. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8680271897443754, 0.8959336065441625, 0.917814180195388], "final_y": [0.12932482496024955, 0.11948757355839212, 0.11359884558685518]}, "mutation_prompt": null}
{"id": "45ede60d-6dc5-4d27-97ed-d3b69e625979", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Hybrid Swarm Algorithm with Adaptive Perturbation: Enhances adaptive inertia and mutation factors with dynamic perturbation for improved exploration stability.", "configspace": "", "generation": 15, "fitness": 0.9017261307654421, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8860631969617015, 0.901176795780866, 0.9179383995537589], "final_y": [0.11657781673937162, 0.11725881572859687, 0.11380232207260566]}, "mutation_prompt": null}
{"id": "6ccbb915-e180-4949-92e5-25af176b037d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.7  # Increased social coefficient for a stronger attraction to global best\n            mutation_factor = 0.7 + 0.4 * adaptive_factor  # Enhanced adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Improved Mutation Strategy: Incorporates a refined mutation mechanism and adjusts coefficients for better exploration and convergence balance.", "configspace": "", "generation": 16, "fitness": 0.892657915329087, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8693496684533956, 0.8981543129271177, 0.9104697646067478], "final_y": [0.12567559232933345, 0.12072748047745252, 0.11325405384768894]}, "mutation_prompt": null}
{"id": "6eb6593d-d9fe-4fc4-aefb-8b7e626a3fe9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.5 + 0.5 * adaptive_factor)  # Adjusted adaptive inertia weight\n            cognitive_coeff = 1.6 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.4  # Adjusted social coefficient\n            mutation_factor = 0.7 + 0.3 * adaptive_factor  # Adjusted adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # New stochastic learning from a random individual\n                random_individual = swarm[np.random.randint(0, self.population_size)]\n                \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) +\n                                    0.1 * (random_individual - swarm[i]))  # Added stochastic influence\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with Adaptive Mutation and Stochastic Learning: Introduces a dynamic inertia weight and adaptive mutation coefficient along with learning from random individuals for improved exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.9009978734513192, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8901097055253853, 0.9058196707517424, 0.9070642440768301], "final_y": [0.11511069835597565, 0.11862215981489954, 0.11353806944303257]}, "mutation_prompt": null}
{"id": "1916f6a6-b23b-48ac-8e26-72b8bd9bd40b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n        reset_threshold = 0.95  # Periodic reset threshold\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                # Periodic reset of global best to avoid stagnation\n                if evaluations % int(self.budget * reset_threshold) == 0:\n                    global_best = np.random.uniform(lb, ub, self.dim)\n                    global_best_value = func(global_best)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Hybrid Swarm Gradient Descent with Reinforced Global Best Update introduces a periodic reset mechanism to restart stagnated global best positions, ensuring exploration and avoiding premature convergence.", "configspace": "", "generation": 18, "fitness": 0.9017013936783852, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8859920167950937, 0.9011263127406008, 0.9179858514994611], "final_y": [0.11699822043586394, 0.11818555201749015, 0.11387219064773191]}, "mutation_prompt": null}
{"id": "bf9b5713-ec68-4a8b-a99a-2468fc1a9374", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.5 + 0.3 * adaptive_factor  # Adjusted adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.15 * (mutant_vector - swarm[i]))  # Enhanced hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.03, self.dim)  # Amplified stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Swarm with Time-variant Mutation and Stochastic Global Exploration: Introduces dynamic mutation and global exploration adjustments to improve convergence speed and solution quality.", "configspace": "", "generation": 19, "fitness": 0.8966880374473579, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8845789173606982, 0.9013070552536001, 0.9041781397277757], "final_y": [0.1165475816446151, 0.11717315696383945, 0.11540024937497406]}, "mutation_prompt": null}
{"id": "83160b4e-4a80-4044-b1d7-78a1a5262b43", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + 0.5 * (global_best - swarm[i])  # Enhanced adaptive mutation scaling\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhance the algorithm with an adaptive mutation scaling based on the best individual's progress, improving exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.8810225394035114, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.042. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8226630572995662, 0.8994483388241469, 0.9209562220868212], "final_y": [0.13615709145389077, 0.11676288119225653, 0.11367200386674936]}, "mutation_prompt": null}
{"id": "b6785dc7-236e-4a46-8eb2-318646da8521", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5 * (1 + 0.1 * np.sin(evaluations))  # Dynamic social coefficient modulation\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Adaptive Hybrid Gradient Descent with Dynamic Social Influence Modulation: Introduces a dynamic social coefficient to balance exploration and exploitation based on evaluation progress.", "configspace": "", "generation": 21, "fitness": 0.895919277773393, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8887920881313445, 0.8967523170005292, 0.9022134281883054], "final_y": [0.11819442298416472, 0.11998006200121303, 0.11582507027752553]}, "mutation_prompt": null}
{"id": "ba87cb7f-565e-4551-83d2-e7bb5aabac6d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.3 * np.sin(evaluations))  # Oscillating cognitive coefficient\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Cognitive-Coefficient: Introduces oscillating cognitive coefficient to balance exploration-exploitation.", "configspace": "", "generation": 22, "fitness": 0.8934578840147687, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.005. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8990774939216291, 0.8879821742287576, 0.893313983893919], "final_y": [0.1126819233607046, 0.1199268156279778, 0.11490658758351713]}, "mutation_prompt": null}
{"id": "aebb79a2-c68a-4cae-9b71-6842cfb9eb6a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Improved Stochasticity: Integrates sophisticated noise reduction in stochastic perturbation for refined global best updates.", "configspace": "", "generation": 23, "fitness": 0.9017261307654421, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8860631969617015, 0.901176795780866, 0.9179383995537589], "final_y": [0.11657781673937162, 0.11725881572859687, 0.11380232207260566]}, "mutation_prompt": null}
{"id": "8b970f19-e625-4d44-abbf-4684adfd6c86", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Secondary mutation strategy\n                if np.random.rand() < 0.1:\n                    mutant_vector = lb + np.random.rand(self.dim) * (ub - lb)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dual Mutation Strategies: Introduces a secondary mutation strategy for increased exploration to improve global search performance.", "configspace": "", "generation": 24, "fitness": 0.8758076562593597, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8477118058029727, 0.8724462558853388, 0.9072649070897676], "final_y": [0.1328402075196624, 0.12755951430225831, 0.11481323679090039]}, "mutation_prompt": null}
{"id": "e5c47333-5374-444d-ae45-9f02fd347e05", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) +\n                                    np.random.normal(0, 0.01 * adaptive_factor, self.dim))  # Adaptive noise injection\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Adaptive Velocity Noise Injection: Improves exploration by incorporating adaptive noise in velocity updates.", "configspace": "", "generation": 25, "fitness": 0.8791907064196046, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.017. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8556463440753037, 0.8900015597386768, 0.8919242154448336], "final_y": [0.1298205029736056, 0.11981635993931838, 0.11493135601900917]}, "mutation_prompt": null}
{"id": "1ed80120-95a5-47f8-a3a8-7bd5071d0c07", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5 * (1 - adaptive_factor)  # Dynamic social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Social Coefficient: Introduces a time-varying social coefficient to balance exploration and exploitation over the course of optimization.", "configspace": "", "generation": 26, "fitness": 0.8842922200450386, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.869624228295741, 0.8913777632356914, 0.8918746686036835], "final_y": [0.117852699903362, 0.11682830202579975, 0.11077286062907254]}, "mutation_prompt": null}
{"id": "98b27b1d-fda6-459a-a773-ae9a511aad67", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with neighborhood-induced perturbation\n                if f_value < global_best_value:\n                    global_best = np.mean(swarm[np.random.choice(self.population_size, 5, replace=False)], axis=0)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Neighborhood-based Mutation: Utilizes a neighborhood-induced perturbation for adaptable exploration and enhanced convergence.", "configspace": "", "generation": 27, "fitness": 0.8338909653470793, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.009. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8451280892096006, 0.833114398058876, 0.8234304087727612], "final_y": [0.13280420544088178, 0.14578704532319342, 0.13281126069156557]}, "mutation_prompt": null}
{"id": "676e7965-9291-4995-a3f4-fbc2ca074411", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            # Modify cognitive_coeff over time for exploration-exploitation balance\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a time-varying cognitive coefficient for enhanced exploration-exploitation balance in the swarm.", "configspace": "", "generation": 28, "fitness": 0.9033544382730626, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ac615b3-1e68-40c9-bd93-8bb8a8fd2d74", "metadata": {"aucs": [0.8923110841382744, 0.9042576241086469, 0.9134946065722667], "final_y": [0.1196382275332224, 0.11732506094637407, 0.11400931830981298]}, "mutation_prompt": null}
{"id": "61c98c44-699d-48fa-8050-8970c466d5f0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  # Adaptive inertia weight with dynamic cap\n            # Modify cognitive_coeff over time for exploration-exploitation balance\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5 * (1 + 0.1 * np.cos(evaluations))  # Adaptive social coefficient\n            mutation_factor = 0.6 + 0.3 * adaptive_factor  # Dynamic mutation factor adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Differential evolution-inspired update\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces adaptive social coefficient and dynamic mutation factor adjustment to enhance swarm convergence.", "configspace": "", "generation": 29, "fitness": 0.9029600181905449, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.017. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "676e7965-9291-4995-a3f4-fbc2ca074411", "metadata": {"aucs": [0.9133612885834234, 0.8792957164888949, 0.9162230494993165], "final_y": [0.11326966311750086, 0.12358224253140171, 0.11129020202950823]}, "mutation_prompt": null}
{"id": "d9393d58-e5c8-4b2c-9b17-2d9bea7ae842", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor)  \n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Introduce dynamic scaling of velocity for improved convergence\n                velocity_scaling = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] *= velocity_scaling\n                self.velocity[i] += (inertia_weight * np.random.random() * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  \n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances swarm navigation with dynamic velocity scaling and selective inertia reduction for improved global search convergence.", "configspace": "", "generation": 30, "fitness": 0.8051045506473081, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.032. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "676e7965-9291-4995-a3f4-fbc2ca074411", "metadata": {"aucs": [0.7615524441677023, 0.8150533501368321, 0.8387078576373898], "final_y": [0.1613810954588203, 0.1262699233080593, 0.13481951057820596]}, "mutation_prompt": null}
{"id": "eaca6869-6067-4236-84d9-c83ac608dfe3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a non-linear decay in the inertia weight to enhance convergence speed.", "configspace": "", "generation": 31, "fitness": 0.9044323905985809, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "676e7965-9291-4995-a3f4-fbc2ca074411", "metadata": {"aucs": [0.8937250048692719, 0.9054631352436322, 0.9141090316828391], "final_y": [0.11941613484258384, 0.11628704036664395, 0.1137720885650636]}, "mutation_prompt": null}
{"id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates adaptive learning rates for velocity update to improve convergence precision.", "configspace": "", "generation": 32, "fitness": 0.9126072881562447, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "eaca6869-6067-4236-84d9-c83ac608dfe3", "metadata": {"aucs": [0.8967250518342327, 0.9133486966953043, 0.9277481159391971], "final_y": [0.11796785282477695, 0.11622367951499923, 0.11219124278786885]}, "mutation_prompt": null}
{"id": "5fa249e7-7056-4207-8829-f751ad7d2922", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.75 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Utilizes a slightly increased mutation factor to enhance exploration capabilities.", "configspace": "", "generation": 33, "fitness": 0.9074539962703634, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8890285038390059, 0.9097480189265027, 0.9235854660455813], "final_y": [0.11937853599363013, 0.11622096179850694, 0.1121037673759534]}, "mutation_prompt": null}
{"id": "f9d0174c-ebf4-4c52-8fdc-f27762fbc31d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.initial_population = self.population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n            \n            # Adaptive swarm size\n            self.population_size = self.initial_population + int(5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Stochastic gradient perturbation\n                gradient_noise = np.random.normal(0, 0.01 * adaptive_factor, self.dim)\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) + gradient_noise)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Incorporates an adaptive swarm size strategy and stochastic gradient perturbation to enhance exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 16')", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {}, "mutation_prompt": null}
{"id": "48ed94d4-2201-4c15-900c-25087845b3dc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * (inertia_weight + np.random.uniform(-0.1, 0.1)) * self.velocity[i] +  # Stochastic adjustment\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces stochastic inertia weight variation to enhance exploration and exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.8883910286235556, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.045. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8267654124081358, 0.9055114003561615, 0.9328962731063694], "final_y": [0.14459358490825047, 0.11623399445013616, 0.11000893826600155]}, "mutation_prompt": null}
{"id": "03237053-1829-4f4b-ba7b-821de4799ef0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * 0.1))  # Refined perturbation\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.12 * (mutant_vector - swarm[i]))  # Adjusted hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances convergence by refining mutation logic and incorporating adaptive exploration.", "configspace": "", "generation": 36, "fitness": 0.906039910846297, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8821299988278619, 0.9119168608810467, 0.9240728728299822], "final_y": [0.12079494456119455, 0.11623125230740705, 0.11233574843602168]}, "mutation_prompt": null}
{"id": "736a1716-c0c2-4a4e-8189-b9a4efcb003a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))  # Changed sin to cos\n            social_coeff = 1.5 + 0.5 * adaptive_factor**2  # Non-linear social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates non-linear cognitive and social coefficients for improved exploration and exploitation balance.", "configspace": "", "generation": 37, "fitness": 0.884505666349488, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.011. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8701411399105758, 0.8959401944491134, 0.8874356646887747], "final_y": [0.12059148731304303, 0.11625992417410025, 0.11995872635521265]}, "mutation_prompt": null}
{"id": "d1003503-b222-4712-b94b-71a6be2b9ed3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.4 + 0.6 * (1 - np.mean(personal_best_value) / global_best_value)  # Dynamic adaptation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a dynamic mutation factor adaptation based on the improvement trajectory for enhanced exploration capabilities.", "configspace": "", "generation": 38, "fitness": 0.9019404452889509, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.011. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.9130844555594326, 0.9050805966811258, 0.8876562836262945], "final_y": [0.11546033873437289, 0.11684289121057656, 0.121636489235875]}, "mutation_prompt": null}
{"id": "d17f989d-038e-47ec-afaf-e138dccd2095", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations))  # Use cosine for dynamic behavior\n            social_coeff = 1.5\n            mutation_factor = 0.7 + 0.3 * adaptive_factor  # Adjust mutation factor for better exploration\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced a dynamic cognitive coefficient and adaptive mutation scale for improved exploration and exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.9065506461245713, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.005. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8998042408256429, 0.906909825196429, 0.9129378723516418], "final_y": [0.11563786237983453, 0.11939021861838206, 0.11221440856442677]}, "mutation_prompt": null}
{"id": "f1f96a3d-2920-44fb-89f5-1d7c0f3a42dc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02 * adaptive_factor, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances stochastic perturbation by integrating a dynamic noise factor to boost exploration.", "configspace": "", "generation": 40, "fitness": 0.9124019308601019, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8966966574161487, 0.9130171725158125, 0.9274919626483442], "final_y": [0.11795766483102199, 0.1162300440173113, 0.11220527186191365]}, "mutation_prompt": null}
{"id": "6c1b9648-432c-43ee-abf5-e091fecf3a02", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.15 * (mutant_vector - swarm[i]))  # Refined hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances convergence with refined hybrid update and improved stochastic perturbation.", "configspace": "", "generation": 41, "fitness": 0.8953634332963046, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8828723255124938, 0.9040906561559525, 0.8991273182204672], "final_y": [0.12396769500102789, 0.11623268687928989, 0.11604727295368322]}, "mutation_prompt": null}
{"id": "3cf75924-6190-49ff-9f78-7d217325954f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations) + np.random.normal(0, 0.05))  # Added stochastic perturbation\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a stochastic perturbation in cognitive coefficient to enhance exploration during velocity update.", "configspace": "", "generation": 42, "fitness": 0.8906456911663643, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.017. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8671381669105824, 0.9051358117600282, 0.8996630948284822], "final_y": [0.12640444082904945, 0.11623890309215434, 0.12039316805402256]}, "mutation_prompt": null}
{"id": "ddf9a266-7642-4f31-b3d6-c7af7d63d84e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.sin(np.pi * adaptive_factor)  # Chaotic inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                local_best = personal_best[np.argmin(personal_best_value[np.unique(indices)])]\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (local_best - swarm[i]) +  # Dynamic neighborhood update\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces chaotic inertia weight and dynamic neighborhood topology to enhance exploration and exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.8566750792239762, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.011. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8553624036185586, 0.8438770752922773, 0.8707857587610928], "final_y": [0.1244317614250402, 0.12683643418895085, 0.11534158824603336]}, "mutation_prompt": null}
{"id": "c0d440fd-fdb7-4609-a721-cf20bef5fcc1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.8 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  # Modified cognitive coefficient\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances exploration by adjusting cognitive coefficient for better convergence.", "configspace": "", "generation": 44, "fitness": 0.9046034020509864, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.8944201286552466, 0.9035083541862902, 0.9158817233114227], "final_y": [0.12217841425087905, 0.1162374403375942, 0.11143763651997851]}, "mutation_prompt": null}
{"id": "4ea4043f-1db2-45ab-a015-863499411e77", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5 * adaptive_factor  # Adaptive social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces an adaptive social coefficient to enhance swarm cohesion and convergence precision.", "configspace": "", "generation": 45, "fitness": 0.9069744722640349, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.9028007093542633, 0.8916708541890891, 0.9264518532487527], "final_y": [0.11463318710659909, 0.125352489181215, 0.11221580496820815]}, "mutation_prompt": null}
{"id": "5ec7ad62-053b-4aa2-9fcf-4f1cb17bc22f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    chaotic_factor = np.sin(10 * evaluations) * 0.02  # Chaotic perturbation\n                    global_best = swarm[i] + np.random.normal(0, chaotic_factor, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Incorporates chaotic perturbation for enhanced diversity and convergence in solution space.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {}, "mutation_prompt": null}
{"id": "14bc3192-8104-4686-a7db-e9439269c9a1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations))  \n            social_coeff = 1.5 * adaptive_factor \n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.05, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing adaptive cognitive and social coefficients along with a stochastic global perturbation.", "configspace": "", "generation": 47, "fitness": 0.9061870662599105, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.9019860330948742, 0.8917359056675989, 0.9248392600172586], "final_y": [0.11538696751772504, 0.12531551216616532, 0.11253477070158957]}, "mutation_prompt": null}
{"id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a more dynamic cognitive coefficient using a sine-based adaptive factor to enhance exploration.", "configspace": "", "generation": 48, "fitness": 0.9169472080535409, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "eb93f97f-dcf9-4cd8-9cbb-290063564e17", "metadata": {"aucs": [0.9123612404329001, 0.9103597455732144, 0.9281206381545082], "final_y": [0.11166650191255756, 0.1162244722403436, 0.11213267945867633]}, "mutation_prompt": null}
{"id": "35d65659-ee0f-4868-aadd-e21c40dfa514", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))\n            social_coeff = 1.5 + 0.5 * np.random.random()  # Time-varying stochastic social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.2 * (mutant_vector - swarm[i]))  # Increased hybrid mutation factor\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces stochastic time-varying adaptive coefficients and improved mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.8779970319592413, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.8592817263266834, 0.8891381481515737, 0.8855712213994668], "final_y": [0.13065138879928528, 0.11656233079491274, 0.11379612485048451]}, "mutation_prompt": null}
{"id": "2ac6d1cd-b83a-4ec9-b00b-1b3e637cc89f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            # social_coeff = 1.5\n            social_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.cos(evaluations * np.pi))  # Modified cosine-based adaptive factor\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a more dynamic social coefficient using a cosine-based adaptive factor to balance exploration and exploitation.", "configspace": "", "generation": 50, "fitness": 0.8973470401349477, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.019. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.8713191340311601, 0.9166886453661823, 0.9040333410075004], "final_y": [0.12548768100132335, 0.11624562682788986, 0.11485751101877972]}, "mutation_prompt": null}
{"id": "39b4db99-969e-4a3b-8b6b-b579ddc4943c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5 * (1 + 0.1 * np.cos(evaluations * np.pi / 3))  # Variable social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances global exploration by introducing a variable social coefficient that adapts based on the swarm's historical performance.", "configspace": "", "generation": 51, "fitness": 0.901225005401541, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.8854107585896394, 0.9030262022783165, 0.9152380553366675], "final_y": [0.11647428704777651, 0.11622776699177884, 0.11354862195041726]}, "mutation_prompt": null}
{"id": "28b651de-19f3-4155-93a5-d17eb557f209", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2 + 0.1 * np.sin(evaluations * np.pi / 10))  # Stochastic oscillation\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces stochastic inertia weight oscillation for enhanced exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.9157148937493673, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.9075964453878741, 0.910714567054101, 0.9288336688061268], "final_y": [0.11058941382933174, 0.1162266275037056, 0.11215334808833621]}, "mutation_prompt": null}
{"id": "347abc2d-eeb7-4098-9459-6c880660c790", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5 * adaptive_factor  # Refined dynamic social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a more dynamic cognitive coefficient using a sine-based adaptive factor to enhance exploration, now with a refined dynamic social coefficient for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.9153200967868426, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.9045595031505709, 0.912987974007015, 0.9284128132029418], "final_y": [0.11753948865622532, 0.11631572625595488, 0.11238960954642285]}, "mutation_prompt": null}
{"id": "3940d7e7-11f5-43a0-b6f5-593329ea1eef", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        # Additional swarm for diversity\n        secondary_swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Incorporates a dual-swarm approach with shared global best exploration to enhance solution diversity.", "configspace": "", "generation": 54, "fitness": 0.8911571685320997, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.021. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.8623941173588994, 0.9022426175053264, 0.9088347707320736], "final_y": [0.12687675303885126, 0.11629373914398677, 0.11196675436707826]}, "mutation_prompt": null}
{"id": "3aaec888-cf4a-494a-9257-505483a21ef8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a sine-based adaptive cognitive coefficient with improved perturbation to enhance exploration.", "configspace": "", "generation": 55, "fitness": 0.9170528141913135, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c091885f-4706-4f41-b579-e36dd0ae0a43", "metadata": {"aucs": [0.9126725169691575, 0.9103703503117113, 0.9281155752930716], "final_y": [0.11164265726137934, 0.11621865925440933, 0.11215231493955324]}, "mutation_prompt": null}
{"id": "5da5c6fc-e8d6-4e5c-957f-1cf82ffb76e2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = min(0.8, 0.7 + 0.3 * adaptive_factor**2)  # Non-linear decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02, self.dim)  # Improved stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Adjusts the stochastic perturbation to increase global exploration capability.", "configspace": "", "generation": 56, "fitness": 0.9169472080535409, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3aaec888-cf4a-494a-9257-505483a21ef8", "metadata": {"aucs": [0.9123612404329001, 0.9103597455732144, 0.9281206381545082], "final_y": [0.11166650191255756, 0.1162244722403436, 0.11213267945867633]}, "mutation_prompt": null}
{"id": "09cca654-4898-402d-a7ea-9397b0ff2b90", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive learning rate for velocity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim)  # Refined stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a dynamic inertia weight strategy and refined stochastic perturbation to enhance convergence and exploration balance.", "configspace": "", "generation": 57, "fitness": 0.9243715752574255, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3aaec888-cf4a-494a-9257-505483a21ef8", "metadata": {"aucs": [0.9235591213452433, 0.9249157538238095, 0.9246398506032241], "final_y": [0.11447278096182578, 0.1116716486400724, 0.11208458465770399]}, "mutation_prompt": null}
{"id": "26f85ada-07d3-4980-ade5-c04bc601772c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim)  # Refined stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances adaptive velocity factor with exponential decay to improve the balance between exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.9246160570443189, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "09cca654-4898-402d-a7ea-9397b0ff2b90", "metadata": {"aucs": [0.9238713428311527, 0.9223072090044048, 0.9276696192973997], "final_y": [0.11452615325350157, 0.11523428932194846, 0.11163084757423336]}, "mutation_prompt": null}
{"id": "00c6b8ea-8813-4dc7-94ff-5a018058ab40", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * adaptive_factor**2  # Quadratic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))\n            social_coeff = 1.2 + 0.6 * np.sqrt(adaptive_factor)  # Dynamic social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduce quadratic decay in inertia weight and dynamic social coefficients for enhanced convergence.", "configspace": "", "generation": 59, "fitness": 0.902009883178795, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.034. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "26f85ada-07d3-4980-ade5-c04bc601772c", "metadata": {"aucs": [0.8558632176121448, 0.9151917539445635, 0.9349746779796768], "final_y": [0.13415471578403693, 0.11622152711222211, 0.11196068150780347]}, "mutation_prompt": null}
{"id": "15cef79e-5756-45c7-8059-f33a795a4baf", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) + np.random.normal(0, 0.002, self.dim))  # Hybrid update with noise\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim) # Refined stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces adaptive mutation and stochastic velocity with Gaussian noise to enhance local search and global convergence.", "configspace": "", "generation": 60, "fitness": 0.8967823285728564, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.043. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "26f85ada-07d3-4980-ade5-c04bc601772c", "metadata": {"aucs": [0.8361707004007355, 0.9181053006746782, 0.9360709846431556], "final_y": [0.14207638604675898, 0.11624921812244104, 0.10973151360259015]}, "mutation_prompt": null}
{"id": "ea4aa028-b077-4476-b93b-0a43833c1458", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.6 + 0.4 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))\n            social_coeff = 1.5\n            mutation_factor = 0.5 + 0.5 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduce dynamic swarm size and adaptive learning rates for enhanced exploration-exploitation balance.", "configspace": "", "generation": 61, "fitness": 0.9167438102769331, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "26f85ada-07d3-4980-ade5-c04bc601772c", "metadata": {"aucs": [0.9225605908842345, 0.9037457167703847, 0.9239251231761799], "final_y": [0.11461657328402297, 0.121344791734322, 0.11196688961181733]}, "mutation_prompt": null}
{"id": "818ab78a-a885-42dd-b0cf-8fd075d3d4b9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.1 * np.sin(evaluations * np.pi / 2))  # Modified sine-based adaptive factor\n            social_coeff = 1.0 + adaptive_factor  # Adaptive social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005, self.dim)  # Refined stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Incorporates dynamic social coefficient adjustment based on evaluation count to enhance convergence and exploration balance.", "configspace": "", "generation": 62, "fitness": 0.9054392715318217, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.003. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "26f85ada-07d3-4980-ade5-c04bc601772c", "metadata": {"aucs": [0.9042284820223955, 0.9100482060750127, 0.9020411264980566], "final_y": [0.11466267927508489, 0.11901614478328404, 0.11894103493319563]}, "mutation_prompt": null}
{"id": "df03ed48-f611-4ab7-8af4-4ddbf3bb5eb4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.sin(evaluations * np.pi / 4))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Refined stochastic perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a stochastic exploration component and modifies the cognitive coefficient to improve search diversity and convergence.", "configspace": "", "generation": 63, "fitness": 0.9246315550369163, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "26f85ada-07d3-4980-ade5-c04bc601772c", "metadata": {"aucs": [0.923846612926088, 0.9224515419535222, 0.927596510231139], "final_y": [0.11455891508838023, 0.11524450295903899, 0.11165351445996763]}, "mutation_prompt": null}
{"id": "6c1f7eb0-299f-4144-8ef2-966fa7a09090", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.sin(evaluations * np.pi / 4))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a refined global best update by incorporating a dynamic Gaussian perturbation based on evaluation progress, enhancing both exploration and convergence.", "configspace": "", "generation": 64, "fitness": 0.9246432408594899, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "df03ed48-f611-4ab7-8af4-4ddbf3bb5eb4", "metadata": {"aucs": [0.9239006438971518, 0.9224158435645631, 0.9276132351167552], "final_y": [0.11445654647688686, 0.1152333646555197, 0.11163737148306563]}, "mutation_prompt": null}
{"id": "c28f5409-31d8-4059-a5cb-8edab1e95797", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.sin(evaluations * np.pi / 4))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    perturbation_scale = 0.05 * adaptive_factor  # Adjusted perturbation scale\n                    global_best = swarm[i] + np.random.normal(0, perturbation_scale, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Implements a refined perturbation strategy by adjusting the Gaussian perturbation's scale based on evaluations, optimizing exploration and convergence balance.", "configspace": "", "generation": 65, "fitness": 0.9191644892157745, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6c1f7eb0-299f-4144-8ef2-966fa7a09090", "metadata": {"aucs": [0.9232723716422567, 0.9085924973231344, 0.9256285986819324], "final_y": [0.11452468963099838, 0.12005710049614271, 0.11175422511104116]}, "mutation_prompt": null}
{"id": "32069d79-5b00-4d75-b475-a5086fe1fcf5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.sin(evaluations * np.pi / 4))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                # Introduce crossover mechanism\n                crossover_prob = 0.9 * adaptive_factor\n                for d in range(self.dim):\n                    if np.random.rand() > crossover_prob:\n                        swarm[i][d] = mutant_vector[d]  # Apply crossover\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a refined global best update by incorporating a dynamic Gaussian perturbation and adaptive crossover mechanism to enhance exploration and convergence.", "configspace": "", "generation": 66, "fitness": 0.863059055098835, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6c1f7eb0-299f-4144-8ef2-966fa7a09090", "metadata": {"aucs": [0.8842500203455523, 0.8592621967959558, 0.8456649481549964], "final_y": [0.12596701467763594, 0.1368661219608066, 0.1385779907020439]}, "mutation_prompt": null}
{"id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances exploration with a refined cognitive coefficient using an adaptive cosine-based mechanism.", "configspace": "", "generation": 67, "fitness": 0.9261872373453252, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6c1f7eb0-299f-4144-8ef2-966fa7a09090", "metadata": {"aucs": [0.9256875812430253, 0.936141292775908, 0.9167328380170422], "final_y": [0.11446661166697569, 0.11162798062868817, 0.11473610874049689]}, "mutation_prompt": null}
{"id": "864b5c14-695d-4984-af40-db7500f47892", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * (0.9 - 0.4 * np.sin(evaluations * np.pi / self.budget)) * self.velocity[i] +  # Sine-based stochastic inertia weight\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances exploration and exploitation by introducing a stochastic inertia weight through a sine-based adaptive mechanism.", "configspace": "", "generation": 68, "fitness": 0.9260426792396874, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.9208573604350815, 0.9302491337682595, 0.9270215435157214], "final_y": [0.11448269063199723, 0.11173573877082577, 0.11196182780896125]}, "mutation_prompt": null}
{"id": "2ddd819b-0078-4e2d-a2c3-b3b3d653db23", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.2 + 0.8 * np.sin(evaluations * np.pi / 6)  # Dynamic sinusoidal modulation for social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a dynamic social coefficient with sinusoidal modulation to enhance global convergence characteristics.", "configspace": "", "generation": 69, "fitness": 0.9053796118326862, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.027. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.8685850851638435, 0.9305845295805049, 0.9169692207537103], "final_y": [0.12624944697333218, 0.11164734226104411, 0.1148809468099905]}, "mutation_prompt": null}
{"id": "1d8600cc-361d-4898-bdac-99d0733aba78", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5 * np.exp(-adaptive_factor * 5)  # Temperature-dependent annealing in social coefficient\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refines social interaction by introducing temperature-dependent annealing in the social coefficient.", "configspace": "", "generation": 70, "fitness": 0.8342511428080771, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.8273509159943029, 0.8466990055721861, 0.8287035068577425], "final_y": [0.12279386062324016, 0.12206298502491353, 0.11270714505935864]}, "mutation_prompt": null}
{"id": "29f6ca05-33c8-4057-bbb1-ef9f56cc5c84", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**2  # Quadratic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-4 * adaptive_factor)  # Modified exponential decay\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.sin(evaluations * np.pi / 4))  # Sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor**2  # Quadratic mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02 * adaptive_factor, self.dim)  # Adjusted Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates dynamic inertia and mutation scaling with Gaussian perturbation to enhance convergence.", "configspace": "", "generation": 71, "fitness": 0.920995076683453, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.9243513936026592, 0.9123057323383306, 0.9263281041093694], "final_y": [0.11444262398431004, 0.1156500750705638, 0.11038767714783793]}, "mutation_prompt": null}
{"id": "18cd33ad-1b91-4a7c-bccb-a2ca881e4f4c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            # Dynamic resizing of the swarm\n            dynamic_population_size = self.initial_population_size + int(adaptive_factor * self.initial_population_size / 2)\n            swarm = swarm[:dynamic_population_size]\n            personal_best = personal_best[:dynamic_population_size]\n            personal_best_value = personal_best_value[:dynamic_population_size]\n            self.velocity = self.velocity[:dynamic_population_size]\n\n            for i in range(dynamic_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(dynamic_population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances exploration using a refined cognitive coefficient and incorporates dynamic swarm resizing for efficient budget utilization.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 16')", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {}, "mutation_prompt": null}
{"id": "a05a8e5d-8310-4192-934c-668a4917eb38", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.3 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted coefficient\n            social_coeff = 1.5\n            mutation_factor = 0.7 + 0.3 * adaptive_factor  # Adjusted mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.15 * (mutant_vector - swarm[i]))  # Adjusted hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005 * adaptive_factor, self.dim)  # Adjusted perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates dynamic parameter tuning with enhanced differential mutation to improve convergence and accuracy.", "configspace": "", "generation": 73, "fitness": 0.921287865704247, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.9308156759824229, 0.9058592199331337, 0.9271887011971844], "final_y": [0.11163096067376388, 0.1213257917951196, 0.11202101785530216]}, "mutation_prompt": null}
{"id": "e7e715d5-637b-4636-b7cd-712618d6961d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))\n\n                # Introduce dynamic learning factor with Gaussian perturbation\n                dynamic_learning_factor = 0.2 * np.random.normal(0, 0.01 * adaptive_factor, self.dim)\n                swarm[i] += self.velocity[i] + dynamic_learning_factor\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates a dynamic learning factor with Gaussian perturbations for enhanced convergence.", "configspace": "", "generation": 74, "fitness": 0.8938991439616838, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.041. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.8372452219963262, 0.914285474010058, 0.9301667358786673], "final_y": [0.14207109956609565, 0.11625560945535718, 0.11265830327971449]}, "mutation_prompt": null}
{"id": "7867f835-9a03-4268-8c09-751cfb846c33", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Dynamic Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # New Line: Adjust dynamic learning rate\n            learning_rate = 0.1 * adaptive_factor  # Dynamic learning rate adjustment\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrates dynamic learning rate adjustment for enhanced convergence reliability and precision.", "configspace": "", "generation": 75, "fitness": 0.9261872373453252, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.9256875812430253, 0.936141292775908, 0.9167328380170422], "final_y": [0.11446661166697569, 0.11162798062868817, 0.11473610874049689]}, "mutation_prompt": null}
{"id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a dynamic global-best update strategy using a cosine decay perturbation mechanism.", "configspace": "", "generation": 76, "fitness": 0.9262893853844844, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4c9f6da3-3304-4541-a3c5-00c8f23ee26b", "metadata": {"aucs": [0.9255599969391275, 0.936108323859332, 0.9171998353549933], "final_y": [0.11452920855763027, 0.11162779229244046, 0.11444626563807203]}, "mutation_prompt": null}
{"id": "081ba4cb-2c68-4c17-b607-e6e8b0739b7f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.3 * np.sin(evaluations * np.pi / 4))  # Modified sine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a dynamic cognitive coefficient using sinusoidal perturbation to enhance diversity and exploration.", "configspace": "", "generation": 77, "fitness": 0.9247983925991629, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9244261109039649, 0.9222999886135537, 0.92766907827997], "final_y": [0.11443534186214566, 0.11524123344754744, 0.11163602051561172]}, "mutation_prompt": null}
{"id": "dde07ce7-e2e4-4865-9a6a-e987438ec4be", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.exp(adaptive_factor * np.pi / 2), self.dim)  # Gaussian perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances the global-best refinement by using a Gaussian distribution for perturbation, improving convergence accuracy.", "configspace": "", "generation": 78, "fitness": 0.9257728056546627, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9258391015372393, 0.9360013910246469, 0.9154779244021021], "final_y": [0.11455000901988888, 0.11163253461476619, 0.11485864931534384]}, "mutation_prompt": null}
{"id": "a442b38b-3660-44d2-9994-007c156a8286", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.sin(adaptive_factor * np.pi / 2), self.dim)  # Dynamic sine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances the global-best update with a sine-based perturbation for improved exploration capability.", "configspace": "", "generation": 79, "fitness": 0.9262753628430943, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9258561035845919, 0.9361462356972735, 0.9168237492474178], "final_y": [0.11449524623722729, 0.11162730517126318, 0.1147130687779826]}, "mutation_prompt": null}
{"id": "21dde28d-3536-48de-aefe-f2b153097691", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.sin(adaptive_factor * np.pi / 2), self.dim)  # Dynamic sine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances swarm exploration and exploitation balance by introducing a sine-adjusted mutation component.", "configspace": "", "generation": 80, "fitness": 0.9262753628430943, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9258561035845919, 0.9361462356972735, 0.9168237492474178], "final_y": [0.11449524623722729, 0.11162730517126318, 0.1147130687779826]}, "mutation_prompt": null}
{"id": "9006979d-a726-451a-be60-89a40b7f86a7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * adaptive_factor  # Adaptive mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Noise-reduced perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refines the global-best update with a noise-reduced perturbation to stabilize convergence.", "configspace": "", "generation": 81, "fitness": 0.9262431055563245, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9254538490433684, 0.9361082128810039, 0.9171672547446011], "final_y": [0.11461783924034874, 0.11162792670279931, 0.1144504831740426]}, "mutation_prompt": null}
{"id": "aedcc5db-fe01-48c5-8ea8-86dce82ff466", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Modified cosine-based adaptive factor\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces a non-linear cosine-based mutation factor to enhance exploration in later stages of the search process.", "configspace": "", "generation": 82, "fitness": 0.9291501537491195, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "80828b6f-b0d3-4eb2-922b-7051d0aa2462", "metadata": {"aucs": [0.9285483318439008, 0.9224878505463636, 0.9364142788570937], "final_y": [0.11449349465156222, 0.11621791815696447, 0.11196680436620032]}, "mutation_prompt": null}
{"id": "b7dddd17-957f-43c7-8225-0bfed83f6d89", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refines the algorithm by adjusting the cognitive coefficient decay for better balance between exploration and exploitation.", "configspace": "", "generation": 83, "fitness": 0.9299833781039347, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "aedcc5db-fe01-48c5-8ea8-86dce82ff466", "metadata": {"aucs": [0.929050228661882, 0.9235217656010242, 0.937378140048898], "final_y": [0.114454119054194, 0.1162178160756735, 0.11196082153511422]}, "mutation_prompt": null}
{"id": "57973afd-889b-4e52-91ca-45b29ebff97e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm improves convergence by dynamically adjusting the social coefficient based on evaluations.", "configspace": "", "generation": 84, "fitness": 0.9317205386366895, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b7dddd17-957f-43c7-8225-0bfed83f6d89", "metadata": {"aucs": [0.9277079047769246, 0.9291858712845603, 0.9382678398485838], "final_y": [0.11445051652538774, 0.11201271675183866, 0.11209920743865864]}, "mutation_prompt": null}
{"id": "3bf3d41f-6786-46c3-aed4-d50b4406a9bb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Modified velocity update with additional random factor for exploration\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) +\n                                    0.05 * np.random.normal(0, 1, self.dim))  # Added Gaussian noise for exploration\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.005 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Reduced perturbation scale\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances convergence by incorporating dynamic perturbation and adaptive learning rates for improved exploration and exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.8945855527686785, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.045. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.8308217169662951, 0.9196223956696241, 0.9333125456701161], "final_y": [0.1450232417904963, 0.11622789692068458, 0.11031900954121965]}, "mutation_prompt": null}
{"id": "5de66a6e-ee08-4a6a-a06d-8737339f7a93", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.2 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances convergence by refining the velocity update with adaptive mutation scaling.", "configspace": "", "generation": 86, "fitness": 0.8892769891817162, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.013. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.8709154181991022, 0.8962764894957428, 0.9006390598503036], "final_y": [0.12424767431665373, 0.12317878969259621, 0.11888786159325693]}, "mutation_prompt": null}
{"id": "b86fa4df-8072-47a4-80dd-01bc8a87702a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(np.random.beta(2, 5) * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances convergence by introducing a dynamic beta distribution in adaptive factor calculation, further refining social coefficient adjustments.", "configspace": "", "generation": 87, "fitness": 0.8941828101560758, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.041. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.8420968778343064, 0.8989836056348234, 0.9414679469990975], "final_y": [0.1417450283204651, 0.11970021110064188, 0.10970623649381306]}, "mutation_prompt": null}
{"id": "34b29aab-a41f-42b7-8596-b8dd02bf7ded", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm refines convergence by dynamically adjusting the social coefficient based on evaluations, with enhanced stochastic perturbation for global best updates.", "configspace": "", "generation": 88, "fitness": 0.931659334516555, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9277209052065726, 0.9290489323273983, 0.938208166015694], "final_y": [0.11445960384610154, 0.11208288483859452, 0.1121197046877831]}, "mutation_prompt": null}
{"id": "a78ea02c-df6b-4d1c-85d2-b3b655c2004c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4) + 0.1 * np.sin(evaluations * np.pi / 3))  # Adjusted decay with trigonometric factor\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances exploration by introducing a trigonometric-based random factor in cognitive coefficient.", "configspace": "", "generation": 89, "fitness": 0.9237830085396165, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9264519079652717, 0.9079389170060188, 0.9369582006475592], "final_y": [0.11456544127521795, 0.12005307615335059, 0.1120948287766006]}, "mutation_prompt": null}
{"id": "3818961d-4ffe-4834-be37-0666f020ad5f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i] + np.random.normal(0, 0.01 * adaptive_factor, self.dim)  # Added local perturbation\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm introduces adaptive local search through random perturbations to enhance solution exploration.", "configspace": "", "generation": 90, "fitness": 0.9028263755027736, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.8693615946810195, 0.9125790171542472, 0.9265385146730541], "final_y": [0.12949951262360437, 0.11623080061131119, 0.11356538028653063]}, "mutation_prompt": null}
{"id": "65e324dd-0474-4f23-ba95-89bce55c1b7d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.alpha = 0.1  # New parameter for Lvy flight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.alpha * (mutant_vector - swarm[i]))  # Adjusted hybrid update\n\n                # Implement Lvy flight perturbation\n                levy_flight = np.random.standard_cauchy(self.dim) * adaptive_factor\n                swarm[i] += self.velocity[i] + levy_flight\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances solution diversity and convergence by incorporating Lvy flight perturbations and adaptive mutation strategies.", "configspace": "", "generation": 91, "fitness": 0.9108032305284482, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9150309436023311, 0.8918695192485045, 0.9255092287345089], "final_y": [0.11711544621860959, 0.12354419872829503, 0.11470380156024873]}, "mutation_prompt": null}
{"id": "4db976a3-acb2-4bf0-a55f-71777231fb07", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                momentum = 0.9  # Introduce momentum to velocity\n                self.velocity[i] = (momentum * self.velocity[i] + \n                                    adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i] + np.random.normal(0, 0.005, self.dim)  # Enhance personal best update with perturbation\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm refines its exploration by introducing momentum to the velocity and enhancing personal best updates with Gaussian perturbation.", "configspace": "", "generation": 92, "fitness": 0.7938065031353055, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.011. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.7847334263149781, 0.7877905401911509, 0.8088955428997879], "final_y": [0.1612826468499372, 0.16272473391589348, 0.1545890910038209]}, "mutation_prompt": null}
{"id": "88625372-5722-47e1-9fcd-e53a6af67b03", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.02 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Increased dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced hybrid search strategy with improved dynamic perturbation for global best updates.", "configspace": "", "generation": 93, "fitness": 0.931659334516555, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9277209052065726, 0.9290489323273983, 0.938208166015694], "final_y": [0.11445960384610154, 0.11208288483859452, 0.1121197046877831]}, "mutation_prompt": null}
{"id": "e1753209-2990-4866-8208-b232f8d9169b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Change: Adjusted inertia weight using a sinusoidal decay\n            inertia_weight = 0.9 - 0.5 * np.sin(adaptive_factor * np.pi)  # Sinusoidal decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm adjusts the inertia weight using a sinusoidal decay to enhance exploration and convergence balance.", "configspace": "", "generation": 94, "fitness": 0.9259545210031476, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9267657185035084, 0.918316597949142, 0.9327812465567921], "final_y": [0.11443598074048877, 0.1162188156198456, 0.11213576958794635]}, "mutation_prompt": null}
{"id": "f06b7f19-8b8a-476d-9619-888bd3ec7569", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n                    global_best = np.clip(global_best, lb + 0.1 * adaptive_factor, ub - 0.1 * adaptive_factor)  # Adaptive boundary reflection\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm fine-tunes swarm exploration by incorporating an adaptive boundary reflection mechanism to enhance solution quality.", "configspace": "", "generation": 95, "fitness": 0.9313922676418862, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9276688536909892, 0.9290981305657058, 0.9374098186689639], "final_y": [0.11455667377394152, 0.11206938609747585, 0.11212641252286204]}, "mutation_prompt": null}
{"id": "7dd204a8-c0dd-4e42-81dc-3a12c373ce17", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i] + np.random.normal(0, 0.01, self.dim)  # Add random perturbation to escape local optima\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm improves convergence by dynamically adjusting the social coefficient and adds a small random perturbation to the personal best for escaping local optima.", "configspace": "", "generation": 96, "fitness": 0.9031979290862401, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.024. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.8696348251121473, 0.9126385085697656, 0.9273204535768077], "final_y": [0.12949466647393404, 0.11624240506851213, 0.11231311054512239]}, "mutation_prompt": null}
{"id": "fc0d769e-eac3-4605-a57d-a2e3099d80c6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]) + 0.01 * np.random.randn(self.dim))  # Added small random perturbation\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing a small, adaptive perturbation to the velocity update.", "configspace": "", "generation": 97, "fitness": 0.8986813064290464, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.041. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.841194216474699, 0.919327497347682, 0.9355222054647585], "final_y": [0.14125683319897497, 0.11622408294626696, 0.11001578581978944]}, "mutation_prompt": null}
{"id": "78e09437-bed0-4876-8553-f8c973099e92", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  \n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  \n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4)) \n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi) \n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2) \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  \n\n                learning_rate = 0.01 + 0.99 * adaptive_factor  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm refines convergence by introducing differential evolution operators and dynamic learning rates, enhancing both exploration and exploitation phases.", "configspace": "", "generation": 98, "fitness": 0.9238560435533018, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9285045005615614, 0.9075652405266212, 0.9354983895717227], "final_y": [0.11483176053909261, 0.12044021845089026, 0.11229094714844956]}, "mutation_prompt": null}
{"id": "696ddedd-a24b-4414-aa6e-5bcd87feab3d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.sin(adaptive_factor * np.pi / 2)  # Changed from cosine to sine for smoother transition\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.sin(adaptive_factor * np.pi / 2), self.dim)  # Changed perturbation from cosine to sine\n\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm refines convergence through a sophisticated blend of dynamic velocity scaling and perturbation techniques.", "configspace": "", "generation": 99, "fitness": 0.9213987846288637, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9244107943498159, 0.9108432341793449, 0.9289423253574305], "final_y": [0.11455877139519544, 0.1193716389675038, 0.11352845527030475]}, "mutation_prompt": null}
{"id": "8a721c11-30b8-4ff9-b98b-9088b5644409", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        mutation_factor = 0.8\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor**3  # Cubic decay in inertia weight\n            adaptive_velocity_factor = 0.5 + 0.5 * np.exp(-3 * adaptive_factor)  # Exponential decay in adaptive velocity factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2) * (1 + 0.2 * np.cos(evaluations * np.pi / 4))  # Adjusted decay of cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Dynamically adjust social coefficient\n            mutation_factor = 0.6 + 0.4 * np.cos(adaptive_factor * np.pi / 2)  # Non-linear cosine-based mutation factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = (swarm[indices[0]] + mutation_factor * (swarm[indices[1]] - swarm[indices[2]]))\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                self.velocity[i] = (adaptive_velocity_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (mutant_vector - swarm[i]))  # Hybrid update\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with refined stochastic perturbation\n                if f_value < global_best_value:\n                    global_best = swarm[i] + np.random.normal(0, 0.01 * np.cos(adaptive_factor * np.pi / 2), self.dim)  # Dynamic cosine perturbation\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        # New refinement step to improve the global best\n        global_best += np.random.normal(0, 0.001, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "The algorithm enhances solution quality by adding a refinement step with Gaussian perturbation on the best solution found.", "configspace": "", "generation": 100, "fitness": 0.9317205386366895, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "57973afd-889b-4e52-91ca-45b29ebff97e", "metadata": {"aucs": [0.9277079047769246, 0.9291858712845603, 0.9382678398485838], "final_y": [0.11445051652538774, 0.11201271675183866, 0.11209920743865864]}, "mutation_prompt": null}
