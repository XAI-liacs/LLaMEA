{"id": "128175e3-22d6-43aa-8af3-0b668287400f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "766fab6f-0779-4bad-96b8-4a8eb6d7f82d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified for dynamic velocity scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic velocity scaling for improved convergence precision.", "configspace": "", "generation": 1, "fitness": 0.8038003386860915, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.020. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "128175e3-22d6-43aa-8af3-0b668287400f", "metadata": {"aucs": [0.7913517045042786, 0.8314856618081978, 0.7885636497457982], "final_y": [0.15856616082129305, 0.1278073033971484, 0.15547358674618972]}, "mutation_prompt": null}
{"id": "3a6aa45b-f445-44db-a029-2bea403f5f40", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.learning_rate = 0.01  # New adaptive learning rate parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        dynamic_scale = 0.1  # New dynamic velocity scaling parameter\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Apply dynamic velocity scaling\n                velocity_scale = 1 + dynamic_scale * np.random.uniform(-1, 1, self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * velocity_scale\n                # Integrate adaptive learning rate\n                swarm[i] += self.learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Incorporates adaptive learning rates and dynamic velocity scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7495665526277809, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.750 with standard deviation 0.026. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "128175e3-22d6-43aa-8af3-0b668287400f", "metadata": {"aucs": [0.7438515782058521, 0.7843848748300083, 0.7204632048474823], "final_y": [0.16176563470983918, 0.15390568799630033, 0.18880042821016751]}, "mutation_prompt": null}
{"id": "c3ac4fed-40fe-40bb-b5df-b84bddb09586", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Dynamic social factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent (ESGD): Incorporates dynamic social and cognitive factors based on global convergence to improve exploration-exploitation balance. ", "configspace": "", "generation": 3, "fitness": 0.8345680597544011, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.023. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "128175e3-22d6-43aa-8af3-0b668287400f", "metadata": {"aucs": [0.8084249977912831, 0.863766937183847, 0.8315122442880736], "final_y": [0.13767552354535784, 0.12642946407249156, 0.13127981467696825]}, "mutation_prompt": null}
{"id": "a2a895d9-7a68-4534-a134-537601109d7a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Use chaotic sequence for inertia weight to enhance exploration\n            inertia_weight = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Dynamic social factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive learning of self-organizing swarms using chaotic inertia weights for improved exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8664323404646975, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.038. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "c3ac4fed-40fe-40bb-b5df-b84bddb09586", "metadata": {"aucs": [0.8128516044058275, 0.8975898821007714, 0.8888555348874937], "final_y": [0.14758366331924322, 0.12145530414712635, 0.12277690689826704]}, "mutation_prompt": null}
{"id": "673875b2-7c49-411d-ae21-52bcff338ff5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)  # Changed\n            cognitive_coeff = 2.0 * adaptive_factor  # Changed\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n            quantum_prob = 0.05 + 0.05 * np.sin(evaluations / self.budget * np.pi)  # New\n\n            for i in range(self.population_size):\n                if np.random.rand() < quantum_prob:  # New\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)  # New quantum-inspired update\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce quantum-inspired position updates and adaptive chaotic inertia to refine swarm exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.8345606540250881, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.005. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a2a895d9-7a68-4534-a134-537601109d7a", "metadata": {"aucs": [0.8415246755157484, 0.8287190169339818, 0.8334382696255342], "final_y": [0.1362924788609544, 0.14010041845836196, 0.13962991442253636]}, "mutation_prompt": null}
{"id": "00f32b67-bf60-4b5e-8e53-13f7f2bed782", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Dynamic velocity clamping\n                max_velocity = (ub - lb) * 0.1\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integration of dynamic velocity clamping and adaptive learning rates for enhanced convergence and exploration efficiency.", "configspace": "", "generation": 6, "fitness": 0.8966888666362682, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a2a895d9-7a68-4534-a134-537601109d7a", "metadata": {"aucs": [0.9031735286650089, 0.8894004428049409, 0.8974926284388548], "final_y": [0.11730379374935218, 0.11728442496854252, 0.11996620295688742]}, "mutation_prompt": null}
{"id": "4f36c6eb-2b3c-45af-ad08-bf12bf60a457", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.stochastic_perturbation = 0.05  # Added stochastic perturbation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Added stochastic perturbation\n                swarm[i] += self.stochastic_perturbation * np.random.uniform(-1, 1, self.dim)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent with stochastic perturbations and diversified exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8898146666015734, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "00f32b67-bf60-4b5e-8e53-13f7f2bed782", "metadata": {"aucs": [0.9091921128920727, 0.8770031619245464, 0.8832487249881013], "final_y": [0.1143114830833819, 0.11930326247850864, 0.12434592690113333]}, "mutation_prompt": null}
{"id": "e861bf8d-eaae-4ca0-bc26-b78b6daec890", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Changed sin to cos\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Dynamic velocity clamping\n                max_velocity = (ub - lb) * 0.1\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + np.random.normal(0, 0.01, self.dim)  # Added stochastic perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by incorporating dynamic inertia adjustment and a stochastic perturbation mechanism.", "configspace": "", "generation": 8, "fitness": 0.8947703072771374, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "00f32b67-bf60-4b5e-8e53-13f7f2bed782", "metadata": {"aucs": [0.9040834421390797, 0.8794197231580447, 0.9008077565342878], "final_y": [0.1106827377531846, 0.11525927572542538, 0.11695241989677696]}, "mutation_prompt": null}
{"id": "41ae6562-73e0-4227-95bc-4691ccbd6a5d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n\n            # Simulated annealing inspired cooling schedule\n            cooling_schedule = np.exp(-evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence precision by incorporating a simulated annealing inspired cooling schedule into adaptive swarm dynamics.", "configspace": "", "generation": 9, "fitness": 0.897031727734778, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "00f32b67-bf60-4b5e-8e53-13f7f2bed782", "metadata": {"aucs": [0.8981060820437607, 0.880984781908977, 0.9120043192515964], "final_y": [0.11787381176586897, 0.12486719812737201, 0.11476817334296496]}, "mutation_prompt": null}
{"id": "6bb2b18c-308e-463f-8988-4c5f9f29850a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.cos(evaluations / self.budget * np.pi)  # Changed sine to cosine\n            cognitive_coeff = 1.2 * adaptive_factor  # Adjusted cognitive coefficient\n            social_coeff = 1.8 + 0.4 * (1 - adaptive_factor)  # Adjusted social coefficient\n\n            # Introduced dynamic search space scaling\n            dynamic_scale = adaptive_factor * (ub - lb)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = dynamic_scale * 0.1  # Used dynamic scaling\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced swarm intelligence via integrated dynamic search space scaling and competitive island cooperation for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.8841695579949995, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.032. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "41ae6562-73e0-4227-95bc-4691ccbd6a5d", "metadata": {"aucs": [0.9014225523428747, 0.8398834468069196, 0.9112026748352042], "final_y": [0.10963508905927943, 0.13692241744781353, 0.10966094886596367]}, "mutation_prompt": null}
{"id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor # Change 2\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Accelerating convergence by introducing dynamic learning coefficients for adaptive swarm dynamics and cooling schedule.", "configspace": "", "generation": 11, "fitness": 0.9232899703377858, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "41ae6562-73e0-4227-95bc-4691ccbd6a5d", "metadata": {"aucs": [0.9309696106266143, 0.9121272376387906, 0.9267730627479527], "final_y": [0.10989771578576635, 0.11629274590996463, 0.11168345790471423]}, "mutation_prompt": null}
{"id": "2764fe16-2ad6-45b7-82d0-334c9e623547", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.secondary_swarm_size = int(0.5 * self.population_size) # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        secondary_swarm = np.random.uniform(lb, ub, (self.secondary_swarm_size, self.dim)) # Change 2\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size + self.secondary_swarm_size # Change 3\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Evaluate the secondary swarm\n            for i in range(self.secondary_swarm_size): # Change 4\n                secondary_position = np.random.uniform(lb, ub, self.dim) # Change 5\n                f_value = func(secondary_position) # Change 6\n                evaluations += 1\n                if f_value < global_best_value: # Change 7\n                    global_best = secondary_position # Change 8\n                    global_best_value = f_value # Change 9\n\n                if evaluations >= self.budget: # Change 10\n                    break # Change 11\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a multi-modal strategy to enhance exploration with a secondary swarm for wider search space coverage.", "configspace": "", "generation": 12, "fitness": 0.9029988142659833, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.015. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9006432897735092, 0.8860026904571949, 0.9223504625672456], "final_y": [0.11805961356551997, 0.11712064707685255, 0.11083603548221754]}, "mutation_prompt": null}
{"id": "425fb7e5-0589-4198-b6f2-6578fd11fde2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.8 + 0.3 * (1 - adaptive_factor) # Change 3\n            exploration_factor = np.random.uniform(0.1, 0.5) # Change 4\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 5\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                direction = np.random.randn(self.dim) / np.linalg.norm(np.random.randn(self.dim)) # Change 6\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    exploration_factor * direction * cooling_schedule) # Change 7\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Refine swarm strategy by introducing stochastic hyper-sphere exploration and non-linear adaptive inertia for enhanced diversification.", "configspace": "", "generation": 13, "fitness": 0.9142112061364891, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9093963810716078, 0.9071606828739378, 0.9260765544639216], "final_y": [0.11025146712387945, 0.11644066521601049, 0.11234229373504356]}, "mutation_prompt": null}
{"id": "bafb7e47-0e7f-455a-847b-70d7b4e3ee7b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 * adaptive_factor  # Change 1\n            social_coeff = 1.9 + 0.3 * (1 - adaptive_factor)  # Change 2\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.2 * cooling_schedule  # Change 3\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance exploration by incorporating dynamic social-cognitive coefficients and adaptive velocity clamping based on convergence rate.", "configspace": "", "generation": 14, "fitness": 0.9174070031941683, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9256732511374446, 0.9103403015617217, 0.9162074568833386], "final_y": [0.11089178461053917, 0.11293833861703062, 0.1138153166735203]}, "mutation_prompt": null}
{"id": "e29e699d-4a14-40fa-b99d-8d9c7e4d708a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            energy_perturbation = np.random.normal(scale=0.1 * cooling_schedule, size=self.dim) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + energy_perturbation # Change 5\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing multi-layer adaptive learning coefficients and energy-based perturbation for enhanced global search and convergence control.", "configspace": "", "generation": 15, "fitness": 0.9149113502094962, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.014. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9277655493594386, 0.8949900642498325, 0.9219784370192176], "final_y": [0.10968814882353906, 0.11856661010446912, 0.1118445242967836]}, "mutation_prompt": null}
{"id": "b635d1fe-a4ae-41e7-8e5d-d89f05711d17", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhancedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.9 - 0.4 * adaptive_factor # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.15 * cooling_schedule # Change 5\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < 0.1: # Change 6\n                    mutation = np.random.normal(0, 0.1 * (ub - lb))\n                    swarm[i] += mutation\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhancedV2", "description": "Enhanced exploration-exploitation balance by introducing adaptive mutation and variable neighborhood search in swarm dynamics.", "configspace": "", "generation": 16, "fitness": 0.8935667153327632, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhancedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8727686302727936, 0.9040651480010432, 0.903866367724453], "final_y": [0.12200454029317942, 0.11940040500434901, 0.11777564997163226]}, "mutation_prompt": null}
{"id": "cfebe7a9-4cf7-48cd-bec1-42d4e3b0e17c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.8 * adaptive_factor # Change 2\n            social_coeff = 1.6 + 0.4 * (1 - adaptive_factor) # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            mutation_rate = 0.05 * (1 - adaptive_factor) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.random() < mutation_rate:  # Change 5\n                    mutation = np.random.uniform(lb, ub, self.dim)\n                    swarm[i] = (swarm[i] + mutation) / 2 # Change 6\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a mutation mechanism and adjusting coefficients for enhanced exploration and convergence control.", "configspace": "", "generation": 17, "fitness": 0.9079086758223974, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.898780397144703, 0.8943889786136896, 0.9305566517087993], "final_y": [0.1108936329736031, 0.12162042500537207, 0.11000763835536131]}, "mutation_prompt": null}
{"id": "142614cf-41cf-45c2-b85c-325f0ea6c7f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi) # Change made here\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence by introducing a dynamic inertia weight modulation based on cosine function for improved balance between exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.9045935007142374, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8925896772685464, 0.9043562912505926, 0.916834533623573], "final_y": [0.11985488410028744, 0.11624650624056843, 0.11212841819964081]}, "mutation_prompt": null}
{"id": "cb8957d4-3527-469a-940e-f315ddf2e62d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.chaos_factor = 4.0  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor \n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) \n\n            # Updated cooling schedule for dynamic adaptation using chaos\n            chaos_map = np.sin(self.chaos_factor * np.pi * (evaluations / self.budget))  # Change 2\n            cooling_schedule = np.exp(-(chaos_map)**2)  # Change 3\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Refining the AdaptiveSwarmGradientDescentEnhanced by integrating chaos theory for better exploration and convergence balance.", "configspace": "", "generation": 19, "fitness": 0.9110028877336068, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.010. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9114852102704935, 0.8990357555409279, 0.9224876973893988], "final_y": [0.11005930186930712, 0.11635276754331147, 0.109980217054514]}, "mutation_prompt": null}
{"id": "f37cde81-4f9a-4910-b678-0d1183b9336c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = np.zeros((self.population_size, dim))  # New Momentum Term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Introducing Logistic Map for Chaotic Behavior\n            chaotic_sequence = 4 * evaluations / self.budget * (1 - evaluations / self.budget) # New Chaotic Map\n            \n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * self.momentum[i])  # Adding Momentum Influence\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + chaotic_sequence * (ub - lb) * 0.05 # Applying Chaotic Perturbation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing adaptive swarm with momentum term and chaotic maps to improve exploration and convergence.", "configspace": "", "generation": 20, "fitness": 0.8205135770031861, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.033. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.863907154747742, 0.7851805295567647, 0.8124530467050513], "final_y": [0.13282515015492258, 0.16342531835214946, 0.1514870920198187]}, "mutation_prompt": null}
{"id": "0c5e9281-3f8d-4799-aaee-67f2a9e30e88", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(evaluations / self.budget * np.pi)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor  # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5)  # Change 4\n\n            if np.random.rand() < 0.1:  # Change 5\n                random_indices = np.random.randint(0, self.population_size, size=(self.population_size, self.dim))\n                swarm = lb + (ub - lb) * np.random.random((self.population_size, self.dim))  # Change 6\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence using adaptive inertia and random search for diversity in particle swarm optimization.", "configspace": "", "generation": 21, "fitness": 0.8905964192018542, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.008. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8846929338778717, 0.8853695286162796, 0.9017267951114113], "final_y": [0.12460700537272562, 0.1241649299921237, 0.11476092096077706]}, "mutation_prompt": null}
{"id": "2c272e7c-057e-46bb-9d91-5071d3009c31", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing exploration by introducing a nonlinear time-varying inertia weight in swarm dynamics to improve convergence.", "configspace": "", "generation": 22, "fitness": 0.9045935007142374, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8925896772685464, 0.9043562912505926, 0.916834533623573], "final_y": [0.11985488410028744, 0.11624650624056843, 0.11212841819964081]}, "mutation_prompt": null}
{"id": "ad27191e-93ac-464f-a67c-b27b323972ea", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            phase_factor = (evaluations / self.budget) ** 0.5  # Change 1\n            inertia_weight = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Change 2\n            cognitive_coeff = 1.5 * phase_factor  # Change 3\n            social_coeff = 2.0 - 0.5 * phase_factor  # Change 4\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                chaos = 0.5 * (np.random.random(self.dim) - 0.5) * (1 - phase_factor)  # Change 5\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + chaos)  # Change 6\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing multi-phase adaptive learning rates and chaotic perturbations to improve exploration and convergence balance.", "configspace": "", "generation": 23, "fitness": 0.91070500167024, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9129832987593333, 0.9147653016208432, 0.9043664046305437], "final_y": [0.1114187152678846, 0.11097537989999584, 0.11098731482603019]}, "mutation_prompt": null}
{"id": "22101dd6-df12-45ed-aa21-bfa14bc3fccf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 1\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.15 * cooling_schedule # Change 2\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Utilizing enhanced adaptive velocity scaling and dynamic boundary adjustments for optimized swarm convergence.", "configspace": "", "generation": 24, "fitness": 0.9125047094126705, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.015. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8919065277302347, 0.9273928459010108, 0.9182147546067656], "final_y": [0.12039789728088335, 0.1117294298916287, 0.11184154136498803]}, "mutation_prompt": null}
{"id": "aebeb69e-9990-4f05-bc8a-d9ac3762854c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.1 * np.cos(evaluations / self.budget * 2 * np.pi) # Change 1\n            cognitive_coeff = 2 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            cooling_schedule = np.exp(-(0.5 * evaluations / self.budget)**2) # Change 4\n            \n            crowding_distance = np.abs(personal_best - global_best).sum(axis=1) # Change 5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i]) + crowding_distance[i] * 0.01 # Change 6\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing hybrid inertia-weight dynamics and crowding distance for diversity preservation in adaptive swarm optimization.", "configspace": "", "generation": 25, "fitness": 0.7930632294841699, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.019. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.7929645063992549, 0.8166209098759099, 0.7696042721773446], "final_y": [0.1551845521958679, 0.14776747616970232, 0.14840154082602275]}, "mutation_prompt": null}
{"id": "a238ec11-0098-4d1b-b787-20c597f64f63", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.chaotic_seq = self.generate_chaotic_sequence(self.budget) # Change 1\n\n    def generate_chaotic_sequence(self, length): # Change 2\n        x = 0.7\n        sequence = []\n        for _ in range(length):\n            x = 4 * x * (1 - x) # Logistic map\n            sequence.append(x)\n        return sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * self.chaotic_seq[evaluations] # Change 3\n            cognitive_coeff = 1.5 + 0.2 * self.chaotic_seq[evaluations] # Change 4\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 5\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Integrating chaotic maps to enhance exploration and convergence in adaptive swarm dynamics.", "configspace": "", "generation": 26, "fitness": 0.9150977845711847, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9295076696931032, 0.9023017534712257, 0.9134839305492255], "final_y": [0.10978541648223772, 0.11638941008660175, 0.11377851301980568]}, "mutation_prompt": null}
{"id": "ee76bf30-aed8-4f0f-b624-ac76663e74ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget) # Modified inertia dampening Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce random perturbation periodically\n                if evaluations % (self.budget // 10) == 0: # Change 2\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb) * adaptive_factor # Change 3\n                    swarm[i] += perturbation\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing solution diversity and convergence by introducing periodic random perturbations and adaptive inertia weight dampening.", "configspace": "", "generation": 27, "fitness": 0.8989411471054821, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8963353393403715, 0.8995405360890494, 0.9009475658870255], "final_y": [0.11003991499475196, 0.11663863450197098, 0.11425549935321289]}, "mutation_prompt": null}
{"id": "93bca3ed-e12f-4950-b37a-5c5cea531927", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Refined adaptive factor computation for more dynamic control\n            adaptive_factor = (1 - (evaluations / self.budget))**1.5  # Change 1\n            \n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Improved convergence by enhancing adaptive factor dynamics to fine-tune swarm exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.9211974854867536, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9340588258877924, 0.912246271000007, 0.9172873595724615], "final_y": [0.11042197881859295, 0.11631970123007396, 0.11418849189953595]}, "mutation_prompt": null}
{"id": "3d6bb52a-fa6e-4c44-8faa-fc3a0b81804c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.local_search_intensity = 5  # New parameter for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor  # Modified line\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Modified line\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.2 * cooling_schedule  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Local search enhancement\n                for _ in range(self.local_search_intensity):  # New loop for local search\n                    local_candidate = swarm[i] + np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(local_candidate, lb, ub)\n                    local_value = func(local_candidate)\n                    evaluations += 1\n                    if local_value < personal_best_value[i]:\n                        personal_best[i] = local_candidate\n                        personal_best_value[i] = local_value\n                    if local_value < global_best_value:\n                        global_best = local_candidate\n                        global_best_value = local_value\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance convergence in adaptive swarm by introducing local search enhancement and dynamic boundary adjustments.", "configspace": "", "generation": 29, "fitness": 0.8382662817691413, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.023. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8191303136186214, 0.8245656630951521, 0.8711028685936502], "final_y": [0.12682706880484085, 0.1237710763517128, 0.11598011713984491]}, "mutation_prompt": null}
{"id": "8751937d-f731-4e68-87e6-926ccff1ed33", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                # Dynamic mutation for exploration-exploitation balance\n                mutation_strength = (ub - lb) * 0.01 * adaptive_factor # Change 1\n                swarm[i] += np.random.normal(0, mutation_strength, self.dim) # Change 2\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance convergence by introducing a dynamic mutation operator for exploration and exploitation balance.", "configspace": "", "generation": 30, "fitness": 0.918816160743441, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.919592119960421, 0.9075343501503411, 0.9293220121195611], "final_y": [0.11072552810237213, 0.11327034980561856, 0.11030033339735357]}, "mutation_prompt": null}
{"id": "e9977737-2bf4-484a-8cd5-3f7a5ae61ea1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor  # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor)  # Change 3\n\n            # Introduce Lévy Flight for diverse exploration\n            levy_flight = np.random.standard_cauchy(self.dim) * adaptive_factor  # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) + levy_flight  # Change 5\n                max_velocity = (ub - lb) * 0.1 * adaptive_factor  # Change 6\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introduce hybrid swarm dynamics with Lévy flight exploration and a novel adaptive inertia mechanism.", "configspace": "", "generation": 31, "fitness": 0.8998500656715042, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.888855110928657, 0.9054657840947105, 0.9052293019911455], "final_y": [0.11604897253638735, 0.11689295651735221, 0.11285499966806734]}, "mutation_prompt": null}
{"id": "be08d640-b17c-4243-81a2-e7be91f95471", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor \n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)\n\n            # New adaptive exploration-exploitation balance\n            exploration_factor = 0.5 * np.cos(evaluations / self.budget * np.pi) + 0.5\n            exploitation_factor = (1 - np.cos(evaluations / self.budget * np.pi)) + 0.1\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) * exploration_factor +\n                                    social_coeff * r2 * (global_best - swarm[i]) * exploitation_factor)\n                \n                # Updated adaptive velocity scaling\n                max_velocity = (ub - lb) * 0.1 * np.exp(-2 * (evaluations / self.budget)**2) \n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence by integrating adaptive velocity scaling and hybrid swarm dynamics with novel exploitation-exploration balancing.", "configspace": "", "generation": 32, "fitness": 0.8797372802998916, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8979752602206479, 0.871501732923438, 0.8697348477555886], "final_y": [0.11080158071250135, 0.12166530091406835, 0.1157758966299981]}, "mutation_prompt": null}
{"id": "9c0d41ad-9364-452d-9a1e-ea847cfe8067", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = np.cos(np.pi * evaluations / self.budget) ** 2  # Change 1\n            inertia_weight = 0.5 + 0.4 * np.sin(evaluations / self.budget * np.pi)  # Change 2\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Change 3\n            social_coeff = 1.5 * (1 + adaptive_factor)  # Change 4\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.2 * adaptive_factor  # Change 5\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introduced an adaptive inertia weight with sinusoidal modulation and dynamic boundary scaling to enhance exploration and exploitation balance in swarm dynamics.", "configspace": "", "generation": 33, "fitness": 0.9028167531617489, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8878973049486182, 0.9123320141446944, 0.9082209403919341], "final_y": [0.12230245161990061, 0.11379773160230766, 0.11298277553914893]}, "mutation_prompt": null}
{"id": "976990d3-d255-4378-b84c-fd6b006c740c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2 # Change 1\n            inertia_weight = 0.9 * np.exp(-0.5 * evaluations / self.budget) # Change 2\n            cognitive_coeff = 1.5 + 0.1 * np.cos(evaluations / self.budget * np.pi) # Change 3\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi) # Change 4\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                \n                # Introduce differential mutation\n                idxs = np.random.choice(self.population_size, 3, replace=False) # Change 5\n                mutant = personal_best[idxs[0]] + self.mutation_factor * (personal_best[idxs[1]] - personal_best[idxs[2]]) # Change 6\n                mutant = np.clip(mutant, lb, ub) # Change 7\n                trial = np.clip(swarm[i] + mutant - personal_best[i], lb, ub) # Change 8\n                \n                swarm[i] = trial if func(trial) < func(swarm[i]) else swarm[i] # Change 9\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing adaptive swarm dynamics with nonlinear inertia and differential mutation to improve convergence and solution quality.", "configspace": "", "generation": 34, "fitness": 0.8526115098621485, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8310819935422071, 0.8644168966138801, 0.8623356394303581], "final_y": [0.1373098101626664, 0.12565164721159439, 0.12950505367003173]}, "mutation_prompt": null}
{"id": "a034d564-6736-4fcb-901b-acb5876eaeea", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor # Change 1\n            social_coeff = 1.7 + 0.3 * adaptive_factor # Change 1\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance convergence speed by incorporating time-varying cognitive and social coefficients into adaptive swarm dynamics.", "configspace": "", "generation": 35, "fitness": 0.9217554373250758, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9230779728531388, 0.9093065986842266, 0.9328817404378624], "final_y": [0.11238952421750137, 0.1167345619327943, 0.11155965152203828]}, "mutation_prompt": null}
{"id": "80850044-dfb6-4779-84f6-d4c88a78eb8a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                stochastic_perturbation = np.random.normal(0, 0.1, self.dim) * adaptive_factor # Change 4\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i] + stochastic_perturbation, -max_velocity, max_velocity) # Change 5\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing stochastic perturbation and adaptive inertia to enhance exploration and exploitation balance during optimization.", "configspace": "", "generation": 36, "fitness": 0.9013070538352902, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8970404920824113, 0.8914171595504436, 0.9154635098730158], "final_y": [0.11845117469487276, 0.12078516316761156, 0.11244212703497625]}, "mutation_prompt": null}
{"id": "acc51503-c23f-41cc-bb6d-688bd01b388a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))  # Change 1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.sub_swarm_count = 3  # Change 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(evaluations / self.budget * np.pi)  # Change 3\n            cognitive_coeff = 1.5 + 0.2 * adaptive_factor  # Change 4\n            social_coeff = 1.5 + 0.4 * (1 - adaptive_factor)  # Change 5\n\n            # Chaotic Initialization for Diversification\n            chaotic_factor = 0.5 + 0.5 * np.sin(evaluations * np.pi / self.budget)  # Change 6\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.2 * chaotic_factor  # Change 7\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a multi-swarm framework with adaptive velocity scaling and chaotic initializations to improve exploration and exploitation.", "configspace": "", "generation": 37, "fitness": 0.9107175254736214, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.008. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9209884512942893, 0.9029254932198643, 0.9082386319067106], "final_y": [0.10964508092257563, 0.11621937954756978, 0.11156688099177225]}, "mutation_prompt": null}
{"id": "312d8b03-dd9d-423a-8e3a-8e27ff53d852", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by fine-tuning inertia weight variability for dynamic swarm adaptation.", "configspace": "", "generation": 38, "fitness": 0.9133333948138262, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.923035146166966, 0.9012931746162787, 0.915671863658234], "final_y": [0.11124713162861899, 0.11717277092997858, 0.11372804219909671]}, "mutation_prompt": null}
{"id": "c476f9dd-5455-4d40-870f-759c1e5bcb5c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            # Introduce a mutation operator to enhance exploration (Change 1)\n            mutation_prob = 0.1 * (1 - adaptive_factor) # Change 2\n            max_velocity = (ub - lb) * 0.1 * cooling_schedule\n            \n            for i in range(self.population_size):\n                # Apply mutation with a certain probability (Change 3)\n                if np.random.rand() < mutation_prob:\n                    swarm[i] += np.random.normal(0, 0.1 * (ub - lb), self.dim) # Change 4\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                # Adaptive boundary adjustment (Change 5)\n                boundary_margin = 0.05 * (ub - lb) * adaptive_factor # Change 6\n                swarm[i] = np.clip(swarm[i], lb + boundary_margin, ub - boundary_margin) # Change 7\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a mutation operator and adaptive boundary adjustments to enhance exploration and exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.9123038816865142, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9111192349552019, 0.90780436675983, 0.917988043344511], "final_y": [0.11060508864273477, 0.11698190771165862, 0.11023679145341292]}, "mutation_prompt": null}
{"id": "38ccd090-9247-4cd6-9aa8-e70234d84e82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            cognitive_coeff = 1.7 * adaptive_factor \n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) \n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                # Change 1: Introduce oscillation in max_velocity for exploration\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * np.cos(evaluations), max_velocity * np.cos(evaluations))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing oscillatory velocity modulation to enhance exploration and convergence dynamics.", "configspace": "", "generation": 40, "fitness": 0.7723090762817213, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.012. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.7718666635588818, 0.787676279634892, 0.7573842856513903], "final_y": [0.16569514805602192, 0.16210326336277725, 0.1737632108852014]}, "mutation_prompt": null}
{"id": "1f9f51b7-3ee7-4f46-a929-f88865636dd5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGeneticHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:  # Alternate between particle update and genetic crossover\n                # Particle update\n                adaptive_factor = 1 - evaluations / self.budget\n                inertia_weight = 0.5 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n                cognitive_coeff = 1.6 * adaptive_factor # Change 2\n                social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 3\n\n                for i in range(self.population_size):\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    max_velocity = (ub - lb) * 0.1\n                    self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n            else:\n                # Genetic crossover\n                parent_indices = np.random.choice(self.population_size, (self.population_size, 2), replace=False)\n                for i in range(self.population_size):\n                    parent1, parent2 = swarm[parent_indices[i]]\n                    crossover_point = np.random.randint(1, self.dim)\n                    offspring = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                    swarm[i] = np.clip(offspring, lb, ub)\n\n            for i in range(self.population_size):\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGeneticHybrid", "description": "Introducing hybrid particle-gene evolution to enhance exploration and convergence through alternating particle updates and genetic crossover.", "configspace": "", "generation": 41, "fitness": 0.9007613170105109, "feedback": "The algorithm AdaptiveSwarmGeneticHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8872731959814182, 0.8973274602754822, 0.9176832947746324], "final_y": [0.11596526070907254, 0.11630486391085104, 0.11079467087002137]}, "mutation_prompt": null}
{"id": "f5a1750e-fd6c-44c0-9dd8-bc2606a46023", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 2.0 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            # Stochastic neighborhood adaptation strategy\n            neighborhood_radius = adaptive_factor * (ub - lb) * 0.5 # Change 4\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                random_neighbor = swarm[np.random.choice(self.population_size)] # Change 5\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    cooling_schedule * (random_neighbor - swarm[i])) # Change 6\n                \n                max_velocity = (ub - lb) * 0.2 * cooling_schedule # Change 7\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence with stochastic neighborhood adaptation and adaptive velocity limits.", "configspace": "", "generation": 42, "fitness": 0.864355379820256, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.013. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8525023205739131, 0.8580333377830628, 0.8825304811037925], "final_y": [0.12170864884942056, 0.13627820249605993, 0.1263640172319338]}, "mutation_prompt": null}
{"id": "a497e361-03f6-4f75-b844-35a3e6432000", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            cognitive_coeff = 1.5 + 0.2 * adaptive_factor  # Updated cognitive coefficient\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            crossover_factor = 0.2 * adaptive_factor  # New crossover factor\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Added r3\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    crossover_factor * r3 * (personal_best[np.random.randint(self.population_size)] - swarm[i]))  # New crossover step\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by integrating adaptive swarm dynamics with a novel velocity update mechanism and adaptive boundary handling.", "configspace": "", "generation": 43, "fitness": 0.9095619912570672, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9099945180847081, 0.9025344711991728, 0.9161569844873205], "final_y": [0.11179847825576628, 0.1168802741692514, 0.11222197957669955]}, "mutation_prompt": null}
{"id": "26bd647d-0d43-4272-8ae4-5b17cbde7a50", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = 5 # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(evaluations / self.budget * np.pi) # Change 2\n            cognitive_coeff = 1.8 * adaptive_factor # Change 3\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 4\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5) # Change 5\n\n            perturbation_intensity = 0.05 * adaptive_factor # Change 6\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Perturbation for enhanced exploration\n                if np.random.rand() < perturbation_intensity: # Change 7\n                    neighbor = swarm[np.random.choice(self.population_size, self.neighborhood_size)].mean(axis=0) # Change 8\n                    swarm[i] = neighbor + np.random.normal(0, (ub - lb) * 0.01) # Change 9\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a perturbation mechanism and adaptive neighborhood for enhanced exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.8713238924595971, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.040. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8166268405712732, 0.8883783750889649, 0.908966461718553], "final_y": [0.1401121227035308, 0.12197738894347399, 0.11570067181011201]}, "mutation_prompt": null}
{"id": "cd9c345a-ee78-46b5-816f-77e9085312a3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget) ** 2  # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * np.exp(-2 * adaptive_factor) # Change 2\n\n            cooling_schedule = np.exp(-(evaluations / self.budget) ** 2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by refining inertia weight dynamics and introducing exponential scaling for social coefficient adaptation.", "configspace": "", "generation": 45, "fitness": 0.9023769515343751, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9081751045431237, 0.8865989299442425, 0.9123568201157592], "final_y": [0.11188114710909858, 0.11693727580697688, 0.11060537389533298]}, "mutation_prompt": null}
{"id": "8716453c-bd82-4bbc-81ff-371321675517", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            # Adaptive cooling and perturbation strategy\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n\n            perturbation_factor = 0.1 * (1 - adaptive_factor) # Change 5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Hybrid local search mechanism\n                local_search_step = perturbation_factor * (2 * np.random.random(self.dim) - 1) # Change 6\n                candidate_solution = swarm[i] + local_search_step # Change 7\n                candidate_solution = np.clip(candidate_solution, lb, ub) # Change 8\n                candidate_value = func(candidate_solution) # Change 9\n\n                f_value = func(swarm[i])\n                evaluations += 1\n\n                if candidate_value < f_value: # Change 10\n                    swarm[i] = candidate_solution # Change 11\n                    f_value = candidate_value # Change 12\n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by combining adaptive swarm dynamics with an adaptive hybrid local search mechanism for intensified exploration.", "configspace": "", "generation": 46, "fitness": 0.8753929763813059, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8896993000818202, 0.8624098169316969, 0.8740698121304008], "final_y": [0.11261003122055302, 0.11246755138695785, 0.117834269884323]}, "mutation_prompt": null}
{"id": "a806c17d-a4a0-45e1-a989-d46181531a69", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] * (0.5 + adaptive_factor * 0.5) # Change 1\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive dimensional reduction technique to guide exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.9185656631781164, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.923676587548555, 0.9083072707258014, 0.9237131312599927], "final_y": [0.11248532682202306, 0.11622645194728232, 0.11222110489160897]}, "mutation_prompt": null}
{"id": "3f2d6a5e-696f-4407-88ca-f118c0e30964", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor \n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) \n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Diversity mechanism\n                if np.random.rand() < 0.1:  # 10% chance\n                    perturbation = (ub - lb) * 0.01 * np.random.randn(self.dim) # Change 1\n                    swarm[i] = np.clip(swarm[i] + perturbation, lb, ub) # Change 2\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance adaptive swarm dynamics by incorporating a diversity mechanism and variable neighborhood search for improved exploration and exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.9152459231563871, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9103349290305095, 0.90917266883463, 0.9262301716040221], "final_y": [0.11117833313322811, 0.11539349708504598, 0.11104111417433171]}, "mutation_prompt": null}
{"id": "ffc85cd3-d5f1-4052-80ef-fc224d55a354", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            # Implementing differential mutation\n            differential_weight = 0.5 + 0.5 * cooling_schedule # Change 1\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = swarm[r1] + differential_weight * (swarm[r2] - swarm[r3]) # Change 2\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Leveraging mutant vector for exploration\n                if np.random.random() < 0.1: # Change 3\n                    swarm[i] = np.clip(mutant_vector, lb, ub) # Change 4\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Incorporating differential mutation for enhanced exploration with dynamic feedback mechanism.", "configspace": "", "generation": 49, "fitness": 0.9016344448459183, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.004. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8969564973217579, 0.9073149050500147, 0.9006319321659819], "final_y": [0.11053272780062473, 0.11143372100965665, 0.1187062247741153]}, "mutation_prompt": null}
{"id": "fed2a87a-49c9-4a31-97b7-bf14ad21b8e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing exploration by adjusting the inertia weight using a cosine function for better adaptability and convergence.", "configspace": "", "generation": 50, "fitness": 0.9106820473349059, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9166827063814704, 0.9050038991885828, 0.9103595364346644], "final_y": [0.11182633404835718, 0.11622432760765233, 0.11374046699023999]}, "mutation_prompt": null}
{"id": "d09642ec-92b1-44d7-b9b7-555d55c8b802", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        return u / (np.abs(v) ** (1 / beta))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            # Adaptive velocity scaling with diversity enhancement\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Introduce Lévy flight for diversity\n                self.velocity[i] += self.levy_flight(self.dim) * cooling_schedule\n\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing diversity enhancement through Lévy flight and adaptive velocity scaling to improve convergence and exploration.", "configspace": "", "generation": 51, "fitness": 0.9003242446407107, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8732356535263812, 0.9071897082434419, 0.9205473721523091], "final_y": [0.1242911180468328, 0.1169731673709421, 0.1128309468919344]}, "mutation_prompt": null}
{"id": "cd97e58b-c9c9-4ad4-a657-a31b8ce4502b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * (0.5 + 0.5 * adaptive_factor) # Change 2 - Updated\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Fine-tunes swarm exploration by adjusting cognitive and social coefficients to enhance adaptive behavior in diverse scenarios.", "configspace": "", "generation": 52, "fitness": 0.9198800400768125, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9305003937195152, 0.9083837393207979, 0.920755987190124], "final_y": [0.11006999550687113, 0.11643147114410979, 0.11161481627288572]}, "mutation_prompt": null}
{"id": "f353d391-608e-4b26-8e3f-6215ac0033e7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor + 0.2  # Change 2\n            social_coeff = 1.7 + 0.5 * (1 - adaptive_factor)  # Change 3\n            quantum_exploration = 0.05 * np.random.standard_normal((self.population_size, self.dim))  # Change 4\n            \n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5)  # Change 5\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.15 * cooling_schedule  # Change 6\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + quantum_exploration[i]  # Change 7\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing quantum-inspired exploration with adaptive velocity scaling for enhanced diversity in swarm dynamics.", "configspace": "", "generation": 53, "fitness": 0.9163641714161518, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9248600483416827, 0.9033836476132353, 0.9208488182935375], "final_y": [0.10975728012808317, 0.11622306724983289, 0.11201615035643153]}, "mutation_prompt": null}
{"id": "43299304-a46f-49cf-b552-59d8a633e4f4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor # Change 2\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n            \n            if np.random.rand() < 0.1:  # Introduce occasional random exploration\n                global_best += np.random.uniform(-0.05, 0.05, self.dim) * (ub - lb)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing random exploration boosts diversity by occasionally perturbing global best position in swarm optimization.", "configspace": "", "generation": 54, "fitness": 0.9164623164723503, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9055183112575882, 0.9174919590040762, 0.9263766791553866], "final_y": [0.11507021227651992, 0.11215554643590131, 0.11078274700357116]}, "mutation_prompt": null}
{"id": "ba4cd38b-90af-4a0c-968c-81339d21f6e9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhancedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.sub_swarm_count = 3  # Change 1: Introduce multiple sub-swarms\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaos_factor = np.sin(np.arange(self.budget) / self.budget * np.pi)  # Change 2: Chaotic sequence\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.2 * chaos_factor[evaluations]  # Change 3: Chaotic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor  # Change 4: Adjusted coefficient\n            social_coeff = 1.9 + 0.2 * (1 - adaptive_factor)  # Change 5: Adjusted coefficient\n\n            # Change 6: Multi-swarm dynamic adaptation\n            for s in range(self.sub_swarm_count):\n                start_idx = s * (self.population_size // self.sub_swarm_count)\n                end_idx = start_idx + (self.population_size // self.sub_swarm_count)\n                sub_swarm = swarm[start_idx:end_idx]\n                sub_velocity = self.velocity[start_idx:end_idx]\n\n                for i in range(len(sub_swarm)):\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    sub_velocity[i] = (inertia_weight * sub_velocity[i] +\n                                       cognitive_coeff * r1 * (personal_best[start_idx + i] - sub_swarm[i]) +\n                                       social_coeff * r2 * (global_best - sub_swarm[i]))\n                    max_velocity = (ub - lb) * 0.1\n                    sub_velocity[i] = np.clip(sub_velocity[i], -max_velocity, max_velocity)\n                    sub_swarm[i] += sub_velocity[i]\n                    sub_swarm[i] = np.clip(sub_swarm[i], lb, ub)\n\n                    f_value = func(sub_swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[start_idx + i]:\n                        personal_best[start_idx + i] = sub_swarm[i]\n                        personal_best_value[start_idx + i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = sub_swarm[i]\n                        global_best_value = f_value\n\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhancedV2", "description": "Introducing multi-swarm dynamics and chaotic inertia weight for enhanced exploration and exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.9201375113081468, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhancedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.016. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9254821955999855, 0.898669408159231, 0.9362609301652237], "final_y": [0.11017647281501308, 0.11562525138257629, 0.10982627041052995]}, "mutation_prompt": null}
{"id": "676b706f-e4ab-4df6-9cd5-9b8500cf3060", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Updated line with logarithmic damping\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) / (1 + np.log1p(evaluations)))  # Change\n                \n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing time-varying acceleration coefficients with logarithmic damping to improve convergence rate and solution quality.", "configspace": "", "generation": 56, "fitness": 0.8722153611465302, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.009. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8622269199978077, 0.8704610596840405, 0.8839581037577422], "final_y": [0.12824842298963102, 0.12560657977294376, 0.11498918513640632]}, "mutation_prompt": null}
{"id": "37f82d29-b23f-45a5-991a-02a9504cced1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(swarm, axis=0)  # Diversity measure\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.sin(evaluations / self.budget * np.pi) * adaptive_factor  # Adaptive inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.9 - 0.2 * diversity.mean()  # Adapt social_coeff based on diversity\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a diversity-preserving mechanism and adaptive inertia to enhance exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.7321356008496055, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.732 with standard deviation 0.026. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.7083331679984148, 0.76890311738062, 0.7191705171697818], "final_y": [0.1952855752653193, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "9de1f04b-a731-48a2-8371-4258c6aaa3e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor + 0.2  # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor)  # Change 3\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.12  # Change 4\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Elite selection mechanism\n                if evaluations % (self.budget // 10) == 0:  # Change 5\n                    elite_index = np.argmin(personal_best_value)\n                    global_best = personal_best[elite_index]\n                    global_best_value = personal_best_value[elite_index]\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing an elite selection mechanism and adaptive decay for improved convergence and diversity preservation.", "configspace": "", "generation": 58, "fitness": 0.8973942474519186, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.027. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9182216560075243, 0.8593735070128545, 0.914587579335377], "final_y": [0.11180350628610292, 0.13163889075169133, 0.11153583681839996]}, "mutation_prompt": null}
{"id": "708d3adf-3ddf-4cce-8bbb-92dcbe2fef1f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.8 * adaptive_factor  # Change\n            social_coeff = 1.6 + 0.4 * (1 - adaptive_factor)  # Change\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            # Introducing stochastic perturbations\n            perturbation = np.random.normal(0, 0.1, (self.population_size, self.dim)) * adaptive_factor  # Change\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    perturbation[i])  # Change\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule * (1 + adaptive_factor)  # Change\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by integrating stochastic perturbations and adaptive velocity constraining.", "configspace": "", "generation": 59, "fitness": 0.9200946687355275, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9241795763419771, 0.9149077510971046, 0.9211966787675003], "final_y": [0.11014762473230955, 0.11633470151478265, 0.11156506998596805]}, "mutation_prompt": null}
{"id": "d9518e8d-f72c-4723-8346-e2a4afdfdedd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                perturbation = np.random.normal(0, 0.01, self.dim) # Change\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    perturbation)\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Incorporating stochastic perturbations in velocity updates to enhance escape from local optima.", "configspace": "", "generation": 60, "fitness": 0.8914428532805578, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.020. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8682119320067819, 0.8892340508263917, 0.9168825770084997], "final_y": [0.1262098465900766, 0.12367038571001565, 0.11255478703462463]}, "mutation_prompt": null}
{"id": "c19b937a-8275-4371-864b-83fdc18a44e9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.8 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            # Introducing an adaptive mutation strategy\n            mutation_strength = 0.05 * (1 - adaptive_factor) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Hybrid velocity update with mutation\n                mutation = np.random.normal(0, mutation_strength, self.dim) # Change 5\n                self.velocity[i] += mutation # Change 6\n                \n                max_velocity = (ub - lb) * 0.1 * np.exp(-(evaluations / self.budget)**2)\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive mutation strategy and hybrid velocity update to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 61, "fitness": 0.9123607567585664, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9021586256381333, 0.9211056000632996, 0.9138180445742662], "final_y": [0.11685495979284632, 0.11165139840244087, 0.10976121733859101]}, "mutation_prompt": null}
{"id": "df489315-6a9a-4172-b6a7-273c1297a58c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.base_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.base_population_size\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.8 - 0.2 * adaptive_factor # Change 3\n            perturbation_strength = 0.05 * (1 - adaptive_factor) # Change 4\n            \n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            for i in range(population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + perturbation_strength * np.random.uniform(-1, 1, self.dim) # Change 5\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % 10 == 0: # Change 6\n                population_size = self.base_population_size + int(adaptive_factor * self.base_population_size) # Change 7\n                self.velocity.resize((population_size, self.dim)) # Change 8\n                swarm.resize((population_size, self.dim)) # Change 9\n                personal_best.resize((population_size, self.dim)) # Change 10\n                personal_best_value.resize(population_size) # Change 11\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Integrating adaptive population size and perturbation-driven exploration to enhance diversity and convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot resize an array that references or is referenced\\nby another array in this way.\\nUse the np.resize function or refcheck=False').", "error": "ValueError('cannot resize an array that references or is referenced\\nby another array in this way.\\nUse the np.resize function or refcheck=False')", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {}, "mutation_prompt": null}
{"id": "bc321980-b164-41c0-b11d-dc502c14cfbf", "solution": "# Description: Introducing a decay factor in the cognitive and social coefficients for better convergence stability.\n\n# Code:\nimport numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            decay_factor = 0.9 ** (evaluations / self.budget) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor * decay_factor # Change 2\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) * decay_factor # Change 3\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a decay factor in the cognitive and social coefficients for better convergence stability.", "configspace": "", "generation": 63, "fitness": 0.9232358976310012, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9306358557761434, 0.9125091002257586, 0.926562736891102], "final_y": [0.11036468125734689, 0.11626751736494445, 0.11181362992197563]}, "mutation_prompt": null}
{"id": "ddc8bb6a-d57a-471b-a048-a8db385b91a9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.8 * adaptive_factor # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 3\n\n            # Multi-phase cooling schedule\n            if evaluations < self.budget / 2: # Change 4\n                cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            else:\n                cooling_schedule = np.exp(-(1 - evaluations / self.budget)**2) \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                perturbation = np.random.uniform(-1, 1, self.dim) * cooling_schedule * 0.05 # Change 5\n                swarm[i] += perturbation # Change 6\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Integrating a multi-phase cooling schedule and adaptive perturbation for enhanced global exploration and convergence. ", "configspace": "", "generation": 64, "fitness": 0.9181278634334255, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.014. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9286066716575928, 0.9272052065226732, 0.8985717121200106], "final_y": [0.10967007620347768, 0.11165846923894573, 0.11351024230803708]}, "mutation_prompt": null}
{"id": "eb43f028-10b7-40d1-a12d-2afc3170e614", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 + 0.5 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence by utilizing dynamic inertia weight adjustment and adaptive cognitive-social coefficients for improved swarm adaptation.", "configspace": "", "generation": 65, "fitness": 0.9113028349001467, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9153110516947082, 0.9016295359333043, 0.9169679170724274], "final_y": [0.1121940576704965, 0.11637982827509807, 0.1127781028720044]}, "mutation_prompt": null}
{"id": "f68e2acf-b123-4a45-8442-61f4bc4c5234", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(3 * evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 + 0.2 * adaptive_factor # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 3\n\n            # Adaptive neighborhood adjustment\n            neighborhood_size = int(1 + adaptive_factor * (self.population_size / 2)) # Change 4\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                local_best = personal_best[np.random.choice(self.population_size, neighborhood_size)].mean(axis=0) # Change 5\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i])) # Change 6\n                max_velocity = (ub - lb) * 0.1 * adaptive_factor # Change 7\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a dynamic inertia weight with periodic perturbation and adaptive neighborhood for enhanced swarm exploration and exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.7426425823804242, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.743 with standard deviation 0.030. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.7237717735312914, 0.7849854564401993, 0.7191705171697818], "final_y": [0.1805845351749108, 0.16394304620525735, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "dbafbb73-7d12-4302-b31a-a22d64061b36", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.25 * np.sin(evaluations / self.budget * np.pi / 2) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.9 + 0.3 * (1 - adaptive_factor) # Change 2\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.08 * cooling_schedule # Change 3\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Fine-tuning swarm dynamics by introducing dynamic inertia dampening and enhanced exploration control for improved convergence.", "configspace": "", "generation": 67, "fitness": 0.9139884767689317, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9212488072815668, 0.9060077205093056, 0.9147089025159226], "final_y": [0.11018848949489612, 0.11631073792848268, 0.11396719369666608]}, "mutation_prompt": null}
{"id": "0be1ebe2-d36d-4d97-ba91-d5ad635ac2b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_rate = 0.1  # Added line for mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                \n                # Apply mutation inspired by genetic algorithms\n                if np.random.rand() < self.mutation_rate:  # Change 2\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (ub - lb) * 0.01  # Change 3\n                    swarm[i] += mutation_vector  # Change 4\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance convergence by introducing adaptive mutation inspired by genetic algorithms and adaptive inertia weight scheduling.", "configspace": "", "generation": 68, "fitness": 0.9129407982590596, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9163441156292598, 0.9126832347694867, 0.9097950443784325], "final_y": [0.11041089946895444, 0.11204616941030987, 0.11290422339797379]}, "mutation_prompt": null}
{"id": "611c0e21-2e03-4c02-8a3f-1814cef860dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation_vector = swarm[np.random.randint(self.population_size)] + 0.5 * (personal_best[np.random.randint(self.population_size)] - personal_best[np.random.randint(self.population_size)]) # Change 1\n                trial_vector = np.clip(mutation_vector, lb, ub) # Change 2\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                trial_value = func(trial_vector) # Change 3\n                evaluations += 1\n\n                if trial_value < personal_best_value[i]: # Change 4\n                    personal_best[i] = trial_vector # Change 5\n                    personal_best_value[i] = trial_value\n\n                if trial_value < global_best_value: # Change 6\n                    global_best = trial_vector\n                    global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by integrating adaptive cooling with differential evolution-inspired mutation and selection mechanisms for swarm dynamics.", "configspace": "", "generation": 69, "fitness": 0.8811725199218592, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8762550766689131, 0.8704334197711933, 0.8968290633254713], "final_y": [0.1173397314739969, 0.115978925914765, 0.11251110193435365]}, "mutation_prompt": null}
{"id": "65993805-aa79-4c75-86e7-14594b79260c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor # Change 2\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Applying stochastic inertia weight for more exploration\n                stochastic_inertia = inertia_weight * np.random.uniform(0.9, 1.1)\n                self.velocity[i] = (stochastic_inertia * self.velocity[i] + # Change 1\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Incorporating a stochastic inertia weight to enhance diversity and avoid premature convergence in swarm-based optimization.", "configspace": "", "generation": 70, "fitness": 0.910051939227925, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9003713220007781, 0.9100981100803023, 0.919686385602695], "final_y": [0.11716191262178122, 0.1118134927372737, 0.11274136082674124]}, "mutation_prompt": null}
{"id": "d4270141-df3d-44d4-a52e-754dbab8e327", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor * (0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)) # Change\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            \n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing swarm exploration by adjusting cognitive coefficient's influence dynamically with a cosine function.", "configspace": "", "generation": 71, "fitness": 0.9205734473570949, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9288604228516403, 0.911142618864596, 0.9217173003550482], "final_y": [0.11062969786934784, 0.11643199070454069, 0.11271872922861625]}, "mutation_prompt": null}
{"id": "ff342b19-7124-48ec-b635-9a11cb2f4b10", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5 * (np.random.randn() * 0.1) # Change 2\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) # Change 3\n            levy_factor = 0.01 # Change 4\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Introduce Lévy flight\n                levy = levy_factor * np.random.standard_normal(self.dim) / (np.random.standard_normal(self.dim)**2) # Change 5\n                self.velocity[i] += levy * adaptive_factor # Change 6\n                \n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence by introducing Lévy flight for exploration and adaptive inertia for exploitation in swarm dynamics.", "configspace": "", "generation": 72, "fitness": 0.9047411316136801, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9013746833838141, 0.8965621640310677, 0.9162865474261583], "final_y": [0.11285031336518547, 0.11686861791189773, 0.11047057694522788]}, "mutation_prompt": null}
{"id": "3c61f5f9-35e0-4f67-a857-ef1ef75f1fab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                \n                # Adaptive mutation to enhance exploration\n                mutation_rate = 0.05 * cooling_schedule # Change 1\n                mutation = np.random.uniform(-mutation_rate, mutation_rate, self.dim) # Change 2\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub) # Change 3\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Integrates adaptive mutation and self-adaptive parameters to enhance exploration-exploitation balance in swarm dynamics.", "configspace": "", "generation": 73, "fitness": 0.9202080958254341, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.009. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9270218871559641, 0.9081699373595198, 0.9254324629608186], "final_y": [0.10983864327398707, 0.11170321811377248, 0.10982711086925334]}, "mutation_prompt": null}
{"id": "8ca1006c-59e1-4516-8ce8-1645ad76a76d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.25 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.8 + 0.3 * (1 - adaptive_factor) # Change 2\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + 0.01 * np.random.randn(self.dim) * cooling_schedule # Change 3\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance swarm dynamics by introducing adaptive perturbation and refining inertia computation.", "configspace": "", "generation": 74, "fitness": 0.9069840501603511, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9051416820682915, 0.8944317840609858, 0.9213786843517762], "final_y": [0.11187998773493457, 0.12062094058153083, 0.1117301021210515]}, "mutation_prompt": null}
{"id": "d4a6d1b7-4259-4393-abe6-18a43796a596", "solution": "import numpy as np\n\nclass QuantumAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * 2 * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.5 + 0.4 * (1 - adaptive_factor) # Change 3\n\n            # Quantum-inspired exploration\n            quantum_explore = 0.5 * np.random.normal(size=(self.population_size, self.dim)) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * quantum_explore[i] # Change 5\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "QuantumAdaptiveSwarm", "description": "Introducing quantum-inspired exploration and adaptive mutative behavior for enhanced convergence in dynamic swarms.", "configspace": "", "generation": 75, "fitness": 0.8198211043621234, "feedback": "The algorithm QuantumAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.015. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8263642692839959, 0.7986966732870148, 0.8344023705153597], "final_y": [0.14265778579884403, 0.15649973894204627, 0.14203643223829365]}, "mutation_prompt": null}
{"id": "8189322d-0046-43d6-887e-637df454e873", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor # Change 2\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) + 0.1 * (1 / (1.618 - adaptive_factor)) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence by introducing a non-linear term in the social coefficient based on Golden Ratio dynamics.", "configspace": "", "generation": 76, "fitness": 0.9196572541011706, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.017. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9341669421554298, 0.8950819016330475, 0.9297229185150344], "final_y": [0.10974294416424946, 0.120350449674828, 0.11041009815649838]}, "mutation_prompt": null}
{"id": "a6c2133b-d3a5-42a0-aed8-27a34a2f37af", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.9 - 0.2 * adaptive_factor # Change 3\n\n            # Updated mechanism for dynamic adaptation with chaotic perturbations\n            chaos_factor = 0.5 * (np.sin(evaluations) + 1) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.15 * chaos_factor # Change 5\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adding chaotic perturbations to swarm movement\n                perturbation = 0.05 * (np.random.rand(self.dim) - 0.5) * chaos_factor # Change 6\n                swarm[i] += perturbation # Change 7\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a diversity mechanism with adaptive inertia weight scaling and chaotic perturbations to enhance exploration in swarm dynamics.", "configspace": "", "generation": 77, "fitness": 0.9093599287238834, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8865829467824827, 0.9177663454658048, 0.9237304939233626], "final_y": [0.11983182933193692, 0.11176549658072865, 0.11013571528985755]}, "mutation_prompt": null}
{"id": "942ad2d1-1a1c-4ba8-bf48-f63007857e57", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            # Change 1: Introduce dynamic neighborhood\n            neighborhood_size = max(1, int(self.population_size * adaptive_factor))\n\n            for i in range(self.population_size):\n                # Change 2: Use neighborhood best\n                neighbors = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                neighborhood_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (neighborhood_best - swarm[i])) # Change 3\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Incorporating dynamic neighborhood structure and adaptive randomization to enhance exploration capability of the swarm.", "configspace": "", "generation": 78, "fitness": 0.9217373281179887, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.92257891240183, 0.917950463303658, 0.9246826086484778], "final_y": [0.10992480169836127, 0.1117760042554049, 0.11256396107747402]}, "mutation_prompt": null}
{"id": "9dcdde29-10bf-43ed-a10c-5fa096861405", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            exploration_factor = np.sin(evaluations / self.budget * np.pi) * 0.5 + 0.5 # Change 1\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                entropy = -np.sum(r1 * np.log(r1 + 1e-9)) # Change 2\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    exploration_factor * entropy) # Change 3\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introduce adaptive exploration factor and entropy-based velocity adjustment to enhance swarm diversity and convergence.", "configspace": "", "generation": 79, "fitness": 0.8550230608168699, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.013. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8689607853412427, 0.8382397688164146, 0.857868628292952], "final_y": [0.1292435596050222, 0.13930085123861868, 0.12731416940892093]}, "mutation_prompt": null}
{"id": "63ae8b53-5df6-43a3-ac02-8e89a0729a0f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            cognitive_coeff = 1.7 * adaptive_factor \n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) \n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                levy_step = self.levy_flight(self.dim) * cooling_schedule\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    levy_step)  # Change 1\n\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a hybrid velocity update strategy by integrating Lévy flight for enhanced exploration and adaptive boundary reflection for robust convergence control.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {}, "mutation_prompt": null}
{"id": "56f588c4-e6f1-4fab-a4f2-dbcd6a08e645", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Modified inertia_weight calculation to use cosine\n            inertia_weight = 0.4 + 0.3 * np.cos(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introduce adaptive inertia weight oscillation using a cosine function to enhance exploration and exploitation balance.", "configspace": "", "generation": 81, "fitness": 0.9106820473349059, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9166827063814704, 0.9050038991885828, 0.9103595364346644], "final_y": [0.11182633404835718, 0.11622432760765233, 0.11374046699023999]}, "mutation_prompt": null}
{"id": "d7362ef3-6a1e-4baf-8f5a-8047c867b2de", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            dynamic_scale = adaptive_factor * (ub - lb) * 0.05 # Change 1\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i] + dynamic_scale * np.random.normal(size=self.dim) # Change 2 and 3\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive mutation and dynamic velocity scaling to enhance exploration-exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.9098679586415682, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9195242863232072, 0.8948284662798647, 0.9152511233216328], "final_y": [0.11092838136257055, 0.11683157889807483, 0.11277941530073987]}, "mutation_prompt": null}
{"id": "a41d37c5-8409-46be-857f-16e34b139a10", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 3\n\n            # Enhanced cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**1.5) # Change 4\n            \n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim) # Change 5\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * cooling_schedule * (r3 - 0.5)) # Change 6\n                max_velocity = (ub - lb) * 0.1 * (0.5 + 0.5 * cooling_schedule) # Change 7\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive turbulence to enhance exploration and prevent premature convergence in swarm optimization.", "configspace": "", "generation": 83, "fitness": 0.9007969517891272, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8957928331000273, 0.881503177798231, 0.9250948444691232], "final_y": [0.11732549111218094, 0.12382231340259497, 0.10991648793367736]}, "mutation_prompt": null}
{"id": "7e127982-18d0-4691-b100-78adc379c52b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.2 * np.sin(evaluations / self.budget * np.pi) # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor # Change 2\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Change 3\n\n            # Updated cooling schedule for dynamic adaptation\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                momentum = 0.9 * self.velocity[i] # Change 4\n                self.velocity[i] = (momentum +\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhancing convergence and exploration by modifying learning coefficients and incorporating momentum in swarm dynamics.", "configspace": "", "generation": 84, "fitness": 0.8412495892543577, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.018. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8160293842398375, 0.8553615616959982, 0.8523578218272375], "final_y": [0.14583923783010266, 0.13614066562886118, 0.1378833765904659]}, "mutation_prompt": null}
{"id": "471a9701-4c55-4d8f-975c-6b718bc08fe9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        # Memory for previous best solutions\n        self.previous_global_best = None  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            # Introduce adaptive mutation rate\n            mutation_rate = 0.1 * (1.0 - global_best_value)  # Change 2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Apply mutation with adaptive rate\n                if np.random.rand() < mutation_rate:  # Change 3\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)  # Change 4\n                    swarm[i] += mutation_vector  # Change 5\n                    swarm[i] = np.clip(swarm[i], lb, ub)  # Change 6\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    self.previous_global_best = global_best  # Change 7\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced swarm adaptation by introducing a memory-based topological influence and adaptive mutation to improve exploration.", "configspace": "", "generation": 85, "fitness": 0.9137352134361305, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9138241860332948, 0.9008048994870999, 0.9265765547879967], "final_y": [0.11065506229139987, 0.12012003575260932, 0.11171950708920053]}, "mutation_prompt": null}
{"id": "72e03804-f2e5-4a14-b0aa-c696b4bf92b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi) \n            cognitive_coeff = 1.7 * adaptive_factor \n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2) \n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                new_direction = np.random.uniform(-1, 1, self.dim)  # Change 1\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    new_direction * 0.01)  # Change 2\n\n                max_velocity = (ub - lb) * (0.1 + 0.05 * adaptive_factor) * cooling_schedule  # Change 3\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive neighborhood adjustment and dynamic velocity scaling in swarm dynamics for enhanced convergence.", "configspace": "", "generation": 86, "fitness": 0.921275780153287, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9173134670968012, 0.9222066420372437, 0.9243072313258167], "final_y": [0.11192487830524511, 0.11171714375858299, 0.11033007513696724]}, "mutation_prompt": null}
{"id": "4f43c97e-67c4-4ab8-9741-5ad3ec06925a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * np.exp(-adaptive_factor)  # Change 1\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                turbulence = np.random.normal(0, 0.1, self.dim) * (1 - adaptive_factor)  # Change 2\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    turbulence)  # Change 3\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced convergence by incorporating adaptive turbulence factors and improved exploration-exploitation balance in adaptive swarm dynamics.", "configspace": "", "generation": 87, "fitness": 0.8919478802406543, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.032. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.8496489123950934, 0.9008685150723792, 0.9253262132544903], "final_y": [0.13192269625402553, 0.11654282916628067, 0.11157873328787127]}, "mutation_prompt": null}
{"id": "29050f44-79ba-4556-8574-2c100a88c56a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhancedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_rate = 0.1 # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi) # Change 2\n            cognitive_coeff = 1.5 * adaptive_factor # Change 3\n            social_coeff = 1.8 - 0.5 * adaptive_factor # Change 4\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                hybrid_velocity = 0.5 * (1 + np.random.rand()) # Change 5\n                mutation = self.mutation_rate * np.random.normal(0, 1, self.dim) # Change 6\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    hybrid_velocity * mutation) # Change 7\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhancedV2", "description": "Enhancing exploration and exploitation balance by introducing adaptive mutation, dynamic inertia, and hybrid velocity approach for improved convergence.", "configspace": "", "generation": 88, "fitness": 0.906128336067881, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhancedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9159499802641462, 0.8898365861798864, 0.9125984417596106], "final_y": [0.10962454579556291, 0.11623298812470384, 0.11209008317214708]}, "mutation_prompt": null}
{"id": "37adce57-50e8-4a80-a200-b0cc2cc91139", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n            \n            # Dynamic population resizing\n            self.population_size = int(self.population_size * (1 + 0.1 * adaptive_factor)) # Change 1\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a dynamic population resizing mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {}, "mutation_prompt": null}
{"id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                # Line modified: Dynamic velocity scaling for exploration-exploitation balance\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a dynamic velocity update mechanism to better adapt to varying search landscapes.", "configspace": "", "generation": 90, "fitness": 0.924062301711758, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.009. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "49c854e6-32de-46d3-9799-2b2a4f480c45", "metadata": {"aucs": [0.9329643214289731, 0.911740509075654, 0.927482074630647], "final_y": [0.10974805689437173, 0.11622537821811518, 0.11005557899458707]}, "mutation_prompt": null}
{"id": "b74b1f46-c1bc-4994-935f-bb26832184f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.2 * np.cos(evaluations / self.budget * np.pi) # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor # Modified line\n            social_coeff = 1.8 + 0.2 * (1 - adaptive_factor) # Modified line\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity) # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    # Hybrid local search: Apply a simple hill climbing step (Added section)\n                    neighbor = global_best + np.random.uniform(-0.01, 0.01, self.dim)\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_value = func(neighbor)\n                    evaluations += 1\n                    if neighbor_value < global_best_value:\n                        global_best = neighbor\n                        global_best_value = neighbor_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhance the algorithm with hybrid local search steps and adaptive coefficient adjustments for improved convergence.", "configspace": "", "generation": 91, "fitness": 0.9187759966996811, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.016. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.89614787687612, 0.9304643799123111, 0.9297157333106122], "final_y": [0.11746621211349306, 0.11168694017269576, 0.10970078147886231]}, "mutation_prompt": null}
{"id": "9e246929-e6da-4bac-9138-c217bc21de4a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                # Line modified: Added Gaussian mutation for enhanced exploration.\n                self.velocity[i] += np.random.normal(0, max_velocity * 0.1, self.dim) * adaptive_factor\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing adaptive mutation with a Gaussian noise component to enhance exploration capabilities.", "configspace": "", "generation": 92, "fitness": 0.9073698512736731, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.8969542423184838, 0.9194467632360761, 0.9057085482664594], "final_y": [0.10990211243110026, 0.11213806958886863, 0.1171761224461274]}, "mutation_prompt": null}
{"id": "174cf925-2e20-4876-a081-180b795a56b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temperature = (1 - evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.4 * np.cos(temperature * np.pi)  # Changed: Temperature-controlled inertia\n            cognitive_coeff = 1.5 + 0.5 * temperature  # Changed\n            social_coeff = 2.0 - 0.5 * temperature  # Changed\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity, max_velocity)  # Changed\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing temperature-controlled multi-phase inertia and learning coefficients for enhanced convergence in diverse landscapes.", "configspace": "", "generation": 93, "fitness": 0.9065601949925327, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.897830912605802, 0.8948574037831576, 0.9269922685886385], "final_y": [0.11798853443264723, 0.12036802200488739, 0.10998201120192064]}, "mutation_prompt": null}
{"id": "a9fd9322-e799-4ed6-92c3-17a9f8963271", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.initial_population_size = self.population_size  # New: Initial population size\n        self.min_population_size = 5  # New: Minimum population size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 * np.exp(-0.5 * (evaluations / self.budget))  # Changed: Nonlinear decay\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # New: Adaptive population size\n            if evaluations % 50 == 0:  # Change population size every 50 evaluations\n                self.population_size = max(self.min_population_size, int(self.initial_population_size * adaptive_factor))\n                swarm = np.resize(swarm, (self.population_size, self.dim))\n                personal_best = np.resize(personal_best, (self.population_size, self.dim))\n                personal_best_value = np.resize(personal_best_value, self.population_size)\n                self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introducing a nonlinear inertia weight decay and adaptive population size for enhanced exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.9170881834109448, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.926487558241168, 0.9082086291099832, 0.9165683628816832], "final_y": [0.11031287228039077, 0.11622609069893408, 0.11356936526862982]}, "mutation_prompt": null}
{"id": "a45fee6b-a2f5-4a61-8749-a42ff0bfcb05", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_rate = 0.05  # New: Mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                # New: Introducing adaptive mutation for exploration\n                mutation = np.random.uniform(-1, 1, self.dim) * self.mutation_rate * adaptive_factor\n                swarm[i] += self.velocity[i] + mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Introduce adaptive mutation in particle positions to enhance exploration while maintaining dynamic velocity updates.", "configspace": "", "generation": 95, "fitness": 0.9063783971070892, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.889654358249057, 0.9216964851377192, 0.9077843479344917], "final_y": [0.11228444345499322, 0.11177483037488056, 0.11691642278084513]}, "mutation_prompt": null}
{"id": "2403f835-779a-4f1f-a1c8-64304a3224b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        last_improvement = 0  # Line added\n\n        while evaluations < self.budget:\n            improvement = global_best_value - np.min(personal_best_value)  # Line added\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * (adaptive_factor + 0.3 * improvement)  # Line modified\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor - 0.2 * improvement)  # Line modified\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    last_improvement = evaluations  # Line added\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Integrate an adaptive cognitive and social coefficient update based on performance feedback.", "configspace": "", "generation": 96, "fitness": 0.924062301711758, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.009. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.9329643214289731, 0.911740509075654, 0.927482074630647], "final_y": [0.10974805689437173, 0.11622537821811518, 0.11005557899458707]}, "mutation_prompt": null}
{"id": "75e8980e-1bcb-4c56-a17b-2fd4bec70703", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        crossover_rate = 0.7\n        mutation_rate = 0.1\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Apply crossover and mutation\n                if np.random.rand() < crossover_rate:\n                    partner_idx = np.random.randint(self.population_size)\n                    crossover_point = np.random.randint(1, self.dim)\n                    swarm[i, :crossover_point] = swarm[partner_idx, :crossover_point]\n\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1 * (ub - lb), self.dim)\n                    swarm[i] += mutation_vector\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced swarm adaptation with dynamic crossover and mutation for improved convergence.", "configspace": "", "generation": 97, "fitness": 0.8995259997591535, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.005. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.9072582593559095, 0.8958570301669899, 0.8954627097545612], "final_y": [0.11649777964819186, 0.12212809053965157, 0.11574304435463545]}, "mutation_prompt": null}
{"id": "c5fd968a-6aa3-4d46-9445-d072f532e9bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Added stochastic perturbation for enhanced local search\n                if np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += perturbation * adaptive_factor\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Enhanced local search through stochastic perturbations for improved exploration-exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.9200372161313921, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.9125936002096664, 0.9219489701818248, 0.9255690780026851], "final_y": [0.1102703629167675, 0.11172103514178577, 0.10982913594149957]}, "mutation_prompt": null}
{"id": "31ec141e-2527-4198-9e8d-c1d845b6ae92", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Change 1: Adaptive inertia weight based on evaluation progress\n            inertia_weight = 0.7 * (1 - evaluations / self.budget) + 0.3\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor, max_velocity * adaptive_factor)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Change 2: Diversity preservation by introducing random perturbation\n                if evaluations < self.budget and np.random.rand() < 0.05:\n                    swarm[i] += np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Incorporating adaptive inertia weight and diversity preservation mechanisms for enhanced exploration-exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.8915766723259578, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.8930769281900323, 0.9047095549289574, 0.8769435338588841], "final_y": [0.11694843439065483, 0.11485024387434539, 0.11737440986809133]}, "mutation_prompt": null}
{"id": "6bbae4c7-f1db-48e7-a8e7-b6e2d018adc8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescentEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.3 * np.sin(evaluations / self.budget * np.pi)\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor)\n\n            cooling_schedule = np.exp(-(evaluations / self.budget)**2)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                max_velocity = (ub - lb) * 0.1 * cooling_schedule\n                # Line modified: Time-dependent velocity scaling for enhanced convergence\n                self.velocity[i] = np.clip(self.velocity[i], -max_velocity * adaptive_factor * (1 + 0.1 * np.cos(evaluations / self.budget * np.pi)), max_velocity * adaptive_factor * (1 + 0.1 * np.cos(evaluations / self.budget * np.pi)))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescentEnhanced", "description": "Refining velocity scaling to further enhance convergence by incorporating time-dependent inertia adjustment.", "configspace": "", "generation": 100, "fitness": 0.9180989751844312, "feedback": "The algorithm AdaptiveSwarmGradientDescentEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4045a0d-ba37-40e2-9b86-373d734cc01c", "metadata": {"aucs": [0.9290277514666665, 0.9068154961532977, 0.9184536779333293], "final_y": [0.10997868263950394, 0.1162831537874055, 0.11227793885583659]}, "mutation_prompt": null}
