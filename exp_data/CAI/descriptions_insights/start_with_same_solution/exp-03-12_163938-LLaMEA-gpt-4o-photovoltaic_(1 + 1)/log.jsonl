{"id": "2e254fc8-15d8-4ccd-b349-aea19401c426", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "fcfa1c2b-1a6e-478e-bfc0-104188f708c1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * adaptive_factor  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic social coefficient that decreases over time to enhance local exploration as convergence nears.", "configspace": "", "generation": 1, "fitness": 0.8231624503480606, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.023. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2e254fc8-15d8-4ccd-b349-aea19401c426", "metadata": {"aucs": [0.7910368823341528, 0.8453459642347445, 0.8331045044752844], "final_y": [0.13409094670799304, 0.1203988152740113, 0.12680380034409622]}, "mutation_prompt": null}
{"id": "e3a63a2b-a02a-42de-b10a-03b10780d649", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            local_search_radius = 0.1 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Perform local search\n                local_candidate = swarm[i] + local_search_radius * np.random.uniform(-1, 1, self.dim)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_value = func(local_candidate)\n                evaluations += 1\n                if local_value < personal_best_value[i]:\n                    swarm[i] = local_candidate\n                    personal_best[i] = local_candidate\n                    personal_best_value[i] = local_value\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) introduces local search with dynamic neighborhood radius to improve convergence speed and solution accuracy.", "configspace": "", "generation": 2, "fitness": 0.8091112513940972, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.023. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2e254fc8-15d8-4ccd-b349-aea19401c426", "metadata": {"aucs": [0.7792622156945831, 0.8361331794711285, 0.8119383590165798], "final_y": [0.16006964723022443, 0.1294121413337589, 0.1386187349498369]}, "mutation_prompt": null}
{"id": "c028b43b-8c2e-48b1-a2e1-235de83d254d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            # Adjusted cognitive and social coefficients\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Refines exploration by dynamically adjusting cognitive and social coefficients based on performance feedback.", "configspace": "", "generation": 3, "fitness": 0.8545027296836528, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.039. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2e254fc8-15d8-4ccd-b349-aea19401c426", "metadata": {"aucs": [0.8085745277447838, 0.850182675030791, 0.9047509862753836], "final_y": [0.15023028921840254, 0.13262907403841084, 0.11454981837913758]}, "mutation_prompt": null}
{"id": "7768b6cc-3278-491f-9963-0144477f2f69", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * (0.5 + adaptive_factor)  # Adjusted inertia\n            if evaluations % 100 == 0:  # Dynamic population size adjustment\n                self.population_size = min(20 + int(np.sqrt(1.5 * dim)), self.population_size + 1)\n            # Adjusted cognitive and social coefficients\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved EASGD with adaptive inertia and dynamic population size adjustment for enhanced convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "c028b43b-8c2e-48b1-a2e1-235de83d254d", "metadata": {}, "mutation_prompt": null}
{"id": "6cd6c113-833d-4267-99b7-0853f40090a3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted dynamic inertia\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Hybrid velocity update\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia and hybrid velocity update to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8671281326529904, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.034. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c028b43b-8c2e-48b1-a2e1-235de83d254d", "metadata": {"aucs": [0.8278995887229795, 0.8635534190891571, 0.9099313901468346], "final_y": [0.14187387251184702, 0.12286640589719455, 0.1161173846756981]}, "mutation_prompt": null}
{"id": "7bd2ec63-ba87-4459-9037-099be03fa1e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted dynamic inertia\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                directional_diversity = np.sign(r3 - 0.5)  # Introduce directional diversity\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) * directional_diversity +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Hybrid velocity update\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce directional diversity in velocity update to enhance exploration capabilities and improve solution quality.", "configspace": "", "generation": 6, "fitness": 0.8117136657139387, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.027. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6cd6c113-833d-4267-99b7-0853f40090a3", "metadata": {"aucs": [0.8133291449336658, 0.8444385772557053, 0.7773732749524445], "final_y": [0.14659234506537888, 0.1278264759134975, 0.1573891370158289]}, "mutation_prompt": null}
{"id": "92bbeb9c-ef06-406e-8b8d-97512617a32f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted dynamic inertia\n            cognitive_coeff = 1.5 * (1 - adaptive_factor) * np.random.uniform(0.5, 1.5)  # Adjusted cognitive coefficient\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Hybrid velocity update\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive cognitive coefficient that decreases linearly to balance exploration and exploitation over function evaluations.", "configspace": "", "generation": 7, "fitness": 0.8359054017290998, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.021. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "6cd6c113-833d-4267-99b7-0853f40090a3", "metadata": {"aucs": [0.8444595120156801, 0.8069800344540327, 0.8562766587175864], "final_y": [0.114517523568889, 0.1426098001009728, 0.1289720795605751]}, "mutation_prompt": null}
{"id": "06d68096-c854-4834-ab7b-e934587d9437", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)  # Temperature-based adaptive inertia\n            cognitive_coeff = 1.5 * temp_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation by introducing a temperature-based adaptive inertia and dynamic population resizing.", "configspace": "", "generation": 8, "fitness": 0.8969215437718869, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6cd6c113-833d-4267-99b7-0853f40090a3", "metadata": {"aucs": [0.873882979721201, 0.9013396636081229, 0.9155419879863367], "final_y": [0.12618699956556378, 0.11446182861655474, 0.11287609849702096]}, "mutation_prompt": null}
{"id": "cd7951b6-e6c2-4ddc-bc26-6f4072220299", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)\n            cognitive_coeff = 1.5 * temp_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    temp_factor * np.random.normal(0, 0.1, self.dim))  # Added random perturbation\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve exploration by including a random perturbation factor in the particle update phase.  ", "configspace": "", "generation": 9, "fitness": 0.8842107417818874, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "06d68096-c854-4834-ab7b-e934587d9437", "metadata": {"aucs": [0.855207520382983, 0.8843240571705298, 0.9131006477921496], "final_y": [0.12840027032695356, 0.12308238260536197, 0.1172358822432914]}, "mutation_prompt": null}
{"id": "2c6b1a89-8f1c-4b8e-b55e-322383052729", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)  # Temperature-based adaptive inertia\n            cognitive_coeff = 1.5 * temp_factor * np.random.uniform(0.5, 1.5)\n            social_coeff = 1.5 * np.random.uniform(0.4, 1.6)  # Adjusted stochastic range for social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation by introducing a temperature-based adaptive inertia and dynamic population resizing, with stochastic adjustment to social coefficient.", "configspace": "", "generation": 10, "fitness": 0.8945123580883512, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "06d68096-c854-4834-ab7b-e934587d9437", "metadata": {"aucs": [0.9059313294225055, 0.8826607930344716, 0.8949449518080764], "final_y": [0.11553029445229812, 0.1213732972778272, 0.12016989191163419]}, "mutation_prompt": null}
{"id": "b6d1ade2-cb4e-4245-923e-9260609e0419", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)  # Temperature-based adaptive inertia\n            diversity = np.std(swarm, axis=0).mean()  # Calculate swarm diversity\n            cognitive_coeff = (1.0 + diversity) * temp_factor * np.random.uniform(0.5, 1.5)  # Adjusted\n            social_coeff = (1.0 - diversity) * np.random.uniform(0.5, 1.5)  # Adjusted\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces dynamic adjustment of cognitive and social coefficients based on swarm diversity to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.7249628283880861, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.725 with standard deviation 0.034. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "06d68096-c854-4834-ab7b-e934587d9437", "metadata": {"aucs": [0.6868148506138565, 0.76890311738062, 0.7191705171697818], "final_y": [0.2029625899996248, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "b76b1df2-0e03-4c8b-b723-6e3bd62664e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)  # Temperature-based adaptive inertia\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Added decay factor\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Added decay factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decay factor in cognitive and social coefficients to balance exploration and exploitation dynamically.", "configspace": "", "generation": 12, "fitness": 0.8974046570598713, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "06d68096-c854-4834-ab7b-e934587d9437", "metadata": {"aucs": [0.9040467225580592, 0.8766381688711797, 0.911529079750375], "final_y": [0.11606467078375582, 0.12091623722084721, 0.11260703282827722]}, "mutation_prompt": null}
{"id": "d441c3cc-7cd9-401c-9132-9ce0d46892f0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.exp(-temp_factor)  # Improved inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Added decay factor\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Added decay factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -abs(lb - ub), abs(lb - ub))  # Adaptive velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive velocity clamping and improved inertia weight to enhance convergence speed and precision.", "configspace": "", "generation": 13, "fitness": 0.8657752125340196, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.031. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "b76b1df2-0e03-4c8b-b723-6e3bd62664e2", "metadata": {"aucs": [0.8277315438383885, 0.8658048341624215, 0.9037892596012488], "final_y": [0.1432843123280193, 0.12270831418466599, 0.11879764670308535]}, "mutation_prompt": null}
{"id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear decay strategy for cognitive and social coefficients to enhance adaptability.", "configspace": "", "generation": 14, "fitness": 0.9012986212368009, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b76b1df2-0e03-4c8b-b723-6e3bd62664e2", "metadata": {"aucs": [0.9123852833582033, 0.8875802450780227, 0.903930335274177], "final_y": [0.11335763660678189, 0.12174803818413782, 0.11484709916287428]}, "mutation_prompt": null}
{"id": "2060233f-717f-4631-89c5-73944e1a6319", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.5 * (1 + np.cos(np.pi * evaluations / self.budget))  # Dynamic inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight strategy based on cosine decay to enhance convergence precision.", "configspace": "", "generation": 15, "fitness": 0.8851089646778082, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "metadata": {"aucs": [0.8708892843065783, 0.8780748866837672, 0.9063627230430791], "final_y": [0.12171742280161824, 0.12304164263957307, 0.11466761690238347]}, "mutation_prompt": null}
{"id": "c8e35efe-0b5a-4abc-bc6e-33ca3c63e74c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.7 + 0.3 * np.cos(temp_factor * np.pi)  # Adaptive inertia\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia and dynamic population sizing based on current evaluations to improve exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8884206639350695, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "metadata": {"aucs": [0.8874442743335905, 0.8881505774880671, 0.8896671399835507], "final_y": [0.12143602776218487, 0.12470738188899377, 0.11812230596696283]}, "mutation_prompt": null}
{"id": "1721f122-d0e1-49d0-a6c7-4442d9e7e906", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            self.population_size = 10 + 2 * int(np.sqrt(dim) * temp_factor)  # Dynamic population size\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the swarm's exploration-exploitation balance by introducing a dynamic population size adjustment.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "metadata": {}, "mutation_prompt": null}
{"id": "1cc8e88c-62c1-46db-856b-06f10bc808f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.5 * np.exp(-temp_factor)\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            # Dynamic population size\n            self.population_size = max(5, self.population_size - int(0.1 * self.population_size))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate dynamic population size adjustment to improve convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8807096262876272, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "metadata": {"aucs": [0.857468374788367, 0.8965565144079849, 0.8881039896665296], "final_y": [0.13052324694721784, 0.11796228057768254, 0.12035701821929601]}, "mutation_prompt": null}
{"id": "9e0c80b3-4172-4bc8-99e2-275cfd447311", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)  # Adaptive inertia weight with cosine decay\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight strategy by incorporating cosine decay for enhanced exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.9179751782096988, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.007. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7eaa5904-7d27-4016-9935-cb9dd3666305", "metadata": {"aucs": [0.9074633431474346, 0.9240702514104714, 0.9223919400711906], "final_y": [0.11148886021776327, 0.11196283103804561, 0.11109240833487244]}, "mutation_prompt": null}
{"id": "f933181b-70b5-40cf-bf6d-87bb88ef9960", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)  # Adaptive inertia weight with cosine decay\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.sin((np.pi/2) * np.random.uniform(0.5, 1.5))  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Changed line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance social coefficient adaptability through a nonlinear sine decay to boost convergence robustness.", "configspace": "", "generation": 20, "fitness": 0.9065247985393641, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9e0c80b3-4172-4bc8-99e2-275cfd447311", "metadata": {"aucs": [0.8999838357464269, 0.9038392192999286, 0.9157513405717369], "final_y": [0.11424169765650694, 0.11635084534114515, 0.11289743094563554]}, "mutation_prompt": null}
{"id": "ffe68445-9246-496c-abd8-946c616cd00c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            inertia_weight = 0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)  # Adaptive inertia weight with cosine decay\n            decay_factor = temp_factor\n            cognitive_coeff = 1.5 * np.random.uniform(0.5, 1.5) * decay_factor**2  # Nonlinear cognitive coefficient decay\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence speed by introducing a nonlinear cognitive coefficient decay for improved balancing of exploration and exploitation phases.", "configspace": "", "generation": 21, "fitness": 0.9153655277879221, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9e0c80b3-4172-4bc8-99e2-275cfd447311", "metadata": {"aucs": [0.9045411585250908, 0.9210387282903125, 0.920516696548363], "final_y": [0.11432518504999067, 0.11269876647976873, 0.11166470055884459]}, "mutation_prompt": null}
{"id": "cd5df2dd-5a71-4ffc-b533-62729da2eed0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.1)  # New randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by incorporating a randomization factor in the inertia weight calculation to improve exploration capabilities.", "configspace": "", "generation": 22, "fitness": 0.9199638483456126, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9e0c80b3-4172-4bc8-99e2-275cfd447311", "metadata": {"aucs": [0.9188466262701479, 0.925822369915812, 0.9152225488508782], "final_y": [0.112411306281468, 0.11248511583012466, 0.11405067582066997]}, "mutation_prompt": null}
{"id": "f2d7503e-11d5-4646-9d8f-5356477221f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2\n            randomization_factor = np.random.uniform(0.9, 1.1)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = 2.0 * np.tanh(decay_factor)  # Modified line\n            social_coeff = 2.0 * np.tanh(decay_factor)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement adaptive personal and social coefficients using a hyperbolic tangent function to balance exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.8843926374988432, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "cd5df2dd-5a71-4ffc-b533-62729da2eed0", "metadata": {"aucs": [0.8523897492073869, 0.8943622353210368, 0.9064259279681063], "final_y": [0.12649451192108851, 0.1182891942418669, 0.11577912566901571]}, "mutation_prompt": null}
{"id": "5f934cc8-71a5-4edb-935b-f55ee95a5d93", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Nonlinear decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.1)  # New randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            # Change: Dynamic cognitive coefficient to improve exploration-exploitation balance\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.sin(evaluations)) \n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing a dynamic cognitive coefficient to further diversify exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.9213028604909447, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cd5df2dd-5a71-4ffc-b533-62729da2eed0", "metadata": {"aucs": [0.9165095362737525, 0.9247355858538366, 0.9226634593452451], "final_y": [0.11181259638644303, 0.11214269792117748, 0.11274490570827445]}, "mutation_prompt": null}
{"id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a stochastic component with time-varying cognitive and social coefficients to enhance adaptive exploration and exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.9303270549926635, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5f934cc8-71a5-4edb-935b-f55ee95a5d93", "metadata": {"aucs": [0.9346899899742984, 0.9312218006232454, 0.9250693743804466], "final_y": [0.11046398247511136, 0.11166022077074933, 0.1137016566272353]}, "mutation_prompt": null}
{"id": "86e954b2-ff46-420c-bf09-efc49cf51b82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.25 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                if np.random.rand() < 0.05:  # Added diversity-enhancing perturbation\n                    self.velocity[i] += np.random.normal(0, 0.1, self.dim)  # Gaussian perturbation\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce diversity-enhancing perturbations and a novel adaptive inertia deceleration mechanism for improved exploration and exploitation.", "configspace": "", "generation": 26, "fitness": 0.8992966502371583, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.025. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8643687073185553, 0.909805783524558, 0.9237154598683616], "final_y": [0.130954441805883, 0.11633496055202042, 0.11007601862581073]}, "mutation_prompt": null}
{"id": "f9548907-cb82-46e0-a314-07cbb677a55f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Linear decreasing inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introducing a linear decreasing strategy for inertia weight to improve balance between exploration and exploitation.", "configspace": "", "generation": 27, "fitness": 0.8682422813683379, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8676960595567158, 0.8672140989167454, 0.8698166856315528], "final_y": [0.1199310022939385, 0.12324909404019091, 0.12376154654368421]}, "mutation_prompt": null}
{"id": "9d7ecf83-882d-48cb-97d5-73c2c8eaa871", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = np.exp(-5 * (evaluations / self.budget))  # Adjusted decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.6 + 0.4 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.6, 1.6)  # Modified cognitive coefficient range\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.4, 1.4)  # Modified social coefficient range\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic hyper-parameter adjustment strategy with enhanced local search for improved exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.8656773996146412, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8377617762194665, 0.876775650502863, 0.8824947721215941], "final_y": [0.1424211572673626, 0.12742893886427575, 0.12890486920816668]}, "mutation_prompt": null}
{"id": "51b14b27-31f5-4ea9-b9a1-d8ba831255ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = 0.4 + 0.6 * np.exp(-3 * temp_factor)  # Dynamic inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                local_best = np.mean(swarm, axis=0)  # New neighborhood component\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (local_best - swarm[i]))  # Incorporating local best\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance velocity update by incorporating dynamic inertia weight adjustment and a new neighborhood component for better convergence.", "configspace": "", "generation": 29, "fitness": 0.8806640823085635, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.015. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8639194655666302, 0.9006002263785056, 0.8774725549805549], "final_y": [0.1309842543269304, 0.12189875918197313, 0.12872156422061887]}, "mutation_prompt": null}
{"id": "2d726d84-6d59-43e7-aca2-f61c7f128758", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2  # Non-linear decay\n            inertia_weight = 0.9 * temp_factor + 0.4  # Adjusted inertia weight\n            cognitive_coeff = 2.0 * np.random.uniform(0.4, 1.2) * np.sin(evaluations / self.budget * np.pi)  # Refined cognitive coefficient\n            social_coeff = 1.5 * np.random.uniform(0.4, 1.2) * np.cos(evaluations / self.budget * np.pi)  # Refined social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the balance of exploration and exploitation by introducing non-linear decay in inertia weight and refining the randomness in coefficients.", "configspace": "", "generation": 30, "fitness": 0.7658252483345439, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.033. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.7235187701655208, 0.76890311738062, 0.8050538574574906], "final_y": [0.186922376983916, 0.1702433386818767, 0.15561428561844548]}, "mutation_prompt": null}
{"id": "bc577e16-71ea-4b4e-86b7-6523c89a8e96", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  \n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  \n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.sin(evaluations / self.budget * np.pi))  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the social coefficient's variability by linking it with a sinusoidal function to better balance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.9292047778633977, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.9313906709483619, 0.9298249934404288, 0.9263986692014026], "final_y": [0.11052590449188704, 0.11184863492335806, 0.11252973701347357]}, "mutation_prompt": null}
{"id": "20889f74-1161-4f5a-8824-909a683d81e4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = 0.5 + 0.4 * np.sin((np.pi/2) * evaluations / self.budget)  # Adaptive inertia modification\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    swarm[i] += np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb) * 0.01  # Chaotic local search\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia modification and chaotic local search to enhance exploration and exploitation. ", "configspace": "", "generation": 32, "fitness": 0.8966815068836328, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8753562009368607, 0.9055740431298331, 0.9091142765842043], "final_y": [0.12526449662209838, 0.11546172389492737, 0.1136757047723147]}, "mutation_prompt": null}
{"id": "05330486-5165-4c79-b508-b3b2cf7cde6b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_scale = np.exp(-0.5 * (evaluations / self.budget))  # Adaptive velocity scaling\n                self.velocity[i] = velocity_scale * (inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive velocity scaling to enhance swarm convergence speed for dynamic environments.", "configspace": "", "generation": 33, "fitness": 0.9230754855209554, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.9325883055518532, 0.9072471822284712, 0.9293909687825421], "final_y": [0.11019515604758823, 0.11840711941164994, 0.11290856595803112]}, "mutation_prompt": null}
{"id": "e7c1a8ca-d7e0-4898-878c-d960c716627f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            mutation_strength = 0.1 * temp_factor  # New mutation strength component\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= (1 + mutation_strength * np.random.randn(self.dim))  # New dynamic scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration-exploitation balance by incorporating a decreasing mutation component and dynamic velocity scaling.", "configspace": "", "generation": 34, "fitness": 0.913963030109179, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.9066474061676316, 0.9121346758217145, 0.923107008338191], "final_y": [0.11291433411462959, 0.11663669437142032, 0.11321177166751561]}, "mutation_prompt": null}
{"id": "901fe109-85ae-4f3c-b917-87f1bae3e7f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.sin((np.pi/2) * temp_factor))  # Adjusted inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine adaptive exploration by adjusting inertia weight using a sinusoidal function for dynamic velocity updates.", "configspace": "", "generation": 35, "fitness": 0.820406347560401, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.013. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.8134699624339584, 0.8384691819215611, 0.8092798983256834], "final_y": [0.1344090808798568, 0.1382032480094919, 0.1396789880931314]}, "mutation_prompt": null}
{"id": "4bc101b3-91a4-41d1-a679-89e51516d0c7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.7, 1.3) * (1 + 0.25 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                perturbation = np.random.uniform(-0.01, 0.01, self.dim)  # Added perturbation\n                swarm[i] += perturbation  # Apply perturbation\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation by introducing a dynamic, step-wise randomization coefficient and a perturbation mechanism.", "configspace": "", "generation": 36, "fitness": 0.9122248600808517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.9097858107062002, 0.9093890883788783, 0.9174996811574765], "final_y": [0.11076735484748246, 0.11630197993205749, 0.1119957081284193]}, "mutation_prompt": null}
{"id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly increase the decay rate to enhance convergence speed and solution quality.", "configspace": "", "generation": 37, "fitness": 0.9309777345120329, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0287b6e0-d8f1-48ad-8794-154cd9ee5e3f", "metadata": {"aucs": [0.9358704465038831, 0.930054743233814, 0.9270080137984018], "final_y": [0.11006680306793637, 0.11169487881080009, 0.11346815772134322]}, "mutation_prompt": null}
{"id": "3c233ee9-0796-4d19-ad87-9725e80c493a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  \n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.5, 1.5) * (1 + 0.1 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < 0.05:  # New mutation strategy\n                    swarm[i] += np.random.normal(0, 0.1, size=self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population mutation and adaptive coefficient modulation to enhance exploration-exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.8860243411781626, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8493020698262678, 0.9123438418436771, 0.8964271118645433], "final_y": [0.13576718325838788, 0.11626891635005643, 0.1147284728481961]}, "mutation_prompt": null}
{"id": "5ef6a03e-c4dc-4292-a8fa-276129242803", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5 * temp_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adaptive mechanism for the social coefficient to improve solution quality.", "configspace": "", "generation": 39, "fitness": 0.9307880920150815, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9365443438320293, 0.9290034088374066, 0.9268165233758084], "final_y": [0.11005610384225417, 0.11172759305316005, 0.11296804947590444]}, "mutation_prompt": null}
{"id": "4dc277df-43e3-4ec0-9b97-366447b78c2e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = 0.7 + 0.3 * np.sin((np.pi * evaluations) / (2 * self.budget))  # New inertia weight strategy\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertial weight based on sinusoidal adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.879751307436158, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.010. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8656104130576433, 0.8863166213911333, 0.8873268878596978], "final_y": [0.13064585600979917, 0.1271011257861432, 0.12056115274214196]}, "mutation_prompt": null}
{"id": "606c1b12-0afa-4533-be48-7ee0fd83cf62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2.0  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm adaptability by fine-tuning velocity and coefficient adjustments for improved convergence.", "configspace": "", "generation": 41, "fitness": 0.9236370636529406, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.010. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9283958999706119, 0.9099441129298089, 0.9325711780584013], "final_y": [0.11035059436935546, 0.11251725240020372, 0.1121628861043239]}, "mutation_prompt": null}
{"id": "00399596-3254-48a8-b633-90768b2beb62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization factor\n            inertia_weight = (0.4 + 0.5 * temp_factor)  # Adaptive inertia\n            decay_factor = temp_factor\n            cognitive_coeff = 1.5 * decay_factor * np.random.uniform(0.6, 1.4)  # Modified cognitive coefficient\n            social_coeff = 1.5 * (1 - decay_factor) * np.random.uniform(0.6, 1.4)  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + \\\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) + \\\n                                    social_coeff * r2 * (global_best - swarm[i])\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia and dynamic coefficients for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 42, "fitness": 0.8533220084597701, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8460916111754591, 0.8534136836018487, 0.8604607306020027], "final_y": [0.11485367915636324, 0.12681816306239213, 0.11232254865651325]}, "mutation_prompt": null}
{"id": "edfc1b50-5c6d-42c7-8863-055d0080a593", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Adjusted decay strategy\n            randomization_factor = np.random.uniform(0.95, 1.15)  # Fine-tuned randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  \n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i] + np.random.normal(0, 0.1, self.dim) * temp_factor  # Added mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive mutation and enhanced velocity decay for improved exploration and convergence.", "configspace": "", "generation": 43, "fitness": 0.9276415737056839, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9299819633735746, 0.9195875839238661, 0.9333551738196111], "final_y": [0.11149599082887063, 0.11635690974616875, 0.11052675364996589]}, "mutation_prompt": null}
{"id": "8c705dff-f7f5-4b19-862a-b368254d4294", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Slightly adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly modify the randomization factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.9293884068543895, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9319915190472534, 0.9275981836019678, 0.9285755179139473], "final_y": [0.110413402187168, 0.11217355668547446, 0.11241342649194341]}, "mutation_prompt": null}
{"id": "4bb3d12b-c2d8-47fa-83ff-5d7e88c43458", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay exponent\n            dynamic_lr = 0.5 + 0.5 * np.exp(-temp_factor)  # Introduced dynamic learning rate\n            inertia_weight = dynamic_lr * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by incorporating a dynamic learning rate and improved inertia weight adaptation.", "configspace": "", "generation": 45, "fitness": 0.8525896111071302, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.006. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8605506325166405, 0.8449700046047521, 0.8522481961999976], "final_y": [0.11654742140992136, 0.12516277733109704, 0.12029677212268619]}, "mutation_prompt": null}
{"id": "df1f3d07-0688-4ff4-a94d-67f5e483de2f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Dynamic adjustment of inertia_weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic adjustment of the inertia_weight to better balance exploration and exploitation.", "configspace": "", "generation": 46, "fitness": 0.92062195690088, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9285617089373516, 0.9265649627526611, 0.906739199012627], "final_y": [0.11108888013004659, 0.1121250135673233, 0.1157402369657472]}, "mutation_prompt": null}
{"id": "b5a01837-5231-44c8-b3a8-1cecb62677ce", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Slightly adjusted decay strategy\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Modified randomization factor for adaptability\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.4, 1.6)  # Refined cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.4, 1.6)  # Refined social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation = np.random.normal(0, 0.1, self.dim)  # Introduced adaptive mutation\n                self.velocity[i] = (inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) + mutation)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation and learning rates to enhance exploration-exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.9260943230849459, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9277722564515992, 0.9214220105440083, 0.9290887022592301], "final_y": [0.11084727965549834, 0.11239337816319228, 0.11239715370965553]}, "mutation_prompt": null}
{"id": "b11d517c-5de4-4819-bc71-c23f94e3060e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.95, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Tweak the randomization factor to improve the balance between exploration and exploitation.", "configspace": "", "generation": 48, "fitness": 0.9181306833609648, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9247069198150735, 0.9000634665722698, 0.9296216636955512], "final_y": [0.11261722850433709, 0.12222825249558267, 0.11257134523990397]}, "mutation_prompt": null}
{"id": "cc844323-2fef-4d57-b2dd-74f8c9df4b0f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.sin((np.pi/2) * temp_factor))  # Used sine function\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.6, 1.4)  # Modified coefficients\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.4, 1.6)  # Adjusted coefficients\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced diversity and convergence by modifying velocity and coefficient strategies.", "configspace": "", "generation": 49, "fitness": 0.8469027571270233, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.025. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8157187930932853, 0.8487697850610159, 0.876219693226769], "final_y": [0.139539585611138, 0.12689664852194205, 0.11560095089057654]}, "mutation_prompt": null}
{"id": "b5ab9849-3de9-45e3-b7c4-4b57d4a6f43a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            phase = evaluations / self.budget\n            temp_factor = 1 - (phase) ** 1.6 \n            randomization_factor = np.random.uniform(0.85, 1.15)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.6 * np.random.uniform(0.5, 1.5) * (1 + 0.15 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_lr = (1 - phase) * r1 + phase * r2  # Adaptive learning rate\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * adaptive_lr * (personal_best[i] - swarm[i]) +\n                                    social_coeff * adaptive_lr * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rates and dual-phase decay to enhance exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.8901627794339623, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8820902977544072, 0.879901607734722, 0.9084964328127575], "final_y": [0.12267405763649875, 0.11815253510837453, 0.11846491651587499]}, "mutation_prompt": null}
{"id": "a634df00-2096-4ea3-95d9-6adca4eb4321", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.4  # Refined decay strategy\n            randomization_factor = np.random.uniform(0.8, 1.1)  # Narrowed randomization factor\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.6, 1.4)  # Adjusted cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.6, 1.4)  # Optimized social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence and exploration balance by refining decay and randomness parameters.", "configspace": "", "generation": 51, "fitness": 0.913293489498344, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9093054821824517, 0.9274494313864381, 0.9031255549261421], "final_y": [0.11222312114937405, 0.11227673290287143, 0.11797355668827492]}, "mutation_prompt": null}
{"id": "1dcb0a43-3330-4933-a244-216f5f09dfda", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.4 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5) * (1 + 0.25 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.1 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by dynamically adjusting the inertia weight and modifying cognitive and social coefficients to improve convergence.", "configspace": "", "generation": 52, "fitness": 0.9114257458064605, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9122435001529164, 0.9029106206841058, 0.919123116582359], "final_y": [0.11136590341741182, 0.12014433629415366, 0.11383630410815404]}, "mutation_prompt": null}
{"id": "c2327a10-12a3-4ff3-97c6-6fe0d4a0026a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6 \n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization range slightly\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.6, 1.4) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Enhanced cognitive coefficient strategy\n            social_coeff = decay_factor * 1.1 * np.random.uniform(0.5, 1.6)  # Adjusted social coefficient range\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic adaptive coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.9194192032651519, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.003. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9155507429576972, 0.9221633927915341, 0.9205434740462243], "final_y": [0.11367791332581156, 0.11241562527118543, 0.11332035520889294]}, "mutation_prompt": null}
{"id": "934d5e21-0006-464a-8180-3bd6a90b8c7d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Increased social coefficient\n            dynamic_swarm_influence = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # New dynamic factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * dynamic_swarm_influence * r2 * (global_best - swarm[i]))  # Applied dynamic factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by adjusting velocity and introducing a dynamic swarm influence factor.", "configspace": "", "generation": 54, "fitness": 0.9178380539149275, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9220244689964063, 0.9187022334593261, 0.9127874592890501], "final_y": [0.11110237645059629, 0.1122312584949251, 0.11330400593800904]}, "mutation_prompt": null}
{"id": "40594f62-9220-4fe6-b7ab-4545ad06abf1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = 0.5 + 0.5 * temp_factor  # Adaptive inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.sin(evaluations / self.budget * np.pi))  # Dynamic cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Enhanced social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight and dynamic social-cognitive balance to enhance convergence and solution quality.", "configspace": "", "generation": 55, "fitness": 0.859223896479827, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.020. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8323020831874335, 0.88176151663582, 0.8636080896162275], "final_y": [0.12177718430239315, 0.12265303700743468, 0.12542908523415397]}, "mutation_prompt": null}
{"id": "ba50eb4b-9db7-4007-97a5-cea7e2a999b9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            improvement_rate = (global_best_value - np.min(personal_best_value)) / np.abs(global_best_value + 1e-10)\n            cognitive_coeff = decay_factor * (1.7 + 0.3 * improvement_rate) * np.random.uniform(0.5, 1.5)\n            social_coeff = decay_factor * (1.3 - 0.2 * improvement_rate) * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive cognitive and social coefficients based on personal and global improvement rates for enhanced exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.929079904129516, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9335120290204616, 0.9278219382205058, 0.9259057451475806], "final_y": [0.11020733411236561, 0.11224206365644929, 0.11358308294734998]}, "mutation_prompt": null}
{"id": "65295c41-ca26-4b8f-9c77-cd2af86aaaf8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.95, 1.15)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos(temp_factor * np.pi))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.6, 1.4) * (1 + 0.3 * np.sin(evaluations / self.budget * np.pi))  # Refined cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.6, 1.4)  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by refining velocity update dynamics and adaptive coefficients.", "configspace": "", "generation": 57, "fitness": 0.7746576943917193, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.024. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.7514139389601179, 0.8082509843770993, 0.7643081598379409], "final_y": [0.14095775042188907, 0.13283074245890436, 0.12829635381361193]}, "mutation_prompt": null}
{"id": "72a2a761-e448-451b-b860-8c4d47334178", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Enhanced inertia weight dynamics\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.6, 1.4) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rates and enhance individual particle exploration to improve optimization efficiency.", "configspace": "", "generation": 58, "fitness": 0.9223854652710065, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9256540872198302, 0.9257301733261594, 0.9157721352670299], "final_y": [0.11163630908552036, 0.1121085709111238, 0.11430466046083676]}, "mutation_prompt": null}
{"id": "dc2fc732-0149-40a8-a7b0-009fdbc483ea", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)) * (0.9 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Adaptive exploration\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                exploration_factor = 1.0 + 0.1 * np.sin(evaluations / self.budget * np.pi)  # New exploration factor\n                self.velocity[i] = inertia_weight * (exploration_factor * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive local exploration with a dynamic exploration factor by modifying velocity update and inertia weight calculation.", "configspace": "", "generation": 59, "fitness": 0.9199137192030614, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9223172434678216, 0.9200996386639296, 0.9173242754774333], "final_y": [0.11307106240979792, 0.11313672684928322, 0.11470355721885084]}, "mutation_prompt": null}
{"id": "79e49f58-7879-4e5a-acd9-77860edd08ca", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 2.0  # Changed decay strategy\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Updated inertia weight strategy\n            acceleration_factor = 2.0 - (1.0 * evaluations / self.budget)  # New acceleration factor\n            cognitive_coeff = acceleration_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Modified cognitive coefficient\n            social_coeff = acceleration_factor * 1.2 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by incorporating a time-varying acceleration factor and alternate inertia decay strategy.", "configspace": "", "generation": 60, "fitness": 0.8425629384591327, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.037. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.7897870894667354, 0.8706539810935954, 0.867247744817067], "final_y": [0.14491230658185816, 0.12166997847987182, 0.12419486118472334]}, "mutation_prompt": null}
{"id": "5a501182-ff9f-4fc0-b92b-e47e905aa47e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)) + 0.1 * np.sin(evaluations / self.budget * np.pi)  # Dynamic inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight strategy to balance exploration and exploitation during optimization.", "configspace": "", "generation": 61, "fitness": 0.9198390921143482, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9257499703060953, 0.9234863304348591, 0.9102809756020903], "final_y": [0.11361635981697926, 0.11382951577347933, 0.11716673116366472]}, "mutation_prompt": null}
{"id": "2868e337-51f7-4629-8837-18957b2fee86", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.sin(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5) * (1 + 0.1 * np.sin(temp_factor * np.pi))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive learning factors influenced by the sine function to refine exploration and exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.9289710625921758, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9319338825617836, 0.9256711855522939, 0.9293081196624501], "final_y": [0.11159330616853458, 0.11190237077802911, 0.11227992546543475]}, "mutation_prompt": null}
{"id": "2c8f3f42-e522-426a-86c4-90e589e4be61", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.learning_rate = np.random.uniform(0.01, 0.1, self.population_size)  # Dynamic learning rates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Enhanced stochasticity\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.4, 1.6) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Adjusted coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.learning_rate[i] * self.velocity[i]  # Applied dynamic learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic learning rate strategy and enhanced stochasticity to boost exploration and exploitation balance.", "configspace": "", "generation": 63, "fitness": 0.7943236001882926, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.032. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8384389515765726, 0.7619826002323073, 0.7825492487559981], "final_y": [0.11893291882692614, 0.16344941030740912, 0.13765972137072657]}, "mutation_prompt": null}
{"id": "024ba090-6651-4b8d-ba60-28b1815a431e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Optimized decay strategy\n            randomization_factor = np.random.uniform(0.85, 1.15)  # Fine-tuned randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Enhanced cognitive coefficient\n            social_coeff = decay_factor * 1.1 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance diversity and convergence by optimizing decay strategy and introducing adaptive exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.9190916631793797, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.005. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9190349493825432, 0.9257600489875104, 0.9124799911680859], "final_y": [0.11157329362976098, 0.11099739875434766, 0.11429979079588037]}, "mutation_prompt": null}
{"id": "be339c5c-b653-416f-b976-b9f4fd16dc3a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Adjusted decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.1)  # Tweaked randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi) * temp_factor))  # Refined inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.sin(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.2 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm dynamics by refining decay and inertia weight strategies for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.7792310236930273, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.022. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.7672658271729174, 0.8095019463738424, 0.7609252975323222], "final_y": [0.1300067475451352, 0.12815384060575163, 0.13183049155439108]}, "mutation_prompt": null}
{"id": "5c3f3d09-9284-44fd-9070-448053abf998", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.5)  # Increased exploration range\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.7, 1.2) * (1 + 0.4 * np.sin(np.pi * evaluations / self.budget))  # Adjusted cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic learning coefficients and enhanced exploration-exploitation balance for improved convergence.", "configspace": "", "generation": 66, "fitness": 0.8872759177136375, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8647681138984418, 0.8825445834912635, 0.9145150557512072], "final_y": [0.13157393797633232, 0.1231121310792126, 0.11476031308320311]}, "mutation_prompt": null}
{"id": "90c66b73-de02-42b8-a1a7-60d90889bd59", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.25)  # Adjusted range\n            inertia_weight = randomization_factor * (0.6 + 0.4 * np.cos((np.pi/2) * temp_factor))  # Modified inertia calc\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.4, 1.6) * (1 + 0.2 * np.sin(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.2 * np.random.uniform(0.6, 1.4)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing adaptive inertia and dynamic coefficients adjustments.", "configspace": "", "generation": 67, "fitness": 0.9082055928113788, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9080723790285831, 0.8947155115074337, 0.9218288878981196], "final_y": [0.11504066471253704, 0.12173821050744504, 0.1131213475199635]}, "mutation_prompt": null}
{"id": "a19acc9c-dff9-4726-b1f7-22898162a632", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Tweaked randomization factor\n            inertia_weight = 0.7 + (0.3 * temp_factor)  # Refined inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 2.0)  # Adjusted cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by refining velocity update and diversity maintenance.", "configspace": "", "generation": 68, "fitness": 0.8426237471475, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.020. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.8200665073690501, 0.8392401368056368, 0.8685645972678131], "final_y": [0.14525373001927655, 0.13003103759687162, 0.12985050143407573]}, "mutation_prompt": null}
{"id": "2b9cd7e6-4819-40c9-a386-0b30120c0c1e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = 0.9  # Added momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.4  # Adjusted decay strategy\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Modified randomization factor\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Adjusted inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.6, 1.4) * (1 + 0.15 * np.cos(evaluations / self.budget * np.pi))  # Tuned cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Increased social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = self.momentum * self.velocity[i] + inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by dynamically adjusting coefficients and introducing a momentum term for improved exploration and exploitation.", "configspace": "", "generation": 69, "fitness": 0.8018573662600478, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.019. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.7877604616889535, 0.7884986153899187, 0.8293130217012714], "final_y": [0.16157067053486518, 0.1624241619574881, 0.1463205746792252]}, "mutation_prompt": null}
{"id": "a7fcc797-9b95-457d-8778-017882e1fd4c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation_factor = 0.1 * np.random.uniform(-1, 1, self.dim) * (1 - evaluations / self.budget)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) + mutation_factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation and elitism to further balance exploration and exploitation.", "configspace": "", "generation": 70, "fitness": 0.9125395099350389, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.9171099803754956, 0.8971751324728625, 0.9233334169567582], "final_y": [0.11247205502963076, 0.11826765850502974, 0.11299854243963592]}, "mutation_prompt": null}
{"id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic cognitive and social coefficients to enhance exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.9314442325068703, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c8b8d32f-6771-4e7c-9609-8a8f9aca4eb0", "metadata": {"aucs": [0.935545637379188, 0.9301800479142877, 0.9286070122271353], "final_y": [0.11009210806457947, 0.11164931772797537, 0.11247619319735302]}, "mutation_prompt": null}
{"id": "c9f0ef09-3364-4c35-9629-acd8d625dfcd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization factor\n            inertia_weight = 0.4 + 0.6 * np.cos(temp_factor * np.pi / 2)  # Nonlinear inertia weight\n            decay_factor = temp_factor\n            learning_rate = 0.1 + 0.9 * np.cos(evaluations / self.budget * np.pi)  # New adaptive learning rate\n            cognitive_coeff = learning_rate * 1.7 * np.random.uniform(0.5, 1.5)  # Modified cognitive coefficient\n            social_coeff = learning_rate * 1.3 * np.random.uniform(0.5, 1.5)  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate adaptive learning rates with time-variant nonlinear inertia weight and enhanced social-cognitive interaction.", "configspace": "", "generation": 72, "fitness": 0.8951294905103033, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.011. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8806167484708028, 0.9059453198421287, 0.8988264032179787], "final_y": [0.12717206957959049, 0.12030876731501383, 0.12099620318557136]}, "mutation_prompt": null}
{"id": "8913d3f8-efb7-4558-877f-164e33f8271b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.5  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.8, 1.3)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.6 + 0.4 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.6 * np.random.uniform(0.4, 1.6) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.4, 1.6)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.1 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize an adaptive synergy between particle clustering and a dynamic velocity scaling for enhanced convergence.", "configspace": "", "generation": 73, "fitness": 0.8882386565461292, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8666644945312352, 0.8876624248535213, 0.9103890502536309], "final_y": [0.1308947578295674, 0.12286929398139979, 0.1163770566257829]}, "mutation_prompt": null}
{"id": "70a6ecd7-02cd-43ec-83f3-6f551b928fad", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.7  # Changed decay strategy slightly\n            randomization_factor = np.random.uniform(0.85, 1.15)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Adjusted inertia weight range\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient slightly\n            social_coeff = decay_factor * 1.2 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient slightly\n\n            for i in range(self.population_size):\n                if np.random.rand() < 0.05:  # Introduce probabilistic velocity reinitialization\n                    self.velocity[i] = np.random.uniform(-1, 1, self.dim) * (ub - lb)\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) + \n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm dynamics with adaptive inertia and probabilistic velocity reinitialization for improved convergence.", "configspace": "", "generation": 74, "fitness": 0.8986622056268544, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8859538518109554, 0.8868275415072467, 0.9232052235623607], "final_y": [0.12252935704459877, 0.12264351616208458, 0.11059183908732717]}, "mutation_prompt": null}
{"id": "bd90d38c-c45d-4e09-a444-e870ef5f14e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.8  # Adjusted decay rate\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * temp_factor)  # Sine-based inertia adjustment\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.4, 1.6) * (1 + 0.25 * np.sin(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.4, 1.6) * (1 + 0.15 * np.sin(evaluations / self.budget * np.pi))  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * self.velocity[i] + cognitive_coeff * r1 * (personal_best[i] - swarm[i]) + social_coeff * r2 * (global_best - swarm[i])\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm stability with adaptive inertia and social coefficients to boost convergence in dynamic environments.", "configspace": "", "generation": 75, "fitness": 0.8885173421172392, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.022. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8577896537685255, 0.8969249256758438, 0.9108374469073485], "final_y": [0.12897276712563088, 0.12068542178370356, 0.1173845219258226]}, "mutation_prompt": null}
{"id": "dc895d96-660a-4417-8ccd-e75abafade8a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5) * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tune the social coefficient using a sinusoidal function for improved convergence.", "configspace": "", "generation": 76, "fitness": 0.927878370958529, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.9266500057828809, 0.9308531131373357, 0.9261319939553703], "final_y": [0.11070636526291966, 0.11170359469217683, 0.11291101740147513]}, "mutation_prompt": null}
{"id": "86562de9-d6ed-411b-a00a-aa6b328fa686", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.sin((np.pi/2) * temp_factor))  # Changed line: nonlinear time-varying inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.8 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Changed line\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_best = personal_best[np.random.choice(self.population_size)]  # Added line: adaptive neighborhood influence\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (neighborhood_best - swarm[i]))  # Changed line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear time-varying inertia weight and adaptive neighborhood influence to balance exploration-exploitation. ", "configspace": "", "generation": 77, "fitness": 0.798240307239098, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.021. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.7691152326956814, 0.8194513548025298, 0.8061543342190831], "final_y": [0.1505095713989142, 0.13415487681836724, 0.14137783991107866]}, "mutation_prompt": null}
{"id": "429dd396-3d82-4c90-969b-00fe3f89e505", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.sin((np.pi/2) * temp_factor))  # Line changed\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tune inertia weight using a dynamic sinusoidal function to better adapt exploration and exploitation over iterations.", "configspace": "", "generation": 78, "fitness": 0.8335703508118991, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.008. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8425877093396964, 0.8346939621987048, 0.8234293808972962], "final_y": [0.1380334290575621, 0.14068180492614013, 0.12612486526082012]}, "mutation_prompt": null}
{"id": "b826cbe5-32dc-4993-8b4b-25e549fd71cc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = 0.4 + 0.4 * np.cos((np.pi/2) * temp_factor)  # Non-linear dynamic inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= (0.5 + 0.5 * np.tanh(evaluations / self.budget * 10 - 5))  # Time-varying strategy for velocity\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a non-linear dynamic inertia weight and a time-varying strategy for the velocity to enhance convergence speed and precision.", "configspace": "", "generation": 79, "fitness": 0.78964934085959, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.021. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.7666273409948652, 0.8175165149710416, 0.7848041666128635], "final_y": [0.13344018883098152, 0.125547267211774, 0.11611340958265692]}, "mutation_prompt": null}
{"id": "ef3029cc-09bb-4d81-80e4-9979f55d2847", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            # Introducing mutation factor for exploration\n            mutation_rate = 0.05  # Added new variable\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                if np.random.rand() < mutation_rate:  # Added mutation operation\n                    swarm[i] += np.random.normal(0, 0.1, self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and convergence by introducing a mutation factor and adaptive inertia weight adjustment.", "configspace": "", "generation": 80, "fitness": 0.890806450826427, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8659295573100534, 0.9031666214433854, 0.9033231737258423], "final_y": [0.1305805255468615, 0.11939326470519562, 0.11348091383017711]}, "mutation_prompt": null}
{"id": "fb8f8d48-a3d8-4e5d-a03c-827447e6b025", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * (r1**1.1) * (personal_best[i] - swarm[i]) +  # Introduced mild non-linearity\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global search by introducing mild non-linearity in velocity update for improved exploration.", "configspace": "", "generation": 81, "fitness": 0.9292171462626331, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.9306615054816714, 0.9263734595933806, 0.9306164737128472], "final_y": [0.11027834431344175, 0.11182514942057109, 0.11244550041004375]}, "mutation_prompt": null}
{"id": "e02181a8-4214-49b2-a95d-9a314997bacb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        \n        # Dynamic velocity clamping\n        velocity_clamp = 0.1 * (ub - lb)\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.95, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = np.clip(inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])), -velocity_clamp, velocity_clamp)  # Introduced velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic velocity clamping and enhanced randomness to balance convergence and exploration.", "configspace": "", "generation": 82, "fitness": 0.9113946133386076, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8898626404248668, 0.9229570821435666, 0.9213641174473894], "final_y": [0.11758152886564932, 0.11204484818722682, 0.11117572412946652]}, "mutation_prompt": null}
{"id": "9d45c63c-7c32-433a-ac43-e2bc9510acde", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.8  # Changed exponent for decay strategy\n            randomization_factor = np.random.uniform(1.0, 1.3)  # Adjusted randomization range\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.4 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = randomization_factor * self.velocity[i] + inertia_weight * (  # Introduced rotational velocity update\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce rotational velocity update and adapt inertia weight non-linearly for enhanced multi-dimensional search.", "configspace": "", "generation": 83, "fitness": 0.8310749676152221, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.010. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.819158492755716, 0.831548958929478, 0.8425174511604727], "final_y": [0.14952851417620505, 0.14528250890667926, 0.14137563490349003]}, "mutation_prompt": null}
{"id": "3d7dd52f-7734-41fa-b19c-6fcab5115334", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(swarm, axis=0).mean()  # Calculate population diversity\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2) \n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)) * diversity  # Adaptive inertia\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi)) \n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5) * diversity  # Dynamic attraction\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) + \n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia and dynamic attraction coefficients based on population diversity for enhanced convergence.", "configspace": "", "generation": 84, "fitness": 0.720714499300354, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.721 with standard deviation 0.039. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.6740698633506605, 0.76890311738062, 0.7191705171697818], "final_y": [0.21185908847573987, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "1bb7e324-50ab-448d-996b-2c9f45380aa1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            mutation_prob = np.random.uniform(0.01, 0.1) * decay_factor  # New mutation probability\n            mutation_strength = 0.1 * (ub - lb) * decay_factor  # New mutation strength\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                if np.random.rand() < mutation_prob:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)  # Mutation applied\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation and inertia decay to enhance convergence speed and solution quality.", "configspace": "", "generation": 85, "fitness": 0.9051634839884546, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8788139316119568, 0.9167949311836165, 0.9198815891697905], "final_y": [0.1260504776083753, 0.11370126512371292, 0.11563764705605861]}, "mutation_prompt": null}
{"id": "d0929def-e546-4894-a862-65b62b497f53", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            # New line for adaptive neighborhood influence\n            neighbor_influence_coeff = 0.1 * np.random.uniform(0.8, 1.2) * (1 - decay_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # New line for applying neighbor influence\n                self.velocity[i] += neighbor_influence_coeff * (np.random.uniform(lb, ub, self.dim) - swarm[i])\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement adaptive neighborhood-based influence to enhance local search capabilities in the swarm.", "configspace": "", "generation": 86, "fitness": 0.8883427538839545, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.029. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8776982189841677, 0.8594919187052361, 0.9278381239624592], "final_y": [0.12706849555215638, 0.1308130036972467, 0.11226589775718021]}, "mutation_prompt": null}
{"id": "2aeee737-b0e4-4fe6-a8fd-64fa1d0bdf5f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb - ((ub - lb) * 0.1), ub + ((ub - lb) * 0.1), (self.population_size, self.dim))  # Changed swarm initialization\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced diversity control mechanism by altering swarm initialization for improved exploration.", "configspace": "", "generation": 87, "fitness": 0.8738872987490626, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.003. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8710592830692445, 0.8725179748127672, 0.8780846383651759], "final_y": [0.13043664620148665, 0.11924846645827258, 0.12429469863619058]}, "mutation_prompt": null}
{"id": "f6016a27-a1b3-4cc8-8150-838d4c72c7ad", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - np.sqrt(evaluations / self.budget)  # Changed to non-linear decay\n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization factor range\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Modified inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = (1.8 + 0.2 * np.sin(evaluations / self.budget * np.pi)) * np.random.uniform(0.5, 1.5)  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.1 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Include adaptive inertia and non-linear decay to improve swarm convergence and exploration-exploitation trade-off.", "configspace": "", "generation": 88, "fitness": 0.8913346691106696, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.006. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8993693430279601, 0.8902503779241729, 0.8843842863798754], "final_y": [0.11879858219997586, 0.12523907454596195, 0.1267780703357091]}, "mutation_prompt": null}
{"id": "9f7f9dd0-2fb6-403b-82a5-288fbc7623f1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  \n            randomization_factor = np.random.uniform(0.85, 1.25)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.5, 1.5)  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.1 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_component = inertia_weight * (self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.tanh(velocity_component)  # Non-linear transformation\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a non-linear velocity transformation for enhanced convergence.", "configspace": "", "generation": 89, "fitness": 0.736706843300288, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.737 with standard deviation 0.023. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.7184971792703316, 0.76890311738062, 0.7227202332499123], "final_y": [0.16742099252338138, 0.1702433386818767, 0.1850519176005444]}, "mutation_prompt": null}
{"id": "fca29c6d-cfb6-448e-88a4-3b6b0f5a0a0f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.diversity_threshold = 0.1  # New diversity parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Additional diversity check and leader reevaluation\n                if np.std(swarm) < self.diversity_threshold:\n                    global_best = swarm[np.random.choice(self.population_size)]  # Adjust leader reevaluation\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Adaptive Swarm Gradient Descent with diversity preservation and leader reevaluation strategy.", "configspace": "", "generation": 90, "fitness": 0.9314442325068703, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.935545637379188, 0.9301800479142877, 0.9286070122271353], "final_y": [0.11009210806457947, 0.11164931772797537, 0.11247619319735302]}, "mutation_prompt": null}
{"id": "341f7062-452f-468c-95e0-7a9c1e1e4d75", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.4 + 0.6 * np.cos((np.pi/2) * temp_factor))  # Increased dynamic range\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.3) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Further modified cognitive coefficient\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.5, 1.5)  # Further adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                local_search_factor = 0.1 * np.random.randn(self.dim)  # Introduce local search\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + local_search_factor)  # Enhanced velocity update\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weights and adaptive local search to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 91, "fitness": 0.9286793902038927, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.004. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.9325836653706171, 0.9234040538854646, 0.9300504513555965], "final_y": [0.11064192444330001, 0.11192552022045488, 0.11142579192174495]}, "mutation_prompt": null}
{"id": "5d7df2cc-6d13-4653-9dff-bba6c3085183", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * temp_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))  # Changed this line\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight decay to enhance adaptability during optimization.", "configspace": "", "generation": 92, "fitness": 0.9308089943932399, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.9342919194982529, 0.9273264438762389, 0.9308086198052279], "final_y": [0.11076620984012175, 0.11308435656330873, 0.11272994285474036]}, "mutation_prompt": null}
{"id": "67df0dc6-7095-4396-9fd7-2a5ffc3c4a04", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.9 * np.random.uniform(0.6, 1.4) * (1 + 0.3 * np.cos(evaluations / self.budget * np.pi))  # Modified\n            social_coeff = decay_factor * 1.5 * np.random.uniform(0.6, 1.4)  # Modified\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence speed and accuracy by optimizing velocity update and coefficient dynamics.", "configspace": "", "generation": 93, "fitness": 0.9018868962281831, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8767325288615055, 0.9010690645461924, 0.9278590952768516], "final_y": [0.12637932374859873, 0.12046416762834034, 0.11189080862516876]}, "mutation_prompt": null}
{"id": "04e7c457-1d77-4239-b6cb-c34cba5404e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor))\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation = np.random.normal(0, 0.1 * decay_factor, self.dim)  # Added mutation strategy\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) + mutation  # Applied mutation\n                self.velocity[i] *= (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Non-linear velocity scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation strategy and non-linear velocity scaling to enhance convergence.", "configspace": "", "generation": 94, "fitness": 0.9098746011597113, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.8854973474018253, 0.9157735221331322, 0.9283529339441763], "final_y": [0.12553216932854372, 0.11729556419975429, 0.11183659876553687]}, "mutation_prompt": null}
{"id": "e991a492-bc74-48e4-818e-db9032fd75a1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)  # Non-linear time-varying inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce non-linear time-varying inertia weight to further balance exploration and exploitation.", "configspace": "", "generation": 95, "fitness": 0.9314499366098098, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0a89e89-812a-46ce-8455-6a5694ff0bf2", "metadata": {"aucs": [0.9343954392150285, 0.9293651410246001, 0.9305892295898006], "final_y": [0.11015249003956173, 0.11181203265319994, 0.11257267479206678]}, "mutation_prompt": null}
{"id": "5c3babaa-b16e-454e-90fb-ceef9651172d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            improvement_factor = np.exp(-global_best_value)  # New improvement factor based on best evaluation\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)\n            decay_factor = temp_factor\n            cognitive_coeff = (improvement_factor + decay_factor) * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = (decay_factor + (1 - improvement_factor)) * 1.3 * np.random.uniform(0.5, 1.5)  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Line unchanged\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive exploration-exploitation switching by modifying inertia and cognitive coefficients based on the current best evaluation.", "configspace": "", "generation": 96, "fitness": 0.8983822117589578, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e991a492-bc74-48e4-818e-db9032fd75a1", "metadata": {"aucs": [0.8619694284166779, 0.8983875607035854, 0.9347896461566103], "final_y": [0.13042563748871205, 0.1201388178231878, 0.1111646320419376]}, "mutation_prompt": null}
{"id": "39df0d65-493a-4f23-8f61-6e86bc38b228", "solution": "import numpy as np\nfrom scipy.stats import qmc\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        sampler = qmc.Sobol(d=self.dim, scramble=True)  # Chaotic Sobol sequence for initialization\n        swarm = qmc.scale(sampler.random(self.population_size), lb, ub)\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    np.random.uniform(-0.1, 0.1, self.dim))  # Add stochastic component\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance diversity by introducing chaotic Sobol sequence initialization and adjust velocity update strategy for improved convergence.", "configspace": "", "generation": 97, "fitness": 0.8973660507154824, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e991a492-bc74-48e4-818e-db9032fd75a1", "metadata": {"aucs": [0.895335184585415, 0.914223820092825, 0.8825391474682072], "final_y": [0.12288080284209202, 0.11336315664453511, 0.1225681109026191]}, "mutation_prompt": null}
{"id": "3debe8c3-62f8-4c3c-ab6c-7895ec85f510", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.learning_rates = np.random.uniform(0.8, 1.2, (self.population_size, dim))  # Add adaptive learning rates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6\n            swarm_diversity = np.std(swarm, axis=0)  # Compute swarm diversity\n            randomization_factor = np.random.uniform(0.9, 1.2)\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_learning = 1 + swarm_diversity  # Create an adaptive learning component\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * self.learning_rates[i] * adaptive_learning * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rates based on swarm diversity to enhance convergence speed and solution quality.", "configspace": "", "generation": 98, "fitness": 0.7397904822209892, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.031. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "e991a492-bc74-48e4-818e-db9032fd75a1", "metadata": {"aucs": [0.6960949993110825, 0.7565645176207232, 0.7667119297311618], "final_y": [0.20005518452079363, 0.15948394511167374, 0.1703159854333819]}, "mutation_prompt": null}
{"id": "d6c8878e-8171-4711-9ed3-5db3281d1228", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.sin(evaluations / self.budget * np.pi) + 1  # Adjusted randomization factor to vary sinusoidally\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)  # Non-linear time-varying inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by altering the randomization factor to vary with a sinusoidal pattern over time.", "configspace": "", "generation": 99, "fitness": 0.8781396299507142, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.009. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e991a492-bc74-48e4-818e-db9032fd75a1", "metadata": {"aucs": [0.8725383560817094, 0.8909536285944176, 0.8709269051760152], "final_y": [0.12849090471133828, 0.12177361455652103, 0.1304514143808737]}, "mutation_prompt": null}
{"id": "0cfef27f-784b-4c3f-ba67-eb7439c2c911", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_factor = 1 - (evaluations / self.budget) ** 1.6  # Changed decay strategy\n            randomization_factor = np.random.uniform(0.9, 1.2)  # Adjusted randomization factor\n            inertia_weight = randomization_factor * (0.5 + 0.5 * np.cos((np.pi/2) * temp_factor)**2)  # Non-linear time-varying inertia weight\n            decay_factor = temp_factor\n            cognitive_coeff = decay_factor * 1.7 * np.random.uniform(0.5, 1.5) * (1 + 0.2 * np.cos(evaluations / self.budget * np.pi))  # Modified cognitive coefficient\n            social_coeff = decay_factor * 1.3 * np.random.uniform(0.5, 1.5) * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = inertia_weight * (self.velocity[i] +\n                                    max(cognitive_coeff, 1.2 * decay_factor) * r1 * (personal_best[i] - swarm[i]) +  # Line changed\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the exploration capability by incorporating a dynamic coefficient into the social component.", "configspace": "", "generation": 100, "fitness": 0.9284346190008598, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.001. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e991a492-bc74-48e4-818e-db9032fd75a1", "metadata": {"aucs": [0.9282772935147698, 0.929123514818913, 0.9279030486688967], "final_y": [0.11041418419130733, 0.11185128766033614, 0.11356489591572716]}, "mutation_prompt": null}
