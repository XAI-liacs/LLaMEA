{"id": "30be19b8-5620-4d01-b6a1-e24e24ce259a", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_local_search_rate = 0.2\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(trial, func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_trial_fitness\n                        if local_trial_fitness < best_fitness:\n                            best_solution = local_trial\n                            best_fitness = local_trial_fitness\n\n        return best_solution\n    \n    def local_search(self, solution, func, evaluations):\n        local = solution.copy()\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "HybridDifferentialEvolution", "description": "A hybrid evolutionary algorithm combining differential evolution with adaptive local search to efficiently navigate complex landscapes and escape local minima.", "configspace": "", "generation": 0, "fitness": 0.21877408338912444, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.002. And the mean value of best solutions found was 0.257 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2211002855037909, 0.21594785681813966, 0.21927410784544277], "final_y": [0.2750063638821535, 0.2676261043965421, 0.2296697894527291]}, "mutation_prompt": null}
{"id": "23046bba-2eab-46bc-83fe-05e2598a5919", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_local_search_rate = 0.2\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = 0.5 + 0.5 * (evaluations / self.budget)\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                self.crossover_rate = 0.5 + 0.4 * np.random.rand()\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(trial, func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_trial_fitness\n                        if local_trial_fitness < best_fitness:\n                            best_solution = local_trial\n                            best_fitness = local_trial_fitness\n\n        return best_solution\n    \n    def local_search(self, solution, func, evaluations):\n        local = solution.copy()\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "HybridDifferentialEvolution", "description": "Enhanced Hybrid Differential Evolution with dynamic crossover and mutation strategies for improved exploration and convergence.", "configspace": "", "generation": 1, "fitness": 0.2268606679303166, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.003. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "30be19b8-5620-4d01-b6a1-e24e24ce259a", "metadata": {"aucs": [0.23098230333178227, 0.22527141292448383, 0.2243282875346837], "final_y": [0.21572019161637612, 0.20785174107232074, 0.244605181011195]}, "mutation_prompt": null}
{"id": "584e485e-4375-47e8-95d5-1cb3f7d518dc", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_local_search_rate = 0.2\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = 0.5 + 0.5 * (evaluations / self.budget)\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                self.crossover_rate = 0.5 + 0.4 * np.random.rand()\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(trial, func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_trial_fitness\n                        if local_trial_fitness < best_fitness:\n                            best_solution = local_trial\n                            best_fitness = local_trial_fitness\n\n        return best_solution\n    \n    def local_search(self, solution, func, evaluations):\n        local = solution.copy()\n        adaptive_perturbation = 0.1 * (1 - evaluations / self.budget)  # Adaptive scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)  # Line changed\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "HybridDifferentialEvolution", "description": "Enhanced Hybrid Differential Evolution with improved local search by adaptive perturbation scaling.", "configspace": "", "generation": 2, "fitness": 0.22745465891215322, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.003. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "23046bba-2eab-46bc-83fe-05e2598a5919", "metadata": {"aucs": [0.23097082371402844, 0.2252649810316798, 0.22612817199075141], "final_y": [0.2158177765900835, 0.20793502691001964, 0.23097078554697936]}, "mutation_prompt": null}
{"id": "3ae77f37-7947-442c-af3d-0bac1865a7a9", "solution": "import numpy as np\n\nclass QuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10 * dim\n        self.harmony_memory = None\n        self.harmony_memory_consideration_rate = 0.95\n        self.pitch_adjustment_rate = 0.5\n        self.bounds = None\n    \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.harmony_memory = np.random.uniform(self.bounds[0], self.bounds[1], (self.harmony_memory_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, self.harmony_memory)\n        evaluations = self.harmony_memory_size\n        best_idx = np.argmin(fitness)\n        best_solution = self.harmony_memory[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n\n            for i in range(self.dim):\n                if np.random.rand() < self.harmony_memory_consideration_rate:\n                    harmony_index = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[harmony_index, i]\n                    if np.random.rand() < self.pitch_adjustment_rate:\n                        adaptive_step = (self.bounds[1] - self.bounds[0]) * (1 - evaluations / self.budget) * np.random.normal()\n                        new_harmony[i] += adaptive_step\n                        new_harmony[i] = np.clip(new_harmony[i], self.bounds[0], self.bounds[1])\n                else:\n                    new_harmony[i] = np.random.uniform(self.bounds[0], self.bounds[1])\n\n            new_fitness = func(new_harmony)\n            evaluations += 1\n\n            if new_fitness < best_fitness:\n                best_solution = new_harmony\n                best_fitness = new_fitness\n\n            worst_idx = np.argmax(fitness)\n            if new_fitness < fitness[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                fitness[worst_idx] = new_fitness\n                \n        return best_solution", "name": "QuantumHarmonySearch", "description": "Quantum-inspired Harmony Search with Adaptive Memory Consideration for diverse and efficient exploration of search space.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "584e485e-4375-47e8-95d5-1cb3f7d518dc", "metadata": {}, "mutation_prompt": null}
{"id": "e0998200-1494-41fe-bc8e-4675f005141b", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_local_search_rate = 0.2\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = 0.6 + 0.4 * (evaluations / self.budget)  # Line changed\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                self.crossover_rate = 0.6 + 0.3 * np.random.rand()  # Line changed\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(trial, func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_trial_fitness\n                        if local_trial_fitness < best_fitness:\n                            best_solution = local_trial\n                            best_fitness = local_trial_fitness\n\n        return best_solution\n    \n    def local_search(self, solution, func, evaluations):\n        local = solution.copy()\n        adaptive_perturbation = 0.1 * (1 - evaluations / self.budget)  # Adaptive scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)  # Line changed\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "HybridDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive crossover and mutation strategies for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.22577108907950058, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.001. And the mean value of best solutions found was 0.235 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "584e485e-4375-47e8-95d5-1cb3f7d518dc", "metadata": {"aucs": [0.22568703398605738, 0.2244920591167705, 0.22713417413567383], "final_y": [0.22887565432134038, 0.23362467265987297, 0.24295076032347585]}, "mutation_prompt": null}
{"id": "940d15f3-9cd4-4d27-96df-3bf5752a4fb4", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.3\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + social_component)              \n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.1 * np.exp(-evaluations / self.budget)  # Exponential perturbation reduction\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Particle Swarm Optimization with Adaptive Inertia Weight and Local Search infused with Stochastic Perturbations.", "configspace": "", "generation": 5, "fitness": 0.22819252070287585, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.002. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "584e485e-4375-47e8-95d5-1cb3f7d518dc", "metadata": {"aucs": [0.22795678864431235, 0.22622052308567586, 0.23040025037863932], "final_y": [0.2046191000909645, 0.20453459853755707, 0.18318737994511802]}, "mutation_prompt": null}
{"id": "7cce9b22-954c-4fed-85c3-44cb1b9d621b", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.exploration_exploitation_balance = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamic balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhanced Particle Swarm Optimization with Dynamic Exploration-Exploitation and Informed Local Search using Memory-based Perturbations.", "configspace": "", "generation": 6, "fitness": 0.23133722665015963, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.004. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "940d15f3-9cd4-4d27-96df-3bf5752a4fb4", "metadata": {"aucs": [0.23428804547675985, 0.2252926097039465, 0.2344310247697725], "final_y": [0.16558610921178685, 0.1823466270157772, 0.16753127925168587]}, "mutation_prompt": null}
{"id": "ba085487-ff77-4d75-bfeb-b9e921a2be8a", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.5  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.exploration_exploitation_balance = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamic balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.1 * np.exp(-evaluations / self.budget)  # Increased perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Adaptive Particle Swarm Optimization with Enhanced Local Search using Dynamic Perturbations for Improved Global Convergence.", "configspace": "", "generation": 7, "fitness": 0.2307629878146966, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.004. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7cce9b22-954c-4fed-85c3-44cb1b9d621b", "metadata": {"aucs": [0.23345080888434755, 0.2253859313613471, 0.2334522231983951], "final_y": [0.18275726965848937, 0.1667576560209424, 0.16557383425076477]}, "mutation_prompt": null}
{"id": "7979deb0-deec-4253-a00f-4d5557ef37cd", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        # Changed line 1: Using chaotic sequence for initialization\n        swarm_positions = self.chaotic_initialization(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.exploration_exploitation_balance = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamic balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Changed line 2: Fitness-based inertia weight update\n                self.inertia_weight = 0.5 + 0.4 * (global_best_fitness / np.min(personal_best_fitness))\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local\n    \n    # Changed line 3-6: New method for chaotic initialization\n    def chaotic_initialization(self, lb, ub, shape):\n        # Logistic map for chaotic numbers\n        x = np.random.random(shape)  # Random initial values\n        for _ in range(10):  # Iterate to ensure chaotic sequence\n            x = 4 * x * (1 - x)\n        return lb + (ub - lb) * x", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhanced Adaptive PSO with Chaos-Driven Initialization and Fitness-Based Inertia for improved convergence and diversity.", "configspace": "", "generation": 8, "fitness": 0.21815502942109963, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.004. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "7cce9b22-954c-4fed-85c3-44cb1b9d621b", "metadata": {"aucs": [0.21358938115188408, 0.218084417958599, 0.22279128915281576], "final_y": [0.3289883650282761, 0.302690449220283, 0.2708593744528327]}, "mutation_prompt": null}
{"id": "0afe4a61-fc9a-4fdc-8a6c-3de57369dcc8", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.exploration_exploitation_balance = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamic balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + (0.5 * evaluations / self.budget)\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Modified AdaptiveParticleSwarmOptimization with a dynamic cognitive coefficient to enhance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.23330258877808205, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.006. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7cce9b22-954c-4fed-85c3-44cb1b9d621b", "metadata": {"aucs": [0.2335079689733961, 0.22639076804990832, 0.2400090293109417], "final_y": [0.16568201266439286, 0.1822792019285403, 0.1658400439954596]}, "mutation_prompt": null}
{"id": "58eaf369-8d1d-4f3d-9510-59a92d7d77a9", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.5  # dynamically increased social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.exploration_exploitation_balance = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamic balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + (0.5 * evaluations / self.budget)\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhanced exploration by dynamically increasing social coefficient for better convergence.", "configspace": "", "generation": 10, "fitness": 0.23135548217763469, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.008. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "0afe4a61-fc9a-4fdc-8a6c-3de57369dcc8", "metadata": {"aucs": [0.2388427504951598, 0.2209931430972184, 0.23423055294052586], "final_y": [0.18235649247217378, 0.18362278377074315, 0.1666231682306225]}, "mutation_prompt": null}
{"id": "59762514-77e1-43f5-8ba7-66e652076a53", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive swarm size and nonlinear cognitive adjustment to enhance convergence and diversity in search.", "configspace": "", "generation": 11, "fitness": 0.2420354161835766, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0afe4a61-fc9a-4fdc-8a6c-3de57369dcc8", "metadata": {"aucs": [0.24181267874181345, 0.2448172078109696, 0.23947636199794675], "final_y": [0.16485578749072904, 0.16485577294306508, 0.1648558004604037]}, "mutation_prompt": null}
{"id": "10e341ad-8bab-4d4e-bc3f-a2c9a0237c1f", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.5  # Adjusted local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Fine-tune the adaptive local search rate to improve exploration and convergence efficiency.", "configspace": "", "generation": 12, "fitness": 0.24013472413655568, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.24302043400777795, 0.24041777343685733, 0.23696596496503175], "final_y": [0.16485580930232313, 0.16485579426006536, 0.164855776704793]}, "mutation_prompt": null}
{"id": "3a5d87c6-a1a3-4747-90f0-fba6e10101cb", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Dynamic social adaptation\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance the swarm's ability to escape local minima by introducing dynamic social coefficient adaptation.", "configspace": "", "generation": 13, "fitness": 0.24095268102096745, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.24014370488269943, 0.244656459318913, 0.23805787886128993], "final_y": [0.16485578834943881, 0.16485577472422808, 0.16485578069133333]}, "mutation_prompt": null}
{"id": "3a9e6ad5-f2fd-4af7-985b-3caa86d6768a", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive swarm size and nonlinear cognitive adjustment to enhance convergence and diversity in search.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.24181267874181345, 0.2448172078109696, 0.23947636199794675], "final_y": [0.16485578749072904, 0.16485577294306508, 0.1648558004604037]}, "mutation_prompt": null}
{"id": "f5accdb6-3fe3-4dff-aa6b-260d38eef6ff", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n        elite_position = global_best_position.copy()  # Elite retention\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with nonlinear scheme\n                self.inertia_weight = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)\n                \n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update velocity with self-adaptive clamping\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)\n                velocity_clamp = np.clip(swarm_velocities[i], -0.1, 0.1)  # Clamping velocities\n                swarm_velocities[i] = velocity_clamp\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n                        elite_position = global_best_position.copy()  # Update elite\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n                            elite_position = global_best_position.copy()  # Update elite\n\n        return elite_position  # Return elite solution\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by introducing dynamic inertia, self-adaptive velocity clamping, and elite retention in the swarm.", "configspace": "", "generation": 15, "fitness": 0.20865502491288945, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.209 with standard deviation 0.000. And the mean value of best solutions found was 0.391 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.20808116726699, 0.20879174438223702, 0.20909216308944134], "final_y": [0.3984193692201833, 0.38444606721734553, 0.3894653779337103]}, "mutation_prompt": null}
{"id": "86fa176b-d257-415d-ae48-eea55a9228ac", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.4 * (self.budget - evaluations) / self.budget)\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Dynamic social coefficient\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.1 * np.exp(-evaluations / self.budget)  # Enhanced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance diversity in search by introducing dynamic social coefficients and adaptive perturbations.", "configspace": "", "generation": 16, "fitness": 0.2409785331556332, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.24008879548714235, 0.2447588182415774, 0.2380879857381798], "final_y": [0.16485579619437196, 0.16485577881502889, 0.16485578333876472]}, "mutation_prompt": null}
{"id": "1eabfbc3-b584-4f62-8731-9b43c172e119", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.bounds = None\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        population = np.random.uniform(self.bounds[0], self.bounds[1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        \n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                    \n                # Select indices for mutation\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Mutation and crossover\n                mutant = np.clip(population[a] + self.mutation_factor * (population[b] - population[c]), self.bounds[0], self.bounds[1])\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection process\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n            \n            # Adaptive mutation factor\n            self.mutation_factor = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)\n        \n        return best_solution", "name": "HybridDifferentialEvolution", "description": "Utilize hybrid differential evolution with adaptive mutation rates and elitism to enhance exploration and balance exploitation for robust optimization.", "configspace": "", "generation": 17, "fitness": 0.22375015605843954, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.002. And the mean value of best solutions found was 0.247 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.22602725292366166, 0.22057147999049953, 0.22465173526115745], "final_y": [0.24211852145328716, 0.2650827560139316, 0.2323804298562524]}, "mutation_prompt": null}
{"id": "56687510-4412-4cc5-bc4c-cc900871a08b", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * (self.budget - evaluations) / self.budget)  # Adjusted reduction\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Adaptively adjust local search rate and reduce inertia weight to improve exploration and convergence.", "configspace": "", "generation": 18, "fitness": 0.24473691208909906, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59762514-77e1-43f5-8ba7-66e652076a53", "metadata": {"aucs": [0.2454019562658456, 0.24420026935074934, 0.24460851065070222], "final_y": [0.16485577221469594, 0.16485577197514834, 0.16485577254837436]}, "mutation_prompt": null}
{"id": "00216faf-5242-46aa-9383-c6aa2d4b1b89", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        self.reduction_factor = 0.8  # New parameter for dimensionality reduction\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n        \n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            \n            if evaluations > self.budget * 0.5:  # Start dimensionality reduction in the second half of budget\n                reduced_dim = int(self.dim * self.reduction_factor)\n                reduction_indices = np.random.choice(self.dim, reduced_dim, replace=False)\n            else:\n                reduction_indices = np.arange(self.dim)\n            \n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + (0.3 * (self.budget - evaluations) / self.budget)\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(len(reduction_indices)), np.random.rand(len(reduction_indices))\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i][reduction_indices] - swarm_positions[i][reduction_indices])\n                social_component = self.c2 * r2 * (global_best_position[reduction_indices] - swarm_positions[i][reduction_indices])\n                \n                swarm_velocities[i][reduction_indices] = (self.inertia_weight * swarm_velocities[i][reduction_indices] +\n                                                           cognitive_component +\n                                                           social_component * self.exploration_exploitation_balance)\n                \n                swarm_positions[i][reduction_indices] = np.clip(\n                    swarm_positions[i][reduction_indices] + swarm_velocities[i][reduction_indices],\n                    self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, reduction_indices)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, reduction_indices):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, len(reduction_indices))\n        local[reduction_indices] += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Introduce dynamic dimensionality reduction and adaptive perturbation scaling to balance exploration and exploitation effectively.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (8,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (8,) (10,) (10,) ')", "parent_id": "56687510-4412-4cc5-bc4c-cc900871a08b", "metadata": {}, "mutation_prompt": null}
{"id": "c52f9ff2-eacd-4747-a2fd-8d75ff19aedf", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + (0.3 * (self.budget - evaluations) / self.budget)\n\n                self.c1 = 1.5 + 0.7 * np.cos(np.pi * evaluations / self.budget)  # Slight increase in cognitive randomness\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)\n                \n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a slight increase in cognitive randomness for enhanced exploration in adaptive PSO.", "configspace": "", "generation": 20, "fitness": 0.243290821245602, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "56687510-4412-4cc5-bc4c-cc900871a08b", "metadata": {"aucs": [0.24414228372497426, 0.24328692867124924, 0.24244325134058253], "final_y": [0.16485577220715453, 0.16485577196673906, 0.1648557763303805]}, "mutation_prompt": null}
{"id": "86970118-641f-417e-b8dc-7c46b93b7f4d", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * (self.budget - evaluations) / self.budget)  # Adjusted reduction\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Incorporate a nonlinear adjustment to the social coefficient to enhance global search dynamics.", "configspace": "", "generation": 21, "fitness": 0.245503059187397, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "56687510-4412-4cc5-bc4c-cc900871a08b", "metadata": {"aucs": [0.24549317645526403, 0.24579189897621934, 0.24522410213070767], "final_y": [0.1648557725082972, 0.16485577255368034, 0.16485577335704715]}, "mutation_prompt": null}
{"id": "135c2c7d-366e-47dd-811d-2057493f9014", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * np.cos(np.pi * evaluations / self.budget))  # Changed to cosine function\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic inertia weight adjustment to enhance convergence speed and solution quality.", "configspace": "", "generation": 22, "fitness": 0.24568887596437095, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "86970118-641f-417e-b8dc-7c46b93b7f4d", "metadata": {"aucs": [0.24570797110398257, 0.24584370870509875, 0.24551494808403151], "final_y": [0.16485577207468094, 0.1648557724718962, 0.16485577263507]}, "mutation_prompt": null}
{"id": "bb9f0bcb-ddef-4ad0-aa30-f0ed42091bcd", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * np.cos(np.pi * evaluations / self.budget))  # Changed to cosine function\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.1 * np.exp(-evaluations / self.budget)  # Increased perturbation amplitude\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce an adaptive exploration strategy by varying the amplitude of perturbation in local search.", "configspace": "", "generation": 23, "fitness": 0.24568814850561294, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "135c2c7d-366e-47dd-811d-2057493f9014", "metadata": {"aucs": [0.24570986743254475, 0.24584447577413093, 0.24551010231016313], "final_y": [0.16485577356625436, 0.1648557719865641, 0.16485577206385993]}, "mutation_prompt": null}
{"id": "f47440cc-dfa6-4afb-bbb7-0e5b51c53894", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Changed to cosine\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * np.cos(np.pi * evaluations / self.budget))  # Changed to cosine function\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.sin(np.pi * evaluations / self.budget)  # Changed to sine\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce dynamic perturbation adjustment and non-linear exploration-exploitation balance for enhanced search capability.", "configspace": "", "generation": 24, "fitness": 0.24488837694766977, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "135c2c7d-366e-47dd-811d-2057493f9014", "metadata": {"aucs": [0.24482291781959553, 0.24475957302984075, 0.24508263999357305], "final_y": [0.16485940225687412, 0.1648557827623005, 0.16485578226366948]}, "mutation_prompt": null}
{"id": "25a9617e-01b1-41d7-b30f-6bfc55909c93", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * np.cos(np.pi * evaluations / self.budget))  # Changed to cosine function\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95  # Add damping factor to velocity\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive mutation strength and refine velocity update to enhance exploration-exploitation.", "configspace": "", "generation": 25, "fitness": 0.24651260912372397, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "135c2c7d-366e-47dd-811d-2057493f9014", "metadata": {"aucs": [0.24659498600210394, 0.24659360044929612, 0.24634924091977184], "final_y": [0.16485577225293124, 0.16485577199211499, 0.1648557725530918]}, "mutation_prompt": null}
{"id": "ccef7781-e247-4ff0-9993-0751a7145c98", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95  # Add damping factor to velocity\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce nonlinear stochastic inertia weight decay to enhance convergence speed.", "configspace": "", "generation": 26, "fitness": 0.24670765532936645, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "25a9617e-01b1-41d7-b30f-6bfc55909c93", "metadata": {"aucs": [0.2465780780376584, 0.24664918891704213, 0.2468956990333988], "final_y": [0.1648557719154764, 0.16485577192082412, 0.16485577198217383]}, "mutation_prompt": null}
{"id": "0ea60f23-feb2-488a-80ba-29a1c78edc4e", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget) * self.exploration_exploitation_balance  # Adaptive scaling added\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95  # Add damping factor to velocity\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive social component scaling based on exploration-exploitation balance to improve convergence. ", "configspace": "", "generation": 27, "fitness": 0.24643277241619177, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ccef7781-e247-4ff0-9993-0751a7145c98", "metadata": {"aucs": [0.2457383187746225, 0.24656300556192545, 0.24699699291202737], "final_y": [0.16485577205392166, 0.1648557719767999, 0.16485577191204126]}, "mutation_prompt": null}
{"id": "e99ec2de-cbe5-498c-b702-22044b2368d5", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance +\n                                       np.random.rand() * 0.1)  # Introduced a dynamic random factor\n                swarm_velocities[i] *= 0.95  # Add damping factor to velocity\n                \n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic random factor in the velocity update for improved exploration.", "configspace": "", "generation": 28, "fitness": 0.24650567864653775, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ccef7781-e247-4ff0-9993-0751a7145c98", "metadata": {"aucs": [0.2465911945460344, 0.24616084944663685, 0.24676499194694201], "final_y": [0.1648561868676568, 0.16485643830718422, 0.1648563091821016]}, "mutation_prompt": null}
{"id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce an adaptive velocity damping factor to balance exploration and exploitation dynamics.", "configspace": "", "generation": 29, "fitness": 0.2468790904884954, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ccef7781-e247-4ff0-9993-0751a7145c98", "metadata": {"aucs": [0.24669467624908104, 0.2468209313177394, 0.24712166389866574], "final_y": [0.16485577342166258, 0.16485578265377376, 0.16485579093031422]}, "mutation_prompt": null}
{"id": "7f2d1475-57cb-4e11-b074-998e436b31e2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.5\n        self.bounds = None\n        self.neighborhood_size = 5  # Neighborhood size for local informant\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1\n            self.inertia_weight = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)\n            self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n            self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                \n                # Choose a random neighborhood for local informant\n                neighbors = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n                local_best_index = neighbors[np.argmin(personal_best_fitness[neighbors])]\n                local_best_position = personal_best_positions[local_best_index]\n                \n                social_component = self.c2 * r2 * (local_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + social_component)\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n\n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        subgroup_size = max(1, int(self.dim * 0.1))  # 10% of dimensions\n        perturbation_indices = np.random.choice(self.dim, subgroup_size, replace=False)\n        perturbation = np.random.normal(0, adaptive_perturbation, subgroup_size)\n        local[perturbation_indices] += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Incorporate a dynamically adaptive neighborhood topology and random subgroup learning to enhance global convergence and avoid local minima.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {}, "mutation_prompt": null}
{"id": "f5461aa3-b474-4e27-9ee7-c9e4a5caa5cf", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * (1 - evaluations / self.budget)  # Dynamic perturbation factor\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic perturbation factor in local search to enhance solution diversity.", "configspace": "", "generation": 31, "fitness": 0.24687908668853065, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.24669466607832535, 0.24682092423451962, 0.24712166975274696], "final_y": [0.1648557719837982, 0.16485577206079305, 0.16485577205926205]}, "mutation_prompt": null}
{"id": "bf627d22-873b-4617-95cf-952f4bcb0239", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically with stochastic variation\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget + np.random.rand())  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget + 0.1))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance global search by adjusting velocity damping and cognitive component dynamically.", "configspace": "", "generation": 32, "fitness": 0.24686554020908305, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.2469975426683857, 0.24657937018311482, 0.24701970777574866], "final_y": [0.16485577563395393, 0.16485577972290577, 0.16485578295527303]}, "mutation_prompt": null}
{"id": "2d2b3b5a-cfdc-4efd-8334-3b9f302fcb09", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            if evaluations % (self.budget // 4) == 0:  # Dynamic reinitialization\n                swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce dynamic swarm reinitialization to enhance convergence speed and avoid local optima.", "configspace": "", "generation": 33, "fitness": 0.2468790904884954, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.24669467624908104, 0.2468209313177394, 0.24712166389866574], "final_y": [0.16485577342166258, 0.16485578265377376, 0.16485579093031422]}, "mutation_prompt": null}
{"id": "9583a54a-ee99-480f-a6a8-a1b87adaf9b0", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1  # Adaptive swarm size\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                velocity_cap = (self.bounds[1] - self.bounds[0]) * 0.1 * (1 - evaluations / self.budget)  # Dynamic velocity cap\n                swarm_velocities[i] = np.clip(swarm_velocities[i], -velocity_cap, velocity_cap)  # Apply velocity cap\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * (0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget))  # Improved perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Optimize local search strategy and velocity update by introducing an adaptive perturbation and dynamic velocity cap.", "configspace": "", "generation": 34, "fitness": 0.2465979815129137, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.24670423785673024, 0.24657497394845163, 0.24651473273355928], "final_y": [0.16485577190497525, 0.164855771917772, 0.16485577190787293]}, "mutation_prompt": null}
{"id": "29f74b30-089b-4368-bb0c-d7e060b7456f", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)\n                swarm_velocities[i] *= 0.9 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.1 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Leverage nonlinear adaptive coefficients with hybrid local search intensification to enhance convergence and diversity.", "configspace": "", "generation": 35, "fitness": 0.24687545462299965, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.24656782994384807, 0.24671812529806292, 0.24734040862708795], "final_y": [0.16485583805071058, 0.16485585471922315, 0.16485580007050904]}, "mutation_prompt": null}
{"id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic swarm size reduction based on the current fitness improvement rate.", "configspace": "", "generation": 36, "fitness": 0.24724849434671733, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "733f7c10-c0d8-45f1-9bbc-a78f6e78b532", "metadata": {"aucs": [0.24718133913186813, 0.24712568564021697, 0.24743845826806687], "final_y": [0.1648557810248964, 0.16485578466726236, 0.16485578017667646]}, "mutation_prompt": null}
{"id": "cf0824fe-1638-483e-aa84-446db609ed94", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic swarm size reduction based on the current fitness improvement rate.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.24718133913186813, 0.24712568564021697, 0.24743845826806687], "final_y": [0.1648557810248964, 0.16485578466726236, 0.16485578017667646]}, "mutation_prompt": null}
{"id": "1692d656-6516-474f-b538-04710dad9dca", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n        initial_fitness_spread = np.ptp(personal_best_fitness)  # Calculate initial fitness spread\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand())) * (initial_fitness_spread / np.max(personal_best_fitness))  # Changed to adaptive initialization\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive inertia weight initialization based on the initial fitness spread to enhance exploration.", "configspace": "", "generation": 38, "fitness": 0.24594355412740285, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.24300472679706087, 0.24724791721452566, 0.247578018370622], "final_y": [0.1818781144957936, 0.16485579002104878, 0.16485578533571543]}, "mutation_prompt": null}
{"id": "ddb1b5cd-6b12-4153-ae9b-4a7e8206fd1d", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with nonlinear decay\n                self.inertia_weight = 0.4 + 0.3 * (1 - (evaluations / self.budget)**2)  # Changed to nonlinear decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)  # Adjusted for balance\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce non-linear inertia weight decay for enhanced exploration-exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.24694535868635656, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.2472531260910883, 0.24628225125851022, 0.24730069870947113], "final_y": [0.16485577948048002, 0.16485578157200675, 0.16485578364238063]}, "mutation_prompt": null}
{"id": "5c6e375b-512c-44a5-891b-516909a77001", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))\n                self.c1 = 1.5 + 0.5 * (global_best_fitness / (personal_best_fitness[i] + 1e-9))  # Fitness-based cognitive adjustment\n                self.c2 = 1.5 + 0.5 * (1 - global_best_fitness / (np.min(personal_best_fitness) + 1e-9))  # Fitness-based social adjustment\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance)\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive learning coefficients with fitness-based scaling to enhance global exploration and local exploitation.", "configspace": "", "generation": 40, "fitness": 0.247069596523258, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.2469048550119829, 0.24690214599494043, 0.24740178856285067], "final_y": [0.16485599324558242, 0.16491117102160957, 0.16485837442892104]}, "mutation_prompt": null}
{"id": "aa754622-4ec3-4bba-a60c-671d9f25e44a", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.5 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] +\n                                       cognitive_component + social_component)\n                swarm_velocities[i] *= 0.9 * (1 - 0.6 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Refined Adaptive Particle Swarm Optimization with enhanced velocity adjustment and dynamic exploration for better convergence.", "configspace": "", "generation": 41, "fitness": 0.2453509689073093, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.24267240579177318, 0.24660286184839475, 0.24677763908175998], "final_y": [0.1818781053376739, 0.16485579760795255, 0.1648557859464027]}, "mutation_prompt": null}
{"id": "28935660-2a91-4856-9e4d-313f563c0378", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))  # Changed to stochastic decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a time-varying stochastic element in velocity update to enhance exploration.", "configspace": "", "generation": 42, "fitness": 0.24731952826129056, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "07325e5b-f22e-45f4-939b-6b08b87b6a9d", "metadata": {"aucs": [0.2473092603123398, 0.24707493240933687, 0.247574392062195], "final_y": [0.16485592631039936, 0.16485587853890593, 0.16485588188320943]}, "mutation_prompt": null}
{"id": "0c8f6293-ae89-417a-a978-4dcec99b4947", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                if np.random.rand() < 0.1:  # Introduced adaptive mutation rate\n                    swarm_positions[i] += np.random.normal(0, 0.1, self.dim)  # Apply mutation\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive mutation to diversify the search space exploration and avoid premature convergence.", "configspace": "", "generation": 43, "fitness": 0.24569106691527343, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "28935660-2a91-4856-9e4d-313f563c0378", "metadata": {"aucs": [0.24249108497545213, 0.24698293397213833, 0.24759918179822982], "final_y": [0.18187817426566844, 0.16485598497350218, 0.16485588635383952]}, "mutation_prompt": null}
{"id": "6b013d4a-829e-4d9f-a137-91deda8dcaf6", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.cos(np.pi * evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.differential_evolution(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def differential_evolution(self, position, func, evaluations):  # Changed function name and content\n        f = 0.8  # Differential weight\n        cr = 0.9  # Crossover probability\n        idxs = [np.random.randint(0, self.swarm_size) for _ in range(3)]\n        a, b, c = personal_best_positions[idxs]\n        mutant = np.clip(a + f * (b - c), self.bounds[0], self.bounds[1])\n        cross_points = np.random.rand(self.dim) < cr\n        trial = np.where(cross_points, mutant, position)\n        return np.clip(trial, self.bounds[0], self.bounds[1])", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance local search by integrating differential evolution for improved exploitation.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'personal_best_positions' is not defined\").", "error": "NameError(\"name 'personal_best_positions' is not defined\")", "parent_id": "28935660-2a91-4856-9e4d-313f563c0378", "metadata": {}, "mutation_prompt": null}
{"id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive inertia weight decay using a non-linear exponential function for enhanced convergence.", "configspace": "", "generation": 45, "fitness": 0.2473765357138182, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "28935660-2a91-4856-9e4d-313f563c0378", "metadata": {"aucs": [0.247440564434799, 0.24711184238421535, 0.24757720032244024], "final_y": [0.16485598587128314, 0.16485590270733907, 0.16485595677275267]}, "mutation_prompt": null}
{"id": "9b8ca3fa-aff3-427d-8b02-96b81493460a", "solution": "import numpy as np\n\nclass DynamicMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3  # Use multiple swarms for diversified search\n        self.swarm_size = 3 * dim\n        self.initial_swarm_size = self.swarm_size\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.local_search_rate = 0.3\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        global_best_position = None\n        global_best_fitness = np.inf\n        swarm_positions = []\n        swarm_velocities = []\n        personal_best_positions = []\n        personal_best_fitness = []\n        \n        for _ in range(self.num_swarms):\n            positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n            velocities = np.zeros((self.swarm_size, self.dim))\n            personal_best = positions.copy()\n            fitness = np.apply_along_axis(func, 1, personal_best)\n            \n            swarm_positions.append(positions)\n            swarm_velocities.append(velocities)\n            personal_best_positions.append(personal_best)\n            personal_best_fitness.append(fitness)\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < global_best_fitness:\n                global_best_position = personal_best[best_index]\n                global_best_fitness = fitness[best_index]\n        \n        evaluations = self.swarm_size * self.num_swarms\n\n        while evaluations < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    if evaluations >= self.budget:\n                        break\n\n                    self.inertia_weight = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear dynamic inertia\n                    self.c1 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n                    self.c2 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_component = self.c1 * r1 * (personal_best_positions[swarm_idx][i] - swarm_positions[swarm_idx][i])\n                    social_component = self.c2 * r2 * (global_best_position - swarm_positions[swarm_idx][i])\n                    \n                    swarm_velocities[swarm_idx][i] = (self.inertia_weight * swarm_velocities[swarm_idx][i] + cognitive_component + social_component)\n                    swarm_velocities[swarm_idx][i] *= 0.9  # Slight damping\n                    \n                    swarm_positions[swarm_idx][i] = np.clip(swarm_positions[swarm_idx][i] + swarm_velocities[swarm_idx][i], self.bounds[0], self.bounds[1])\n                    \n                    current_fitness = func(swarm_positions[swarm_idx][i])\n                    evaluations += 1\n\n                    if current_fitness < personal_best_fitness[swarm_idx][i]:\n                        personal_best_positions[swarm_idx][i] = swarm_positions[swarm_idx][i]\n                        personal_best_fitness[swarm_idx][i] = current_fitness\n\n                        if current_fitness < global_best_fitness:\n                            global_best_position = swarm_positions[swarm_idx][i]\n                            global_best_fitness = current_fitness\n\n                    if np.random.rand() < self.local_search_rate:\n                        local_trial = self.local_search(swarm_positions[swarm_idx][i], func, evaluations)\n                        evaluations += 1\n                        local_trial_fitness = func(local_trial)\n                        if local_trial_fitness < personal_best_fitness[swarm_idx][i]:\n                            personal_best_positions[swarm_idx][i] = local_trial\n                            personal_best_fitness[swarm_idx][i] = local_trial_fitness\n                            if local_trial_fitness < global_best_fitness:\n                                global_best_position = local_trial\n                                global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "DynamicMultiSwarmPSO", "description": "Employ a dynamic multi-swarm strategy with adaptive learning rates and inertia weights to balance global exploration and local exploitation.", "configspace": "", "generation": 46, "fitness": 0.24086017709014498, "feedback": "The algorithm DynamicMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.2434394188618605, 0.2386874179934131, 0.2404536944151614], "final_y": [0.1648557832853459, 0.1818781106481907, 0.16485583783853242]}, "mutation_prompt": null}
{"id": "8f5993d1-1f42-4802-aa64-16a4ceaf237f", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget)) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            neighbor_radius = int(self.dim * np.cos(np.pi * evaluations / (2 * self.budget))) + 1  # Dynamic neighborhood size\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                velocity_scaling = 0.9 - 0.4 * (evaluations / self.budget)**2  # Nonlinear scaling\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance) * velocity_scaling\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic neighborhood adjustment strategy and nonlinear velocity scaling to enhance the exploitation phase.", "configspace": "", "generation": 47, "fitness": 0.2467120463076581, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.24665759953007016, 0.246597576294998, 0.2468809630979062], "final_y": [0.16485577191078127, 0.16485577190898915, 0.16485577191849787]}, "mutation_prompt": null}
{"id": "96289c6c-ef30-4122-a18e-1bebf142dfde", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a nonlinear adaptive social coefficient adjustment using cosine for enhanced convergence.", "configspace": "", "generation": 48, "fitness": 0.24724398015143256, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.24725830438057605, 0.24714907199044067, 0.24732456408328096], "final_y": [0.16485591609677352, 0.16485584104387352, 0.16485584855311408]}, "mutation_prompt": null}
{"id": "a070c83f-d23e-4273-84cf-178931c885ec", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand())) + 0.1 * np.sin(2 * np.pi * evaluations / self.budget) # Changed to exponential decay + oscillation\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive swarm size reduction and variable inertia weight oscillation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": 0.24731502997153001, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.24734249589321888, 0.24708609948144977, 0.24751649453992142], "final_y": [0.16485590105377934, 0.16485587154088466, 0.1648558665026133]}, "mutation_prompt": null}
{"id": "417ee1fc-d6bd-492a-afe7-e661313a8ff8", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        convergence_measure = np.std(np.apply_along_axis(func, 1, personal_best_positions))  # Convergence measure\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * convergence_measure  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance local search by incorporating a dynamic perturbation magnitude based on the swarm's convergence state.", "configspace": "", "generation": 50, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'personal_best_positions' is not defined\").", "error": "NameError(\"name 'personal_best_positions' is not defined\")", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {}, "mutation_prompt": null}
{"id": "71c45eca-4bee-4d52-a72b-160d159a052f", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                levy = np.random.standard_cauchy(self.dim) * 0.01  # Lévy flight step\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + levy)  # Lévy flight applied here\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Further optimize exploration by incorporating Lévy flight for stochastic position updates in the particle swarm.", "configspace": "", "generation": 51, "fitness": 0.24731093667789236, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.24685582176618992, 0.2473376252329076, 0.24773936303457955], "final_y": [0.16485580768882313, 0.16485579010981932, 0.16485580478093864]}, "mutation_prompt": null}
{"id": "d3c21726-6770-4974-98cb-0f1413a449c3", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                chaotic_factor = 0.7 * np.sin(np.pi * evaluations / self.budget)  # Chaotic sequence factor\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, chaotic_factor, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Refine velocity update with adaptive chaotic sequences for improved exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.2473277962188013, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.2474282058074455, 0.24696812554149317, 0.24758705730746522], "final_y": [0.16485584391974217, 0.1648559131870314, 0.16485582363766127]}, "mutation_prompt": null}
{"id": "ef19b61e-68f1-4a10-9a27-0723038fbb3f", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.95  # Adjusted initial inertia weight\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Nonlinear cognitive adjustment\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive inertia weight decay using a non-linear exponential function for enhanced convergence with a slight increase in initial inertia weight.", "configspace": "", "generation": 53, "fitness": 0.2473765357138182, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.247440564434799, 0.24711184238421535, 0.24757720032244024], "final_y": [0.16485598587128314, 0.16485590270733907, 0.16485595677275267]}, "mutation_prompt": null}
{"id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)  # Added adaptive decay factor\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce an adaptive decay factor to the cognitive coefficient for enhanced balance between local and global searches.", "configspace": "", "generation": 54, "fitness": 0.24738005577681724, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8724376c-ceb4-410d-b42f-2dcdae2c62fd", "metadata": {"aucs": [0.24744381458212306, 0.24710642686397954, 0.24758992588434914], "final_y": [0.1648558870607496, 0.1648559642036299, 0.1648558610407499]}, "mutation_prompt": null}
{"id": "aece0772-edb4-41d6-8a83-3b3eebf1b258", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            self.adaptive_local_search_rate = 0.4 + 0.2 * np.cos(np.pi * evaluations / self.budget)  # Time-varying local search rate\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)  # Added adaptive decay factor\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a time-varying factor to dynamically adjust the local search rate for better convergence in complex landscapes.", "configspace": "", "generation": 55, "fitness": 0.2471974040201975, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "metadata": {"aucs": [0.24689068857105612, 0.2472438269174405, 0.24745769657209582], "final_y": [0.16485587726277773, 0.164855880831848, 0.16485597748401815]}, "mutation_prompt": null}
{"id": "a070332c-4c55-4dca-ab43-c7f16e86b282", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            variance_in_fitness = np.var(personal_best_fitness)  # New line for variance calculation\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness) + variance_in_fitness)) + 1  # Modified line for dynamic adjustment\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance global exploration by introducing a dynamic swarm size adjustment mechanism based on variance in fitness scores.", "configspace": "", "generation": 56, "fitness": 0.24708252676175227, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "metadata": {"aucs": [0.24701366562537264, 0.24677867353077898, 0.24745524112910522], "final_y": [0.16485600082849294, 0.16485590849928222, 0.16485594034178075]}, "mutation_prompt": null}
{"id": "7735e7f6-9657-4de4-94b1-018c9dd5d10d", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.swarm_size += int(self.initial_swarm_size * 0.1 * (evaluations < self.budget / 2))  # Dynamic increment early\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)  # Added adaptive decay factor\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear social adjustment\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic swarm size increment factor to enhance exploration capabilities early in the optimization process.", "configspace": "", "generation": 57, "fitness": 0.24724129739957681, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "metadata": {"aucs": [0.24706824890722, 0.2470796681922378, 0.24757597509927265], "final_y": [0.16485587474708407, 0.16485588939313423, 0.16485591911370168]}, "mutation_prompt": null}
{"id": "afd4a3ee-9c8c-420a-8b02-0713b4e9b9b9", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9  # Original: 0.9\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.adaptive_local_search_rate = 0.4  # Increased local search rate\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1  # Dynamic reduction\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Nonlinear balance\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Update inertia weight dynamically with stochastic decay\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))  # Changed to exponential decay\n\n                # Update cognitive coefficient dynamically\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)  # Added adaptive decay factor\n\n                # Update social coefficient dynamically\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget) + 0.2 * np.cos(np.pi * evaluations / (2 * self.budget))  # Enhanced social adaptation\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + \n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))  # Added stochastic element\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive damping factor\n\n                # Update position\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                # Evaluate new position\n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                # Local search with stochastic perturbations\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)  # Reduced perturbation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim) + 0.02 * np.sin(2 * np.pi * evaluations / self.budget)  # Chaotic perturbation\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a chaotic perturbation mechanism and enhanced social adaptation for improved global optimization.", "configspace": "", "generation": 58, "fitness": 0.24597472022113434, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "metadata": {"aucs": [0.24304710173231892, 0.2473581399322642, 0.24751891899881995], "final_y": [0.18187827185796335, 0.16485588337477874, 0.16485587928935397]}, "mutation_prompt": null}
{"id": "d1f7ebe0-47ad-4eda-a532-e50e1f8a764b", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Incorporate a dynamic perturbation scaling based on fitness improvement to enhance convergence towards optimal solutions.", "configspace": "", "generation": 59, "fitness": 0.24738462074453701, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d455b0ab-cdde-437d-bdbd-60f3c823d764", "metadata": {"aucs": [0.24744380388889253, 0.24710731580147804, 0.24760274254324044], "final_y": [0.16485581437554897, 0.16485589984650884, 0.1648558692543195]}, "mutation_prompt": null}
{"id": "93fef182-0072-48f8-8b11-c10da151f675", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation * (1 + np.random.rand()), self.dim)  # Stochastic factor added\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Incorporate stochastic mutation in local search to improve exploration capabilities.", "configspace": "", "generation": 60, "fitness": 0.24733115930174043, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d1f7ebe0-47ad-4eda-a532-e50e1f8a764b", "metadata": {"aucs": [0.2473017962229419, 0.24718526797229312, 0.24750641370998627], "final_y": [0.16485596055704266, 0.16485589872743522, 0.1648558611095231]}, "mutation_prompt": null}
{"id": "0ff66bcc-8382-4b21-8f58-e88daf3a38f8", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness)) * 0.9) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a decay factor to dynamically adjust the swarm size for balancing exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.24733237415668421, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d1f7ebe0-47ad-4eda-a532-e50e1f8a764b", "metadata": {"aucs": [0.24724691082841332, 0.24706490521105295, 0.2476853064305864], "final_y": [0.16485589364164532, 0.16485583260618575, 0.16485591821520307]}, "mutation_prompt": null}
{"id": "08ed6d12-b811-4811-abda-860b875e1d56", "solution": "import numpy as np\n\nclass ChaoticParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n\n        evaluations = self.swarm_size\n\n        def chaotic_sequence(x, a=1.4):\n            return a * x * (1 - x)\n\n        chaos_factor = np.random.rand(self.swarm_size)  # Initial chaotic sequence\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            \n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                chaos_perturbation = 2 * (chaotic_sequence(chaos_factor[i])) - 1  # Chaotic perturbation\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + \n                                       chaos_perturbation * np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n                # Update the chaotic sequence\n                chaos_factor[i] = chaotic_sequence(chaos_factor[i])\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "ChaoticParticleSwarmOptimization", "description": "Incorporate a chaotic sequence to enhance diversity in swarm movements for improved global exploration.", "configspace": "", "generation": 62, "fitness": 0.24578692457551934, "feedback": "The algorithm ChaoticParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d1f7ebe0-47ad-4eda-a532-e50e1f8a764b", "metadata": {"aucs": [0.24716720565398242, 0.2427920768154631, 0.24740149125711253], "final_y": [0.16485579858967403, 0.181878114452394, 0.16485578891940167]}, "mutation_prompt": null}
{"id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Refine the perturbation scaling by incorporating a sinusoidal decay to enhance local search adaptability.", "configspace": "", "generation": 63, "fitness": 0.24739342380067422, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d1f7ebe0-47ad-4eda-a532-e50e1f8a764b", "metadata": {"aucs": [0.2474410169386747, 0.2471329876622297, 0.2476062668011183], "final_y": [0.16485585800857583, 0.16485584752475257, 0.1648558645125595]}, "mutation_prompt": null}
{"id": "6b02fc1b-6e66-480a-82f3-10dab5b72446", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.log(1 + (self.budget - evaluations) / self.budget)\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + np.log1p(improvement))  # Enhanced perturbation adaptation\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a logarithmic decay in the inertia weight and enhance local search exploitation by adapting the perturbation based on global best improvement.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {}, "mutation_prompt": null}
{"id": "82409595-0464-43b7-8d5c-d50abdc7e518", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n                # Swarm size hyperbolic decay\n                self.swarm_size = int(self.initial_swarm_size / (1 + 0.5 * evaluations / self.budget) + 1)\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduced adaptive swarm size scaling using hyperbolic decay to enhance convergence and robustness.", "configspace": "", "generation": 65, "fitness": 0.24739342380067422, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.2474410169386747, 0.2471329876622297, 0.2476062668011183], "final_y": [0.16485585800857583, 0.16485584752475257, 0.1648558645125595]}, "mutation_prompt": null}
{"id": "af7e46b1-c6b9-44c6-96d7-396a2461a809", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget) * np.exp(-evaluations / (2 * self.budget))  # Added decay factor\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce decay in exploration-exploitation balance to better adaptively guide the swarm.", "configspace": "", "generation": 66, "fitness": 0.24738565350801855, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.24744070081321334, 0.24711129497329087, 0.24760496473755145], "final_y": [0.16485593361636097, 0.16485594354481659, 0.16485589686214241]}, "mutation_prompt": null}
{"id": "cef9c610-8dd4-4673-9524-92f13e3fe691", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i]) * np.sin(np.pi * evaluations / self.budget)\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance the convergence by introducing a dynamic learning rate factor in the cognitive component.", "configspace": "", "generation": 67, "fitness": 0.2472973203812052, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.2470736324932562, 0.24733866113785496, 0.2474796675125044], "final_y": [0.16485583797327474, 0.16485589562317116, 0.16485588254273553]}, "mutation_prompt": null}
{"id": "7e00fdd6-c709-48e0-830e-7a17991de3bb", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.05, self.dim))  # Reduced noise factor\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget))\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Slightly reduce the noise factor in velocity update to enhance convergence stability.", "configspace": "", "generation": 68, "fitness": 0.2473842057252653, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.24741689744890705, 0.24713695161991323, 0.24759876810697556], "final_y": [0.16485581407078143, 0.16485578951632696, 0.16485580793630517]}, "mutation_prompt": null}
{"id": "a30c0fb3-f4a2-4d21-891f-319ba85250d3", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.swarm_size = int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * np.random.rand()\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce randomness in velocity damping to enhance the algorithm's versatility in handling diverse problem landscapes.", "configspace": "", "generation": 69, "fitness": 0.24387113186596954, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.002. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.2411314697735395, 0.24470377865965764, 0.24577814716471147], "final_y": [0.17367872131646622, 0.16589657984621042, 0.16531345907124706]}, "mutation_prompt": null}
{"id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a non-linear convergence mechanism and adjust perturbation with adaptive scaling based on fitness variance.", "configspace": "", "generation": 70, "fitness": 0.24739906480521268, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d9dfdd88-44e9-477b-a734-136cae797ef5", "metadata": {"aucs": [0.24725182703861603, 0.2472910852891529, 0.2476542820878691], "final_y": [0.16485590979960918, 0.1648559908580154, 0.16485591671836464]}, "mutation_prompt": null}
{"id": "50f9510c-3afe-420e-8329-9346472dc326", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.4 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.6 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.6 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.cos(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance adaptive components and integrate local search for improved global and local exploration.", "configspace": "", "generation": 71, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {}, "mutation_prompt": null}
{"id": "65ec6f8b-9e6e-4268-809f-e83b6ed03a53", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance) * (1 + 0.1 * (global_best_fitness / np.min(personal_best_fitness)))\n                \n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce velocity scaling based on global best fitness improvement to enhance convergence.", "configspace": "", "generation": 72, "fitness": 0.2468574035668378, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.24621512182652838, 0.24687909764115223, 0.24747799123283276], "final_y": [0.16485603476308675, 0.16485593529588372, 0.16485586530567797]}, "mutation_prompt": null}
{"id": "9edbf8d3-59d1-403e-b415-8023e60b8447", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            adaptive_local_search_rate = 0.4 + 0.1 * (global_best_fitness / np.min(personal_best_fitness))\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by incorporating a dynamic update of the adaptive local search rate based on the fitness improvement rate.", "configspace": "", "generation": 73, "fitness": 0.24726147793253228, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.24712209603298319, 0.24717827752066834, 0.24748406024394531], "final_y": [0.1648559572040822, 0.16485594874934362, 0.1648559241280283]}, "mutation_prompt": null}
{"id": "d160e26e-6eaa-4e0a-8130-5360f70207c9", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        momentum_factor = 0.9  # Introduced momentum factor for perturbation\n        perturbation = momentum_factor * np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance local search effectiveness by incorporating a momentum-driven perturbation mechanism.", "configspace": "", "generation": 74, "fitness": 0.2473990158964743, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.24725174891161994, 0.24729101510020357, 0.24765428367759945], "final_y": [0.16485596244235268, 0.16485599388126138, 0.16485593132455667]}, "mutation_prompt": null}
{"id": "1701c6cb-2921-4cbf-9b4c-dadac0f6a798", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (0.5 * self.budget + np.random.rand()))  # Modified line\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce adaptive inertia weight scaling based on evaluations to enhance convergence in the search process.", "configspace": "", "generation": 75, "fitness": 0.247373462923951, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.24719461608550986, 0.24730149363168408, 0.247624279054659], "final_y": [0.16485594960402228, 0.16485589530282974, 0.16485585525631385]}, "mutation_prompt": null}
{"id": "a319f05e-1486-4383-8881-c1dfce4ac7f6", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand()))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate * (1 + fitness_variance):  # Updated line\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic local search rate to balance exploitation and exploration more effectively.", "configspace": "", "generation": 76, "fitness": 0.2470681353906237, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.2469599864819354, 0.2465798075203336, 0.24766461216960212], "final_y": [0.16485585172255046, 0.16485602038401248, 0.16485604068693527]}, "mutation_prompt": null}
{"id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Refine the balance between exploration and exploitation by tweaking the inertia weight's decay rate.", "configspace": "", "generation": 77, "fitness": 0.24739906488510668, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c19f89f4-1cdc-45db-af85-0ad849e2e00b", "metadata": {"aucs": [0.24725182714356375, 0.24729108528796617, 0.24765428222379016], "final_y": [0.16485590967383734, 0.16485599056108435, 0.16485591652304277]}, "mutation_prompt": null}
{"id": "8ffa2fe6-a97c-499a-8cf5-a6ca8deaae0c", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget) * (1 + fitness_variance)  # Adjusted social component\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance the global search by adjusting the social component's influence based on fitness variance.", "configspace": "", "generation": 78, "fitness": 0.24738582018444763, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.2472474199004111, 0.24727212853498126, 0.2476379121179505], "final_y": [0.16485590911179926, 0.16485589536408485, 0.16485591453044668]}, "mutation_prompt": null}
{"id": "75eba53b-acd3-40b2-910d-c456b685d630", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            \n            # Added perturbation to global best position\n            global_perturbation = np.random.normal(0, 0.01 * (1 - evaluations / self.budget), self.dim)\n            global_best_position = np.clip(global_best_position + global_perturbation, self.bounds[0], self.bounds[1])\n            \n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Improve global convergence by introducing a small adaptive perturbation to the global best position.", "configspace": "", "generation": 79, "fitness": 0.24719687394372067, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24697960162369104, 0.24726233036163436, 0.24734868984583658], "final_y": [0.16485588823938557, 0.16485597872411517, 0.16485586801243024]}, "mutation_prompt": null}
{"id": "be56fad4-d41f-47e0-90ea-06bd8139adb5", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate + 0.1 * (evaluations / self.budget):  # Increased local search rate\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance exploration by increasing adaptive local search attempts based on budget utilization.", "configspace": "", "generation": 80, "fitness": 0.24735319483982868, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.2472234213292659, 0.2471868470902836, 0.24764931609993657], "final_y": [0.16485591108689512, 0.16485592669262616, 0.16485602964022605]}, "mutation_prompt": null}
{"id": "dfaad7e1-26f7-4f6b-80bf-d72a92815d0a", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.cos(np.pi * evaluations / (2 * self.budget))  # Changed sine to cosine for smoother decay\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Improve the convergence by fine-tuning the exploration-exploitation balance with a cosine-based decay function.", "configspace": "", "generation": 81, "fitness": 0.24542887035460317, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24233446937937364, 0.24689492407179692, 0.247057217612639], "final_y": [0.18187821793137993, 0.16485589411935508, 0.16485594877978227]}, "mutation_prompt": null}
{"id": "3424dc9b-22d1-45c0-8466-e744a4eff507", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5)) + 0.1 * np.sin(np.pi * evaluations / self.budget)  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget) * (1 + 0.1 * np.cos(np.pi * evaluations / self.budget))  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by tweaking local search perturbation and adaptive inertia weight with a sinusoidal factor.", "configspace": "", "generation": 82, "fitness": 0.24733286911056696, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.2472135224221058, 0.24726386417745883, 0.24752122073213623], "final_y": [0.16485597941309849, 0.16485590692126417, 0.16485589107914445]}, "mutation_prompt": null}
{"id": "52ac8880-56a7-44b6-a216-1cda99cc1ae3", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n                \n                noise_scale = 0.1 * (1 + fitness_variance / np.max(personal_best_fitness))  # Adaptive noise scale\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, noise_scale, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance the AdaptiveParticleSwarmOptimization by introducing adaptive exploration using noise scaling based on the fitness diversity of the swarm.", "configspace": "", "generation": 83, "fitness": 0.24739784873610027, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.2472531698597631, 0.24729002217722873, 0.24765035417130898], "final_y": [0.16485592878379018, 0.16485596246952539, 0.16485596889219323]}, "mutation_prompt": null}
{"id": "9a43e1fa-1f34-4ca4-8ba4-6dd23dc46785", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * (1 + np.abs(improvement))  # Enhanced dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance the adaptive local search by incorporating a dynamic perturbation scale dependent on the fitness improvement rate.", "configspace": "", "generation": 84, "fitness": 0.24737540664591798, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24721560017777533, 0.24728279525515695, 0.24762782450482168], "final_y": [0.16485591886048934, 0.16485589393664735, 0.1648559201859222]}, "mutation_prompt": null}
{"id": "779025b0-83ee-45be-a406-f01d183493b1", "solution": "import numpy as np\n\nclass EnhancedDynamicParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.bounds = None\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n\n        evaluations = self.swarm_size\n\n        def swarm_diversity():\n            return np.mean(np.std(swarm_positions, axis=0))\n\n        while evaluations < self.budget:\n            diversity = swarm_diversity()\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-diversity)  # Nonlinear dynamic inertia\n            self.c1 = 1.5 + (0.5 * np.cos(np.pi * evaluations / self.budget)) * (1 + diversity)\n            self.c2 = 1.5 + (0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 - diversity)\n\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component + social_component)\n                \n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n\n    def local_search(self, position, func, evaluations):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "EnhancedDynamicParticleSwarmOptimization", "description": "Enhance convergence by introducing a nonlinear dynamic strategy for inertia weight and accelerating components based on swarm diversity.", "configspace": "", "generation": 85, "fitness": 0.2217558521625503, "feedback": "The algorithm EnhancedDynamicParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.004. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.21975697539284822, 0.21843983163390568, 0.227070749460897], "final_y": [0.3088016227447695, 0.3183462575005682, 0.26220307535852283]}, "mutation_prompt": null}
{"id": "a98a35b2-912b-4ac1-a408-8381e718fa2d", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                self.adaptive_local_search_rate = 0.3 + 0.7 * (global_best_fitness / np.max(personal_best_fitness))\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic adjustment to the adaptive local search rate based on fitness improvement rate to enhance convergence speed.", "configspace": "", "generation": 86, "fitness": 0.2471787880312244, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24688836323548413, 0.2472191722138879, 0.24742882864430116], "final_y": [0.16485591989718262, 0.16485591197884153, 0.16485589100707942]}, "mutation_prompt": null}
{"id": "34d3e9f4-ab77-46d1-8680-abc5327bd4fe", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            diversity = np.std(swarm_positions)  # Calculate diversity\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                self.adaptive_local_search_rate = 0.2 + 0.6 * (1 - diversity)  # Adjust based on diversity\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a dynamic adjustment of the adaptive local search rate based on population diversity to enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.2472610662718512, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24707610611593445, 0.24701948030070708, 0.24768761239891213], "final_y": [0.16485589040981274, 0.1648558549722995, 0.16485597916740558]}, "mutation_prompt": null}
{"id": "1d2e41ab-cb9c-46aa-9ee1-43746cfec757", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)\n        # Introduced dynamic mutation rate in local search\n        mutation_rate = 0.1 * np.random.rand() * np.cos(np.pi * evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim) + mutation_rate\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Incorporate a dynamic mutation rate in the local search to enhance exploration capabilities.", "configspace": "", "generation": 88, "fitness": 0.24729780740586607, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24706712317790824, 0.24724164958916373, 0.24758464945052627], "final_y": [0.16485593963342726, 0.16485596868509267, 0.1648559229734401]}, "mutation_prompt": null}
{"id": "6a255240-bff6-4e04-b59a-69df072debae", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                self.adaptive_local_search_rate = 0.4 + 0.1 * (global_best_fitness - current_fitness) / global_best_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by introducing dynamic adjustment of adaptive local search rate based on fitness improvement.", "configspace": "", "generation": 89, "fitness": 0.24729064989514873, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24712794274201966, 0.2471560835586707, 0.24758792338475588], "final_y": [0.1648558917169144, 0.16485600856985005, 0.16485589564983516]}, "mutation_prompt": null}
{"id": "8d76f852-2cf8-4bc2-907d-169c2d512f03", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by introducing adaptive swarm size scaling based on fitness improvement.", "configspace": "", "generation": 90, "fitness": 0.24739906859008828, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3bd6164a-ad60-4f1e-aec6-54cd65987eba", "metadata": {"aucs": [0.24725183661342998, 0.24729108928696208, 0.24765427986987276], "final_y": [0.1648558308527891, 0.16485594556161853, 0.1648559334810792]}, "mutation_prompt": null}
{"id": "6524c704-fe21-4763-94b5-84076d2261bb", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            \n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - evaluations / self.budget) * (global_best_fitness / (np.max(personal_best_fitness) + 1e-9)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            \n            neighborhood_size = max(1, int(self.swarm_size * 0.2))\n            neighbors = np.random.choice(self.swarm_size, (self.swarm_size, neighborhood_size), replace=True)\n            \n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                local_best_index = neighbors[i][np.argmin(personal_best_fitness[neighbors[i]])]\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (personal_best_positions[local_best_index] - swarm_positions[i])\n                \n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance)\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n                if np.random.rand() < 0.1:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm_positions[i] = np.clip(swarm_positions[i] + mutation, self.bounds[0], self.bounds[1])\n                    mutation_fitness = func(swarm_positions[i])\n                    evaluations += 1\n                    if mutation_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = swarm_positions[i]\n                        personal_best_fitness[i] = mutation_fitness\n                        if mutation_fitness < global_best_fitness:\n                            global_best_position = swarm_positions[i]\n                            global_best_fitness = mutation_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "EnhancedAdaptivePSO", "description": "Improve convergence by incorporating dynamic swarm topology adaptation and introducing a diversity-enhancing mutation mechanism.", "configspace": "", "generation": 91, "fitness": 0.24707494258463245, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d76f852-2cf8-4bc2-907d-169c2d512f03", "metadata": {"aucs": [0.24688729261871323, 0.24692514123124676, 0.24741239390393732], "final_y": [0.16485577211540725, 0.164855772071818, 0.16485577200678103]}, "mutation_prompt": null}
{"id": "73852143-c78f-4890-b7da-c3005c2e5a66", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.5 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.8 * np.sin(np.pi * evaluations / self.budget)  # More aggressive social component\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + fitness_variance)\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Improved exploration through dynamic adjustment of inertia weight and more aggressive social components.", "configspace": "", "generation": 92, "fitness": 0.2466698312818999, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d76f852-2cf8-4bc2-907d-169c2d512f03", "metadata": {"aucs": [0.24646359786247052, 0.2466015434854416, 0.24694435249778757], "final_y": [0.16485606630926786, 0.16485585910176703, 0.16485588568349563]}, "mutation_prompt": null}
{"id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by incorporating a learning rate influenced by fitness variance.", "configspace": "", "generation": 93, "fitness": 0.24741917694587212, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d76f852-2cf8-4bc2-907d-169c2d512f03", "metadata": {"aucs": [0.2473025002662077, 0.24732851464090722, 0.24762651593050145], "final_y": [0.16485591898816, 0.16485591371363872, 0.1648559496265113]}, "mutation_prompt": null}
{"id": "6df2d008-8c87-433b-b261-deb5c00dcd0e", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget * 0.8))  # Fine-tuned decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Improve convergence with fine-tuned inertia weight decay for dynamic adaptability.", "configspace": "", "generation": 94, "fitness": 0.2471729553122134, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.24746829436982243, 0.24728625792643444, 0.24676431364038331], "final_y": [0.16485590867827593, 0.16485585060534003, 0.16485589726023475]}, "mutation_prompt": null}
{"id": "3c1aabac-b0bd-437e-a314-fc4f6ab2e0fb", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by dynamically adjusting the swarm size based on fitness improvements.", "configspace": "", "generation": 95, "fitness": 0.24741917694587212, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.2473025002662077, 0.24732851464090722, 0.24762651593050145], "final_y": [0.16485591898816, 0.16485591371363872, 0.1648559496265113]}, "mutation_prompt": null}
{"id": "9fbc2e5e-357e-4c8c-8218-ee5bc4d5dbda", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            \n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n\n                self.c1 = 1.6 + 0.4 * np.sin(np.pi * evaluations / self.budget)\n\n                self.c2 = 1.6 + 0.4 * np.cos(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance)\n                swarm_velocities[i] *= 0.95 * (1 - 0.3 * np.sin(np.pi * evaluations / self.budget))\n                \n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                parent_index = (i + 1) % self.swarm_size\n                crossover_point = np.random.randint(1, self.dim - 1)\n                offspring = np.concatenate((swarm_positions[i][:crossover_point], swarm_positions[parent_index][crossover_point:]))\n                offspring = np.clip(offspring, self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(offspring)\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = offspring\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = offspring\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n        return global_best_position\n\n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement)\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "HybridPSO", "description": "Hybridizes PSO with a genetic algorithm crossover operator to enhance diversity and convergence.  ", "configspace": "", "generation": 96, "fitness": 0.24700505693412778, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.2470787467574903, 0.24679694566476784, 0.24713947838012518], "final_y": [0.16485577904499282, 0.1648557812397754, 0.16485577362528314]}, "mutation_prompt": null}
{"id": "f14b17b3-6546-4786-a986-92ae541d607c", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                self.adaptive_local_search_rate = 0.4 + 0.1 * (global_best_fitness - current_fitness) / (1 + fitness_variance)\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduce a learning adaptive local search rate based on fitness improvement for enhanced convergence.", "configspace": "", "generation": 97, "fitness": 0.247199493991637, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.24734197887825915, 0.24663550546733182, 0.24762099762932], "final_y": [0.16485588585471067, 0.16485589069962348, 0.16485590433874853]}, "mutation_prompt": null}
{"id": "a951e328-672d-4a1b-94e9-2e71870e0537", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5)) * (1 + np.mean(personal_best_fitness) / np.abs(global_best_fitness))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Enhance convergence by adjusting inertia weight based on fitness improvement rate.", "configspace": "", "generation": 98, "fitness": 0.2366743922237461, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.008. And the mean value of best solutions found was 0.201 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.2416328881818265, 0.2251000104486427, 0.24329027804076908], "final_y": [0.16485619020328224, 0.27439188194462816, 0.1648560284732724]}, "mutation_prompt": null}
{"id": "11c210f2-1431-4b70-90c0-d937657ea96a", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.initial_swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.adaptive_local_search_rate = 0.4\n        self.exploration_exploitation_balance = 0.5\n        self.bounds = None\n        \n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        swarm_positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            fitness_variance = np.var(personal_best_fitness)\n            self.swarm_size = max(5, int(self.initial_swarm_size * (1 - np.sqrt(evaluations / self.budget)) * (global_best_fitness / np.max(personal_best_fitness)))) + 1\n            self.exploration_exploitation_balance = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget) + 0.1 *  (global_best_fitness - np.min(personal_best_fitness)) # <-- Changed line\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-evaluations / (self.budget + np.random.rand() * 0.5))  # Adjusted decay rate\n\n                self.c1 = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget) * np.exp(-evaluations / self.budget)\n\n                self.c2 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - swarm_positions[i])\n                social_component = self.c2 * r2 * (global_best_position - swarm_positions[i])\n                swarm_velocities[i] = (self.inertia_weight * swarm_velocities[i] + cognitive_component +\n                                       social_component * self.exploration_exploitation_balance + np.random.normal(0, 0.1, self.dim))\n                swarm_velocities[i] *= 0.95 * (1 - 0.5 * np.sin(np.pi * evaluations / self.budget)) * (1 + 0.5 * fitness_variance)  # Modified fitness variance impact\n\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], self.bounds[0], self.bounds[1])\n                \n                current_fitness = func(swarm_positions[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < global_best_fitness:\n                        global_best_position = swarm_positions[i]\n                        global_best_fitness = current_fitness\n\n                if np.random.rand() < self.adaptive_local_search_rate:\n                    local_trial = self.local_search(swarm_positions[i], func, evaluations, global_best_fitness - current_fitness)\n                    evaluations += 1\n                    local_trial_fitness = func(local_trial)\n                    if local_trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = local_trial\n                        personal_best_fitness[i] = local_trial_fitness\n                        if local_trial_fitness < global_best_fitness:\n                            global_best_position = local_trial\n                            global_best_fitness = local_trial_fitness\n\n        return global_best_position\n    \n    def local_search(self, position, func, evaluations, improvement):\n        local = position.copy()\n        adaptive_perturbation = 0.05 * np.exp(-evaluations / self.budget) * (1 + improvement) * np.sin(np.pi * evaluations / self.budget)  # Dynamic perturbation scaling\n        perturbation = np.random.normal(0, adaptive_perturbation, self.dim)\n        local += perturbation\n        local = np.clip(local, self.bounds[0], self.bounds[1])\n        return local", "name": "AdaptiveParticleSwarmOptimization", "description": "Introduced fitness improvement influence on exploration-exploitation balance for better convergence.", "configspace": "", "generation": 99, "fitness": 0.24741917694587212, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e67444ec-0bfa-4a6b-9111-9e7f8b9426c9", "metadata": {"aucs": [0.2473025002662077, 0.24732851464090722, 0.24762651593050145], "final_y": [0.16485591898816, 0.16485591371363872, 0.1648559496265113]}, "mutation_prompt": null}
