{"id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm leverages a modified particle swarm optimization with a dynamic inertia weight and adaptive velocity clamping to efficiently explore and exploit the search space for high-performing solutions in black box optimization problems.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 127, in evaluatePhotonic\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n  File \"<string>\", line 11, in __init__\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 127, in evaluatePhotonic\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n  File \"<string>\", line 11, in __init__\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "742ac6e9-ec1e-4b44-bc58-579a2064fadd", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.evaluations = 0\n\n    def initialize(self, func):\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm leverages a modified particle swarm optimization with a dynamic inertia weight and adaptive velocity clamping to efficiently explore and exploit the search space for high-performing solutions in black box optimization problems, with improved initialization to prevent exceptions.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "1e62cf18-0fde-46d6-941b-17a5c98b438f", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim, bounds):\n        self.budget = budget\n        self.dim = dim\n        self.bounds = bounds  # Adjusted line to store bounds\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (self.bounds.ub - self.bounds.lb) * 0.2\n        self.min_velocity = -(self.bounds.ub - self.bounds.lb) * 0.2\n        self.particles = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm employs a dynamic particle swarm optimization with adjusted inertia weight and velocity clamping for effective exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\").", "error": "TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "d29b0f04-233c-42b7-ae2e-1c4f81455a1a", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim, func):\n        self.budget = budget\n        self.dim = dim\n        self.func = func\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (self.func.bounds.ub - self.func.bounds.lb) * 0.2\n        self.min_velocity = -(self.func.bounds.ub - self.func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], self.func.bounds.lb, self.func.bounds.ub)\n\n    def evaluate_particle(self, i):\n        score = self.func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i)\n                    self.evaluate_particle(i)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm uses an adaptive particle swarm optimization with dynamic inertia weight and velocity clamping to efficiently navigate the search space in black box optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'func'\").", "error": "TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'func'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "89d7751f-732f-48a0-97ef-2d9158a983ab", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim, bounds):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (bounds.ub - bounds.lb) * 0.2\n        self.min_velocity = -(bounds.ub - bounds.lb) * 0.2\n        self.particles = np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.5 + 0.4 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm improves upon DynamicPSO by initializing particles within the bounds without referencing `func` and slightly adjusts the inertia weight dynamics for improved convergence efficiency.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\").", "error": "TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "757180e9-8a45-4e6c-971b-e4da506ca5d5", "solution": "import numpy as np\n\nclass EnhancedDynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = None\n        self.min_velocity = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def initialize_particles(self, func):\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n\n    def update_coefficients(self):\n        diversity = np.mean(np.std(self.particles, axis=0))\n        self.cognitive_coeff = 2.5 - 1.5 * (diversity / np.max(diversity))\n        self.social_coeff = 1.5 + 1.5 * (diversity / np.max(diversity))\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def local_restart(self, i, func):\n        if np.allclose(self.velocities[i], np.zeros(self.dim), atol=1e-3):\n            self.particles[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n            self.velocities[i] = np.random.uniform(self.min_velocity, self.max_velocity, self.dim)\n\n    def __call__(self, func):\n        self.initialize_particles(func)\n        while self.evaluations < self.budget:\n            self.update_coefficients()\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    self.local_restart(i, func)\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedDynamicPSO", "description": "The Enhanced DynamicPSO algorithm introduces a local restart strategy for stagnating particles and dynamically adjusts the cognitive and social coefficients based on population diversity to improve convergence in complex optimization landscapes.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "11743b46-4028-4fc8-82b4-38af68de3471", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n        # Adjust cognitive and social coefficients based on exploration success\n        self.cognitive_coeff = 2.0 * (self.budget - self.evaluations) / self.budget\n        self.social_coeff = 2.0 * self.evaluations / self.budget\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm uses a modified particle swarm optimization with dynamic inertia weight and adaptive velocity clamping, now also adjusting cognitive and social coefficients in response to exploration success to optimize black box functions.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "b59c2d15-9b62-4e11-9729-87143efad7c8", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim, bounds):\n        self.budget = budget\n        self.dim = dim\n        self.bounds = bounds\n        self.pop_size = 30  # Number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = (self.bounds.ub - self.bounds.lb) * 0.2\n        self.min_velocity = -(self.bounds.ub - self.bounds.lb) * 0.2\n        self.particles = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], self.bounds.lb, self.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    # Dynamically adjust inertia weight\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm enhances a modified particle swarm optimization by dynamically adjusting inertia weight and modifying the velocity update to improve exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\").", "error": "TypeError(\"DynamicPSO.__init__() missing 1 required positional argument: 'bounds'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "5b95c549-8d9a-4581-8f34-e4f8282ccf00", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm uses a modified particle swarm optimization with dynamic inertia and adaptive velocity clamping, improved by initializing the velocity range in `__call__` rather than `__init__` to avoid referencing undefined variables.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "4213639b-040e-49b4-bb26-4ddd6ca74cc4", "solution": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 28  # Slightly decreased number of particles\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_velocity = None  # Placeholder, initialized later\n        self.min_velocity = None  # Placeholder, initialized later\n        self.particles = None  # Placeholder, initialized later\n        self.velocities = None  # Placeholder, initialized later\n        self.personal_best_positions = None  # Placeholder, initialized later\n        self.personal_best_scores = None  # Placeholder, initialized later\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def initialize(self, func):\n        self.max_velocity = (func.bounds.ub - func.bounds.lb) * 0.2\n        self.min_velocity = -(func.bounds.ub - func.bounds.lb) * 0.2\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (\n            self.inertia_weight * self.velocities[i] +\n            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n            self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n        )\n        self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n        self.particles[i] += self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n    def evaluate_particle(self, i, func):\n        score = func(self.particles[i])\n        self.evaluations += 1\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.particles[i]\n        if score < self.global_best_score:\n            self.global_best_score = score\n            self.global_best_position = self.particles[i]\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations < self.budget:\n                    self.update_particle(i, func)\n                    self.evaluate_particle(i, func)\n                    self.inertia_weight = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_score", "name": "DynamicPSO", "description": "The algorithm utilizes a modified particle swarm optimization with dynamic inertia, adaptive velocity clamping, and enhanced convergence through slightly decreased population size for improved search efficiency in black box optimization problems.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {}, "mutation_prompt": null}
{"id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        return self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "The algorithm employs a synergy between differential evolution and simulated annealing, using adaptive parameter tuning to dynamically balance exploration and exploitation for robust black box optimization.", "configspace": "", "generation": 10, "fitness": 0.5147240417895551, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.515 with standard deviation 0.028. And the mean value of best solutions found was 0.391 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "ca657038-b07c-48a3-b79d-1303f3ffe92a", "metadata": {"aucs": [0.5001286680649036, 0.5544035212818552, 0.4896399360219066], "final_y": [0.399757523386962, 0.36020258415302586, 0.4130789301696747]}, "mutation_prompt": null}
{"id": "565988d0-6386-4b9f-be6c-4e397e0324eb", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.mean(np.std(self.population, axis=0))\n        adaptive_mutation_factor = self.mutation_factor * (1 + diversity)  # Adaptive mutation factor\n        return self.population[a] + adaptive_mutation_factor * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "The algorithm enhances convergence by incorporating a self-adaptive mutation factor, which dynamically adjusts based on population diversity.", "configspace": "", "generation": 11, "fitness": 0.40244033245040506, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.402 with standard deviation 0.060. And the mean value of best solutions found was 0.486 (0. is the best) with standard deviation 0.051.", "error": "", "parent_id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "metadata": {"aucs": [0.34657487680375876, 0.3755732561290621, 0.48517286441839436], "final_y": [0.5349365605614659, 0.5079529949612298, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "06582642-7548-46d9-b94a-30b1bfa4b83a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        return self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                if np.random.rand() > 0.5:  # Self-adaptive mutation\n                    self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            self.crossover_prob = 0.6 + 0.4 * np.random.rand()  # Self-adaptive crossover\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced Differential Evolution with Simulated Annealing by adding self-adaptive crossover and mutation strategies for improved convergence.", "configspace": "", "generation": 12, "fitness": 0.505582801288369, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.506 with standard deviation 0.016. And the mean value of best solutions found was 0.354 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "metadata": {"aucs": [0.4972283762227293, 0.4916618494616988, 0.5278581781806788], "final_y": [0.323695486248029, 0.3548353727692116, 0.3828886415260231]}, "mutation_prompt": null}
{"id": "c4153f00-a415-43ef-aa9b-8fcd453c81ea", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.8  # Slightly increased crossover probability for better exploration\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        return self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "The algorithm synergizes differential evolution and simulated annealing, with a slight adjustment to the crossover probability for improved exploitation-exploration balance in black box optimization.", "configspace": "", "generation": 13, "fitness": 0.4875273381585526, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.488 with standard deviation 0.027. And the mean value of best solutions found was 0.376 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "metadata": {"aucs": [0.45600815018345986, 0.521410285991428, 0.48516357830076995], "final_y": [0.38234981042555705, 0.3304895994056565, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "0b897f04-6c44-4d90-be09-60da0cbe5ebc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        return self.population[a] + self.adaptive_mutation_factor() * (self.population[b] - self.population[c])\n\n    def adaptive_mutation_factor(self):\n        return 0.5 + 0.5 * np.random.rand()\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This variant enhances the exploration phase by dynamically adjusting the mutation factor, allowing for improved navigation through the search space.", "configspace": "", "generation": 14, "fitness": 0.5120016595969088, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.030. And the mean value of best solutions found was 0.385 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "metadata": {"aucs": [0.4764928893439212, 0.5096158132360066, 0.5498962762107985], "final_y": [0.4074363934390346, 0.3874027439767037, 0.360117591905727]}, "mutation_prompt": null}
{"id": "ee68c436-a63c-4ed6-891a-0a7264164fb6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in self.population])  # Elitism: retain best individual\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced differential evolution annealing using adaptive mutation and elitism for improved convergence.", "configspace": "", "generation": 15, "fitness": 0.5216998872288352, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.522 with standard deviation 0.045. And the mean value of best solutions found was 0.347 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "3079aa60-f72e-426e-bfe7-8eb9acc78404", "metadata": {"aucs": [0.48260845133347097, 0.4982368562219893, 0.5842543541310454], "final_y": [0.3903439540506374, 0.33805012433401893, 0.31272613947302164]}, "mutation_prompt": null}
{"id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved adaptive cooling and elitism strategy to enhance convergence and robustness.", "configspace": "", "generation": 16, "fitness": 0.5356729294296179, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.536 with standard deviation 0.015. And the mean value of best solutions found was 0.333 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "ee68c436-a63c-4ed6-891a-0a7264164fb6", "metadata": {"aucs": [0.555939912682572, 0.5198740686725356, 0.531204806933746], "final_y": [0.27628848655795035, 0.3831797263097453, 0.34049080205619264]}, "mutation_prompt": null}
{"id": "91232e0f-6cc8-4cd2-8141-3a4070778e50", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced convergence by adjusting crossover probability adaptively based on evaluations.", "configspace": "", "generation": 17, "fitness": 0.5070228026961386, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.507 with standard deviation 0.031. And the mean value of best solutions found was 0.348 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.49963404204170914, 0.4727516390206513, 0.5486827270260554], "final_y": [0.3306393859983562, 0.3897609125317423, 0.3236776515909493]}, "mutation_prompt": null}
{"id": "d529b30d-57cd-4359-92f9-ba60cc3a5dfb", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * ((self.budget - self.evaluations) / self.budget)  # Updated adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            if self.evaluations % (self.budget // 2) == 0:  # Reset temperature halfway\n                self.temperature = 100.0\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced exploration by adaptive mutation and temperature reset for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.5356729294296179, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.536 with standard deviation 0.015. And the mean value of best solutions found was 0.333 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.555939912682572, 0.5198740686725356, 0.531204806933746], "final_y": [0.2762884865579506, 0.3831797263097446, 0.34049080205619353]}, "mutation_prompt": null}
{"id": "deb8f4b4-2233-4731-816d-899190fabb4c", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        dynamic_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce dynamic crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.5070228026961386, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.507 with standard deviation 0.031. And the mean value of best solutions found was 0.348 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.49963404204170914, 0.4727516390206513, 0.5486827270260554], "final_y": [0.3306393859983562, 0.3897609125317423, 0.3236776515909493]}, "mutation_prompt": null}
{"id": "6256cdc7-7a30-43f2-beea-5f618b73c6f2", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9  # Adjusted crossover probability\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adjusted probability of crossover to enhance exploration in the search space.", "configspace": "", "generation": 20, "fitness": 0.5275584437557354, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.528 with standard deviation 0.025. And the mean value of best solutions found was 0.338 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.5508049499227186, 0.5394322918028326, 0.4924380895416548], "final_y": [0.3239501851021691, 0.29515295432518274, 0.3960561478662912]}, "mutation_prompt": null}
{"id": "2013f567-cf6e-4c48-b0eb-e273a542decc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - (self.evaluations / self.budget) ** 2)  # Improved adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced DifferentialEvolutionSimulatedAnnealing with improved adaptive mutation factor for better exploration.", "configspace": "", "generation": 21, "fitness": 0.505153388843778, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.505 with standard deviation 0.029. And the mean value of best solutions found was 0.345 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.508153953764815, 0.46790692383808585, 0.5393992889284331], "final_y": [0.3620664371109603, 0.33545839098618124, 0.3369792883992595]}, "mutation_prompt": null}
{"id": "5ffdd8c2-b198-4b8c-9607-88d28a0d545c", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        dynamic_factor = np.random.rand() * 0.2  # New dynamic factor added for diversity\n        return self.population[a] + (F_adaptive + dynamic_factor) * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance mutation diversity by incorporating a dynamic factor into the mutation strategy.", "configspace": "", "generation": 22, "fitness": 0.5317291056693189, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.532 with standard deviation 0.022. And the mean value of best solutions found was 0.330 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.5000392275661922, 0.5479065251820843, 0.5472415642596798], "final_y": [0.3298460572087839, 0.32220284104959807, 0.3390965756046814]}, "mutation_prompt": null}
{"id": "518835d9-4a02-44ff-a2f5-889220b67b25", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced population diversity through adaptive crossover probability for improved search exploration.", "configspace": "", "generation": 23, "fitness": 0.5070228026961386, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.507 with standard deviation 0.031. And the mean value of best solutions found was 0.348 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.49963404204170914, 0.4727516390206513, 0.5486827270260554], "final_y": [0.3306393859983562, 0.3897609125317423, 0.3236776515909493]}, "mutation_prompt": null}
{"id": "4ee9663d-39e5-4a65-a220-7610bea22035", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.9, 1.1)  # New exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced adaptive mutation strategy by introducing an exploration factor for better diversity.", "configspace": "", "generation": 24, "fitness": 0.5485323155177307, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.549 with standard deviation 0.015. And the mean value of best solutions found was 0.320 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "8c47c417-c15f-4c8e-b642-d4266bc00382", "metadata": {"aucs": [0.5294533459800486, 0.5499606290680257, 0.5661829715051179], "final_y": [0.30000082399966377, 0.30843256133810404, 0.3519834555940661]}, "mutation_prompt": null}
{"id": "31c17ecb-6a06-48c7-9969-3f84e2a8f4ac", "solution": "import numpy as np\n\nclass HybridEvolutionaryHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30  # Number of harmonies in the memory\n        self.harmony_memory = np.random.uniform(-1.0, 1.0, (self.harmony_memory_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n        self.harmony_memory_consideration_rate = 0.9\n        self.pitch_adjust_rate = 0.3\n        self.adaptive_rate_decay = 0.99  # Decay rate for adaptive harmony memory consideration and pitch adjust rates\n\n    def generate_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.harmony_memory_consideration_rate:\n                random_index = np.random.randint(self.harmony_memory_size)\n                new_harmony[i] = self.harmony_memory[random_index, i]\n                if np.random.rand() < self.pitch_adjust_rate:\n                    new_harmony[i] += np.random.uniform(-0.01, 0.01)\n            else:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        return np.clip(new_harmony, lb, ub)\n\n    def __call__(self, func):\n        # Initialize harmony memory within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_harmony = self.generate_new_harmony(lb, ub)\n            new_score = func(new_harmony)\n            self.evaluations += 1\n\n            worst_index = np.argmax([func(harmony) for harmony in self.harmony_memory])\n            if new_score < func(self.harmony_memory[worst_index]):\n                self.harmony_memory[worst_index] = new_harmony\n            \n            current_best_index = np.argmin([func(harmony) for harmony in self.harmony_memory])\n            if func(self.harmony_memory[current_best_index]) < self.best_score:\n                self.best_score = func(self.harmony_memory[current_best_index])\n                self.best_solution = self.harmony_memory[current_best_index].copy()\n            \n            # Adapt harmony memory consideration rate and pitch adjust rate\n            self.harmony_memory_consideration_rate *= self.adaptive_rate_decay\n            self.pitch_adjust_rate *= self.adaptive_rate_decay\n\n        return self.best_solution, self.best_score", "name": "HybridEvolutionaryHarmonySearch", "description": "Hybrid Evolutionary Harmony Search with Adaptive Harmony Memory considering both diversity and convergence.", "configspace": "", "generation": 25, "fitness": 0.46280352402396224, "feedback": "The algorithm HybridEvolutionaryHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.463 with standard deviation 0.018. And the mean value of best solutions found was 0.409 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4ee9663d-39e5-4a65-a220-7610bea22035", "metadata": {"aucs": [0.46176118881940686, 0.4411928058182891, 0.4854565774341906], "final_y": [0.39733798822715016, 0.41356174939001034, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "18fe910a-f147-430a-8b4d-602c42a80c87", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.98  # Changed cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.9, 1.1)  # New exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        self.crossover_prob = 0.5 + 0.5 * np.random.rand()  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adaptive crossover probability with dynamic adjustment for improved diversity.", "configspace": "", "generation": 26, "fitness": 0.5426503830649189, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.543 with standard deviation 0.055. And the mean value of best solutions found was 0.328 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "4ee9663d-39e5-4a65-a220-7610bea22035", "metadata": {"aucs": [0.510049740492706, 0.49835492505876877, 0.6195464836432817], "final_y": [0.397100811578865, 0.32917661876952187, 0.2589536773540122]}, "mutation_prompt": null}
{"id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improve exploration by dynamically updating the exploration factor and modifying the cooling rate.", "configspace": "", "generation": 27, "fitness": 0.5690181406815119, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.058. And the mean value of best solutions found was 0.326 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "4ee9663d-39e5-4a65-a220-7610bea22035", "metadata": {"aucs": [0.6467694169377343, 0.5513307107666673, 0.5089542943401344], "final_y": [0.28729054899627826, 0.32194960464671096, 0.36746689473660776]}, "mutation_prompt": null}
{"id": "251489b6-ae0f-4e31-8456-4e83534508df", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        dynamic_crossover_prob = self.crossover_prob * (0.5 + np.cos(self.evaluations / self.budget * np.pi) / 2)  # Dynamic crossover prob\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_prob  # Modified line\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance convergence by incorporating a dynamic crossover probability and adaptive mutation factor scaling.", "configspace": "", "generation": 28, "fitness": 0.5673416386051062, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.567 with standard deviation 0.021. And the mean value of best solutions found was 0.278 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5969362680000267, 0.5527125341741834, 0.5523761136411085], "final_y": [0.26291199702787493, 0.2691474115609851, 0.30292400805809583]}, "mutation_prompt": null}
{"id": "02e9da07-43fb-4fa1-95ca-29a72fa1e8eb", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_prob_adaptive = self.crossover_prob * (1 - self.evaluations / self.budget)  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < crossover_prob_adaptive\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by varying crossover probability dynamically based on evaluations.", "configspace": "", "generation": 29, "fitness": 0.5353935206743413, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.535 with standard deviation 0.031. And the mean value of best solutions found was 0.321 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5480674118344635, 0.49312909768435387, 0.5649840525042064], "final_y": [0.35984309267635994, 0.36555600810509103, 0.23855907066142634]}, "mutation_prompt": null}
{"id": "a16d5960-94fb-4215-a203-fa7cdd0874af", "solution": "import numpy as np\nfrom scipy.stats import levy\n\nclass AdaptiveLvyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx, diversity):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget) * (1 + np.std(diversity))\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def levy_flight(self, dim):\n        step = levy.rvs(size=dim)\n        return step\n\n    def crossover(self, target, mutant, diversity):\n        cross_prob = self.crossover_prob + np.std(diversity) * 0.2\n        crossover_mask = np.random.rand(self.dim) < cross_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            diversity = np.std(self.population, axis=0)\n            \n            for i in range(self.pop_size):\n                if np.random.rand() < 0.3:  # Probability for Lvy flight\n                    mutant = self.population[i] + self.levy_flight(self.dim)\n                else:\n                    mutant = self.mutate(i, diversity)\n                \n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant, diversity)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            \n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "AdaptiveLvyFlightDE", "description": "Enhance exploration-exploitation balance by adaptively adjusting mutation and crossover strategies based on population diversity and integrating Lvy flights for dynamic exploration.", "configspace": "", "generation": 30, "fitness": 0.5180570115212119, "feedback": "The algorithm AdaptiveLvyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.518 with standard deviation 0.132. And the mean value of best solutions found was 0.402 (0. is the best) with standard deviation 0.093.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.6933536240502962, 0.3755732561290621, 0.48524415438427737], "final_y": [0.28044945844031954, 0.5079529949612298, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "3f888c35-5a03-4a56-a855-9b6cd0b9f655", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        self.crossover_prob = 0.9 * (1 - self.evaluations / self.budget) + 0.1  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration and exploitation with dynamic crossover probability adjustment based on current performance.", "configspace": "", "generation": 31, "fitness": 0.5253129661801689, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.525 with standard deviation 0.076. And the mean value of best solutions found was 0.343 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5084887249126047, 0.44182207035337673, 0.6256281032745254], "final_y": [0.33878625734349044, 0.3820146676421323, 0.30728211741628775]}, "mutation_prompt": null}
{"id": "79e3e7b6-c974-4b10-b13a-a921019bde63", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        # Modified to introduce a dynamic crossover probability\n        crossover_prob_dynamic = self.crossover_prob * (1 - self.evaluations / self.budget)\n        crossover_mask = np.random.rand(self.dim) < crossover_prob_dynamic\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic crossover probability for enhanced exploration and exploitation balance.", "configspace": "", "generation": 32, "fitness": 0.5353935206743413, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.535 with standard deviation 0.031. And the mean value of best solutions found was 0.321 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5480674118344635, 0.49312909768435387, 0.5649840525042064], "final_y": [0.35984309267635994, 0.36555600810509103, 0.23855907066142634]}, "mutation_prompt": null}
{"id": "22e436c4-faca-4f90-82aa-f3d554253083", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        diversity_measure = np.std(self.population, axis=0).mean()  # Added diversity measure\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor * (1 + diversity_measure)\n\n    def crossover(self, target, mutant):\n        crossover_prob_adjusted = self.crossover_prob + 0.2 * np.random.uniform(-0.1, 0.1)  # Adjusted crossover probability\n        crossover_mask = np.random.rand(self.dim) < crossover_prob_adjusted\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance mutation strategy by incorporating a diversity measure and adjusting the crossover probability.", "configspace": "", "generation": 33, "fitness": 0.4024447091167888, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.402 with standard deviation 0.060. And the mean value of best solutions found was 0.486 (0. is the best) with standard deviation 0.051.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.3465764154889235, 0.3755732561290621, 0.4851844557323808], "final_y": [0.5349365605614659, 0.5079529949612298, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "948a3816-540d-440f-87e7-61fefaf2cf1e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        adaptive_crossover = self.crossover_prob * (1 + (self.best_score - np.min([func(ind) for ind in self.population])) / self.best_score)\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in self.population])  # Refined elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improve exploitation through adaptive crossover probability and elitism strategy refinement.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {}, "mutation_prompt": null}
{"id": "03613ff2-54a6-4675-a349-b501495aa5d2", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 40  # Increased population size\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.6, 1.6)  # Enhanced dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improve exploration and exploitation by adjusting population size and enhancing mutation diversity.", "configspace": "", "generation": 35, "fitness": 0.5540640854261084, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.554 with standard deviation 0.051. And the mean value of best solutions found was 0.342 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5084879432892293, 0.5284151965235253, 0.6252891164655708], "final_y": [0.3337919005365624, 0.3728766695391771, 0.3201669813511897]}, "mutation_prompt": null}
{"id": "64682ca0-3835-47b6-934d-6982d3de32a0", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        self.crossover_prob = 0.7 + 0.3 * (1 - self.evaluations / self.budget)  # Adaptive dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive dynamic crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 36, "fitness": 0.565593385005326, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.566 with standard deviation 0.091. And the mean value of best solutions found was 0.308 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.666607983574258, 0.4453240397635835, 0.5848481316781364], "final_y": [0.2627481222424556, 0.35067564790753813, 0.30971974362470267]}, "mutation_prompt": null}
{"id": "e0f1276d-3546-41ed-84f9-319d5506af1a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.population[np.argmin([func(ind) for ind in self.population])] = self.best_solution  # Apply greedy selection\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploitation by integrating greedy selection in the elitism mechanism.", "configspace": "", "generation": 37, "fitness": 0.5690181406815119, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.058. And the mean value of best solutions found was 0.326 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.6467694169377343, 0.5513307107666673, 0.5089542943401344], "final_y": [0.28729054899627826, 0.32194960464671096, 0.36746689473660776]}, "mutation_prompt": null}
{"id": "e59e37dd-7d84-4266-989c-a7732979584e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Number of individuals\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n        exploration_factor = np.random.uniform(0.5, 1.5)  # Dynamic exploration factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        if trial_score < target_score or np.random.rand() < np.exp((target_score - trial_score) / self.temperature):\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        # Initialize population within given bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])  # Changed elitism index strategy\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate  # Simulated Annealing cooling\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce enhanced trial vector selection by incorporating an adaptive crossover probability.", "configspace": "", "generation": 38, "fitness": 0.5353935206743413, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.535 with standard deviation 0.031. And the mean value of best solutions found was 0.321 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.5480674118344635, 0.49312909768435387, 0.5649840525042064], "final_y": [0.35984309267635994, 0.36555600810509103, 0.23855907066142634]}, "mutation_prompt": null}
{"id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance selection strategy by introducing a probabilistic acceptance criterion based on a decay factor to improve convergence.", "configspace": "", "generation": 39, "fitness": 0.5706277310909266, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.571 with standard deviation 0.057. And the mean value of best solutions found was 0.326 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "03f216d6-9d89-4d6f-81d4-25fac7664302", "metadata": {"aucs": [0.6467694169377343, 0.5561594819949108, 0.5089542943401344], "final_y": [0.28729054899627826, 0.3233037280634746, 0.36746689473660776]}, "mutation_prompt": null}
{"id": "3effa63f-17d2-4e0d-85b8-19cd0fff2f3b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_prob  # Changed line\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive crossover probability based on evaluations to enhance exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.5307617366391318, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.531 with standard deviation 0.035. And the mean value of best solutions found was 0.340 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "metadata": {"aucs": [0.5694054663489685, 0.48377424249256806, 0.539105501075859], "final_y": [0.2908964537703571, 0.36919451495862277, 0.3611112182149556]}, "mutation_prompt": null}
{"id": "435dc26c-b7c7-4ec8-b845-79ca019e6553", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            if self.evaluations % (self.budget // 10) == 0:  # Dynamic population resizing\n                self.pop_size = int(self.pop_size * 0.95)\n                self.population = self.population[:self.pop_size]\n\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive crossover probability and dynamic population resizing to enhance diversity and convergence.", "configspace": "", "generation": 41, "fitness": 0.5304610798047653, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.530 with standard deviation 0.034. And the mean value of best solutions found was 0.331 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "metadata": {"aucs": [0.5388881362069691, 0.566675878418988, 0.48581922478833894], "final_y": [0.3073387456937955, 0.2770319235285935, 0.40787559826863784]}, "mutation_prompt": null}
{"id": "5bfe77a6-2818-4723-81b3-1fbca31535a6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_prob = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive crossover probability based on current evaluations to balance exploration and exploitation.", "configspace": "", "generation": 42, "fitness": 0.5307617366391318, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.531 with standard deviation 0.035. And the mean value of best solutions found was 0.340 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "metadata": {"aucs": [0.5694054663489685, 0.48377424249256806, 0.539105501075859], "final_y": [0.2908964537703571, 0.36919451495862277, 0.3611112182149556]}, "mutation_prompt": null}
{"id": "d62525c6-24a3-4980-8589-6a7e4b3507ee", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        dynamic_crossover_prob = self.crossover_prob * (self.evaluations / self.budget)  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.temperature *= self.cooling_rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic crossover probability for balancing exploration and exploitation based on the remaining budget.", "configspace": "", "generation": 43, "fitness": 0.5259389966346552, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.526 with standard deviation 0.020. And the mean value of best solutions found was 0.347 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "metadata": {"aucs": [0.5289673209363832, 0.4997266642263417, 0.5491230047412405], "final_y": [0.3489906436945426, 0.3371572254303802, 0.35454636650572735]}, "mutation_prompt": null}
{"id": "3c523257-5823-4451-92df-c4022e87c08b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)  # Adjust cooling rate adaptively\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adjust the cooling rate adaptively based on the progress of evaluations to balance exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.5751392156111174, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.575 with standard deviation 0.052. And the mean value of best solutions found was 0.310 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "fdf0cca5-4db6-4b4c-b351-b8a517df7984", "metadata": {"aucs": [0.6467694169377343, 0.5545163260447279, 0.5241319038508898], "final_y": [0.28729054899627826, 0.2987207746290189, 0.3451185790448038]}, "mutation_prompt": null}
{"id": "1dbe991e-98c8-4874-9814-9f26b4a6dfb3", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        # Adjust crossover probability based on evaluation progress\n        self.crossover_prob = 0.7 + 0.3 * (self.evaluations / self.budget)\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploitation by dynamically adjusting the crossover probability based on evaluation progress.", "configspace": "", "generation": 45, "fitness": 0.5472845543421956, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.547 with standard deviation 0.007. And the mean value of best solutions found was 0.328 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "3c523257-5823-4451-92df-c4022e87c08b", "metadata": {"aucs": [0.5368822905415034, 0.5538256762820712, 0.551145696203012], "final_y": [0.36233530248434787, 0.3221176042922781, 0.2990566882255531]}, "mutation_prompt": null}
{"id": "c0398a6a-5285-4bfc-bd29-250440d0ad2f", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        diversity_factor = np.std(self.population) / 10.0  # New diversity factor\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor + diversity_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)  # Adjust cooling rate adaptively\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce population diversity control by adapting mutation strategies to enhance exploration-exploitation balance.", "configspace": "", "generation": 46, "fitness": 0.5471459430244144, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.547 with standard deviation 0.036. And the mean value of best solutions found was 0.334 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3c523257-5823-4451-92df-c4022e87c08b", "metadata": {"aucs": [0.4994428695560843, 0.5568075581670324, 0.5851874013501265], "final_y": [0.3296486890931728, 0.3484549928622528, 0.3231020833343564]}, "mutation_prompt": null}
{"id": "f0a0b3c2-9fb7-4173-b761-bc70f0703c43", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget  # New decay factor\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))  # Modified acceptance probability\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.02 * (self.evaluations / self.budget)  # Adjust cooling rate adaptively\n            self.mutation_factor = 0.8 * (1 - self.evaluations / self.budget)  # Adaptive mutation factor\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive learning rates and elitism to improve convergence and prevent premature freezing in the optimization process.", "configspace": "", "generation": 47, "fitness": 0.5305419622417918, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.531 with standard deviation 0.023. And the mean value of best solutions found was 0.327 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "3c523257-5823-4451-92df-c4022e87c08b", "metadata": {"aucs": [0.5271577964872309, 0.5037341739342274, 0.560733916303917], "final_y": [0.3809355063675277, 0.30183881800522805, 0.2978809067033725]}, "mutation_prompt": null}
{"id": "69520af9-ef56-4302-a2d5-a3753f6c20a9", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        adaptive_cp = self.crossover_prob * (1 - self.evaluations / self.budget)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < adaptive_cp\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive crossover probability based on evaluation progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.535747990165364, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.536 with standard deviation 0.032. And the mean value of best solutions found was 0.333 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3c523257-5823-4451-92df-c4022e87c08b", "metadata": {"aucs": [0.5632031906272572, 0.4907721235241268, 0.5532686563447082], "final_y": [0.3210572823711063, 0.33475714450298466, 0.34328132914552256]}, "mutation_prompt": null}
{"id": "e76988bd-604a-4193-a459-8f62179dc8e5", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive population size scaling based on evaluation progress to enhance diversity and convergence.", "configspace": "", "generation": 49, "fitness": 0.5824454016860224, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.582 with standard deviation 0.029. And the mean value of best solutions found was 0.303 (0. is the best) with standard deviation 0.049.", "error": "", "parent_id": "3c523257-5823-4451-92df-c4022e87c08b", "metadata": {"aucs": [0.5818418631782369, 0.6181395239928215, 0.5473548178870088], "final_y": [0.3056261886764827, 0.24115549915503776, 0.36120256938980855]}, "mutation_prompt": null}
{"id": "854fa12b-ed3d-4ffa-bc1c-59507700f3b1", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - (self.evaluations / self.budget) ** 2)  # Changed line\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Update mutation factor adaptively based on dynamic evaluation progress for improved exploration.", "configspace": "", "generation": 50, "fitness": 0.5167873510771467, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.517 with standard deviation 0.017. And the mean value of best solutions found was 0.361 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "e76988bd-604a-4193-a459-8f62179dc8e5", "metadata": {"aucs": [0.502747587715159, 0.5405278506771813, 0.5070866148390998], "final_y": [0.34630500666730746, 0.3603326701942716, 0.37734604541467387]}, "mutation_prompt": null}
{"id": "ee16353e-b6a2-481c-bfa9-64582418b30e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.98 + 0.02 * (self.evaluations / self.budget)  # Changed line\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce elitism with adaptive learning rate to preserve top solutions and enhance convergence.", "configspace": "", "generation": 51, "fitness": 0.5824454016860224, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.582 with standard deviation 0.029. And the mean value of best solutions found was 0.303 (0. is the best) with standard deviation 0.049.", "error": "", "parent_id": "e76988bd-604a-4193-a459-8f62179dc8e5", "metadata": {"aucs": [0.5818418631782369, 0.6181395239928215, 0.5473548178870088], "final_y": [0.3056261886764827, 0.24115549915503776, 0.36120256938980855]}, "mutation_prompt": null}
{"id": "f40600ed-de52-4824-a43d-94074e6c0777", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        self.crossover_prob = 0.7 + 0.3 * (1 - self.evaluations / self.budget)  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce dynamic crossover probability scaling based on remaining budget and trial solution quality to improve convergence.", "configspace": "", "generation": 52, "fitness": 0.519476426796029, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.519 with standard deviation 0.012. And the mean value of best solutions found was 0.331 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "e76988bd-604a-4193-a459-8f62179dc8e5", "metadata": {"aucs": [0.5310813586069735, 0.5031316740828105, 0.524216247698303], "final_y": [0.28259827788734104, 0.3887513819271149, 0.3203430027736922]}, "mutation_prompt": null}
{"id": "823176c0-fc2d-415b-915b-a2feca02e5b6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget) * (1 - self.best_score)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance the exploitation phase by adjusting the mutation factor based on current solution quality and evaluations.", "configspace": "", "generation": 53, "fitness": 0.5671239671534606, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.567 with standard deviation 0.042. And the mean value of best solutions found was 0.341 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "e76988bd-604a-4193-a459-8f62179dc8e5", "metadata": {"aucs": [0.6235474982744726, 0.5219822092184951, 0.5558421939674139], "final_y": [0.29568735575151184, 0.38729545059387194, 0.3395841161624661]}, "mutation_prompt": null}
{"id": "74427ee0-3d73-4243-b512-339064aca8a1", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.5:  # Dynamic mutation strategy\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.2 * (self.evaluations / self.budget)  # Adaptive crossover probability\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce dynamic crossover probability and adaptive mutation strategy for enhanced exploration and exploitation.", "configspace": "", "generation": 54, "fitness": 0.5870113957722269, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.587 with standard deviation 0.093. And the mean value of best solutions found was 0.308 (0. is the best) with standard deviation 0.074.", "error": "", "parent_id": "e76988bd-604a-4193-a459-8f62179dc8e5", "metadata": {"aucs": [0.5605844245553957, 0.4890388533548371, 0.711410909406448], "final_y": [0.340183109707756, 0.3777667398790091, 0.20494539995861705]}, "mutation_prompt": null}
{"id": "d4a83432-6ddb-43ad-8ec5-5af148ec1d4d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.5:  # Dynamic mutation strategy\n            return self.population[a] + F_adaptive * np.random.uniform(0.5, 1.5) * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.2 * (self.evaluations / self.budget)  # Adaptive crossover probability\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.95 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance global search by introducing mutation diversity through random scaling of differential vectors.", "configspace": "", "generation": 55, "fitness": 0.5265053259856244, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.527 with standard deviation 0.050. And the mean value of best solutions found was 0.336 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "74427ee0-3d73-4243-b512-339064aca8a1", "metadata": {"aucs": [0.5873327373178769, 0.46389963894208197, 0.5282836016969141], "final_y": [0.29402428595982144, 0.39031663762961444, 0.32434164936714227]}, "mutation_prompt": null}
{"id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Refine mutation and crossover strategies with adaptive parameters and elitism to enhance exploration and convergence.", "configspace": "", "generation": 56, "fitness": 0.5879573693704149, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.074. And the mean value of best solutions found was 0.309 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "74427ee0-3d73-4243-b512-339064aca8a1", "metadata": {"aucs": [0.6088817242830629, 0.4886962147227498, 0.666294169105432], "final_y": [0.31166830008591884, 0.36916741670820674, 0.24691752673549483]}, "mutation_prompt": null}
{"id": "beb354a3-4e61-4d28-830c-0f63b2ac46b9", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, self.dim))  # Initialize velocities\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                self.velocities[i] = 0.5 * self.velocities[i] + 0.5 * (new_population[i] - self.population[i])  # Update velocities\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate competitive particle swarm dynamics into differential evolution to enhance exploration and convergence.", "configspace": "", "generation": 57, "fitness": 0.5336944956996416, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.534 with standard deviation 0.021. And the mean value of best solutions found was 0.354 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.5475281983210324, 0.5045971200773798, 0.5489581687005123], "final_y": [0.33774889221316584, 0.37534534131367847, 0.34982642663666763]}, "mutation_prompt": null}
{"id": "3d3abf54-3731-4ffe-9936-abe0c4e4c2c3", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + (F_adaptive * 0.5 + 0.5) * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic mutation scaling factor to balance exploration and exploitation as the budget is consumed.", "configspace": "", "generation": 58, "fitness": 0.544643625359661, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.545 with standard deviation 0.096. And the mean value of best solutions found was 0.353 (0. is the best) with standard deviation 0.090.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.43066626523300156, 0.5369194043768801, 0.6663452064691016], "final_y": [0.45507600169301776, 0.36718375553620786, 0.23632244330099572]}, "mutation_prompt": null}
{"id": "ca476fbc-23dc-4ece-a486-7effcd6751ad", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (0.8 + 0.2 * np.cos(np.pi * self.evaluations / self.budget))  # Dynamic adjustment (changed)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Refine mutation and crossover strategies by dynamically adjusting the mutation factor for improved exploration.", "configspace": "", "generation": 59, "fitness": 0.5398355231351953, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.540 with standard deviation 0.038. And the mean value of best solutions found was 0.312 (0. is the best) with standard deviation 0.065.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.48668120496944867, 0.575655433882087, 0.5571699305540505], "final_y": [0.36048179550084625, 0.22036092303190657, 0.354739708388243]}, "mutation_prompt": null}
{"id": "89b9e686-d258-4a66-b19d-b6836996357b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            direction = np.sign(self.best_solution - self.population[idx])  # New directional exploitation\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b]) * direction\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        dynamic_factor = self.evaluations / self.budget  # New dynamic factor for more adaptive crossover\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring + dynamic_factor * (self.best_solution - offspring)  # Integrate best solution influence\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate dynamic mutation and crossover with adaptive scaling and directional exploitation for better convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {}, "mutation_prompt": null}
{"id": "51f8c990-45c1-4397-acb2-8ba4050762b3", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n                # Stochastic local search to enhance diversity (added)\n                if np.random.rand() < 0.05:\n                    new_population[i] += np.random.normal(scale=0.1, size=self.dim)\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce stochastic local search to enhance diversity and escape local minima.", "configspace": "", "generation": 61, "fitness": 0.5336256684814588, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.534 with standard deviation 0.012. And the mean value of best solutions found was 0.336 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.529432672318632, 0.5501405417758074, 0.5213037913499368], "final_y": [0.33974303248779925, 0.2966899501313348, 0.3706161399334653]}, "mutation_prompt": null}
{"id": "f6c60f6c-6674-43a7-918f-574c2cf361cc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        diversity_factor = np.std(self.population) # New diversity enhancement factor\n        if trial_score < target_score or np.random.rand() < acceptance_prob * diversity_factor:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Implement diversity-enhanced selection to maintain diverse solutions while converging towards optimal regions.", "configspace": "", "generation": 62, "fitness": 0.5866110320887877, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.587 with standard deviation 0.074. And the mean value of best solutions found was 0.307 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.6088817242830629, 0.4870896703069607, 0.6638617016763395], "final_y": [0.31166830008591884, 0.3438406086480469, 0.2652213000242425]}, "mutation_prompt": null}
{"id": "dc1c3a61-6c4a-42d9-b589-43f63305f320", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate a dynamic scaling factor for exploration-exploitation balance to enhance convergence.", "configspace": "", "generation": 63, "fitness": 0.5879573693704149, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.074. And the mean value of best solutions found was 0.309 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.6088817242830629, 0.4886962147227498, 0.666294169105432], "final_y": [0.31166830008591884, 0.36916741670820674, 0.24691752673549483]}, "mutation_prompt": null}
{"id": "d07d12fc-f939-479a-87bf-36c30133a0ee", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive mutation factor using a nonlinear scaling based on evaluations\n        F_adaptive = self.mutation_factor * (1 - (self.evaluations / self.budget)**2)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Utilize adaptive mutation factor based on a nonlinear scaling of evaluations to improve exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.48720111180667286, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.487 with standard deviation 0.042. And the mean value of best solutions found was 0.397 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.42811585976250477, 0.525098684364671, 0.5083887912928429], "final_y": [0.4480248674226298, 0.3445789844817817, 0.39926505167533644]}, "mutation_prompt": null}
{"id": "2b2bad3d-bc8f-4d36-936b-500a32af26c4", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        diversity_factor = np.std(self.population)  # Added line: compute diversity of population\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor * diversity_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic mutation factor based on the diversity of population to enhance exploration vs. exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.501009713251154, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.501 with standard deviation 0.050. And the mean value of best solutions found was 0.358 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.4500239956198019, 0.483742235468563, 0.5692629086650971], "final_y": [0.32890704793129444, 0.4174895306859251, 0.32818707456251894]}, "mutation_prompt": null}
{"id": "f48c8f74-c13a-43a1-aee8-11a895d0c208", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 2.0)  # Enhanced exploration range\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            if elitism_idx != np.argmin([func(ind) for ind in self.population]):  # Adaptive elitism\n                self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive elitism and enhanced exploration with dynamic mutation factor to improve convergence.", "configspace": "", "generation": 66, "fitness": 0.4847442601345054, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.485 with standard deviation 0.032. And the mean value of best solutions found was 0.388 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.44026616152657794, 0.5036435020863836, 0.5103231167905545], "final_y": [0.41072049327128124, 0.358128714057508, 0.39514527418615364]}, "mutation_prompt": null}
{"id": "e5692039-f93b-471d-995d-14280e5729f8", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.9\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.5:  # Enhanced dynamic mutation strategy\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        adaptive_mask = np.random.rand(self.dim) < (0.5 + 0.5 * (self.evaluations / self.budget))  # Self-adaptive strategy\n        offspring = np.where(adaptive_mask, mutant, target)\n        offspring = np.where(crossover_mask, offspring, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            self.pop_size = int(20 + 10 * (0.5 + 0.5 * np.sin(np.pi * self.evaluations / self.budget)))  # Adaptive population size\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate an adaptive population structure and dynamic mutation strategy with a self-adaptive crossover mechanism to enhance solution diversity and convergence rates.", "configspace": "", "generation": 67, "fitness": 0.5695639754341301, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.570 with standard deviation 0.040. And the mean value of best solutions found was 0.328 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.5699840474755051, 0.5205465975608183, 0.6181612812660668], "final_y": [0.3212860820508405, 0.3559828406412415, 0.3074769522264459]}, "mutation_prompt": null}
{"id": "6fecc7cf-e553-4524-b719-b74e12685531", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive mutation factor based on temperature\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget) * (self.temperature / 100.0)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive mutation factor based on the temperature to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 68, "fitness": 0.5879573693704149, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.074. And the mean value of best solutions found was 0.309 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.6088817242830629, 0.4886962147227498, 0.666294169105432], "final_y": [0.31166830008591884, 0.36916741670820674, 0.24691752673549483]}, "mutation_prompt": null}
{"id": "703b3f68-eb41-4d86-afcc-8d57044c4efd", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.9 - 0.4 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce self-adaptive crossover probability to improve diversity and convergence.", "configspace": "", "generation": 69, "fitness": 0.5398230740252622, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.540 with standard deviation 0.054. And the mean value of best solutions found was 0.324 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.5138920037074135, 0.49010362351153913, 0.615473594856834], "final_y": [0.24483044874821036, 0.39855359454200756, 0.3283296954442573]}, "mutation_prompt": null}
{"id": "d352274e-61f6-4e8d-bef4-6ab1eba02386", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        jitter = np.random.normal(0, 0.1, self.dim)  # Change 1: Added jitter\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor + jitter\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b]) + jitter\n\n    def crossover(self, target, mutant):\n        crossover_prob_dynamic = 0.5 + 0.4 * np.random.rand()  # Change 2: Introduced randomness in crossover probability\n        crossover_mask = np.random.rand(self.dim) < crossover_prob_dynamic  # Change 3: Applied dynamic crossover probability\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget)  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduced jitter in mutation and a dynamic crossover strategy to better balance exploration and exploitation.", "configspace": "", "generation": 70, "fitness": 0.49592771549726766, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.496 with standard deviation 0.031. And the mean value of best solutions found was 0.356 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.5196768467920906, 0.4517614135807969, 0.5163448861189154], "final_y": [0.3330903611537037, 0.3959381449762869, 0.337879979564359]}, "mutation_prompt": null}
{"id": "b36d6b90-4f73-420a-80c9-335242c60f16", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced exploration with adaptive crossover probability depending on the population's diversity for better convergence.", "configspace": "", "generation": 71, "fitness": 0.6187004654372845, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.079. And the mean value of best solutions found was 0.293 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "b6e3e396-c7e1-46b6-a47f-7e823eea7611", "metadata": {"aucs": [0.6444827229140667, 0.511841397597826, 0.699777275799961], "final_y": [0.3060075860725566, 0.35193462005548104, 0.22194290730455768]}, "mutation_prompt": null}
{"id": "c53840c8-d0e8-48ae-a1d7-e4888851bb21", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - (self.evaluations / self.budget) * 0.5)  # Adjusted mutation factor (changed)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved search strategy by dynamically adjusting mutation factor for better exploration and exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.5691075000461681, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.113. And the mean value of best solutions found was 0.332 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.5128058950896555, 0.4675355984331595, 0.7269810066156892], "final_y": [0.37290563155899736, 0.36936366745857696, 0.2533123353131729]}, "mutation_prompt": null}
{"id": "8c32ec7a-70b5-482d-b3b5-c6aee837baa3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.init_temperature = 100.0\n        self.temperature = self.init_temperature\n        self.cooling_rate_initial = 0.95\n        self.cooling_rate_final = 0.85\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n        \n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def adjust_temperature(self):\n        progress_ratio = self.evaluations / self.budget\n        self.temperature = self.init_temperature * (self.cooling_rate_initial - progress_ratio * (self.cooling_rate_initial - self.cooling_rate_final))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            self.population = new_population\n            self.adjust_temperature()\n            \n        return self.best_solution, self.best_score", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Temperature Adjustment enhances exploration and exploitation by dynamically adjusting mutation strategies, crossover probabilities, and temperature decay based on evaluation progress.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {}, "mutation_prompt": null}
{"id": "11cece97-913a-4a7f-a4b1-f90db7a5259d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        diversity_factor = np.var(self.population)  # Added line\n        if np.random.rand() < 0.6 + 0.2 * diversity_factor:  # Dynamic mutation strategy adjusted\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            if np.random.rand() < 0.5:  # Added line for adaptive elitism\n                self.population = new_population\n                self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n\n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduces adaptive elitism and diversity preservation by dynamically adjusting the population elitism and enhancing the mutation strategy.", "configspace": "", "generation": 74, "fitness": 0.5055393375928829, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.506 with standard deviation 0.025. And the mean value of best solutions found was 0.380 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.4733626467342169, 0.508050438332796, 0.535204927711636], "final_y": [0.39614733425664783, 0.3677637763241097, 0.37673084942999746]}, "mutation_prompt": null}
{"id": "e9c9d44c-6fcd-4ac6-996a-dcd3df1b988a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) * (0.8 + 0.2 * population_variance) # Adjusted cooling rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved cooling rate adjustment by incorporating population diversity for better convergence.", "configspace": "", "generation": 75, "fitness": 0.6187004654372845, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.079. And the mean value of best solutions found was 0.293 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.6444827229140667, 0.511841397597826, 0.699777275799961], "final_y": [0.3060075860725566, 0.35193462005548104, 0.22194290730455768]}, "mutation_prompt": null}
{"id": "433938e2-6350-4d64-bbd6-4a51989db54a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            # Add a factor based on the best score found so far (changed)\n            self.crossover_prob += 0.01 * (1 - self.best_score / (self.best_score + 1))\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Dynamically tune the crossover probability based on population diversity and current best score for improved convergence.", "configspace": "", "generation": 76, "fitness": 0.5913379106171038, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.591 with standard deviation 0.089. And the mean value of best solutions found was 0.286 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.6731772925307258, 0.46825626118332775, 0.6325801781372583], "final_y": [0.26747294669756605, 0.28984978840646825, 0.30013809183174833]}, "mutation_prompt": null}
{"id": "7e9b7a09-c5ff-4724-9500-74cb78d56fe7", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.7, 1.3)  # Adjusted exploration_factor range (changed)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.8 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved exploration through dynamic mutation weights and enhanced cooling for balancing convergence.", "configspace": "", "generation": 77, "fitness": 0.5545678340594936, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.555 with standard deviation 0.058. And the mean value of best solutions found was 0.321 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.5315823004442184, 0.4979293424297351, 0.6341918593045275], "final_y": [0.32167774494619283, 0.3522728675828558, 0.2887403383872176]}, "mutation_prompt": null}
{"id": "54bbe472-fb65-4b2b-ad23-bb7c21e22cd6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def local_search(self, solution, lb, ub):  # Local search refinement\n        perturbation = np.random.uniform(-0.01, 0.01, self.dim)\n        new_solution = np.clip(solution + perturbation, lb, ub)\n        return new_solution\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                trial = self.local_search(trial, lb, ub)  # Apply local search\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.03 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced exploration with local search refinement and dynamic cooling for improved convergence.", "configspace": "", "generation": 78, "fitness": 0.506848705490941, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.507 with standard deviation 0.032. And the mean value of best solutions found was 0.342 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.4617503855226036, 0.5239146701679911, 0.5348810607822281], "final_y": [0.3713002403235157, 0.3234038762286954, 0.3304036500744172]}, "mutation_prompt": null}
{"id": "7b58096a-1a05-4a8e-811f-da939716aa78", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        adaptive_exploration = np.random.uniform(0.8, 1.2)  # Enhanced exploration (changed)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor * adaptive_exploration\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced local search capability by adding adaptive mutation and improved exploration with variable crossover probabilities.", "configspace": "", "generation": 79, "fitness": 0.49061805209386317, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.491 with standard deviation 0.021. And the mean value of best solutions found was 0.379 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.4644857976388671, 0.5158030041764821, 0.4915653544662404], "final_y": [0.37327948325374405, 0.35700332636322585, 0.4062228931631877]}, "mutation_prompt": null}
{"id": "b00ce9d3-bb1b-427b-aa8b-ab334bbdd227", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.5 + 0.2 * np.exp(-self.evaluations / self.budget):  # More adaptive mutation strategy\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            diversity_factor = np.var(self.population) / self.dim + 0.1  # Dynamic diversity factor\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b]) * diversity_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved local and global search balance by integrating adaptive mutation factor and dynamic population diversity analysis.", "configspace": "", "generation": 80, "fitness": 0.45213679480700114, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.452 with standard deviation 0.062. And the mean value of best solutions found was 0.410 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.4341524250920281, 0.38696954316479915, 0.5352884161641761], "final_y": [0.4473485100523197, 0.4090928173200302, 0.3729492180025781]}, "mutation_prompt": null}
{"id": "3aa44125-11e3-470c-8e46-3f3a6d34a08a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            if np.random.rand() < 0.5:  # Adaptive elitism replacement strategy (changed)\n                self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrates elitism with an adaptive elitism replacement strategy to enhance convergence by preserving high-quality solutions.", "configspace": "", "generation": 81, "fitness": 0.5546390857454736, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.555 with standard deviation 0.060. And the mean value of best solutions found was 0.334 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.5360788660936588, 0.49187046642378873, 0.6359679247189733], "final_y": [0.36913847183935444, 0.3608189620260627, 0.27234168707274986]}, "mutation_prompt": null}
{"id": "274a1766-cc46-4b9a-b0f1-ba03811b727e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8  # Improved initialization\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improved initialization of population to enhance exploration and avoid premature convergence.", "configspace": "", "generation": 82, "fitness": 0.6371727540438396, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.637 with standard deviation 0.098. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "b36d6b90-4f73-420a-80c9-335242c60f16", "metadata": {"aucs": [0.5078406363520656, 0.657203810311375, 0.7464738154680783], "final_y": [0.34607511542752645, 0.2835546106343938, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "59e60595-ce41-42fd-8199-eb4c4b64fbe6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n            # Adaptive mutation factor scaling added\n        F_adaptive = self.mutation_factor * (0.5 + 0.5 * (1 - self.evaluations / self.budget))\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8  # Improved initialization\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introducing adaptive mutation factor scaling to improve balance between exploration and exploitation.", "configspace": "", "generation": 83, "fitness": 0.6371727540438396, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.637 with standard deviation 0.098. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "274a1766-cc46-4b9a-b0f1-ba03811b727e", "metadata": {"aucs": [0.5078406363520656, 0.657203810311375, 0.7464738154680783], "final_y": [0.34607511542752645, 0.2835546106343938, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "6ddbdf4a-e779-42ae-88a3-fe00e8634b3e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        decay_exploration = (self.budget - self.evaluations) / self.budget  # Decay factor added\n        if np.random.rand() < 0.6:  # Dynamic mutation strategy (changed)\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor * decay_exploration\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance  # Adaptive crossover probability (changed)\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8  # Improved initialization\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))  # Adaptive population size (changed)\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget) # Adjusted cooling rate (changed)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Incorporate a decay factor in mutation strategy to enhance exploration as budget decreases.", "configspace": "", "generation": 84, "fitness": 0.6017363008379077, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.602 with standard deviation 0.103. And the mean value of best solutions found was 0.307 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "274a1766-cc46-4b9a-b0f1-ba03811b727e", "metadata": {"aucs": [0.5160864348472287, 0.5426486521984162, 0.7464738154680783], "final_y": [0.33281076267813814, 0.33016405820709516, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "3381f303-ec6e-47f5-9fa4-45378f8a6eec", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.9  # Changed factor for better exploration\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Adjusted for better exploitation\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.7, 1.3)  # Changed for more balanced exploration\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(25 + 10 * (self.evaluations / self.budget))  # Adjusted population size\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(ind) for ind in new_population])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrates adaptive strategies in mutation, crossover, and population management to enhance exploration and exploitation in a hybrid differential evolution and simulated annealing framework.", "configspace": "", "generation": 85, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "274a1766-cc46-4b9a-b0f1-ba03811b727e", "metadata": {}, "mutation_prompt": null}
{"id": "e0fece94-a89f-45c5-b7d2-996739be609c", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            # Updated elitism index computation to enhance convergence\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adaptive elitism retention by dynamically adjusting the elitism index to enhance convergence.", "configspace": "", "generation": 86, "fitness": 0.641893012382584, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.642 with standard deviation 0.095. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "274a1766-cc46-4b9a-b0f1-ba03811b727e", "metadata": {"aucs": [0.5165006990529857, 0.6627045226266881, 0.7464738154680783], "final_y": [0.34607511542752645, 0.2835546106343938, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "1471b0c0-3ec2-493b-9c74-ba567c9a1542", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                self.mutation_factor = 0.6 + 0.4 * population_variance  # Line modified for dynamic mutation adaptation\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced convergence by incorporating a dynamic mutation factor adjustment based on population diversity.", "configspace": "", "generation": 87, "fitness": 0.6123163319805173, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.612 with standard deviation 0.100. And the mean value of best solutions found was 0.312 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.5659043472906453, 0.519234453866993, 0.7518101947839138], "final_y": [0.32969708020848965, 0.3648108759745242, 0.24090244396312688]}, "mutation_prompt": null}
{"id": "50565db4-3d7e-4c32-adaa-b129dad28671", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive crossover probability enhancement to improve diversity and convergence.", "configspace": "", "generation": 88, "fitness": 0.641893012382584, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.642 with standard deviation 0.095. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.5165006990529857, 0.6627045226266881, 0.7464738154680783], "final_y": [0.34607511542752645, 0.2835546106343938, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "8a4a6c6d-8e63-4751-b569-8dea11c288ca", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            # Updated elitism index computation to enhance convergence\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.1 * (self.evaluations / self.budget)  # Modify this line\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive cooling rate adjustment based on evaluations to enhance convergence robustness.", "configspace": "", "generation": 89, "fitness": 0.641893012382584, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.642 with standard deviation 0.095. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.5165006990529857, 0.6627045226266881, 0.7464738154680783], "final_y": [0.34607511542752645, 0.2835546106343938, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "ed3a99bb-e358-4f9e-998a-8153c825e51f", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - np.cos(np.pi * self.evaluations / (2 * self.budget)))\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduced adaptive mutation factor scaling using cosine annealing to balance exploration and exploitation.", "configspace": "", "generation": 90, "fitness": 0.6348933160782971, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.635 with standard deviation 0.082. And the mean value of best solutions found was 0.287 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.5503141883296291, 0.6080933159062342, 0.7462724439990281], "final_y": [0.32624394166832116, 0.27592113518414074, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "dd3c5adf-ce8b-423a-823c-1f8af16e1e2d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.6, 1.4)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            # Updated elitism index computation to enhance convergence\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Hybridizing dynamic adaptive mutation and elitism with balanced exploration-exploitation trade-off.", "configspace": "", "generation": 91, "fitness": 0.6044750562793108, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.604 with standard deviation 0.122. And the mean value of best solutions found was 0.329 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.44905373455339814, 0.6180399797047202, 0.7463314545798139], "final_y": [0.40392567210530606, 0.3249146266361991, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "c69fa14c-8af8-4d3f-ba7a-bb73d545e0be", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5 + np.var(self.population))  # Updated line\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            # Updated elitism index computation to enhance convergence\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced exploration by adjusting exploration factor based on population variance for better diversity maintenance.", "configspace": "", "generation": 92, "fitness": 0.6266957728001025, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.627 with standard deviation 0.090. And the mean value of best solutions found was 0.303 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.6031138909548514, 0.5306906804376601, 0.7462827470077957], "final_y": [0.2663766672639679, 0.38333021540127643, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "faf0f885-728a-4571-93dd-60e14f358549", "solution": "import numpy as np\n\nclass HybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.temperature = self.initial_temp\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        return self.population[a] + F_adaptive * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = np.exp((target_score - trial_score) / (self.temperature * (1 - self.evaluations / self.budget)))\n        if trial_score < target_score or np.random.rand() < decay_factor:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        dynamic_cooling_rate = lambda x: 0.9 + 0.1 * (1 - x / self.budget)\n        \n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 10 * (1 - (self.evaluations / self.budget)**2))\n            \n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n\n            elite_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elite_idx] = self.best_solution\n            self.temperature *= dynamic_cooling_rate(self.evaluations)\n\n        return self.best_solution, self.best_score", "name": "HybridDifferentialAnnealing", "description": "Hybridized differential evolution with an adaptive cooling annealing strategy and dynamic population management for enhanced convergence.", "configspace": "", "generation": 93, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 28 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 28 is out of bounds for axis 0 with size 20')", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {}, "mutation_prompt": null}
{"id": "cad869da-a35b-4f8e-a68e-9b6bd4f554f8", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[b])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = self.best_solution\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            self.mutation_factor = 0.8 + 0.1 * (1 - self.evaluations / self.budget) # Added line\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhancing convergence by combining adaptive cooling with a dynamic mutation factor.", "configspace": "", "generation": 94, "fitness": 0.6135587375217688, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.614 with standard deviation 0.097. And the mean value of best solutions found was 0.311 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.5198293830689754, 0.5743730140282528, 0.7464738154680783], "final_y": [0.3414174381083853, 0.3339093433440421, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "2944247f-4880-4c10-a08a-7ee158e28315", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            # Improved exploration: random selection among current population\n            d = np.random.choice(indices)  \n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[d])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            # Ensure elitism with improved solution retention\n            self.population[elitism_idx] = 0.5 * self.best_solution + 0.5 * self.population[elitism_idx]\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Refinement of mutation and elitism strategies for improved diversity and convergence.", "configspace": "", "generation": 95, "fitness": 0.7697266434909218, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.037. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "e0fece94-a89f-45c5-b7d2-996739be609c", "metadata": {"aucs": [0.7405971486454905, 0.8221174018386558, 0.746465379988619], "final_y": [0.20264145630471297, 0.2239341282652132, 0.2591239161317923]}, "mutation_prompt": null}
{"id": "c8251604-d1f8-4e5a-bc7f-3383b6c11efd", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            d = np.random.choice(indices)  \n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[d]) + F_adaptive * (self.best_solution - self.population[idx])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = 0.5 * self.best_solution + 0.5 * self.population[elitism_idx]\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced mutation strategy for improved diversity by introducing dynamic selection pressure.", "configspace": "", "generation": 96, "fitness": 0.7408826869037642, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.741 with standard deviation 0.059. And the mean value of best solutions found was 0.249 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "2944247f-4880-4c10-a08a-7ee158e28315", "metadata": {"aucs": [0.6570271816713911, 0.7863498361955799, 0.7792710428443219], "final_y": [0.27833597880309824, 0.23859134498012835, 0.23056006248660177]}, "mutation_prompt": null}
{"id": "5c86a58e-e59b-470f-a1a9-41af374630f5", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            # Improved exploration: random selection among current population\n            d = np.random.choice(indices)  \n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[d])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob * (0.5 + 0.5 * self.evaluations / self.budget)\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            # Ensure elitism with improved solution retention\n            self.population[elitism_idx] = 0.5 * self.best_solution + 0.5 * self.population[elitism_idx]\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adaptive mutation and dynamic crossover strategies for enhanced exploration and convergence.", "configspace": "", "generation": 97, "fitness": 0.7213841612184296, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.721 with standard deviation 0.090. And the mean value of best solutions found was 0.232 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "2944247f-4880-4c10-a08a-7ee158e28315", "metadata": {"aucs": [0.6930402238845922, 0.6281679380714262, 0.8429443216992706], "final_y": [0.24673248184126528, 0.2401270895292914, 0.20851049853647663]}, "mutation_prompt": null}
{"id": "893267e4-25da-40e0-bd01-5cd7e86d3722", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.5, 1.5)\n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            # Improved exploration: random selection among current population\n            d = np.random.choice(indices)  \n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[d])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        acceptance_prob = np.exp((target_score - trial_score) / (self.temperature * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i) * (1 + 0.01 * np.random.randn(self.dim))\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            # Ensure elitism with improved solution retention\n            self.population[elitism_idx] = 0.5 * self.best_solution + 0.5 * self.population[elitism_idx]\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n            \n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce learning rate adaptation in mutation to enhance convergence.", "configspace": "", "generation": 98, "fitness": 0.6726743773189132, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.673 with standard deviation 0.083. And the mean value of best solutions found was 0.244 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "2944247f-4880-4c10-a08a-7ee158e28315", "metadata": {"aucs": [0.5584710919573663, 0.7055239666801483, 0.7540280733192252], "final_y": [0.256281813564486, 0.2212168972589298, 0.25343974390063173]}, "mutation_prompt": null}
{"id": "5124e8cf-bb60-4814-a1a8-8cd73d6cf1f8", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.evaluations = 0\n        self.secondary_population = np.random.uniform(-1.0, 1.0, (self.pop_size, self.dim))\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.pop_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_adaptive = self.mutation_factor * (1 - self.evaluations / self.budget)\n        exploration_factor = np.random.uniform(0.4, 1.4) \n        if np.random.rand() < 0.6:\n            return self.population[a] + F_adaptive * (self.population[b] - self.population[c]) * exploration_factor\n        else:\n            d = np.random.choice(indices)\n            return self.population[idx] + F_adaptive * (self.population[a] - self.population[d])\n\n    def crossover(self, target, mutant):\n        rand_crossover_prob = self.crossover_prob + np.random.uniform(-0.1, 0.1)\n        crossover_mask = np.random.rand(self.dim) < rand_crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def select(self, target, trial, func):\n        target_score = func(target)\n        trial_score = func(trial)\n        self.evaluations += 2\n        decay_factor = (self.budget - self.evaluations) / self.budget\n        adaptive_temp = self.temperature * (1 + 0.1 * np.sin(self.evaluations))\n        acceptance_prob = np.exp((target_score - trial_score) / (adaptive_temp * decay_factor))\n        if trial_score < target_score or np.random.rand() < acceptance_prob:\n            return trial, trial_score\n        return target, target_score\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_variance = np.var(self.population)\n        self.crossover_prob = 0.5 + 0.3 * (self.evaluations / self.budget) + 0.2 * population_variance\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim)) * 0.8\n        while self.evaluations < self.budget:\n            new_population = np.zeros_like(self.population)\n            self.pop_size = int(20 + 15 * (self.evaluations / self.budget))\n            self.secondary_population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                mutant = self.mutate(i)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                new_population[i], score = self.select(self.population[i], trial, func)\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = new_population[i]\n            elitism_idx = np.argmin([func(new_population[i]) for i in range(self.pop_size)])\n            self.population = new_population\n            self.population[elitism_idx] = 0.5 * self.best_solution + 0.5 * self.population[elitism_idx]\n            self.cooling_rate = 0.9 + 0.05 * (self.evaluations / self.budget)\n\n        return self.best_solution, self.best_score", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adaptive multi-population strategy with dynamic crossover and temperature adjustments to enhance convergence and exploration balance.", "configspace": "", "generation": 99, "fitness": 0.6007423591598681, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.601 with standard deviation 0.062. And the mean value of best solutions found was 0.307 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "2944247f-4880-4c10-a08a-7ee158e28315", "metadata": {"aucs": [0.5147111508662946, 0.6323870425763185, 0.6551288840369909], "final_y": [0.3432019036583728, 0.28806468849744105, 0.2909489174438781]}, "mutation_prompt": null}
