{"id": "c5fb54e6-9b1a-490b-8da8-10e9938fa989", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.5\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < func(global_best):\n                global_best = personal_best[current_best_idx]\n\n        return global_best", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Differential Evolution (DE) to explore and exploit search spaces efficiently.", "configspace": "", "generation": 0, "fitness": 0.16817017114794722, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.168 with standard deviation 0.020. And the mean value of best solutions found was 0.825 (0. is the best) with standard deviation 0.239.", "error": "", "parent_id": null, "metadata": {"aucs": [0.170006169226522, 0.19199339484469802, 0.14251094937262165], "final_y": [0.8433128205260966, 0.5234232029763438, 1.1082169476872354]}, "mutation_prompt": null}
{"id": "773df67f-d95b-4eb6-b592-9b63e6ef36c8", "solution": "import numpy as np\n\nclass QuantumInspiredBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.min_freq = 0.0\n        self.max_freq = 2.0\n        self.alpha = 0.9\n        self.gamma = 0.9\n        self.loudness = np.ones(self.pop_size)\n        self.pulse_rate = np.random.rand(self.pop_size)\n        self.q_alpha = 0.05  # Quantum step size\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.zeros((self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_bat = population[np.argmin(fitness)]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                freq = self.min_freq + (self.max_freq - self.min_freq) * np.random.rand()\n                velocities[i] += (population[i] - best_bat) * freq\n                candidate = population[i] + velocities[i]\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_bat + self.q_alpha * np.random.randn(self.dim)\n\n                candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n                candidate_fitness = func(candidate)\n                evaluations += 1\n\n                if (candidate_fitness < fitness[i]) and (np.random.rand() < self.loudness[i]):\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * evaluations / self.budget))\n\n                if candidate_fitness < func(best_bat):\n                    best_bat = candidate\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_bat", "name": "QuantumInspiredBatAlgorithm", "description": "A novel metaheuristic named Quantum-inspired Bat Algorithm (QiBA) integrates quantum principles with the Bat Algorithm to enhance exploration and exploitation in optimization processes. ", "configspace": "", "generation": 1, "fitness": 0.16440098182541388, "feedback": "The algorithm QuantumInspiredBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.164 with standard deviation 0.040. And the mean value of best solutions found was 1.253 (0. is the best) with standard deviation 1.053.", "error": "", "parent_id": "c5fb54e6-9b1a-490b-8da8-10e9938fa989", "metadata": {"aucs": [0.1080975093196398, 0.1960815323168269, 0.18902390383977496], "final_y": [2.742208293727381, 0.49384203975888397, 0.5217353335545365]}, "mutation_prompt": null}
{"id": "b10d0348-e37b-40fb-ba6a-f6ee2c083a1b", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Differential Evolution (DE), incorporating adaptive parameters and elitism to balance exploration and exploitation more effectively.", "configspace": "", "generation": 2, "fitness": 0.18109802460692812, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.181 with standard deviation 0.049. And the mean value of best solutions found was 0.558 (0. is the best) with standard deviation 0.395.", "error": "", "parent_id": "c5fb54e6-9b1a-490b-8da8-10e9938fa989", "metadata": {"aucs": [0.17789606553319792, 0.1224430373604497, 0.2429549709271367], "final_y": [0.48890080628778876, 1.073528374148505, 0.11292780849449584]}, "mutation_prompt": null}
{"id": "4503f887-1f79-485e-b457-930cf888dd20", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Incorporate a dynamic adjustment to the cognitive constant to enhance personal best influence over time.", "configspace": "", "generation": 3, "fitness": 0.20403515205495668, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.022. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.053.", "error": "", "parent_id": "b10d0348-e37b-40fb-ba6a-f6ee2c083a1b", "metadata": {"aucs": [0.20132559309367748, 0.23271077874203194, 0.17806908432916058], "final_y": [0.29517005858061934, 0.20476283192962155, 0.33112374506296843]}, "mutation_prompt": null}
{"id": "c481cd72-7ea7-4ded-9f82-5be0fb633eba", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + (self.mutation_factor * (1 - evaluations / self.budget)) * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Integrate a decay factor into the mutation factor to dynamically adjust exploration-exploitation balance over time.", "configspace": "", "generation": 4, "fitness": 0.1698544153198139, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.170 with standard deviation 0.011. And the mean value of best solutions found was 0.655 (0. is the best) with standard deviation 0.136.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.1545346539060568, 0.17729457711107388, 0.177734014942311], "final_y": [0.7630613689410041, 0.4634083624622624, 0.7394630616906088]}, "mutation_prompt": null}
{"id": "9fde80b7-b5c7-4e9b-af7a-d24e04cba9bf", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n        self.learning_rate = 0.01  # New parameter for adaptive learning\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + self.learning_rate * velocities[i]  # Adaptive step size\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    adaptive_mutation = self.mutation_factor * (1 - evaluations / self.budget)  # Adaptive mutation\n                    mutant = np.clip(a + adaptive_mutation * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce adaptive mutation and learning rates to balance exploration and exploitation dynamically.", "configspace": "", "generation": 5, "fitness": 0.14098641417181687, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.141 with standard deviation 0.012. And the mean value of best solutions found was 1.123 (0. is the best) with standard deviation 0.327.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.13423741690939606, 0.15767894358601586, 0.13104288202003866], "final_y": [1.583228681793028, 0.857923395569813, 0.9284170637681499]}, "mutation_prompt": null}
{"id": "e65587c3-b6cf-467c-80e5-42a636807f29", "solution": "import numpy as np\n\nclass EnhancedHybridPSODEV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1\n        self.no_improvement_tolerance = 10  # Tolerance before reducing inertia\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        evaluations = self.pop_size\n        no_improvement_counter = 0\n        last_improvement = evaluations\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                        last_improvement = evaluations\n                else:\n                    no_improvement_counter += 1\n\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n                            last_improvement = evaluations\n\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            self.inertia_weight = max(0.4, 0.9 - (evaluations - last_improvement) / (self.budget / 10))\n\n        return global_best", "name": "EnhancedHybridPSODEV2", "description": "Introduce a dynamic inertia weight adaptation based on recent progress to balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.18920173030713916, "feedback": "The algorithm EnhancedHybridPSODEV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.189 with standard deviation 0.011. And the mean value of best solutions found was 0.427 (0. is the best) with standard deviation 0.077.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.17865501533181916, 0.20459866074768596, 0.18435151484191237], "final_y": [0.3438079702341582, 0.4080871391336581, 0.5304443673238036]}, "mutation_prompt": null}
{"id": "06896d6a-0dc0-433f-9d7a-0ba6700fd991", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * ((evaluations / self.budget) ** 3))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Enhance the dynamic adjustment of the cognitive constant with a cubic function for smoother exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.18072789220877258, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.181 with standard deviation 0.019. And the mean value of best solutions found was 0.390 (0. is the best) with standard deviation 0.167.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.1991886450713608, 0.18865517947573218, 0.15433985207922474], "final_y": [0.46769705900113334, 0.5447960892161408, 0.1581930878868416]}, "mutation_prompt": null}
{"id": "51ef0a49-ce95-4c1e-ba31-3f7f0bf79a96", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 - (1.0 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic social constant that decreases to focus on individual exploration over time.", "configspace": "", "generation": 8, "fitness": 0.19421175543908262, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.194 with standard deviation 0.033. And the mean value of best solutions found was 0.312 (0. is the best) with standard deviation 0.179.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.15839542238194781, 0.23850238456955253, 0.18573745936574748], "final_y": [0.5002151323450315, 0.07058010381692846, 0.3653992818294435]}, "mutation_prompt": null}
{"id": "9d42540a-569f-4f78-99ad-b0f2baaaf562", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 - (0.5 * (evaluations / self.budget))  # Adaptive social constant\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce adaptive social constant to balance exploration and exploitation dynamically.", "configspace": "", "generation": 9, "fitness": 0.1800193219588506, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.180 with standard deviation 0.013. And the mean value of best solutions found was 0.387 (0. is the best) with standard deviation 0.148.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.17925788481864446, 0.16440991464741195, 0.19639016641049534], "final_y": [0.448259721148073, 0.5293484072273729, 0.1823285172392046]}, "mutation_prompt": null}
{"id": "bd1a04a2-49a9-4e56-96c1-85dc0dc3cb61", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 + (0.5 * (1 - evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce a time-varying social constant to balance exploration and exploitation more effectively.", "configspace": "", "generation": 10, "fitness": 0.16913685387492328, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.169 with standard deviation 0.007. And the mean value of best solutions found was 0.561 (0. is the best) with standard deviation 0.231.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.1601503475199476, 0.17106468559223742, 0.1761955285125848], "final_y": [0.8803750216347928, 0.34193784534797894, 0.45927719994843386]}, "mutation_prompt": null}
{"id": "3513b24e-3b48-484e-a4b4-294dd7b03ef2", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 + (0.5 * (1 - evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic social constant adjustment to enhance global best influence over time.", "configspace": "", "generation": 11, "fitness": 0.16913685387492328, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.169 with standard deviation 0.007. And the mean value of best solutions found was 0.561 (0. is the best) with standard deviation 0.231.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.1601503475199476, 0.17106468559223742, 0.1761955285125848], "final_y": [0.8803750216347928, 0.34193784534797894, 0.45927719994843386]}, "mutation_prompt": null}
{"id": "4c213a7b-3d67-4cf5-85e5-14418891a13f", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 - (0.5 * (evaluations / self.budget))  # New dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce an adaptive social constant to balance exploration and exploitation dynamically.", "configspace": "", "generation": 12, "fitness": 0.18855619015404068, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.189 with standard deviation 0.012. And the mean value of best solutions found was 0.429 (0. is the best) with standard deviation 0.126.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.18723324004083175, 0.17450417508447513, 0.20393115533681516], "final_y": [0.6074365798250291, 0.34193784534797894, 0.33671161321847415]}, "mutation_prompt": null}
{"id": "5a9cdd3b-9457-4baf-824d-019d32ce43a5", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.social_const = 1.5 - (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            self.inertia_weight = max(0.4, 0.9 - no_improvement_counter * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Adaptive adjustment of the social constant to strengthen global best influence over iterations.", "configspace": "", "generation": 13, "fitness": 0.17040740902454077, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.170 with standard deviation 0.012. And the mean value of best solutions found was 0.642 (0. is the best) with standard deviation 0.268.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.15602447569218614, 0.16928846699313638, 0.1859092843882998], "final_y": [1.0052005718417552, 0.5544363647567605, 0.3653992818294435]}, "mutation_prompt": null}
{"id": "310658e5-2b10-408d-a3ff-f1f8999a0c94", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n        previous_best_score = None  # Added for improvement tracking\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            avg_improvement = (previous_best_score - min(personal_best_scores)) if previous_best_score is not None else 0\n            previous_best_score = min(personal_best_scores)  # Track previous best score\n            self.inertia_weight = max(0.4, 0.9 - avg_improvement * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Enhanced the dynamic adjustment for cognitive constant and adaptive inertia weight based on average improvement.", "configspace": "", "generation": 14, "fitness": 0.20579987606625608, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.206 with standard deviation 0.019. And the mean value of best solutions found was 0.415 (0. is the best) with standard deviation 0.207.", "error": "", "parent_id": "4503f887-1f79-485e-b457-930cf888dd20", "metadata": {"aucs": [0.22543358483652187, 0.21270094303030884, 0.17926510033193754], "final_y": [0.2424742735742269, 0.29686362579836645, 0.7068782219185635]}, "mutation_prompt": null}
{"id": "43a30d0b-4299-4b04-89d9-be7e2c83783b", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n        previous_best_score = None\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))\n            self.mutation_factor = 0.8 + 0.2 * np.random.rand()  # Self-adaptive mutation\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            elite_count = max(1, int(self.elitism_rate * self.pop_size))\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            avg_improvement = (previous_best_score - min(personal_best_scores)) if previous_best_score is not None else 0\n            previous_best_score = min(personal_best_scores)\n            self.inertia_weight = max(0.4, 0.9 - avg_improvement * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Enhanced dynamic PSO-DE with adaptive parameters, self-adaptive mutation rate, and improved elitism.", "configspace": "", "generation": 15, "fitness": 0.16454542970427843, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.165 with standard deviation 0.018. And the mean value of best solutions found was 1.008 (0. is the best) with standard deviation 0.552.", "error": "", "parent_id": "310658e5-2b10-408d-a3ff-f1f8999a0c94", "metadata": {"aucs": [0.18434402319182097, 0.140938913735279, 0.16835335218573533], "final_y": [0.39326761173713887, 1.7319867024266002, 0.8993767210897345]}, "mutation_prompt": null}
{"id": "d2651ddd-a5a9-40dd-aac2-6711f1f7fea7", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n        previous_best_score = None  # Added for improvement tracking\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n\n            # Adapt inertia weight\n            avg_improvement = (previous_best_score - min(personal_best_scores)) if previous_best_score is not None else 0\n            previous_best_score = min(personal_best_scores)  # Track previous best score\n            self.inertia_weight = max(0.4, 0.9 - avg_improvement * 0.01)\n\n            # Adaptive mutation factor\n            self.mutation_factor = 0.8 + (0.2 * no_improvement_counter / self.pop_size)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Introduce adaptive mutation factor based on the no_improvement_counter to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.1281429872402242, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.128 with standard deviation 0.026. And the mean value of best solutions found was 2.514 (0. is the best) with standard deviation 1.442.", "error": "", "parent_id": "310658e5-2b10-408d-a3ff-f1f8999a0c94", "metadata": {"aucs": [0.09181417904824796, 0.14266693032387157, 0.149947852348553], "final_y": [4.5496980312758195, 1.6159400678493352, 1.3774630367925909]}, "mutation_prompt": null}
{"id": "cd6a8f85-66b9-4613-b814-08a41ff3f458", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7  # Reduced initial crossover rate\n        self.elitism_rate = 0.1  # Proportion of elite individuals retained\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        no_improvement_counter = 0\n        previous_best_score = None  # Added for improvement tracking\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.5 + (0.5 * (evaluations / self.budget))  # Dynamic adjustment\n            self.crossover_rate = 0.7 + (0.1 * (evaluations / self.budget))  # Adaptive crossover rate\n            for i in range(self.pop_size):\n                # PSO update with adaptive inertia\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                particle = population[i] + velocities[i]\n                particle = np.clip(particle, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(particle)\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = particle\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = particle\n                        no_improvement_counter = 0\n                else:\n                    no_improvement_counter += 1\n\n                # DE update\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, population[i])\n\n                    # Evaluate trial\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial\n                        personal_best_scores[i] = trial_score\n                        if trial_score < func(global_best):\n                            global_best = trial\n                            no_improvement_counter = 0\n\n            # Update global best with elitism\n            elite_count = int(self.elitism_rate * self.pop_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for idx in elite_indices:\n                if personal_best_scores[idx] < func(global_best):\n                    global_best = personal_best[idx]\n            \n            # Introduce random immigrants for diversity\n            if no_improvement_counter > 10:  # If no improvement, introduce random immigrants\n                for j in range(self.pop_size // 5):\n                    new_individual = np.random.uniform(bounds[:, 0], bounds[:, 1], self.dim)\n                    population[np.random.randint(0, self.pop_size)] = new_individual\n\n            # Adapt inertia weight\n            avg_improvement = (previous_best_score - min(personal_best_scores)) if previous_best_score is not None else 0\n            previous_best_score = min(personal_best_scores)  # Track previous best score\n            self.inertia_weight = max(0.4, 0.9 - avg_improvement * 0.01)\n\n        return global_best", "name": "EnhancedHybridPSODE", "description": "Improved exploration via adaptive crossover rate and inclusion of random immigrant strategy for diversity enhancement.", "configspace": "", "generation": 17, "fitness": 0.1705692103091148, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.171 with standard deviation 0.046. And the mean value of best solutions found was 0.955 (0. is the best) with standard deviation 0.611.", "error": "", "parent_id": "310658e5-2b10-408d-a3ff-f1f8999a0c94", "metadata": {"aucs": [0.14678320220004337, 0.13008294043898805, 0.23484148828831297], "final_y": [0.9297042768058182, 1.7150317879067936, 0.21907291479000324]}, "mutation_prompt": null}
{"id": "cfc25752-be0d-4bb6-9b0f-f7fa5300641c", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            # Adaptive parameters adjustment\n            self.f = np.random.uniform(0.4, 0.9)\n            self.cr = np.random.uniform(0.6, 1.0)\n            self.inertia_weight = max(0.4, self.inertia_weight - 0.01 * (func(global_best) / (evaluations + 1)))\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "A Swarm-based Adaptive Differential Evolution (SADE) integrates swarm intelligence principles with adaptive differential mutation and crossover strategies to enhance exploration and exploitation balance in black-box optimization problems.", "configspace": "", "generation": 18, "fitness": 0.2191738490004753, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.012. And the mean value of best solutions found was 0.072 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "310658e5-2b10-408d-a3ff-f1f8999a0c94", "metadata": {"aucs": [0.22868723775756317, 0.20284398187489694, 0.22599032736896574], "final_y": [0.05068061644467327, 0.03445379283619416, 0.12984555068746584]}, "mutation_prompt": null}
{"id": "dfc6c1ef-8241-48bb-b634-de1f563b9fca", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = np.random.uniform(0.6, 1.0)\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhancing SwarmAdaptiveDifferentialEvolution with a dynamic inertia weight strategy and mutation factor for improved convergence.", "configspace": "", "generation": 19, "fitness": 0.23298968078521223, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.032. And the mean value of best solutions found was 0.046 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "cfc25752-be0d-4bb6-9b0f-f7fa5300641c", "metadata": {"aucs": [0.2426849878496088, 0.1902755793848535, 0.2660084751211744], "final_y": [0.016829396392646728, 0.1114172009383669, 0.008708811690335848]}, "mutation_prompt": null}
{"id": "3c0bfb34-554d-4d2c-9b20-132dedc509d3", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0] - np.abs(population[i] * 0.01), bounds[:, 1] + np.abs(population[i] * 0.01))  # Adaptive boundary scaling\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = np.random.uniform(0.6, 1.0)\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Adding adaptive boundary scaling to enhance exploration in the population update phase.", "configspace": "", "generation": 20, "fitness": 0.18917402144189222, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.189 with standard deviation 0.006. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "dfc6c1ef-8241-48bb-b634-de1f563b9fca", "metadata": {"aucs": [0.18330558842929, 0.19668668394017874, 0.1875297919562079], "final_y": [0.21535717800079351, 0.17401884413965074, 0.1358144076257089]}, "mutation_prompt": null}
{"id": "8569754e-34ba-4613-ac8b-cc9930469177", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = np.random.uniform(0.6, 1.0)\n            self.pop_size = max(10, int(20 * (1 - evaluations / self.budget)))  # Adaptive population size\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Integrating an adaptive population size strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.2005482647895911, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.201 with standard deviation 0.004. And the mean value of best solutions found was 0.063 (0. is the best) with standard deviation 0.058.", "error": "", "parent_id": "dfc6c1ef-8241-48bb-b634-de1f563b9fca", "metadata": {"aucs": [0.20558885413283856, 0.2010811266483561, 0.19497481358757862], "final_y": [0.026145022570999543, 0.14412882151384415, 0.017781283112136104]}, "mutation_prompt": null}
{"id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing a dynamic crossover rate strategy and a perturbation factor for improved exploration and exploitation balance.", "configspace": "", "generation": 22, "fitness": 0.23910224327551863, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.007. And the mean value of best solutions found was 0.058 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "dfc6c1ef-8241-48bb-b634-de1f563b9fca", "metadata": {"aucs": [0.2428640375075486, 0.22874099771172574, 0.24570169460728153], "final_y": [0.047857662324750104, 0.10045597444727217, 0.0261105062765772]}, "mutation_prompt": null}
{"id": "7bdc353f-8c79-4176-9aca-54e356649964", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5 + 0.1 * np.random.rand()\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing stochastic element in inertia weight for better exploration and exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.20288225108938784, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.203 with standard deviation 0.012. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.1879760797344716, 0.2044375794071801, 0.21623309412651182], "final_y": [0.16077267725390645, 0.15118808146813553, 0.16916644305657266]}, "mutation_prompt": null}
{"id": "0581b522-80a5-471a-8a16-982842f61987", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n            self.pop_size = max(10, int(20 - 10 * (evaluations / self.budget)))  # Dynamic population size\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing a dynamic population size adjustment and adaptive inertia weight for enhancing exploration and exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.2046903539169116, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.017. And the mean value of best solutions found was 0.035 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.21273616835423237, 0.21985749263205956, 0.18147740076444285], "final_y": [0.017150869684189846, 0.02069422369063279, 0.06584422529476552]}, "mutation_prompt": null}
{"id": "cb9b711d-d042-4d9f-9a58-6618287f05af", "solution": "# Description: Introducing a dynamic scaling of the inertia weight to enhance exploration in early iterations.\n# Code:\nimport numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.4\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing a dynamic scaling of the inertia weight to enhance exploration in early iterations.", "configspace": "", "generation": 25, "fitness": 0.18486706098414993, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.185 with standard deviation 0.009. And the mean value of best solutions found was 0.279 (0. is the best) with standard deviation 0.237.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.1788173567207686, 0.17794805792480473, 0.19783576830687644], "final_y": [0.100715848629249, 0.6145935281859253, 0.12261270382700634]}, "mutation_prompt": null}
{"id": "c3a731b2-e2f8-41b3-ac02-aaed7351e053", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            diversity = np.mean(np.std(population, axis=0))\n            self.f = 0.3 + 0.7 * (diversity / (bounds[:, 1] - bounds[:, 0]).mean())  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Refine the mutation strategy by dynamically adjusting the differential weight based on the diversity of the population.", "configspace": "", "generation": 26, "fitness": 0.2133825210975759, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.011. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.092.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.21575830489315495, 0.22591440354101366, 0.1984748548585591], "final_y": [0.05695818195735671, 0.12641923440612574, 0.2784210641188024]}, "mutation_prompt": null}
{"id": "81f929c6-5882-47f3-9740-549038a351f8", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    # Selectively update global best based on improvement rate\n                    if particle_score < func(global_best) and np.random.rand() < 0.5:\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced local search by dynamically adjusting personal best update strategy for better exploration.", "configspace": "", "generation": 27, "fitness": 0.19087180892779673, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.191 with standard deviation 0.028. And the mean value of best solutions found was 0.501 (0. is the best) with standard deviation 0.335.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.2297513556543217, 0.17001578287380825, 0.17284828825526022], "final_y": [0.02732975049626209, 0.7382555010273438, 0.7382142170542954]}, "mutation_prompt": null}
{"id": "3b0897e1-0445-4044-a00d-7335aac0d0ae", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            if iteration % 10 == 0:  # Reduce population size iteratively\n                self.pop_size = max(5, self.pop_size - 1)\n                population = population[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best = personal_best[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n                \n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                velocities[i] *= 0.9  # Damping factor for velocity\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)\n            self.cr = 0.6 + 0.4 * np.random.rand()\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduce adaptive population size strategy and enhanced velocity update for improved convergence.", "configspace": "", "generation": 28, "fitness": 0.2247490413708172, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.006. And the mean value of best solutions found was 0.048 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.22951206878745756, 0.2285572114354687, 0.21617784388952532], "final_y": [0.04641339032109084, 0.04290580231312926, 0.054002028338448575]}, "mutation_prompt": null}
{"id": "ee80e87d-a537-4825-842d-c3c15321f86d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n        self.quantum_gate = 0.5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n\n        while evaluations < self.budget:\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                \n                # Quantum-inspired update\n                theta = np.arctan2(velocities[i], population[i])\n                quantum_velocity = self.quantum_gate * np.tan(theta)\n                population[i] += quantum_velocity\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n            self.quantum_gate = 0.5 * np.cos(iteration * np.pi / max_iterations)\n\n        return global_best", "name": "QuantumInspiredPSO", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Adaptive Quantum Gate for enhanced convergence and exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.11992091043240376, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.120 with standard deviation 0.028. And the mean value of best solutions found was 2.767 (0. is the best) with standard deviation 1.857.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.08166611378337063, 0.13296984129347356, 0.14512677622036707], "final_y": [5.363108474949663, 1.8089900169682833, 1.1288772116952464]}, "mutation_prompt": null}
{"id": "9ac45828-8592-4015-a12d-bbb3c9eefa10", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.min_pop_size = 10\n        self.pop_size = self.initial_pop_size\n        self.f = 0.5  # Differential weight\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < 0.6 + 0.4 * np.random.rand(), mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.7 + 0.3 * (1 - (iteration / max_iterations))\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic mutation factor\n            # Dynamic population size adjustment for diversity\n            if iteration % 10 == 0 and self.pop_size > self.min_pop_size:\n                self.pop_size -= 1\n                population = population[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best = personal_best[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing a synergy of adaptive inertia weights and a dynamic swarm size for enhanced convergence and diversity.", "configspace": "", "generation": 30, "fitness": 0.21036464537614027, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.210 with standard deviation 0.035. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.22079991619794737, 0.1635941748164258, 0.24669984511404763], "final_y": [0.18656523056329655, 0.20092713400537346, 0.13935858792723438]}, "mutation_prompt": null}
{"id": "68f145db-78d4-4165-a281-23144cf07cca", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = self.inertia_weight - (iteration / max_iterations) * 0.3  # Adjusted line\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing a dynamic inertia weight strategy and elitism preservation for enhanced convergence and diversity maintenance.", "configspace": "", "generation": 31, "fitness": 0.22406038615409998, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.024. And the mean value of best solutions found was 0.021 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.22080900507907075, 0.19614199278323163, 0.2552301605999976], "final_y": [0.030712540551091013, 0.0251555154447689, 0.0074976200052129256]}, "mutation_prompt": null}
{"id": "0b2be1d1-f263-4ba9-abff-1662291475eb", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                # New exploration factor\n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Adaptive parameters adjustment\n            self.f = 0.5 + 0.4 * (evaluations / self.budget)  # Dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhancing exploration-exploitation balance using a dynamically weighted blend of differential evolution and particle swarm optimization strategies.", "configspace": "", "generation": 32, "fitness": 0.31506349032691616, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.315 with standard deviation 0.014. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b6621290-9b89-423d-9c8b-a8f450ad1c92", "metadata": {"aucs": [0.30674783061420274, 0.33540488577254135, 0.3030377545940044], "final_y": [0.0003146111675374464, 0.00020670322056021089, 0.0018350329084968248]}, "mutation_prompt": null}
{"id": "6c3068f8-9fb6-499a-99c8-91bf1f100aca", "solution": "import numpy as np\n\nclass EnhancedChaoticSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n        self.chaos_sequence = self.generate_chaos_sequence(self.budget)\n\n    def generate_chaos_sequence(self, length):\n        x = 0.7\n        sequence = []\n        for _ in range(length):\n            x = 4 * x * (1 - x)  # Logistic map\n            sequence.append(x)\n        return sequence\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                # New exploration factor\n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Chaotic parameter adaptation\n            self.f = 0.5 + 0.4 * self.chaos_sequence[evaluations]  # Chaotic mutation factor\n            self.cr = 0.6 + 0.4 * self.chaos_sequence[evaluations]  # Chaotic crossover rate\n\n        return global_best", "name": "EnhancedChaoticSwarmDifferentialEvolution", "description": "Improved exploration-exploitation balance by integrating chaotic maps for parameter adaptation in differential evolution and particle swarm optimization hybrid.", "configspace": "", "generation": 33, "fitness": 0.29267283899651464, "feedback": "The algorithm EnhancedChaoticSwarmDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.027. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0b2be1d1-f263-4ba9-abff-1662291475eb", "metadata": {"aucs": [0.2976709218481831, 0.2575848800677487, 0.3227627150736121], "final_y": [0.0015014626941975326, 0.005881981307283946, 0.0010209940458761422]}, "mutation_prompt": null}
{"id": "66c83735-0ed7-4d84-82df-63f3463d6435", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptive differential mutation with elite recombination\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Elite recombination\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Evaluate trial\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            # PSO-like velocity update and position update\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                # New exploration factor\n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                # Evaluate\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            iteration += 1\n\n            # Stochastic adaptive parameters adjustment\n            self.f = 0.5 + 0.3 * np.random.rand()  # Stochastic dynamic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhancing adaptive exploration-exploitation balance using a dynamically weighted blend of differential evolution and particle swarm optimization with elite recombination and stochastic adaptive parameters.", "configspace": "", "generation": 34, "fitness": 0.3170501637124271, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.317 with standard deviation 0.025. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0b2be1d1-f263-4ba9-abff-1662291475eb", "metadata": {"aucs": [0.29468792332366556, 0.3052361279100807, 0.3512264399035351], "final_y": [0.0009773677033493094, 0.0012796067603332694, 7.842567084005329e-05]}, "mutation_prompt": null}
{"id": "41b641c5-5acc-4df8-94f7-f4df9bea4648", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Integration of self-adaptive parameters with Lvy flight-based exploration for enhanced convergence in hybrid differential evolution and particle swarm optimization.", "configspace": "", "generation": 35, "fitness": 0.3426698659892138, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.343 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66c83735-0ed7-4d84-82df-63f3463d6435", "metadata": {"aucs": [0.3444884057154973, 0.33219727969818236, 0.35132391255396167], "final_y": [0.00021006761843875638, 0.0005013576954438524, 0.0002728235624233053]}, "mutation_prompt": null}
{"id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress.", "configspace": "", "generation": 36, "fitness": 0.3610151474925202, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.361 with standard deviation 0.018. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "41b641c5-5acc-4df8-94f7-f4df9bea4648", "metadata": {"aucs": [0.3407921095544152, 0.35852094367955656, 0.38373238924358877], "final_y": [0.003929477408308279, 0.002875561877542051, 9.441787185082393e-05]}, "mutation_prompt": null}
{"id": "8d08a243-371b-42eb-aa3e-c8e8535dc61e", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * np.var(personal_best_scores)\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.mean(np.abs(velocities))  # Dynamic crossover rate based on velocity diversity\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced exploration through stochastic inertia weight and adaptive crossover rate based on diversity in the population.", "configspace": "", "generation": 37, "fitness": 0.26709063822743495, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.004. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.26289415356364865, 0.2729693794318885, 0.2654083816867677], "final_y": [0.014231193612720919, 0.0038459142405990305, 0.025837311137602823]}, "mutation_prompt": null}
{"id": "17dbfa79-4db4-41a5-b2b4-cdaf3be3ded8", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        historical_best_scores = []\n\n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_factor = np.random.rand() * (personal_best_scores[i] / (np.min(historical_best_scores + [np.inf]) + 1e-8))\n                mutant = np.clip(a + mutant_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n            \n            if iteration % (max_iterations // 3) == 0:\n                regroup_index = np.random.choice(self.pop_size, 1)\n                population[regroup_index] = np.random.uniform(bounds[:, 0], bounds[:, 1], self.dim)\n\n            historical_best_scores.append(np.min(personal_best_scores))\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incorporate adaptive mutation strategies using historical performance and a dynamic swarm regrouping to enhance global exploration.", "configspace": "", "generation": 38, "fitness": 0.2944704021837435, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.019. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.26778814192545786, 0.3119116060238356, 0.30371145860193693], "final_y": [0.001608176957601013, 0.0007108125777087181, 0.0006986352957834005]}, "mutation_prompt": null}
{"id": "977c42c7-0ce4-43b9-83d0-ba335b7286b2", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Modified Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim) * 0.1\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhance exploration by modifying the Lvy flight mechanism for better escape from local optima.", "configspace": "", "generation": 39, "fitness": 0.29798886529437274, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.012. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3149927545646305, 0.28561457330918893, 0.2933592680092988], "final_y": [0.006450647456031448, 0.021680482563203665, 0.0005659859077858441]}, "mutation_prompt": null}
{"id": "2d9e759e-6644-4200-8126-a37a621e7217", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        success_history = []\n\n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n                    success_history.append(1)\n                else:\n                    success_history.append(0)\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            dynamic_factor = np.mean(success_history[-self.pop_size:])  # Dynamic adjustment based on recent success\n            self.f = (0.4 + dynamic_factor * 0.3) * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration by integrating a dynamic adjustment of mutation strategy based on the success history of trial vector generation.", "configspace": "", "generation": 40, "fitness": 0.26004129481091226, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.017. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.23681702848762065, 0.2653739266189825, 0.27793292932613367], "final_y": [0.016345875839059415, 0.004901639078015781, 0.002793511455143041]}, "mutation_prompt": null}
{"id": "79eaaa88-9db2-49e7-a6e5-2c392ce8b625", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.1:\n                    local_search = personal_best[i] + np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(local_search, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  \n            self.cr = 0.5 + 0.5 * np.random.rand()  \n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved convergence and diversity by incorporating a dynamic inertia weight schedule and adaptive local search strategy.", "configspace": "", "generation": 41, "fitness": 0.24974998356397027, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.250 with standard deviation 0.050. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.18109756172705682, 0.29961565671171797, 0.268536732253136], "final_y": [0.019773959482444523, 0.0008463575870322911, 0.0030508592646708212]}, "mutation_prompt": null}
{"id": "00859599-31fd-4935-9bb7-25ef500be60a", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim) * 0.01\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through improved dynamic adjustment of cognitive and social constants with adaptive mutation strategy based on Lvy flights.", "configspace": "", "generation": 42, "fitness": 0.2704722936554355, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.270 with standard deviation 0.037. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.28450998487308665, 0.21923454047950097, 0.307672355613719], "final_y": [0.0027821314719419323, 0.015323173750751665, 0.0011345100928002961]}, "mutation_prompt": null}
{"id": "2b34df83-3b29-494a-9526-c0102e6c6374", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.1:  # Changed from 0.05 to 0.1\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration by altering the Lvy flight probability, balancing exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.24351740642031294, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.041. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2525556479220782, 0.2889027888045186, 0.18909378253434206], "final_y": [0.003700370027867663, 0.013370703136296505, 0.0409986812763555]}, "mutation_prompt": null}
{"id": "6206c685-a9cf-4c87-b7d1-34a07e540e22", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduce an adaptive personal best inertia strategy for enhanced convergence and exploration balance.", "configspace": "", "generation": 44, "fitness": 0.2281571756594719, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.012. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.21753434047617137, 0.24566557552756974, 0.22127161097467463], "final_y": [0.0296148565158222, 0.01010714875808166, 0.006611151737058727]}, "mutation_prompt": null}
{"id": "db9b9738-fc86-472e-ac95-bc0a82f1dbee", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c) + 0.1 * np.random.standard_normal(self.dim), bounds[:, 0], bounds[:, 1])  # Added noise for enhanced exploration\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration and exploitation balance with dynamic mutation strategy.", "configspace": "", "generation": 45, "fitness": 0.24746931998260527, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.039. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.21479783053854717, 0.22501640396815148, 0.3025937254411172], "final_y": [0.011728681786952768, 0.011276018774254657, 0.002484552288392095]}, "mutation_prompt": null}
{"id": "3f9ec8ce-785c-4f38-bfd0-4b59643f6471", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.45 + 0.25 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through a slight adjustment to the dynamic mutation factor range.", "configspace": "", "generation": 46, "fitness": 0.3135968971758945, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.314 with standard deviation 0.065. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.22217566016081058, 0.3514577491742866, 0.36715728219258625], "final_y": [0.0061297188047777585, 0.001002088192112825, 0.00013565883216967722]}, "mutation_prompt": null}
{"id": "14d56be2-b838-4b85-be2c-7a19002ac002", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Chaos-based exploration enhancement\n                if np.random.rand() < 0.05:\n                    chaos = np.random.uniform(-1, 1, self.dim)\n                    trial = np.clip(trial + chaos, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.sin(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.sin(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.cos(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.3 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Integration of elite guidance and chaos theory for enhanced exploration and convergence.", "configspace": "", "generation": 47, "fitness": 0.23814487992079902, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.238 with standard deviation 0.011. And the mean value of best solutions found was 0.046 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.25385413191620376, 0.23063784312954005, 0.22994266471665326], "final_y": [0.017988484503769518, 0.05033774984916624, 0.06939924803331253]}, "mutation_prompt": null}
{"id": "5caeedf8-eb98-45e3-a6a4-d0a5b778998f", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            diversity = np.mean(np.std(population, axis=0))  # Added line: Calculate diversity\n            self.f = 0.4 + 0.2 * diversity  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduces adaptive mutation factor and crossover rate based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.27759876544207357, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.278 with standard deviation 0.017. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2763538957377101, 0.2577158111937856, 0.2987265893947251], "final_y": [0.0036560147971521047, 0.0051421388550924796, 0.0007928500229516315]}, "mutation_prompt": null}
{"id": "f505d153-4d17-42cb-9e62-a7a94c19d168", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Increased frequency of Lvy flight-based exploration\n                if np.random.rand() < 0.1:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced exploration by increasing the frequency of Lvy flight-based exploration.", "configspace": "", "generation": 49, "fitness": 0.29552887040580206, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.296 with standard deviation 0.008. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.29051972102589696, 0.30629534288303284, 0.28977154730847643], "final_y": [0.004770250837924854, 0.002664113064816469, 0.000959261654410237]}, "mutation_prompt": null}
{"id": "161d3821-5457-4f1a-8ede-e4123bde8e64", "solution": "import numpy as np\n\nclass QuantumAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Quantum-inspired stochastic tunneling\n                if np.random.rand() < 0.2:\n                    q_tunnel = np.random.standard_normal(size=self.dim)\n                    trial = np.clip(trial + q_tunnel * (bounds[:, 1] - bounds[:, 0]) / 10, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best[i] - population[i]) +\n                                 self.social_const * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "QuantumAdaptiveSwarmOptimization", "description": "Quantum-inspired adaptive swarm optimization leveraging stochastic tunneling to escape local optima while dynamically adjusting exploration and exploitation.", "configspace": "", "generation": 50, "fitness": 0.22183621075104232, "feedback": "The algorithm QuantumAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2324742551063409, 0.2166269775558627, 0.21640739959092337], "final_y": [0.19007185390863307, 0.11041968537419836, 0.19416301120295004]}, "mutation_prompt": null}
{"id": "ae6b685a-0267-4068-a585-763e4dde8394", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            diversity = np.var(population, axis=0).mean()  # Added diversity measure\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c) * (1 + diversity), bounds[:, 0], bounds[:, 1])  # Adjusted mutation\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Increased probability of elite influence\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.07:  # Increased probability for Levy flight\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.3 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incorporates multi-strategy mutation with adaptive population diversity control for enhanced exploration and exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.3389566602266398, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.339 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.36081314158218236, 0.3466068492553299, 0.309449989842407], "final_y": [0.000184863881229872, 0.00039390756409983117, 0.0004266415937328459]}, "mutation_prompt": null}
{"id": "51602dc8-c132-4928-9c62-c301b4410833", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.4 + 0.6 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced adaptability with stochastic adjustments to mutation and crossover rates for improved exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.2557027323017783, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.021. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2857035592899043, 0.24301745586993717, 0.23838718174549345], "final_y": [0.007645164252553778, 0.012279498020139348, 0.0035009679769133256]}, "mutation_prompt": null}
{"id": "21f8113b-f57f-43b0-8d4c-854774aad242", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.85 - (iteration / max_iterations) * 0.4  # Change 1\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor, Change 2\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced adaptive differential evolution leveraging dynamic inertia and stochastic crossover.", "configspace": "", "generation": 53, "fitness": 0.34660153530040666, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.347 with standard deviation 0.006. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.35128670461507894, 0.3509033002808162, 0.33761460100532503], "final_y": [9.913230613138802e-05, 0.0002697638527850513, 0.0006427801119917832]}, "mutation_prompt": null}
{"id": "8b8b3115-697c-4750-a9f0-d780c6412532", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * (iteration / max_iterations) * np.pi) ** 2  # Modified exploration factor\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduced dynamic adjustment in exploration factor to enhance diversification over iterations.", "configspace": "", "generation": 54, "fitness": 0.31862651121843505, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.319 with standard deviation 0.035. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.36778691004531305, 0.29929209010943847, 0.28880053350055357], "final_y": [0.0006563550924117216, 0.0027254357351450243, 0.0009551917471092913]}, "mutation_prompt": null}
{"id": "ebc94f09-882e-4abd-88fb-2852cb55a2fc", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutation_factor = self.f * (1.1 - (iteration / max_iterations) * 0.6)\n                mutant = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Additive Gaussian noise for exploration\n                if np.random.rand() < 0.05:\n                    noise = np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(trial + noise, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration-exploitation balance using adaptive mutation strategies and noise addition.", "configspace": "", "generation": 55, "fitness": 0.32134220463737634, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.027. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.34326685814984614, 0.28314289616755284, 0.3376168595947301], "final_y": [0.0004840204134973885, 0.0025479732488780877, 0.0015159042421679701]}, "mutation_prompt": null}
{"id": "4aabf21b-82a8-4e0f-a5d3-11ade0039dee", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            self.inertia_weight = inertia_weight_dynamic  # Updated adaptive inertia weight\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi) + 0.1  # Slightly increased exploration factor\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through adaptive inertia and stochastic exploration refinement.", "configspace": "", "generation": 56, "fitness": 0.30018531723414127, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.022. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2896207523450336, 0.28055918394157175, 0.3303760154158185], "final_y": [0.0010098651171266025, 0.001740071111562758, 0.0007333977142956349]}, "mutation_prompt": null}
{"id": "f5b37ca7-eccf-44ed-954c-f2b276e55c9b", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.5 + 0.4 * np.sin(np.pi * iteration / max_iterations)  # Sinusoidal varying factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduced a time-varying sinusoidal adjustment to the differential weight for improved exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.27557727384975383, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.033. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3160085839346817, 0.27522970766344734, 0.23549352995113249], "final_y": [0.0009047255754768338, 0.0028309994777898535, 0.02042288640033701]}, "mutation_prompt": null}
{"id": "856883a8-8a64-4c6f-a4dc-72a9e7809f09", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            # Adaptive mutation based on population diversity\n            diversity = np.std(population, axis=0).mean()  \n            self.f = 0.4 + 0.2 * np.random.rand() * (1.0 - diversity)  # Updated line\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence by introducing adaptive mutation based on population diversity.", "configspace": "", "generation": 58, "fitness": 0.28808138491457996, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.288 with standard deviation 0.034. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2679577150583802, 0.26084303256127483, 0.33544340712408494], "final_y": [0.001801622730823415, 0.013492971623796675, 0.002722337519034306]}, "mutation_prompt": null}
{"id": "0d37e601-d004-4e3d-bb55-8c9b672916cc", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.4 + (iteration / max_iterations) * 0.5  # Modified dynamic range\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.3 + 0.3 * np.random.rand()  # Modified stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved dynamic adjustment of inertia and mutation for enhanced global exploration and convergence precision.", "configspace": "", "generation": 59, "fitness": 0.3199530421817314, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.320 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3196359808100301, 0.3301744257029835, 0.31004872003218054], "final_y": [0.00022462840255343437, 0.00029098957871391204, 0.000697895481642518]}, "mutation_prompt": null}
{"id": "18ca2492-ca10-4411-a6a3-d39c11b81ddc", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration**2 / max_iterations**2 * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration**2 / max_iterations**2 * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced search by incorporating non-linear decay for cognitive and social constants.", "configspace": "", "generation": 60, "fitness": 0.3245417684733722, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.325 with standard deviation 0.045. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3680049602476192, 0.2628809329884717, 0.3427394121840256], "final_y": [0.0001583429846843975, 0.000745336592257009, 0.0006424656411835691]}, "mutation_prompt": null}
{"id": "ecab0ddf-432e-4864-97a6-b9aece05ce6d", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy * 0.1, bounds[:, 0], bounds[:, 1])  # Slightly adjusted for stability\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.25 * np.random.rand()  # Slightly increased stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress with improved stochastic components.", "configspace": "", "generation": 61, "fitness": 0.28165633814008534, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.282 with standard deviation 0.031. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2650085717144437, 0.3251271061435693, 0.25483333656224294], "final_y": [0.009094151118954402, 0.001535828705537236, 0.022029733906421257]}, "mutation_prompt": null}
{"id": "2decb940-98cc-4229-abe4-f0b0b25f29bf", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through adaptive elite learning and dynamic parameter tuning.", "configspace": "", "generation": 62, "fitness": 0.26002217410172196, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.020. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.28740310312809925, 0.2432379568974954, 0.2494254622795713], "final_y": [0.0014049542788877683, 0.01289675779269274, 0.0038057356388576367]}, "mutation_prompt": null}
{"id": "3a0e7b81-734f-420e-88d5-9ad5dcd8d08c", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.03:  # Reduced probability\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.7 + (iteration / max_iterations) * 0.2  # Adjusted dynamic range\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved balance between exploration and exploitation by adaptive inertia weight tuning and selective use of Lvy flight.", "configspace": "", "generation": 63, "fitness": 0.30080472471308395, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.024. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.27364569527478944, 0.2970513249410618, 0.3317171539234006], "final_y": [0.013116515559574724, 0.003783781878899301, 0.0013968143349763077]}, "mutation_prompt": null}
{"id": "f4b1cdd6-bc14-4482-8d2d-cb1adf6c7857", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population_size = self.initial_pop_size\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = population_size\n        iteration = 0\n        max_iterations = self.budget // self.initial_pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(population_size):\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            # Dynamic population size scaling\n            population_size = self.initial_pop_size + int((0.1 + 0.1 * np.sin(iteration / max_iterations * np.pi)) * self.initial_pop_size)\n            population_size = min(population_size, 50)  # Ensure population size remains manageable\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing dynamic population size scaling for better adaptability and convergence efficiency.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 21 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 21 is out of bounds for axis 0 with size 20')", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {}, "mutation_prompt": null}
{"id": "7281a53d-39f9-425b-bf03-06e9837accdb", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n            \n            if iteration % 10 == 0:  # Hybridization step every 10 iterations\n                self.f = 0.5 + 0.1 * np.sin(iteration / max_iterations * np.pi)\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved convergence by introducing a periodic hybridization of differential evolution and particle swarm components.", "configspace": "", "generation": 65, "fitness": 0.25169968507103807, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.019. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.23062404873085485, 0.2770500061940713, 0.24742500028818804], "final_y": [0.028606833751933597, 0.0043874844985355085, 0.004637338332800122]}, "mutation_prompt": null}
{"id": "1ab76c4c-c26a-4f5a-9fd5-a43b3a204b02", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand() * (1 - evaluations / self.budget)  # Adaptive mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through adaptive mutation factor based on individual performance.", "configspace": "", "generation": 66, "fitness": 0.22531448124816691, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.031. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.207.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2636725182695112, 0.2240837154081572, 0.18818721006683237], "final_y": [0.0029031632964887353, 0.005388384509704022, 0.4424268245260316]}, "mutation_prompt": null}
{"id": "7daab3c4-a332-4527-aa79-69d191aac33a", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n            # New stochastic factor added to exploration\n            if np.random.rand() < 0.1:\n                population += np.random.normal(loc=0, scale=0.1, size=population.shape)\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress, with improved exploration using an added stochastic factor.", "configspace": "", "generation": 67, "fitness": 0.30286570571713745, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.010. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.29276398326629405, 0.2997165643605877, 0.3161165695245306], "final_y": [0.0013720455230421705, 0.00288462615699014, 0.0049850986048558255]}, "mutation_prompt": null}
{"id": "471af663-b769-402a-9fac-378f0bcaa302", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Dynamic Lvy flight-based exploration\n                if np.random.rand() < 0.05 + 0.05 * (1 - iteration / max_iterations):\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced diversity through dynamic levy flight integration for improved exploration.", "configspace": "", "generation": 68, "fitness": 0.31018269192945686, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.012. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.29306853419989787, 0.3225419807210175, 0.31493756086745517], "final_y": [0.000518306577998395, 0.0008527559864872939, 0.0024833024561530448]}, "mutation_prompt": null}
{"id": "6920e6c8-9576-47e2-a009-39366c5cc548", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            # Self-adaptive strategy for mutation factor and crossover rate\n            self.f = 0.4 + 0.5 * (1 - iteration / max_iterations)\n            self.cr = 0.5 + 0.5 * (iteration / max_iterations)\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved global search by introducing a self-adaptive strategy for dynamic adjustment of differential weight and crossover rate.", "configspace": "", "generation": 69, "fitness": 0.2720992478819165, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.026. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.24513409031441913, 0.2634567884601273, 0.3077068648712029], "final_y": [0.015563670112257358, 0.0019461790100883238, 0.0025293801571744322]}, "mutation_prompt": null}
{"id": "59028019-e741-45b4-8746-10cb4b7b89b5", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Increased chance for diversity\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.1:  # Increased probability for Lvy flight\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.4  # Modified inertia scaling\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration through adaptive scaling of inertia weight and enhanced diversity mechanisms.", "configspace": "", "generation": 70, "fitness": 0.251835587153702, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.017. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.23105006731688604, 0.25145425484355644, 0.2730024393006636], "final_y": [0.017985453417320527, 0.008157680062717509, 0.0024688168115527464]}, "mutation_prompt": null}
{"id": "8f876206-fd6d-477d-9c50-a0bcf3c1d6fd", "solution": "import numpy as np\n\nclass ChaoticSwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        chaotic_factor = 0.7\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            chaotic_factor = self.logistic_map(chaotic_factor)\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5 * chaotic_factor\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * chaotic_factor  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * chaotic_factor  # Dynamic crossover rate\n\n        return global_best", "name": "ChaoticSwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of parameters with chaotic maps for better exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.2588852481132971, "feedback": "The algorithm ChaoticSwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.259 with standard deviation 0.009. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2647559554031921, 0.2658444877391306, 0.2460553011975687], "final_y": [0.011098642023302562, 0.008705526880313915, 0.0027024128198737036]}, "mutation_prompt": null}
{"id": "9cdeb0e2-ae4c-4bb1-9fad-256abb8f04f9", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.sin(iteration / max_iterations * np.pi)  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incremental improvement of exploration capability via adaptive mutation factor adjustments.", "configspace": "", "generation": 72, "fitness": 0.3262765403801605, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.326 with standard deviation 0.037. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3562319480069782, 0.27377370563075676, 0.3488239675027466], "final_y": [0.0006320612707891384, 0.00480976454298818, 0.0006746862502853354]}, "mutation_prompt": null}
{"id": "ef1e3b0d-5f79-4e15-8c15-b50a5f5a5984", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.3 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.4 + 0.6 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration and exploitation balance using adaptive parameters and stochastic elements.", "configspace": "", "generation": 73, "fitness": 0.2495124036515978, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.250 with standard deviation 0.046. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.191.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.26347433652076346, 0.187858534470547, 0.29720433996348294], "final_y": [0.004539721062322172, 0.40948111722332614, 0.0023006459660845574]}, "mutation_prompt": null}
{"id": "b720bcfc-84d3-4518-96dd-1174e593cc68", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.cos(np.pi * iteration / max_iterations)  # Adjusted dynamic mutation factor\n            self.cr = 0.5 + 0.5 * np.sin(np.pi * iteration / max_iterations)  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced adaptive convergence with dynamic mutation and crossover factors using a contextual learning approach.", "configspace": "", "generation": 74, "fitness": 0.280717100489183, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.020. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2898119945059551, 0.25302126409091075, 0.2993180428706833], "final_y": [0.0015857797625381106, 0.005104612608512935, 0.0016696432556777083]}, "mutation_prompt": null}
{"id": "de302d17-75df-4a61-acc9-fa31828d69f1", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        max_iterations = self.budget // self.pop_size\n        inertia_weight_dynamic = self.inertia_weight\n        \n        for iteration in range(max_iterations):\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Increase probability for elite cooperation\n                    trial = 0.7 * trial + 0.3 * personal_best[elite_idx]\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.08:  # Adjust Lvy flight probability\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.4  # Adjust dynamic weight\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.3 * np.sin(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.3 * np.sin(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.cos(0.5 * iteration / max_iterations * np.pi)  # Adjust exploration factor\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            self.f = 0.3 + 0.4 * np.random.rand()  # Adjust mutation factor range\n            self.cr = 0.4 + 0.6 * np.random.rand()  # Adjust crossover rate range\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Integrates a self-adaptive mutation strategy and dynamic parameter tuning to enhance exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.18266892772967303, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.183 with standard deviation 0.025. And the mean value of best solutions found was 0.519 (0. is the best) with standard deviation 0.540.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.20406734111027713, 0.1478738033905581, 0.19606563868818383], "final_y": [0.12905211416810933, 1.2829027683035352, 0.14384651988328903]}, "mutation_prompt": null}
{"id": "915bfc3c-b32a-4dd8-af1e-a4e7ba360223", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Changed from 0.1\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced exploration with strategic hybridization of mutation and crossover techniques.", "configspace": "", "generation": 76, "fitness": 0.3282295587472038, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.328 with standard deviation 0.022. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3352165233983263, 0.3512032765066556, 0.29826887633662946], "final_y": [0.00046711869247227167, 0.00017608715818054793, 0.0024066128542719026]}, "mutation_prompt": null}
{"id": "7b407774-48a5-4646-86d5-30060e2e5007", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor (increased variance)\n            self.cr = 0.4 + 0.6 * np.random.rand()  # Dynamic crossover rate (increased range)\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhance convergence by incorporating a self-adaptive mutation strategy and dynamic crossover scaling.", "configspace": "", "generation": 77, "fitness": 0.3209638505330736, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.024. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.33842744945974856, 0.2868919914463345, 0.33757211069313775], "final_y": [0.0002360385682161073, 0.0020470873260889223, 0.0010952692407614065]}, "mutation_prompt": null}
{"id": "9f03858d-7cc1-4a90-b9f8-6a4b80f4c296", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)**2  # Modified line\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Optimizes convergence by introducing a dynamic adaptive exploration factor based on iteration progress.", "configspace": "", "generation": 78, "fitness": 0.28001872683165824, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.280 with standard deviation 0.026. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.25331910428545845, 0.3144701183231222, 0.2722669578863941], "final_y": [0.002788397642185356, 0.00039044397996302157, 0.0015609273557783954]}, "mutation_prompt": null}
{"id": "af7d2d27-e4d0-4bd1-9d19-c864f66bcc49", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand() * np.cos(iteration / max_iterations * np.pi)  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Innovative convergence acceleration by integrating adaptive chaos-inspired mutation dynamics for improved exploration.", "configspace": "", "generation": 79, "fitness": 0.2706875119435426, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.271 with standard deviation 0.029. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2799089328697931, 0.23165633259390295, 0.30049727036693175], "final_y": [0.007428914055741962, 0.006864603211262092, 0.0006775073483035109]}, "mutation_prompt": null}
{"id": "79295e72-db51-4682-8e22-bf97ffaece6b", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Modified elitist blending probability\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor range\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Leveraging stochastic learning rate adaptation and improved crossover mechanism for enhanced convergence and exploration in differential evolution.", "configspace": "", "generation": 80, "fitness": 0.2764111577561234, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.029. And the mean value of best solutions found was 0.009 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3064947799958111, 0.28492151165976476, 0.23781718161279441], "final_y": [0.0006370955654749009, 0.005824685684219813, 0.01903962247372034]}, "mutation_prompt": null}
{"id": "34a7d8a1-51b5-415d-add6-527945fe7bf8", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            diversity = np.std(population, axis=0).mean()\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5 + 0.1 * diversity\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduced adaptive inertia weight by dynamically varying it based on population diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 81, "fitness": 0.347277389580646, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.347 with standard deviation 0.028. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.33721809372022093, 0.3848559120965209, 0.3197581629251962], "final_y": [0.0005179833818980306, 0.00016980225392637256, 0.00212461949815092]}, "mutation_prompt": null}
{"id": "247e11aa-28a4-459e-81b0-ab00c372bbe9", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Improved Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy_scale = (1 - iteration / max_iterations) * 0.5\n                    levy = levy_scale * np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved exploration through adaptive Lvy flight scaling based on iteration progress.", "configspace": "", "generation": 82, "fitness": 0.29324362192432996, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.018. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2679183017523875, 0.30279597226451116, 0.3090165917560912], "final_y": [0.002385423550240579, 0.002584806875361954, 0.0012007468335337342]}, "mutation_prompt": null}
{"id": "fbcaa46c-fd37-4731-abfa-d9b30ad92a0a", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:  # Adjusted probability\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Enhanced Lvy flight-based exploration\n                if np.random.rand() < 0.07:  # Adjusted probability\n                    levy = np.random.standard_cauchy(size=self.dim) * 0.01  # Scaled Lvy flights\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.35 + 0.25 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incorporate adaptive mutation and crossover rates with a novel Lvy flight mechanism for improved exploration and convergence.", "configspace": "", "generation": 83, "fitness": 0.28466349340366753, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.285 with standard deviation 0.052. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3082523867599105, 0.3326670379788088, 0.21307105547228322], "final_y": [0.0025192619579395424, 0.004472694515394325, 0.05032206304084197]}, "mutation_prompt": null}
{"id": "490e63ae-3bfb-40f9-9a95-3420aa6b82d3", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.3 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Further refined convergence through adaptive mutation factor modulation.", "configspace": "", "generation": 84, "fitness": 0.2377837046975286, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.238 with standard deviation 0.051. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.299.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.25957551002553125, 0.16798143694864065, 0.2857941671184139], "final_y": [0.004697615126935637, 0.6376100858666225, 0.0027450321146032662]}, "mutation_prompt": null}
{"id": "6a19b59c-ac17-4944-9317-1940eb84e0f2", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Refined Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim) * 0.01\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incrementally enhanced exploration through refined Lvy flight application for improved search space coverage.", "configspace": "", "generation": 85, "fitness": 0.3516109999880473, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.352 with standard deviation 0.012. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.36264311746458733, 0.33467718060145246, 0.357512701898102], "final_y": [0.0008776140340391314, 0.0004468911797028462, 0.0002622818355872452]}, "mutation_prompt": null}
{"id": "a5240657-c6bc-4350-91e6-2794111e6655", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.random.choice(np.where(personal_best_scores == np.min(personal_best_scores))[0])  # Randomly choose elite index\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduce randomness in personal best candidate selection for enhanced diversity.", "configspace": "", "generation": 86, "fitness": 0.2743907242228514, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.274 with standard deviation 0.007. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2843168591639583, 0.26785622805776643, 0.2709990854468294], "final_y": [0.00470343440756805, 0.010382790976273445, 0.004749452375040202]}, "mutation_prompt": null}
{"id": "22ae2aaf-4764-443d-985b-375bfddfb9f7", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n            # Implementing chaotic maps for exploration enhancement\n            chaotic_map = np.sin(iteration / max_iterations * np.pi)\n            self.f = self.f * chaotic_map\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incorporating chaotic maps to enhance exploration capability and improve convergence speed.", "configspace": "", "generation": 87, "fitness": 0.25434603732279637, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.254 with standard deviation 0.018. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2286575162534802, 0.26573424130675105, 0.2686463544081579], "final_y": [0.01166580478882004, 0.009375816009789179, 0.0017883828477453603]}, "mutation_prompt": null}
{"id": "1f0671f1-4653-4d58-9fff-19243cd0ad16", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n        self.temperature = 1.0  # Initial temperature for simulated annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                # Hybrid with Simulated Annealing\n                trial_score = func(trial)\n                if trial_score < personal_best_scores[i] or np.exp(-(trial_score - personal_best_scores[i]) / self.temperature) > np.random.rand():\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n                self.temperature *= 0.99  # Cooling down\n\n                evaluations += 1\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress and hybridizing with Simulated Annealing for diversification.", "configspace": "", "generation": 88, "fitness": 0.258163207602215, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.258 with standard deviation 0.020. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2861397952864767, 0.23806953020943222, 0.2502802973107361], "final_y": [0.0022910630529265202, 0.03009352983721311, 0.0026469086039001867]}, "mutation_prompt": null}
{"id": "060ee55d-fd80-4d8f-82a3-93bd4f395539", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.6 + 0.4 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress.", "configspace": "", "generation": 89, "fitness": 0.35195071921574983, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.352 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.30381431356840327, 0.37349150634163286, 0.37854633773721336], "final_y": [0.004495053306424388, 0.00045806336595203314, 0.0007811253451582247]}, "mutation_prompt": null}
{"id": "da0720df-21bd-4106-8bc7-ca1b7206a8b7", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.sin(iteration / max_iterations * np.pi)  # Adjusted sine-based mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced dynamic exploration by introducing a sine-based mutation factor for adaptive search space coverage.", "configspace": "", "generation": 90, "fitness": 0.30382044491159627, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.021. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.32297064783860585, 0.2753083210349243, 0.3131823658612586], "final_y": [0.00038693358308658347, 0.00125906047104019, 0.0013369777248611167]}, "mutation_prompt": null}
{"id": "16e6abea-e9b6-45d4-a3d4-cf6975ef2b98", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.15:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Enhanced Lvy flight-based exploration\n                if np.random.rand() < 0.1:\n                    levy = np.random.standard_cauchy(size=self.dim) * 0.1\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.sin(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.sin(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.cos(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.5 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.4 * np.random.rand()  # Oscillating crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced exploration-exploitation balance through adaptive Lvy flights and oscillating crossover rates.", "configspace": "", "generation": 91, "fitness": 0.20817110270890996, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.208 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.093.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.21510671906081258, 0.21607002199666758, 0.19333656706924973], "final_y": [0.0412377941814272, 0.07434200288136787, 0.253791674432397]}, "mutation_prompt": null}
{"id": "211fff06-a9ec-4ca1-897b-70cd5f4e1318", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi) + 0.01 * np.random.randn()) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduced a small perturbation to the cognitive component to enhance diversity and avoid premature convergence.", "configspace": "", "generation": 92, "fitness": 0.30985268129046534, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.007. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.3093994316106009, 0.3012149944475607, 0.31894361781323444], "final_y": [0.0005669602553251035, 0.0013854169278129846, 0.0005714435773560389]}, "mutation_prompt": null}
{"id": "ef3beb57-beb5-4257-ae9b-a4911b9b079b", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            local_best = personal_best[np.argmin([func(ind) for ind in personal_best])]  # Local best integration\n            for i in range(self.pop_size):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]) +\n                                 0.1 * r3 * (local_best - population[i]))  # Additional local best influence\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Refined dynamic adjustment by incorporating local best influence and adaptive exploration adjustments for enhanced convergence.", "configspace": "", "generation": 93, "fitness": 0.2610682916812747, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.261 with standard deviation 0.010. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2579604928343908, 0.2746326456313818, 0.2506117365780516], "final_y": [0.019204930226376298, 0.004846542182840641, 0.02028673500875078]}, "mutation_prompt": null}
{"id": "c768bbdf-3311-4875-84a6-3872589a0708", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.cos((iteration / max_iterations) * np.pi)  # Improved dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced convergence through dynamic adjustment of cognitive and social constants based on iteration progress and an improved dynamic crossover strategy.", "configspace": "", "generation": 94, "fitness": 0.2728036184615062, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.273 with standard deviation 0.018. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2961349908665214, 0.27120717560321406, 0.25106868891478307], "final_y": [0.002166135060577014, 0.008092410365524726, 0.006138500733006338]}, "mutation_prompt": null}
{"id": "7d28aa9a-8278-43f3-9ced-453f62084c23", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n\n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            quantum_factor = 0.1 * np.random.rand(self.dim)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c) + quantum_factor, bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Hybrid Adaptive Differential Learning with Quantum-Inspired Mutation Enhancements.", "configspace": "", "generation": 95, "fitness": 0.2766024565095761, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.277 with standard deviation 0.033. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.2944853673917136, 0.3049320675349865, 0.23038993460202828], "final_y": [0.0007408738901002287, 0.00019516953692050057, 0.007612042424289095]}, "mutation_prompt": null}
{"id": "fe5d9d50-de3f-4363-98c5-acb7cf0168f8", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n                if iteration % 10 == 0 and i == elite_idx:\n                    self.pop_size = min(self.pop_size + 1, 30)  # Dynamically adjust population size\n                    population = np.vstack([population, population[elite_idx]])  # Reinforce with elite\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Improved algorithm convergence by dynamically adjusting the population size and integrating a stochastic elite reinforcement strategy.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {}, "mutation_prompt": null}
{"id": "a84fe351-38e8-489c-bef9-907bad344141", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Enhanced exploration by introducing adaptive elite diversification mechanism.", "configspace": "", "generation": 97, "fitness": 0.26024484949594273, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.007. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.25928312776811113, 0.25164025388863254, 0.2698111668310845], "final_y": [0.013947527728693402, 0.003288691943103747, 0.011483937788486498]}, "mutation_prompt": null}
{"id": "82b864f1-595e-4c5f-a748-c55e6b678e5a", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.2:  # Adjust exploration probability\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.1:  # Increase Lvy flight probability\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.cos(0.5 * iteration / max_iterations * np.pi)  # Alter exploration factor\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.3 + 0.3 * np.random.rand()  # Adjusted stochastic mutation factor\n            self.cr = 0.4 + 0.6 * np.random.rand()  # Dynamic crossover rate\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Incorporates adaptive parameter tuning and strategic diversity enhancement to improve exploration-exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.15589506867190964, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.156 with standard deviation 0.042. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.099.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.09780550303818869, 0.17602522376207375, 0.1938544792154665], "final_y": [0.13127926354975109, 0.011532843108413574, 0.25327416056128904]}, "mutation_prompt": null}
{"id": "8eb9f0ce-8ced-4c1d-963b-0f8ede2138b7", "solution": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover rate\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.4\n        self.social_const = 1.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        evaluations = self.pop_size\n        iteration = 0\n        max_iterations = self.budget // self.pop_size\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(personal_best_scores)\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                if np.random.rand() < 0.1:\n                    trial = (trial + personal_best[elite_idx]) / 2\n\n                # Lvy flight-based exploration\n                if np.random.rand() < 0.05:\n                    levy = np.random.standard_cauchy(size=self.dim)\n                    trial = np.clip(trial + levy, bounds[:, 0], bounds[:, 1])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < func(global_best):\n                        global_best = trial\n\n            inertia_weight_dynamic = 0.9 - (iteration / max_iterations) * 0.5\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight_dynamic * velocities[i] +\n                                 (self.cognitive_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r1 * (personal_best[i] - population[i]) +\n                                 (self.social_const + 0.5 * np.cos(iteration / max_iterations * np.pi)) * r2 * (global_best - population[i]))\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                exploration_factor = np.sin(0.5 * iteration / max_iterations * np.pi)\n                velocities[i] *= exploration_factor\n\n                particle_score = func(population[i])\n                evaluations += 1\n                if particle_score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = particle_score\n                    if particle_score < func(global_best):\n                        global_best = population[i]\n\n            iteration += 1\n\n            self.f = 0.4 + 0.2 * np.random.rand() * (1 - iteration / max_iterations)  # Adjusted stochastic mutation factor\n            self.cr = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n            self.inertia_weight = 0.9 * (1 - iteration / max_iterations) + 0.4  # Adaptive inertia weight\n\n        return global_best", "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introducing adaptive exploration-exploitation balance by varying the differential weight and inertia dynamically based on iteration progression.", "configspace": "", "generation": 99, "fitness": 0.2710082562962123, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.271 with standard deviation 0.020. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f6b2647-79a7-4206-8fe5-aaab411f5e0d", "metadata": {"aucs": [0.25298639562127345, 0.29861318118855706, 0.2614251920788063], "final_y": [0.0034563579847819697, 0.002826416560371379, 0.00496058676572907]}, "mutation_prompt": null}
