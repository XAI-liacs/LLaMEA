{"id": "b312ac7a-048f-437f-9452-c2ee40fb9f85", "solution": "import numpy as np\n\nclass HybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for _ in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "HybridDifferentialAnnealing", "description": "The algorithm employs a hybrid approach combining elements of differential evolution and simulated annealing to explore and exploit the search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.6925878047485639, "feedback": "The algorithm HybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.693 with standard deviation 0.056. And the mean value of best solutions found was 0.207 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7546440031910748, 0.7035532308967585, 0.6195661801578582], "final_y": [0.19591489318053168, 0.19465984825126714, 0.22914953220426637]}, "mutation_prompt": null}
{"id": "645ee652-deaa-4b66-9850-ae80cca724ed", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm leverages an adaptive hybrid approach integrating a self-adjusting differential evolution with simulated annealing to enhance exploration and convergence in diverse search spaces.", "configspace": "", "generation": 1, "fitness": 0.8393188692265262, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.021. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b312ac7a-048f-437f-9452-c2ee40fb9f85", "metadata": {"aucs": [0.8662101783929704, 0.8156450237809247, 0.8361014055056835], "final_y": [0.1687977467957985, 0.18662672821668203, 0.18240329063464655]}, "mutation_prompt": null}
{"id": "ba0465e7-9180-4047-91ea-8cc72799bd7c", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.97  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm leverages an adaptive hybrid approach integrating a self-adjusting differential evolution with simulated annealing and enhanced adaptive mutation decay to improve convergence in diverse search spaces.", "configspace": "", "generation": 2, "fitness": 0.734032734097602, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.734 with standard deviation 0.069. And the mean value of best solutions found was 0.250 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.6697354590616298, 0.703236982444688, 0.8291257607864883], "final_y": [0.2918833154718078, 0.25839311070248905, 0.1999158020479913]}, "mutation_prompt": null}
{"id": "1f3b136f-04b0-40f0-8899-4f1ccbb45def", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def dynamic_population_size(self, generation):\n        # Increase population size dynamically every few generations\n        if generation % 10 == 0 and self.population_size < self.initial_population_size * 2:\n            self.population_size += 1\n\n    def adjust_temperature(self, fitness):\n        # Adjust temperature based on neighborhood fitness variance\n        variance = np.var(fitness)\n        self.temperature = max(0.1, self.temperature * np.exp(-0.05 * variance))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            self.dynamic_population_size(gen)\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            self.adjust_temperature(fitness)\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "EnhancedAdaptiveHybridDifferentialAnnealing", "description": "The Enhanced Adaptive Hybrid Differential Annealing algorithm introduces dynamic population sizing and neighborhood-based temperature adjustments to improve convergence and exploration balance.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {}, "mutation_prompt": null}
{"id": "e8f261bd-bc9e-47b9-973a-b6050ce67936", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        random_factor = np.random.uniform(0.5, 1.5)  # New line for randomness\n        mutant = np.clip(a + random_factor * self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm refines the mutation strategy by introducing randomness in the mutation factor to enhance exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.7909430395613929, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.018. And the mean value of best solutions found was 0.187 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.8043745722752433, 0.7651326996678183, 0.8033218467411171], "final_y": [0.18434131813707821, 0.2056052393071558, 0.1706894238558695]}, "mutation_prompt": null}
{"id": "a528ef6a-d7ec-4a5f-82c9-ede8af668099", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        # Enhanced crossover strategy: introduce exploratory noise\n        noise = np.random.normal(0, 0.01, self.dim)  # Add small Gaussian noise\n        trial += noise\n        return np.clip(trial, self.bounds.lb, self.bounds.ub)\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm leverages an adaptive hybrid approach integrating a self-adjusting differential evolution with simulated annealing to enhance exploration and convergence in diverse search spaces, now with enhanced crossover strategy to improve exploration.", "configspace": "", "generation": 5, "fitness": 0.8368628523722269, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.016. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.8599148799520105, 0.8266097930880655, 0.8240638840766045], "final_y": [0.1660941801576833, 0.17086593662712202, 0.1850811110581686]}, "mutation_prompt": null}
{"id": "c9ae4eae-6690-4af3-a23d-48c07ce98ef8", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n            \n            # Dynamic crossover rate adjustment based on fitness variance\n            fitness_variance = np.var(fitness)\n            self.crossover_rate = 0.5 + 0.5 * (fitness_variance / (fitness_variance + 1))\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "Introduces a dynamic crossover rate adjustment based on the fitness variance to further enhance solution diversity and convergence in complex search spaces.", "configspace": "", "generation": 6, "fitness": 0.8255657326166109, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.059. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.8614052529775212, 0.7425734570047182, 0.8727184878675932], "final_y": [0.16505941360035392, 0.194144752787775, 0.1649610200309628]}, "mutation_prompt": null}
{"id": "b3aed1fe-153f-49b5-851b-c6b16b476c10", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n                self.crossover_rate = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate adjustment\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "Enhancing the algorithm by introducing a dynamic crossover rate adjustment based on fitness improvement trends to balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.7563549920719339, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.756 with standard deviation 0.081. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.7492803163824788, 0.6613134552333536, 0.8584712045999691], "final_y": [0.22933586345505574, 0.27131029025507947, 0.16599485760176036]}, "mutation_prompt": null}
{"id": "6e3063db-479b-4b4a-ae66-5879d1aefc79", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n            # Dynamic crossover rate adjustment based on diversity\n            fitness_std = np.std(fitness)\n            self.crossover_rate = 0.7 + 0.3 * (1 - fitness_std / (np.mean(fitness) + 1e-10))\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm enhances convergence by introducing a dynamic crossover rate adjustment based on population diversity.", "configspace": "", "generation": 8, "fitness": 0.7400522004467659, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.018. And the mean value of best solutions found was 0.241 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.7150776088969029, 0.7473513676554329, 0.7577276247879621], "final_y": [0.2704422813895745, 0.2273336456341437, 0.22381560206353668]}, "mutation_prompt": null}
{"id": "2ba4a1b3-9505-4d1f-9b38-fce3828b1d11", "solution": "# Description: The algorithm enhances its adaptive hybrid approach by integrating a diversity mechanism to maintain population variety and improve convergence.\n# Code:\nimport numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.diversity_threshold = 0.1  # New line for diversity mechanism\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Diversity mechanism to re-initialize population at specified diversity threshold\n            stddev_fitness = np.std(fitness)  # New line for diversity calculation\n            if stddev_fitness < self.diversity_threshold:  # New line for diversity check\n                individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm enhances its adaptive hybrid approach by integrating a diversity mechanism to maintain population variety and improve convergence.", "configspace": "", "generation": 9, "fitness": 0.6453533795597258, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.645 with standard deviation 0.025. And the mean value of best solutions found was 0.291 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.6684862051768933, 0.610616184676766, 0.6569577488255183], "final_y": [0.28461029919878467, 0.30183515135861405, 0.28547625847409763]}, "mutation_prompt": null}
{"id": "cb3a8668-34df-46dd-a4fe-816453833d65", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.temperature = 1.0\n        self.alpha = 0.95  # Cooling schedule\n        self.mutation_decay = 0.99  # Decay for mutation factor\n        self.history = []\n\n    def mutate(self, individuals):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + self.mutation_factor * (b - c), self.bounds.lb, self.bounds.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def acceptance_probability(self, current_value, candidate_value):\n        if candidate_value < current_value:\n            return 1.0\n        else:\n            return np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        individuals = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in individuals])\n        self.history.extend(fitness)\n\n        for gen in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                mutant = self.mutate(individuals)\n                trial = self.crossover(individuals[i], mutant)\n                trial_fitness = func(trial)\n                self.history.append(trial_fitness)\n\n                if self.acceptance_probability(fitness[i], trial_fitness) > np.random.rand():\n                    individuals[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive mutation factor adjustment\n            best_fitness = np.min(fitness)\n            mean_fitness = np.mean(fitness)\n            if best_fitness < mean_fitness:\n                self.mutation_factor *= self.mutation_decay\n\n            # Adaptive cooling schedule adjustment based on fitness convergence\n            if gen > 0 and abs(np.min(self.history[-self.population_size:]) - np.min(self.history[-2*self.population_size:-self.population_size])) < 1e-6:\n                self.alpha *= 0.99\n\n            # Cooling down the temperature\n            self.temperature *= self.alpha\n\n        best_idx = np.argmin(fitness)\n        return individuals[best_idx], fitness[best_idx], self.history", "name": "AdaptiveHybridDifferentialAnnealing", "description": "The algorithm improves by incorporating adaptive annealing factors, dynamically adjusting temperature based on fitness convergence rate to balance exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.8392865384968063, "feedback": "The algorithm AdaptiveHybridDifferentialAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.021. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.86618954832581, 0.8156666355629831, 0.8360034316016263], "final_y": [0.16881579536640012, 0.1866023640468386, 0.18247961507444566]}, "mutation_prompt": null}
{"id": "19ab94d3-4cf7-4fa0-8b6c-847da33ee8c5", "solution": "import numpy as np\n\nclass SwarmLevyCooperativeOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.alpha = 0.1  # Influence of local best\n        self.beta = 0.2   # Influence of global best\n        self.levy_scale = 0.5\n        self.history = []\n\n    def levy_flight(self, step_size):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        return step_size * (u / np.abs(v) ** (1 / self.levy_scale))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        positions = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(ind) for ind in positions])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        self.history.extend(personal_best_scores)\n\n        evaluations = self.swarm_size\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (velocities[i] +\n                                 self.alpha * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.beta * r2 * (global_best_position - positions[i]))\n                \n                positions[i] += velocities[i]\n\n                # Apply Levy flight\n                if np.random.rand() < 0.3:\n                    positions[i] += self.levy_flight(0.1)\n\n                positions[i] = np.clip(positions[i], self.bounds.lb, self.bounds.ub)\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = personal_best_positions[i]\n\n            self.history.extend(personal_best_scores)\n\n        return global_best_position, personal_best_scores[global_best_idx], self.history", "name": "SwarmLevyCooperativeOptimization", "description": "The algorithm employs a swarm-based cooperative coevolution strategy, synergistically blending particle dynamics with memory-enhanced levy flights to enhance diversity and convergence precision in complex black-box landscapes.", "configspace": "", "generation": 11, "fitness": 0.8555310264939119, "feedback": "The algorithm SwarmLevyCooperativeOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.045. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "645ee652-deaa-4b66-9850-ae80cca724ed", "metadata": {"aucs": [0.8533751173793389, 0.8016483414177626, 0.911569620684634], "final_y": [0.20948087922429182, 0.2232519850470951, 0.1833500114142902]}, "mutation_prompt": null}
{"id": "1458a7d2-807b-46ca-8829-7fe714a48b37", "solution": "import numpy as np\n\nclass SwarmLevyCooperativeOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.alpha = 0.1  # Influence of local best\n        self.beta = 0.2   # Influence of global best\n        self.levy_scale = 0.5\n        self.history = []\n\n    def levy_flight(self, step_size):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        return step_size * (u / np.abs(v) ** (1 / self.levy_scale))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        positions = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(ind) for ind in positions])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        self.history.extend(personal_best_scores)\n\n        evaluations = self.swarm_size\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (velocities[i] +\n                                 self.alpha * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.beta * r2 * (global_best_position - positions[i]))\n                \n                positions[i] += velocities[i]\n\n                # Apply Levy flight\n                if np.random.rand() < 0.5:  # Increased probability of Levy flight\n                    positions[i] += self.levy_flight(0.1)\n\n                positions[i] = np.clip(positions[i], self.bounds.lb, self.bounds.ub)\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = personal_best_positions[i]\n\n            self.history.extend(personal_best_scores)\n\n        return global_best_position, personal_best_scores[global_best_idx], self.history", "name": "SwarmLevyCooperativeOptimization", "description": "The algorithm enhances exploration by increasing the likelihood of Levy flights, fostering diverse search paths and improving convergence in complex landscapes.", "configspace": "", "generation": 12, "fitness": 0.8040539316828287, "feedback": "The algorithm SwarmLevyCooperativeOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.097. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "19ab94d3-4cf7-4fa0-8b6c-847da33ee8c5", "metadata": {"aucs": [0.9193838697093841, 0.6831426726332329, 0.809635252705869], "final_y": [0.1858203636217831, 0.28603400762479847, 0.21566889072582207]}, "mutation_prompt": null}
{"id": "0e9f51c8-043f-41d7-96eb-369a4b512f22", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "The algorithm integrates a hybrid quantum-inspired optimization mechanism with adaptive mutation and differential learning to efficiently explore and exploit complex black-box landscapes.", "configspace": "", "generation": 13, "fitness": 0.9166807417407732, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.040. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "19ab94d3-4cf7-4fa0-8b6c-847da33ee8c5", "metadata": {"aucs": [0.9647072517430222, 0.9177763451186925, 0.8675586283606049], "final_y": [0.1656230205874677, 0.18266225402815017, 0.199112915786131]}, "mutation_prompt": null}
{"id": "f0a6abef-6d49-481f-ad7b-c46324eb12c8", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            if evaluations > self.budget / 2:  # Dynamic population scaling\n                self.population_size = max(10, int(self.population_size * 0.9))\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "The algorithm enhances exploration by adaptive dynamic population size scaling during the search process.", "configspace": "", "generation": 14, "fitness": 0.9165207062465403, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.040. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "0e9f51c8-043f-41d7-96eb-369a4b512f22", "metadata": {"aucs": [0.9646341521669787, 0.9177629013368785, 0.8671650652357636], "final_y": [0.16568877373367408, 0.18268035395999038, 0.19960289818941623]}, "mutation_prompt": null}
{"id": "e531179b-cca5-4b4b-a365-6e04e5e1af32", "solution": "import numpy as np\n\nclass SwarmDrivenQuantumEvolutionaryOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.quantum_superposition_rate = 0.6\n        self.entanglement_factor = 0.5\n        self.history = []\n\n    def quantum_superposition(self, swarm):\n        superposed = np.random.rand(self.swarm_size, self.dim)\n        mask = np.random.rand(self.swarm_size, self.dim) < self.quantum_superposition_rate\n        return np.where(mask, superposed, swarm)\n\n    def swarm_intelligence(self, swarm, best):\n        global_influence = np.random.rand(self.dim) * (best - swarm)\n        local_influence = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        new_positions = swarm + self.entanglement_factor * (global_influence + local_influence)\n        return np.clip(new_positions, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        swarm = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.swarm_size, self.dim))\n        scores = np.array([func(ind) for ind in swarm])\n        best_idx = np.argmin(scores)\n        best_solution = swarm[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.swarm_size\n        while evaluations < self.budget:\n            superposed_swarm = self.quantum_superposition(swarm)\n            new_swarm = self.swarm_intelligence(superposed_swarm, best_solution)\n\n            for i in range(self.swarm_size):\n                new_score = func(new_swarm[i])\n                evaluations += 1\n\n                if new_score < scores[i]:\n                    scores[i] = new_score\n                    swarm[i] = new_swarm[i]\n\n                if new_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = new_swarm[i]\n\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "SwarmDrivenQuantumEvolutionaryOptimization", "description": "The algorithm leverages a novel Swarm-Driven Quantum Evolutionary Optimization that combines quantum-inspired superposition and entanglement with swarm intelligence to navigate and optimize complex black-box landscapes efficiently.", "configspace": "", "generation": 15, "fitness": 0.4701237983593865, "feedback": "The algorithm SwarmDrivenQuantumEvolutionaryOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.470 with standard deviation 0.032. And the mean value of best solutions found was 0.418 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "0e9f51c8-043f-41d7-96eb-369a4b512f22", "metadata": {"aucs": [0.42541364816909955, 0.4887423048434897, 0.4962154420655702], "final_y": [0.46402998951262864, 0.41379549904142665, 0.3760986299439767]}, "mutation_prompt": null}
{"id": "f8c4718a-4fe0-4fa7-9b11-93dfeec716cc", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate * (1 - scores[i] / scores[best_idx]):\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            if evaluations % 100 == 0:  # Adapt population size every 100 evaluations\n                self.population_size = min(self.budget - evaluations, self.population_size + 1)\n                population = np.resize(population, (self.population_size, self.dim))\n                scores = np.resize(scores, self.population_size)\n\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "The algorithm introduces selective crossover and adaptive population size to enhance exploration and exploitation efficiency in complex search spaces.", "configspace": "", "generation": 16, "fitness": 0.4632111557791962, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.463 with standard deviation 0.034. And the mean value of best solutions found was 0.434 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "0e9f51c8-043f-41d7-96eb-369a4b512f22", "metadata": {"aucs": [0.41584610300173286, 0.4887423048434897, 0.4850450594923661], "final_y": [0.47239265783783124, 0.41379549904142665, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "15a1ec21-3d8e-4744-8e4e-af1fcf6b3b83", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "This refined algorithm enhances exploration by introducing a dynamic mutation factor and adaptive population size, balancing exploration and exploitation more effectively.", "configspace": "", "generation": 17, "fitness": 0.924886996493532, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.021. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "0e9f51c8-043f-41d7-96eb-369a4b512f22", "metadata": {"aucs": [0.9521142255884407, 0.9010839624765583, 0.921462801415597], "final_y": [0.17119918748514806, 0.18942469072480428, 0.1826266081178055]}, "mutation_prompt": null}
{"id": "0659d157-d82c-42cb-a721-4babd02955c6", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history + [best]) / np.max(self.history + [best]))  # Improved mutation adaptation\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "This refined algorithm enhances exploration by introducing a dynamic mutation factor and adaptive population size, balancing exploration and exploitation more effectively, with improved memory of the best scores for enhanced mutation adaptation.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (41,) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (41,) + inhomogeneous part.')", "parent_id": "15a1ec21-3d8e-4744-8e4e-af1fcf6b3b83", "metadata": {}, "mutation_prompt": null}
{"id": "6d1dd5b9-2bea-40ec-8351-c3e091384d76", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        new_solution = solution - gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "This refined algorithm introduces local search intensification by leveraging a hybrid strategy combining quantum bit flip and gradient approximation, enhancing convergence speed and solution quality.", "configspace": "", "generation": 19, "fitness": 0.9485663022279636, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.012. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "15a1ec21-3d8e-4744-8e4e-af1fcf6b3b83", "metadata": {"aucs": [0.9315657358805237, 0.953097445175763, 0.9610357256276041], "final_y": [0.16733789908944852, 0.1674066235813908, 0.1668168766096354]}, "mutation_prompt": null}
{"id": "7b79461a-0005-4819-bd2b-9290be859da3", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        new_solution = solution - gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                # Introduce a dynamic crossover rate\n                self.crossover_rate = 0.5 + 0.5 * np.std(population) / (np.max(population) - np.min(population))\n\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduces a dynamic crossover rate based on the diversity of the population to enhance exploration and exploitation balance.  ", "configspace": "", "generation": 20, "fitness": 0.9384266540201516, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.006. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6d1dd5b9-2bea-40ec-8351-c3e091384d76", "metadata": {"aucs": [0.9311850970514344, 0.9457401028707507, 0.9383547621382695], "final_y": [0.16650146458904624, 0.16767714673470102, 0.167315915922721]}, "mutation_prompt": null}
{"id": "1a0eed9e-4fc6-4d31-951d-edff4d123356", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio)  # Adaptive intensity based on progress\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  # Calculate evaluation ratio\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced convergence through adaptive adjustment of local search intensity based on evaluation progress.", "configspace": "", "generation": 21, "fitness": 0.9569911477193968, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6d1dd5b9-2bea-40ec-8351-c3e091384d76", "metadata": {"aucs": [0.9456881326634471, 0.9609015486350952, 0.9643837618596481], "final_y": [0.16541365614180892, 0.16540553629514976, 0.16545763081020826]}, "mutation_prompt": null}
{"id": "655309bf-5e4f-4c00-80bd-1285a5e0ac6f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio) * (1 + np.std(self.history) / np.max([1, np.max(self.history)]))  # Enhanced adaptive intensity\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  # Calculate evaluation ratio\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improved convergence by enhancing local search intensity using a dynamically adjusted scaling factor.", "configspace": "", "generation": 22, "fitness": 0.954754248478638, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.005. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a0eed9e-4fc6-4d31-951d-edff4d123356", "metadata": {"aucs": [0.9482574882270272, 0.9563416984381362, 0.9596635587707507], "final_y": [0.16553527835480752, 0.16556470402272627, 0.16560547195041508]}, "mutation_prompt": null}
{"id": "7cb41e5b-8fe4-430e-86d8-65b0954331d3", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        dynamic_factor = self.mutation_factor * (1 - np.std(self.history) / np.max(self.history))  # Dynamic mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio)  # Adaptive intensity based on progress\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  # Calculate evaluation ratio\n            self.crossover_rate = 0.5 + 0.5 * np.std(scores) / np.max(scores)  # Dynamic crossover rate based on diversity\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced dynamic crossover rate adjustment based on population diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.9396068711996041, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a0eed9e-4fc6-4d31-951d-edff4d123356", "metadata": {"aucs": [0.9094461558324347, 0.9501508541715817, 0.9592236035947961], "final_y": [0.165604109143354, 0.16554375716616798, 0.16519035994585585]}, "mutation_prompt": null}
{"id": "9133f539-d503-4ef6-88a1-9200740b1f78", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  # Adjusted mutation factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  # Modified intensity\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  # Adaptive population size\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  # Calculate evaluation ratio\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                # New local search integration\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improved convergence through adaptive mutation factor and dynamic local search enhancement based on diversity.", "configspace": "", "generation": 24, "fitness": 0.9595343247783109, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1a0eed9e-4fc6-4d31-951d-edff4d123356", "metadata": {"aucs": [0.956686471215004, 0.9580630884100714, 0.9638534147098571], "final_y": [0.16636993989982174, 0.16694477566701815, 0.16821489478916019]}, "mutation_prompt": null}
{"id": "879f0788-0ee9-4078-b56a-a96ff429993e", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced mutation strategy by incorporating adaptive scaling based on historical performance.", "configspace": "", "generation": 25, "fitness": 0.9614375641533953, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.005. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9133f539-d503-4ef6-88a1-9200740b1f78", "metadata": {"aucs": [0.9545890842926867, 0.9630161490311182, 0.9667074591363811], "final_y": [0.16835590587387073, 0.16763637215754812, 0.16771335874634086]}, "mutation_prompt": null}
{"id": "bfaf7652-6c1d-4489-af02-8649a4177ade", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor) * (1 - eval_ratio)  # Adjusted mutation factor\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Fine-tune the mutation factor based on the evaluation ratio to enhance the convergence rate.", "configspace": "", "generation": 26, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_ratio' is not defined\").", "error": "NameError(\"name 'eval_ratio' is not defined\")", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {}, "mutation_prompt": null}
{"id": "7120ce91-d2d8-44a3-bdaa-19f4ddb685c7", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                # Adaptive crossover rate based on diversity\n                self.crossover_rate = 0.3 + 0.4 * (1 - np.std(scores) / (np.max(scores) - np.min(scores)))\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced adaptive crossover based on current population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.9407718947421527, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.026. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9036862861106747, 0.9625793384207433, 0.9560500596950401], "final_y": [0.18439654981592613, 0.16624841910803756, 0.16611551040921613]}, "mutation_prompt": null}
{"id": "362ec302-15cd-4512-8a5f-7ae8dd04f230", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.std(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.var(self.history) / np.max(self.history)))  # Changed std to var\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Refined differentiation by incorporating variance-scaled mutation and adaptive memory utilization.", "configspace": "", "generation": 28, "fitness": 0.9609874226139073, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.006. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9527276676292942, 0.9636741546241865, 0.9665604455882414], "final_y": [0.16829593177117208, 0.1674021882871427, 0.16696254680466405]}, "mutation_prompt": null}
{"id": "0fb24cba-e188-432e-aee1-4a96eb4d0a1c", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            self.crossover_rate = max(0.5, np.std(population) / (np.std(population) + 1))  # Adjust crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Refined adaptive strategy by adjusting crossover rate based on dynamic diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.9487483115446547, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.022. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.963413083981179, 0.9176713598842668, 0.9651604907685182], "final_y": [0.16638181517352757, 0.18342950503972888, 0.16714513946962373]}, "mutation_prompt": null}
{"id": "c878703e-1516-432a-bcd4-6f447f57546d", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best, eval_ratio):\n        q = np.random.rand(self.dim) * (1 - eval_ratio)  # Adaptive quantum bit flip probability\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution, eval_ratio)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced adaptive quantum bit flip probability based on evaluation ratio to improve diversity and exploration.", "configspace": "", "generation": 30, "fitness": 0.9601412748128092, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9537736286349976, 0.9595392917534614, 0.9671109040499687], "final_y": [0.16734054657595188, 0.16721216340464773, 0.16715499396430245]}, "mutation_prompt": null}
{"id": "93f3a680-22d0-4aff-a0c5-4cd843e43529", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        diversity_seeds = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))  # Diversity seeds\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        population = np.vstack((population, diversity_seeds))[:self.population_size]  # Initial population with diversity\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improved population initialization by adding diversity seeds to enhance exploration.", "configspace": "", "generation": 31, "fitness": 0.9452665105730419, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.027. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9078605497782759, 0.9674453636749589, 0.960493618265891], "final_y": [0.18327764547963654, 0.16705052921072672, 0.16673534292615477]}, "mutation_prompt": null}
{"id": "12bd7603-eed5-49f5-8c64-6032c5acc1ed", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n        self.momentum = np.zeros(dim)\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))\n        learning_rate = 0.1 * (1 - eval_ratio) + 0.9 * np.linalg.norm(self.momentum)\n        new_solution = solution - intensity * learning_rate * gradient * (solution - np.mean(self.history))\n        self.momentum = 0.9 * self.momentum + 0.1 * (new_solution - solution)\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce a dynamic learning rate inspired by momentum-based optimization to enhance convergence speed in QuantumAdaptiveDifferentialOptimization.", "configspace": "", "generation": 32, "fitness": 0.4631039002823825, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.463 with standard deviation 0.034. And the mean value of best solutions found was 0.434 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.4157292905016189, 0.4886401830797875, 0.4849422272657412], "final_y": [0.47239265783783124, 0.41379549904142665, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "695de503-7305-4600-9167-d7e8afb13315", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))\n        learning_rate = 0.1 / (1 + eval_ratio)  # Adaptive learning rate\n        new_solution = solution - learning_rate * intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrate an adaptive learning rate in the local search phase to enhance convergence efficiency.", "configspace": "", "generation": 33, "fitness": 0.9311724522625039, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.026. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9376525871777074, 0.9593712051046724, 0.8964935645051318], "final_y": [0.1648651029798085, 0.16486496145681473, 0.18189028872221658]}, "mutation_prompt": null}
{"id": "a9c65cfe-da4f-465c-911c-87f3dea7c078", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        adaptive_factor = np.std(population)  # New adaptive factor based on diversity\n        mutant = a + dynamic_factor * historical_factor * adaptive_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Incorporate adaptive mutation factor based on population diversity for improved exploration.", "configspace": "", "generation": 34, "fitness": 0.9600563590635701, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9591535302291382, 0.9636002108447829, 0.9574153361167894], "final_y": [0.16718100229423072, 0.1669327320752635, 0.16700070783652154]}, "mutation_prompt": null}
{"id": "e416402c-d0f2-46f3-9286-7085f09f9fbc", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            diversity_factor = np.std(population) / (np.std(population) + 1)  # Calculate diversity\n            self.crossover_rate = 0.8 * (1 - diversity_factor) + 0.1  # Adaptive crossover rate\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate dependent on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.907246616533751, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.018. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.8920718332736257, 0.9327150072854162, 0.8969530090422112], "final_y": [0.16864092519496188, 0.16836333696837824, 0.16773519656124503]}, "mutation_prompt": null}
{"id": "5df9b64f-397b-4432-be45-86fd6fb968c0", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        # Adjust gradient intensity based on historical score variance\n        intensity = np.exp(-eval_ratio * (np.var(self.history) / (np.max(self.history) + 1)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Fine-tune local search by adjusting gradient intensity based on historical score variance.", "configspace": "", "generation": 36, "fitness": 0.9612741373245255, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9540354694560395, 0.9640782090733548, 0.9657087334441821], "final_y": [0.1671832252857769, 0.1666524885771965, 0.16693782854748318]}, "mutation_prompt": null}
{"id": "b22440bb-bf32-4c3e-a5d2-177ba54f0f2d", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            self.crossover_rate = 0.9 * diversity_factor + 0.1  # Adaptive crossover rate based on diversity\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce an adaptive crossover rate based on population diversity to enhance exploration capabilities.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'diversity_factor' is not defined\").", "error": "NameError(\"name 'diversity_factor' is not defined\")", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {}, "mutation_prompt": null}
{"id": "bf0e1c6b-0177-4c58-8a8c-ea9c11c2fab6", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.mutation_factor = 0.5 + 0.5 * eval_ratio  # Adaptive mutation factor\n            self.crossover_rate = 0.5 + 0.5 * (1 - eval_ratio)  # Adaptive crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced adaptive mutation and crossover rates based on the evaluation ratio to enhance exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.9483014287341843, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.022. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.960758098111269, 0.9173217813856034, 0.9668244067056808], "final_y": [0.16633737938988002, 0.18432911795167706, 0.16677286054236917]}, "mutation_prompt": null}
{"id": "5bbb8704-d6d5-4dfd-ba50-d80d6f0797d1", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n        self.learning_rate = 0.1  # Added learning rate\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.var(population) / (np.var(population) + 1)  # Enhanced diversity calculation\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        learning_factor = self.learning_rate * self.budget / (self.budget + len(self.history))  # Adaptive learning rate\n        mutant = a + dynamic_factor * historical_factor * learning_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))\n        perturbation = gradient * (solution - np.mean(self.history))  # Enhanced perturbation calculation\n        new_solution = solution - intensity * perturbation\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrates a dynamically adaptive learning rate and diversity management for balanced exploration and exploitation in optimization.", "configspace": "", "generation": 39, "fitness": 0.9613647298996476, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9541884382523557, 0.9626688323924982, 0.9672369190540892], "final_y": [0.16669692606856634, 0.16696696247071985, 0.16747095583325444]}, "mutation_prompt": null}
{"id": "4ddcfb56-7316-4781-b8b1-7279fcf454ff", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio)  # Time-varying crossover rate based on eval_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced mutation strategy with time-varying crossover rates based on historical performance.", "configspace": "", "generation": 40, "fitness": 0.9437946146403755, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.031. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9003327596635109, 0.9579042140576005, 0.9731468702000149], "final_y": [0.1846490000387474, 0.16773664472205085, 0.16664229101446226]}, "mutation_prompt": null}
{"id": "299ddd64-d91a-4565-a6c9-9e748230d21b", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            self.crossover_rate = min(0.9, 0.1 + 0.8 * (1 - np.std(scores) / np.mean(scores)))  # Adaptive crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce an adaptive crossover rate based on historical diversity to improve convergence.", "configspace": "", "generation": 41, "fitness": 0.909609810724576, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.019. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9366432117957078, 0.8990337877255733, 0.893152432652447], "final_y": [0.16676843616861292, 0.18375543733694955, 0.1904046920186412]}, "mutation_prompt": null}
{"id": "a38d3b31-3dec-4ba2-828d-6e980d615fb8", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < (q * 0.5 + 0.5)  # Altered quantum flip probability\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history[-self.population_size:]) / (np.mean(self.history[-self.population_size:]) + 1)  # Recent history\n        mutant = a + dynamic_factor * historical_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def dynamic_crossover(self, trial_solution, target_solution, eval_ratio):\n        crossover_prob = self.crossover_rate * (1 - eval_ratio)\n        crossover = np.random.rand(self.dim) < crossover_prob  # Dynamic crossover rate\n        return np.where(crossover, trial_solution, target_solution)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * np.std(self.history) / (np.max(self.history) + 1))  # Enhanced normalization\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.dynamic_crossover(mutant, best_solution, eval_ratio)  # Dynamic crossover\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrating dynamic crossover and quantum-enhanced local search for adaptive optimization.", "configspace": "", "generation": 42, "fitness": 0.8957430545419821, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.083. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9582237708499433, 0.9512227414253385, 0.7777826513506646], "final_y": [0.1666274772976828, 0.16690918882315708, 0.22076256702255814]}, "mutation_prompt": null}
{"id": "2c505bd3-022d-44c2-aca1-d461bd7bf3a7", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        mutant = a + dynamic_factor * historical_factor * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            self.crossover_rate = 0.7 + 0.3 * (1 - (np.std(population) / (np.std(population) + 1)))  # Adaptive crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introducing an adaptive crossover rate based on the population's diversity to balance exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.9571065488957916, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9532109713583848, 0.9601865999445803, 0.9579220753844098], "final_y": [0.16704592221299142, 0.16732005838810393, 0.1680068753890428]}, "mutation_prompt": null}
{"id": "f7ab8dfd-b075-4195-9104-e7e8030a0327", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced adaptive scaling by introducing history-based noise reduction for maintaining diversity.", "configspace": "", "generation": 44, "fitness": 0.9623478760404262, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "879f0788-0ee9-4078-b56a-a96ff429993e", "metadata": {"aucs": [0.9553318328161036, 0.9647144914803503, 0.9669973038248244], "final_y": [0.1669080365828871, 0.16638428373632796, 0.1675867054114576]}, "mutation_prompt": null}
{"id": "0b55377c-5640-4b49-ab58-6cb8e6af24a8", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        self.history.extend(scores)\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget \n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.3  # Dynamic crossover rate adjustment\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Dynamically adjust crossover rate based on historical success rate to improve convergence speed.", "configspace": "", "generation": 45, "fitness": 0.9473480052122826, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.024. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f7ab8dfd-b075-4195-9104-e7e8030a0327", "metadata": {"aucs": [0.9649622639971744, 0.9131938708673448, 0.9638878807723283], "final_y": [0.1667239077038215, 0.184764114601484, 0.16801206327114326]}, "mutation_prompt": null}
{"id": "b6010d9d-0011-41c8-9922-0ad9daefb039", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        diversity = np.std(solution) / (np.std(solution) + 1)  # Compute diversity\n        q = np.random.rand(self.dim) * (1 - diversity)  # Adjust q based on diversity\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history))\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive quantum bit flip probability based on population diversity to enhance exploration.", "configspace": "", "generation": 46, "fitness": 0.7774235109244989, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.068. And the mean value of best solutions found was 0.227 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "f7ab8dfd-b075-4195-9104-e7e8030a0327", "metadata": {"aucs": [0.7057468901025817, 0.8685562629216845, 0.7579673797492305], "final_y": [0.26360499046067987, 0.18567503023762977, 0.23177149428159982]}, "mutation_prompt": null}
{"id": "27f66b1e-7712-448a-abdf-2e9eabd65e59", "solution": "import numpy as np\n\nclass DynamicQuantumSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.alpha = 0.5  # Cognitive weight\n        self.beta = 0.3   # Social weight\n        self.gamma = 0.2  # Inertia weight\n        self.history = []\n\n    def quantum_update(self, particle, personal_best, global_best):\n        q = np.random.rand(self.dim)\n        c1 = self.alpha * np.random.rand(self.dim) * (personal_best - particle)\n        c2 = self.beta * np.random.rand(self.dim) * (global_best - particle)\n        inertia = self.gamma * q * (global_best - personal_best)\n        new_particle = particle + c1 + c2 + inertia\n        return np.clip(new_particle, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 3))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        personal_bests = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_bests])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_bests[global_best_idx]\n\n        self.history.extend(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                new_particle = self.quantum_update(population[i], personal_bests[i], global_best)\n                new_score = func(new_particle)\n                evaluations += 1\n\n                if new_score < personal_best_scores[i]:\n                    personal_bests[i] = new_particle\n                    personal_best_scores[i] = new_score\n\n                new_population.append(new_particle)\n\n                if new_score < personal_best_scores[global_best_idx]:\n                    global_best = new_particle\n                    global_best_idx = i\n\n            population = np.array(new_population)\n            self.history.extend(personal_best_scores)\n\n        return global_best, personal_best_scores[global_best_idx], self.history", "name": "DynamicQuantumSwarmOptimization", "description": "Dynamic Quantum Swarm Optimization leveraging adaptive quantum-inspired updates with self-balancing social and cognitive components.", "configspace": "", "generation": 47, "fitness": 0.9486686579695477, "feedback": "The algorithm DynamicQuantumSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.015. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f7ab8dfd-b075-4195-9104-e7e8030a0327", "metadata": {"aucs": [0.959237802120708, 0.9593421944274383, 0.9274259773604967], "final_y": [0.1724129424889047, 0.17124230780355598, 0.18245932255839226]}, "mutation_prompt": null}
{"id": "c8f54b65-0994-4acd-a59f-a30f65f865e7", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / np.max(self.history)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()  # Randomized intensity\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget \n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1  # Adaptive crossover rate adjustment\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced adaptive crossover rate adjustment and enhanced local search to improve convergence speed and robustness.", "configspace": "", "generation": 48, "fitness": 0.9742943714029249, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f7ab8dfd-b075-4195-9104-e7e8030a0327", "metadata": {"aucs": [0.9704103389762068, 0.9716888934769384, 0.9807838817556296], "final_y": [0.16506381904091938, 0.1649216544944495, 0.16495551534668285]}, "mutation_prompt": null}
{"id": "b1089076-e220-49a2-9640-6a6f711bf645", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))  # Normalized intensity\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()  # Randomized intensity\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget \n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1  # Adaptive crossover rate adjustment\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduced a normalized intensity factor in local search to enhance solution exploitation while maintaining a minimal change rate.", "configspace": "", "generation": 49, "fitness": 0.9742943723837888, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8f54b65-0994-4acd-a59f-a30f65f865e7", "metadata": {"aucs": [0.9704103421195445, 0.9716888935535618, 0.9807838814782606], "final_y": [0.16506381875566, 0.16492165436172124, 0.1649555155725636]}, "mutation_prompt": null}
{"id": "1b567128-e8b5-48a9-a37a-48dcb6667979", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = 1 / (1 + np.abs(np.mean(self.history)))  # Adjusted historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))  \n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        exploration_factor = 0.5 * np.random.rand(self.dim)  # New exploration factor\n        new_solution += exploration_factor * (self.bounds.ub - self.bounds.lb) * np.random.normal(size=self.dim)\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget \n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1  \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced synergy of quantum and differential strategies with adaptive search mechanisms for improved convergence.", "configspace": "", "generation": 50, "fitness": 0.6817822231107162, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.682 with standard deviation 0.051. And the mean value of best solutions found was 0.260 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "b1089076-e220-49a2-9640-6a6f711bf645", "metadata": {"aucs": [0.611747109777445, 0.7023201750154409, 0.7312793845392629], "final_y": [0.3108686198795475, 0.2239855116126208, 0.24482112925570831]}, "mutation_prompt": null}
{"id": "6c37c1dd-54ab-4db0-8725-4c7bcacb0d4f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.55  # Adjusted mutation factor\n        self.crossover_rate = 0.75  # Adjusted crossover rate\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)  # Diversity factor\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)  \n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)  # Historical factor\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))  # New noise reduction factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * (b - c)  # Enhanced mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))  # Normalized intensity\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()  # Randomized intensity\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)  \n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget \n            self.crossover_rate = 0.75 * (1 - eval_ratio) + 0.1  # Adaptive crossover rate adjustment\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced solution exploitation through a refined mutation strategy and dynamic crossover adaptation.", "configspace": "", "generation": 51, "fitness": 0.9692066991348337, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b1089076-e220-49a2-9640-6a6f711bf645", "metadata": {"aucs": [0.9557309017386979, 0.971850019721768, 0.9800391759440352], "final_y": [0.16500717016234367, 0.16492434175222326, 0.1649390837274889]}, "mutation_prompt": null}
{"id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)  # New constraint adaptation\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introducing a dynamic constraint adaptation mechanism to balance exploration and exploitation by adjusting the mutation and crossover strategies based on the diversity and quality of solutions.", "configspace": "", "generation": 52, "fitness": 0.9747916620402393, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b1089076-e220-49a2-9640-6a6f711bf645", "metadata": {"aucs": [0.9722214170971512, 0.9712878677444243, 0.9808657012791423], "final_y": [0.16503525267378638, 0.1649045372809973, 0.16499378922880725]}, "mutation_prompt": null}
{"id": "7446f3a9-8966-4f03-b601-bb79b1d10239", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))\n        intensity *= np.random.choice([0.5, 1.0, 1.5])  # Adaptive intensity adjustment\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            best_cluster = np.mean(population[np.argsort(scores)[:3]], axis=0)  # Cluster top solutions\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_cluster)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Incorporating adaptive local search intensity and historical solution clustering to enhance convergence and diversity in solution space.", "configspace": "", "generation": 53, "fitness": 0.9669375849130751, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.9541650945445629, 0.9766519554248365, 0.9699957047698259], "final_y": [0.16501938425178841, 0.16493259604927668, 0.16508752980112018]}, "mutation_prompt": null}
{"id": "f929fbe8-9bac-4a16-8881-b424bbe2c706", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)  # New constraint adaptation\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)**0.5))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance local search by refining the intensity calculation for better convergence control.", "configspace": "", "generation": 54, "fitness": 0.9747894217930361, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.9722217297795109, 0.9712878095463672, 0.9808587260532301], "final_y": [0.16503516906250115, 0.16490450965163772, 0.16500001412896026]}, "mutation_prompt": null}
{"id": "f4cc9305-5bb9-4e5d-9937-c648a692db6e", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * (0.5 + 0.5 * np.random.rand())\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance the algorithm's efficiency by modifying the local search component to improve convergence speed through a more adaptive gradient scaling approach.", "configspace": "", "generation": 55, "fitness": 0.9356789201239386, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.023. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.9684045923829003, 0.9143304898837136, 0.9243016781052021], "final_y": [0.16560630286151956, 0.18357049667432856, 0.18305920689605526]}, "mutation_prompt": null}
{"id": "12c9dd66-af6a-498d-b921-cdf65b01d614", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        # Prioritize lower score regions\n        sorted_indices = np.argsort(self.history) if self.history else np.arange(self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        population[sorted_indices[:self.population_size//2]] = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size//2, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution exploitation by updating population initialization strategy to prioritize regions with previously observed lower scores.", "configspace": "", "generation": 56, "fitness": 0.9229141793194647, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.007. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.9323448950821881, 0.9140088731606559, 0.9223887697155501], "final_y": [0.16497315345089825, 0.1819972491531825, 0.1819714352879036]}, "mutation_prompt": null}
{"id": "7643a00a-1f4a-470b-ba63-0a5b3f943841", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        noise_scale = np.random.rand()  # New line added for noise scaling\n        gradient = np.random.normal(scale=0.1 * noise_scale, size=self.dim)  # Modified line\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.max(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhancing solution diversity and convergence by introducing a noise scaling factor to the local search gradient calculation.", "configspace": "", "generation": 57, "fitness": 0.9025566899476143, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.100. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.7617000083639279, 0.9711072839434622, 0.9748627775354529], "final_y": [0.24173697361261548, 0.16486819896349036, 0.16486390912476057]}, "mutation_prompt": null}
{"id": "33ad6fc8-2f0c-40e8-baa1-c6d48344fd53", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)  # New constraint adaptation\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance local search precision by adjusting intensity based on evaluation progress and solution variance.", "configspace": "", "generation": 58, "fitness": 0.9753705313216566, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db23a254-02bf-4893-88e9-6db9cbc66bfa", "metadata": {"aucs": [0.9736735387898464, 0.9715472889276906, 0.9808907662474328], "final_y": [0.16487940705589665, 0.16487774923777787, 0.1649435385278416]}, "mutation_prompt": null}
{"id": "76e62a10-7f40-4a2d-a85b-b03de7b2882e", "solution": "import numpy as np\n\nclass CoevolutionaryParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.history = []\n        self.velocity_clamp = 0.1\n\n    def adapt_weights(self, diversity, eval_ratio):\n        self.inertia_weight = 0.7 + 0.3 * (1 - diversity)\n        self.cognitive_weight = 1.5 * (1 + eval_ratio)\n        self.social_weight = 1.5 * (1 - eval_ratio)\n\n    def update_velocity(self, particle_velocity, particle_position, personal_best, global_best):\n        cognitive_component = self.cognitive_weight * np.random.rand(self.dim) * (personal_best - particle_position)\n        social_component = self.social_weight * np.random.rand(self.dim) * (global_best - particle_position)\n        new_velocity = self.inertia_weight * particle_velocity + cognitive_component + social_component\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        particles = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.swarm_size, self.dim))\n        personal_bests = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_bests])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_bests[global_best_idx]\n\n        self.history.extend(personal_best_scores)\n\n        evaluations = self.swarm_size\n        while evaluations < self.budget:\n            diversity = np.std(personal_best_scores) / (np.mean(personal_best_scores) + 1e-9)\n            eval_ratio = evaluations / self.budget\n            self.adapt_weights(diversity, eval_ratio)\n\n            for i in range(self.swarm_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.bounds.lb, self.bounds.ub)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                    if score < personal_best_scores[global_best_idx]:\n                        global_best_idx = i\n                        global_best = personal_bests[i]\n\n            self.history.extend(personal_best_scores)\n\n        return global_best, personal_best_scores[global_best_idx], self.history", "name": "CoevolutionaryParticleSwarmOptimization", "description": "Implement a Coevolutionary Particle Swarm Optimization that adapts swarm intelligence based on historical interactions and environmental changes to dynamically balance exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.479276755622319, "feedback": "The algorithm CoevolutionaryParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.479 with standard deviation 0.021. And the mean value of best solutions found was 0.416 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "33ad6fc8-2f0c-40e8-baa1-c6d48344fd53", "metadata": {"aucs": [0.45113232820745175, 0.5005746790402701, 0.48612325961923497], "final_y": [0.43045419098679993, 0.40296286833200956, 0.4154906861836606]}, "mutation_prompt": null}
{"id": "49c71af3-6d46-4650-8cb2-e5cb5996d4a6", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)  # New constraint adaptation\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient_scale = np.std(np.abs(solution - np.median(self.history)))  # Adjusted line\n        gradient = np.random.normal(scale=gradient_scale, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improve exploration by dynamically adjusting gradient scale based on current solution's deviation from median history.", "configspace": "", "generation": 60, "fitness": 0.4697914476014535, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.470 with standard deviation 0.038. And the mean value of best solutions found was 0.425 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "33ad6fc8-2f0c-40e8-baa1-c6d48344fd53", "metadata": {"aucs": [0.41692516597521967, 0.5074041173367747, 0.4850450594923661], "final_y": [0.46448156522732287, 0.3947787054336236, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "fef00447-a517-4934-8279-43b62bba9c85", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Augment exploration by incorporating adaptive mutation scale based on historical variance.", "configspace": "", "generation": 61, "fitness": 0.975377675720885, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33ad6fc8-2f0c-40e8-baa1-c6d48344fd53", "metadata": {"aucs": [0.9736916251192197, 0.9715475560654043, 0.9808938459780306], "final_y": [0.16487896359664822, 0.16489508127557917, 0.16494174048912358]}, "mutation_prompt": null}
{"id": "3a69005e-6d44-4074-826d-3c20b10fd4e3", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)  # Adjusted mutation scale\n        adaptive_variance = np.sqrt(np.var(self.history) + 1)  # Added adaptive variance scaling\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * adaptive_variance * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance exploration efficiency by adjusting mutation factor with adaptive variance scaling.", "configspace": "", "generation": 62, "fitness": 0.9753776730461058, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.9736916286106122, 0.9715475482961249, 0.9808938422315799], "final_y": [0.16487896282431058, 0.16489508223869342, 0.1649417423025673]}, "mutation_prompt": null}
{"id": "e890a07e-c413-4417-98ed-35f2fe620b88", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q * np.std(self.history)  # Adaptive scaling based on diversity\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance exploration by refining quantum bit flip with adaptive scaling based on diversity.", "configspace": "", "generation": 63, "fitness": 0.8891367859981069, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.005. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.8880000049871136, 0.883564675286715, 0.8958456777204921], "final_y": [0.18262719491204948, 0.1826727233684683, 0.18266113983405263]}, "mutation_prompt": null}
{"id": "18c4a099-0b34-429a-8d7a-82a4c0f0102f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)\n        perturbation = np.random.normal(loc=0.0, scale=0.1, size=self.dim)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c) + perturbation\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improve exploration by incorporating dynamic diversification using historical variance-enhanced mutation scale with perturbation.", "configspace": "", "generation": 64, "fitness": 0.936639005091764, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.026. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.9721538594667387, 0.9257995547905543, 0.911963601017999], "final_y": [0.16500617059694445, 0.18198182773289318, 0.18196887209464163]}, "mutation_prompt": null}
{"id": "9e3c1f34-5b78-45e4-a4ea-86b80a1f549e", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.8 * (1 - eval_ratio) + 0.1  # Adjusted crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution accuracy by fine-tuning mutation and crossover mechanisms based on evaluation progress.", "configspace": "", "generation": 65, "fitness": 0.9579491440205049, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.9383499328859901, 0.9648333358959496, 0.970664163279575], "final_y": [0.16493238858956372, 0.16499073432342148, 0.16492090270945048]}, "mutation_prompt": null}
{"id": "fe32e2f1-5374-491e-952d-62ea8749f5cb", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history) / (np.var(self.history) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history)) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * (np.std(scores) / (np.std(scores) + 1))  # Line changed for adaptive crossover\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrate adaptive crossover rate adjustment based on population variance to enhance convergence.", "configspace": "", "generation": 66, "fitness": 0.9367206944788237, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.028. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.9753130086388687, 0.9094545360685339, 0.9253945387290685], "final_y": [0.16492024207759715, 0.18192680951497198, 0.18230608565753637]}, "mutation_prompt": null}
{"id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()  # Adjusted local search\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution diversity and convergence by adjusting mutation scale based on elite history variance.", "configspace": "", "generation": 67, "fitness": 0.9754918234515898, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fef00447-a517-4934-8279-43b62bba9c85", "metadata": {"aucs": [0.973360644551407, 0.9717803456313734, 0.9813344801719888], "final_y": [0.16490435095650546, 0.1649015101357143, 0.1648765257376965]}, "mutation_prompt": null}
{"id": "bfe1331b-574f-4486-9c46-281b7f189b58", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.exp(-np.std(self.history) / (np.mean(self.history) + 1e-5))  # Modified constraint factor\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history[-5:]) / (np.mean(self.history[-5:]) + 1e-5)))  # Adjusted intensity\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution exploration by dynamically adjusting mutation constraints and search intensity based on historical variance.", "configspace": "", "generation": 68, "fitness": 0.9753621944999785, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.973280911979957, 0.9720886208016001, 0.9807170507183786], "final_y": [0.1649144125152635, 0.16491014543841898, 0.16493577077449473]}, "mutation_prompt": null}
{"id": "db6dadd1-0690-40ab-81e8-56a5ca00c432", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        fitness_variance = np.var([func(a), func(b), func(c)])  # New line: Incorporate fitness variance\n        mutation_scale = (np.var(self.history[-10:]) + fitness_variance) / (np.var(self.history[-10:]) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Refine mutation scale by incorporating fitness variance for enhanced exploration.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {}, "mutation_prompt": null}
{"id": "f0af9d80-8aa3-4e40-b7a4-81dc832d6a6b", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)  # Adjusted mutation scale\n        adaptive_trend = np.exp(-np.abs(np.diff(self.history[-10:])).sum() / (len(self.history[-10:]) + 1))  # New adaptive trend\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * adaptive_trend * (b - c)  # Modified mutant\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()  # Adjusted local search\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * np.mean(np.diff(self.history[-10:]))  # Modified crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate and mutation scale based on historical improvement trend to enhance convergence speed and solution quality.", "configspace": "", "generation": 70, "fitness": 0.9561926848578103, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.020. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9765631122230429, 0.9622715079840861, 0.9297434343663018], "final_y": [0.16490853979027675, 0.16494601578323365, 0.18196440148571535]}, "mutation_prompt": null}
{"id": "e52d0f8d-098c-4071-a6f3-7a45039c221a", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)  # Adjusted mutation scale\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()  # Adjusted local search\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * (np.std(scores) / (np.std(scores) + 1e-5))  # Dynamic crossover rate based on diversity\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce a dynamic crossover rate based on population diversity to enhance convergence.", "configspace": "", "generation": 71, "fitness": 0.9753862960368603, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9733544383000241, 0.9718709361776807, 0.9809335136328763], "final_y": [0.16495669661418222, 0.1649018602192246, 0.1649459640813009]}, "mutation_prompt": null}
{"id": "0f625845-5a85-4ef8-b40f-582f7ec6dfc8", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)  # Adjusted mutation scale\n        exploration_prob = 0.1 + 0.9 * (1 - diversity_factor)  # New exploration probability\n        if np.random.rand() < exploration_prob:  # Add exploration mechanism\n            mutant = np.random.uniform(self.bounds.lb, self.bounds.ub, self.dim)\n        else:\n            mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()  # Adjusted local search\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce a probability-based exploration mechanism to enhance diversity and convergence.", "configspace": "", "generation": 72, "fitness": 0.9530932062868778, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.034. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9746153233236431, 0.979246570745173, 0.9054177247918171], "final_y": [0.16490972052759245, 0.16492243232764836, 0.18202317214431607]}, "mutation_prompt": null}
{"id": "668b7660-7752-4b30-a60d-e7f0ebde5f5d", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1) + np.random.normal(0, 0.1)  # Adjusted mutation scale with noise\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()  # Adjusted local search\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 + np.random.normal(0, 0.05)  # Adjusted crossover rate with noise\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Improve mutation diversity by integrating a noise factor into the crossover rate and mutation scale.", "configspace": "", "generation": 73, "fitness": 0.9562405416487998, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9751023382888852, 0.9701766616208856, 0.9234426250366287], "final_y": [0.16493313439203927, 0.16494375748063794, 0.1819338207482697]}, "mutation_prompt": null}
{"id": "498e5a77-57e4-4dfa-bd86-b141890be371", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def adaptive_crossover(self, score_ratio):\n        return self.crossover_rate * (1 - score_ratio) + 0.3\n\n    def global_communication(self, population, best_solution):\n        return np.mean(population, axis=0) + 0.3 * (best_solution - np.mean(population, axis=0))\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best, global_com):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        mutation_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)\n        gamma = 0.1 * (global_com - a)\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c) + gamma\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            global_com = self.global_communication(population, best_solution)\n            for i in range(self.population_size):\n                score_ratio = scores[i] / (np.max(scores) + 1e-5)\n                self.crossover_rate = self.adaptive_crossover(score_ratio)\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution, global_com)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce a global communication strategy and adaptive crossover to enhance solution convergence and diversity in quantum adaptive differential optimization.", "configspace": "", "generation": 74, "fitness": 0.9630652236277036, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9582786002868129, 0.9639304005770414, 0.9669866700192565], "final_y": [0.16494487715546968, 0.1648982981627345, 0.16494676681408182]}, "mutation_prompt": null}
{"id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)  # Introduced decay factor\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor  # Adjusted mutation scale with decay\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Further refine solution accuracy by introducing a decay factor on mutation scale based on iterations.", "configspace": "", "generation": 75, "fitness": 0.9754918286995661, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08c4d904-6f48-45d3-a9c7-4db282e66e9d", "metadata": {"aucs": [0.9733606499362204, 0.9717803479261985, 0.9813344882362791], "final_y": [0.16490435034402118, 0.1649015094962526, 0.16487652467593483]}, "mutation_prompt": null}
{"id": "11ef6ecc-f4aa-4b2e-876a-5d8234a40a7f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio * decay_factor) + 0.1  # Modified crossover rate with decay\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Refine solution accuracy by introducing a decay factor in crossover rate based on iterations.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'decay_factor' is not defined\").", "error": "NameError(\"name 'decay_factor' is not defined\")", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {}, "mutation_prompt": null}
{"id": "c5e4da50-20ff-41bf-9424-71740e9f1d5c", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)  # Introduced decay factor\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor  # Adjusted mutation scale with decay\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1 * (1 + np.std(self.history)), size=self.dim)  # Dynamic gradient scale\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce a dynamic gradient scale adapting to the current diversity to enhance exploration.", "configspace": "", "generation": 77, "fitness": 0.9403525177205877, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.027. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9781801136469548, 0.9137836816990342, 0.9290937578157743], "final_y": [0.16493828860313686, 0.18203702554794043, 0.1820151868084363]}, "mutation_prompt": null}
{"id": "58aa4c58-2641-4795-9838-fc0ba1ac768f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n        self.learning_rate = 0.01  # Introduced adaptive learning rate\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        adapt_factor = 1 + self.learning_rate * np.mean(self.history)  # Adaptive learning component\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c) * adapt_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive learning rates and diversity-driven mutation to enhance convergence and solution quality.", "configspace": "", "generation": 78, "fitness": 0.9754918275454129, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9733606485081627, 0.9717803478090159, 0.9813344863190601], "final_y": [0.16490435047555707, 0.16490150965772532, 0.16487652497048888]}, "mutation_prompt": null}
{"id": "83b52d94-0250-4d48-8624-47aef2716ec0", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * (np.mean(scores[:10]) / (np.mean(self.history) + 1e-5))  # Change made here\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce an adaptive crossover rate based on historical improvement to enhance exploration.", "configspace": "", "generation": 79, "fitness": 0.955252423604917, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9257590886450888, 0.9627471065681209, 0.9772510756015413], "final_y": [0.18195168918534732, 0.16497007651216145, 0.1649439011911843]}, "mutation_prompt": null}
{"id": "bedd9330-3f3f-4fe3-8d60-d25ed38ae320", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)  # Introduced decay factor\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor  # Adjusted mutation scale with decay\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.2  # Adjusted crossover rate modulation\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate modulation for improved exploration and exploitation balancing.", "configspace": "", "generation": 80, "fitness": 0.9485216364736272, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9207156667296337, 0.9692733371228593, 0.9555759055683888], "final_y": [0.165265299918109, 0.16497461732559637, 0.1649865862122728]}, "mutation_prompt": null}
{"id": "d5916384-86f3-437d-8d70-d1c140846c5b", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * np.std(scores) / (np.mean(scores) + 1)  # Changed crossover rate adjustment\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate adjustment based on historical performance to enhance solution diversity.", "configspace": "", "generation": 81, "fitness": 0.9385411177571136, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.027. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9760071506450182, 0.9113095124693276, 0.9283066901569947], "final_y": [0.1649560928747017, 0.18200439164127702, 0.18202689509739467]}, "mutation_prompt": null}
{"id": "63b76e0c-9c23-4d6b-a767-dd7ef4a2e3ff", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            diversity_adaptive_rate = 0.5 + 0.5 * (1 - np.std(scores) / (np.mean(scores) + 1e-5))  # Change 1\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + diversity_adaptive_rate  # Change 2\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate based on diversity to enhance exploration and solution quality refinement.", "configspace": "", "generation": 82, "fitness": 0.9751032481173337, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9653276134463505, 0.9769431904480566, 0.983038940457594], "final_y": [0.16486305491550712, 0.16486958991413192, 0.16486222782631377]}, "mutation_prompt": null}
{"id": "bb6bbd37-738f-4ab4-9493-421a87bb5b92", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - np.std(population) / (np.std(population) + 1)) + 0.1  # Changed line\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance mutation adaptability by incorporating a dynamic crossover rate based on solution diversity.", "configspace": "", "generation": 83, "fitness": 0.8846211606587708, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.026. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9098600168663512, 0.8945194323850592, 0.8494840327249022], "final_y": [0.16534476850122515, 0.18228344878848546, 0.18275262489023492]}, "mutation_prompt": null}
{"id": "e5dc11d6-8d12-492f-848d-72540bd3446b", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        # Adjusted mutation scale with self-adaptive mechanism\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor * (1 + np.std(self.history[-10:]))\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhanced adaptive mutation scale by incorporating a self-adaptive mechanism based on historical performance trends.", "configspace": "", "generation": 84, "fitness": 0.9754917895685472, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9733606170009608, 0.971780340363273, 0.9813344113414079], "final_y": [0.1649043535504543, 0.16490151446946266, 0.16487653591071116]}, "mutation_prompt": null}
{"id": "54d3459f-4ee9-44ca-b40f-db09a190d1c7", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1 * diversity_factor  # Adjusted crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    self.mutation_factor = 0.5 * (1 + diversity_factor)  # Adjusted mutation factor\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution exploration by dynamically adapting crossover rate and mutation factor based on population diversity.", "configspace": "", "generation": 85, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'diversity_factor' is not defined\").", "error": "NameError(\"name 'diversity_factor' is not defined\")", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {}, "mutation_prompt": null}
{"id": "4dbfcb59-6014-40a5-8569-c62023eada98", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        adaptive_gradient = intensity * gradient * (solution - np.mean(self.history[-5:])) \n        new_solution = solution - adaptive_gradient * np.random.normal(scale=0.5)\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.9 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance local search with adaptive gradient scaling and dynamic crossover to improve solution refinement.", "configspace": "", "generation": 86, "fitness": 0.9578238506059801, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.025. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.967881941440664, 0.9235606662257917, 0.9820289441514842], "final_y": [0.1648793527393122, 0.18190807273630238, 0.16487927792978307]}, "mutation_prompt": null}
{"id": "b7ca8082-082d-4ed5-a0cb-73bfe7fbfb54", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            diversity_factor = np.std(scores) / (np.std(scores) + 1)  # New line\n            self.crossover_rate = 0.7 * (1 - eval_ratio * diversity_factor) + 0.1  # Modified line\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Introduce adaptive crossover rate enhanced by population diversity for improved convergence.", "configspace": "", "generation": 87, "fitness": 0.9414110708303185, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.050. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9746513474353007, 0.8705307749209168, 0.9790510901347381], "final_y": [0.1648968463940622, 0.20066703409951336, 0.1648692187339279]}, "mutation_prompt": null}
{"id": "1f53a59b-be6e-48d8-9b07-4ee4b5b9c043", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def chaotic_map(self, n):\n        return 0.7 * n * (1 - n)  # Logistic map for chaos\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        chaotic_factor = self.chaotic_map(np.random.rand())  # Introduce chaotic factor\n        adaptive_factor = chaotic_factor * (1 - diversity_factor)  # Adaptive mutation\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + adaptive_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        learning_rate = 0.1 * np.sin(np.pi * eval_ratio)  # Oscillating learning rate\n        new_solution = solution - learning_rate * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance the search efficiency by introducing adaptive learning and chaotic maps for parameter tuning.", "configspace": "", "generation": 88, "fitness": 0.8389690947877554, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.117. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.6798372204894343, 0.9558079534752323, 0.8812621103985998], "final_y": [0.2629653771913645, 0.16510396844866948, 0.1702789860665943]}, "mutation_prompt": null}
{"id": "19f359d5-b6e2-4840-9cf7-e525d001301f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.5 + 0.2 * (1 - eval_ratio)  # Adjusted dynamic crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance adaptive strategies through dynamic crossover rate adjustments.", "configspace": "", "generation": 89, "fitness": 0.9243136389119709, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.047. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9800594751833811, 0.8660214252502814, 0.9268600163022503], "final_y": [0.1648922010358438, 0.20060072411296515, 0.1819341733336366]}, "mutation_prompt": null}
{"id": "3bd9e65d-1b87-4e7c-9297-87a60cd41464", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + diversity_factor * 0.3  # Adjusted crossover rate\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    if diversity_factor > 0.5:  # Strategy blending based on diversity\n                        trial_solution = self.differential_mutation(population, best_solution)\n                    else:\n                        trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance convergence precision by introducing a dynamic crossover rate and strategy blending based on diversity.", "configspace": "", "generation": 90, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'diversity_factor' is not defined\").", "error": "NameError(\"name 'diversity_factor' is not defined\")", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {}, "mutation_prompt": null}
{"id": "4268b1d4-fbb8-46a9-b0a0-4e6328664cab", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) + 1e-6) * decay_factor  # Enhanced mutation scale adaptation\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            elite = np.argmin(scores)  # Elite preservation\n            population = np.array(new_population)\n            population[elite] = best_solution  # Preserve elite solution\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution exploration by adapting mutation based on historical variance and introducing elite preservation.", "configspace": "", "generation": 91, "fitness": 0.975485944471298, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9733606445493789, 0.9717655894807976, 0.9813315993837176], "final_y": [0.16490435087566402, 0.16490150835157247, 0.16488125782625918]}, "mutation_prompt": null}
{"id": "880d7cef-3e35-474c-9aeb-970892e858fa", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        probabilistic_factor = np.random.uniform(0.5, 1.5)  # New probabilistic factor\n        mutant = a + self.mutation_factor * historical_factor * mutation_scale * probabilistic_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        probabilistic_adjustment = np.random.uniform(0.8, 1.2)  # New probabilistic adjustment\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * probabilistic_adjustment\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance solution diversity and selection precision through adaptive scaling and probabilistic local search integration.", "configspace": "", "generation": 92, "fitness": 0.9456850698999895, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.030. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.903269353899141, 0.969796516382468, 0.9639893394183593], "final_y": [0.18315192222804133, 0.16581172089913798, 0.16600113796790794]}, "mutation_prompt": null}
{"id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        self.mutation_factor *= (1 - len(self.history) / self.budget)  # Dynamic mutation factor adjustment\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance the optimization process by integrating a dynamic adjustment to the mutation factor, decreasing it as evaluations approach the budget limit for refined exploration.", "configspace": "", "generation": 93, "fitness": 0.9754919835167817, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "139409eb-e93a-42f8-8b95-cedc2a7d243e", "metadata": {"aucs": [0.9733608025605022, 0.9717804418557148, 0.9813347061341278], "final_y": [0.16490433177901676, 0.16490148907877888, 0.16487649730869203]}, "mutation_prompt": null}
{"id": "baaa83c5-3060-4de3-a984-149817a14c36", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        self.mutation_factor *= (1 - len(self.history) / self.budget)  # Dynamic mutation factor adjustment\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            adaptive_success_rate = np.mean(self.history) / (np.mean(self.history) + 1)  # New line\n            self.crossover_rate = 0.7 * (1 - adaptive_success_rate) + 0.1  # Modified line\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrate an adaptive crossover rate adjustment based on historical success to enhance exploration-exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.9362019483635695, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.036. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.8857895750290291, 0.961530913053768, 0.9612853570079113], "final_y": [0.1649668050355969, 0.164894182685684, 0.1648872315124501]}, "mutation_prompt": null}
{"id": "13068475-80bb-4fef-b7bc-38f1c9146e5f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        adaptive_scale = np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = adaptive_scale * decay_factor\n        exploration_factor = 1 - np.mean(self.history[-10:]) / (np.max(self.history[-10:]) + 1e-5)\n        self.mutation_factor *= (1 - len(self.history) / self.budget) \n        mutant = a + self.mutation_factor * diversity_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * exploration_factor * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Refine the optimization process by incorporating adaptive exploration-exploitation balance using historical performance to enhance solution quality.", "configspace": "", "generation": 95, "fitness": 0.9754915226948793, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.973360191316415, 0.9717815371979616, 0.9813328395702611], "final_y": [0.16490435201267772, 0.16490150992113717, 0.1648768141390875]}, "mutation_prompt": null}
{"id": "e07f9460-8fba-4cd5-b8f6-53d24fb8f1a0", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best, diversity):\n        q = np.random.rand(self.dim) * (1 - diversity)  # Line modified to adjust quantum bit flip probability\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        self.mutation_factor *= (1 - len(self.history) / self.budget)  # Dynamic mutation factor adjustment\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                diversity = np.std(population) / (np.mean(population) + 1e-5)\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution, diversity)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance exploration by dynamically adjusting the quantum bit flip probability based on the diversity of the population.", "configspace": "", "generation": 96, "fitness": 0.9327940668987579, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.021. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.9236083534837818, 0.9619388843228642, 0.9128349628896275], "final_y": [0.16504935714987523, 0.1649106800873168, 0.18195409636112625]}, "mutation_prompt": null}
{"id": "5e085824-d5a9-43f8-b7c4-2b9722d0f9a0", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        multiscale_factor = np.random.uniform(0.5, 1.5)  # Multi-scale mutation adjustment\n        self.mutation_factor *= (1 - len(self.history) / self.budget)  # Dynamic mutation factor adjustment\n        mutant = a + multiscale_factor * dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Integrate a multi-scale mutation strategy to diversify exploration while maintaining convergence balance.", "configspace": "", "generation": 97, "fitness": 0.9356953627082092, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.054. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.8596113346152382, 0.9804899144909445, 0.966984839018445], "final_y": [0.20066279631601724, 0.16493075627693266, 0.1649105681737164]}, "mutation_prompt": null}
{"id": "0e29db10-6ee0-468b-9ac2-92c1d17c9e7f", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        self.mutation_factor *= (1 - len(self.history) / self.budget)  # Dynamic mutation factor adjustment\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.var(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance exploration by incorporating adaptive local search adjustments based on the best solution's variance.", "configspace": "", "generation": 98, "fitness": 0.9751703269020132, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.9730676040150273, 0.971852199093334, 0.9805911775976784], "final_y": [0.1650158775197168, 0.16489706226357104, 0.16496137447618564]}, "mutation_prompt": null}
{"id": "3367e72c-470b-49aa-aac9-8bfbb2fcae09", "solution": "import numpy as np\n\nclass QuantumAdaptiveDifferentialOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def quantum_bit_flip(self, solution, best):\n        q = np.random.rand(self.dim)\n        flip = np.random.rand(self.dim) < q\n        return np.where(flip, best, solution)\n\n    def differential_mutation(self, population, best):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        diversity_factor = np.std(population) / (np.std(population) + 1)\n        dynamic_factor = self.mutation_factor * (1 - diversity_factor)\n        historical_factor = np.mean(self.history) / (np.mean(self.history) + 1)\n        noise_reduction = 1 / (1 + np.exp(-np.std(self.history)))\n        constraint_factor = np.var(self.history) / (np.var(self.history) + 1)\n        decay_factor = np.exp(-len(self.history) / self.budget)\n        mutation_scale = (np.var(self.history[-10:]) / (np.var(self.history[-10:]) + 1)) * decay_factor\n        self.mutation_factor *= 1 / (1 + np.exp(len(self.history) / (0.1 * self.budget)))  # Sigmoid adjustment\n        mutant = a + dynamic_factor * historical_factor * noise_reduction * constraint_factor * mutation_scale * (b - c)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def local_search(self, solution, eval_ratio):\n        gradient = np.random.normal(scale=0.1, size=self.dim)\n        intensity = np.exp(-eval_ratio * (np.std(self.history) / (np.mean(self.history) + 1e-5)))\n        new_solution = solution - intensity * gradient * (solution - np.mean(self.history[-5:])) * np.random.rand()\n        return np.clip(new_solution, self.bounds.lb, self.bounds.ub)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = min(max(10, int(self.budget / (self.dim * 2))), self.population_size)\n        population = np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n\n        self.history.extend(scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            new_population = []\n            eval_ratio = evaluations / self.budget\n            self.crossover_rate = 0.7 * (1 - eval_ratio) + 0.1\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    mutant = self.differential_mutation(population, best_solution)\n                    trial_solution = self.quantum_bit_flip(mutant, best_solution)\n                else:\n                    trial_solution = population[i]\n\n                trial_solution = self.local_search(trial_solution, eval_ratio)\n\n                trial_score = func(trial_solution)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population.append(trial_solution)\n                    scores[i] = trial_score\n                else:\n                    new_population.append(population[i])\n\n                if trial_score < scores[best_idx]:\n                    best_idx = i\n                    best_solution = trial_solution\n\n            population = np.array(new_population)\n            self.history.extend(scores)\n\n        return best_solution, scores[best_idx], self.history", "name": "QuantumAdaptiveDifferentialOptimization", "description": "Enhance the search by scaling mutation factor with a sigmoid function over evaluations for better control.", "configspace": "", "generation": 99, "fitness": 0.975492006780856, "feedback": "The algorithm QuantumAdaptiveDifferentialOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "12ea339c-bd00-41ce-ac4d-9f0e86f15276", "metadata": {"aucs": [0.9733608523924664, 0.9717803824045254, 0.9813347855455765], "final_y": [0.16490433084200984, 0.16490148560708473, 0.164876480425599]}, "mutation_prompt": null}
