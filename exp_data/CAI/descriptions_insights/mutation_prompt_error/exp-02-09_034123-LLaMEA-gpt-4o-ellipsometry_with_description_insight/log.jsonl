{"id": "1135792d-aa7f-4968-9f02-761a091c53db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_samples = self._uniform_sampling(bounds, 5 * self.dim)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            \n            if self.budget <= 0:\n                break\n        \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "A hybrid local-global optimization algorithm combining BFGS for rapid convergence with initial sampling for global coverage, iteratively refining bounds based on promising regions.", "configspace": "", "generation": 0, "fitness": 0.7876651715288071, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.011. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8026999696359179, 0.7797903126338701, 0.7805052323166335], "final_y": [9.823015930178332e-08, 1.7250027606278596e-07, 1.6049747746889718e-07]}, "mutation_prompt": null}
{"id": "fff80a57-ba05-419c-bfc2-721f8f9820b6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MultiStartLocalOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_initial_samples = min(10 * self.dim, self.budget // (2 * self.dim))\n        initial_samples = self._uniform_sampling(bounds, num_initial_samples)\n        \n        best_sample = None\n        best_value = float('inf')\n        self.budget -= num_initial_samples\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n\n            res = minimize(func, sample, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget // len(initial_samples)})\n            self.budget -= res.nfev\n            \n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "MultiStartLocalOptimizer", "description": "A Multi-start Local Optimizer using Nelder-Mead for robust convergence and adaptive budget allocation to focus on promising regions.", "configspace": "", "generation": 1, "fitness": 0.35181018673704684, "feedback": "The algorithm MultiStartLocalOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.352 with standard deviation 0.074. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "1135792d-aa7f-4968-9f02-761a091c53db", "metadata": {"aucs": [0.25015201679141774, 0.4226070051533013, 0.3826715382664213], "final_y": [0.03674441120010454, 0.002012768292709795, 0.005776403388933528]}, "mutation_prompt": null}
{"id": "d956427e-244a-496a-b024-9e9d8f4cfbb9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_samples = self._uniform_sampling(bounds, 5 * self.dim)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer using adaptive sampling to refine initial guesses, increasing convergence speed.", "configspace": "", "generation": 2, "fitness": 0.8250466310706838, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.019. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1135792d-aa7f-4968-9f02-761a091c53db", "metadata": {"aucs": [0.8239728407640297, 0.8029239941308206, 0.8482430583172009], "final_y": [6.525706388133768e-08, 7.815246470229929e-08, 2.5319121151053628e-08]}, "mutation_prompt": null}
{"id": "cbccf734-15ab-45f3-9f20-a77ab3b6caa6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with dynamic adjustment of sampling density based on budget usage to improve convergence efficiency.", "configspace": "", "generation": 3, "fitness": 0.8269935021758754, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.013. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d956427e-244a-496a-b024-9e9d8f4cfbb9", "metadata": {"aucs": [0.8440960016827654, 0.8229201242113984, 0.8139643806334625], "final_y": [2.9512782856017006e-08, 2.891894446764021e-08, 6.671727112940063e-08]}, "mutation_prompt": null}
{"id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.95 + best_sample * 0.05, func.bounds.lb, func.bounds.ub)  # Adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with adaptive boundary narrowing based on convergence to improve efficiency.", "configspace": "", "generation": 4, "fitness": 0.8324144423152745, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.028. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbccf734-15ab-45f3-9f20-a77ab3b6caa6", "metadata": {"aucs": [0.8029206029159287, 0.823622715192174, 0.8707000088377205], "final_y": [4.639630464951407e-08, 2.695024198481735e-09, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "208af409-66d3-4eed-9032-8478a9aeee1a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(8 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted sampling rate\n        initial_samples = self._latin_hypercube_sampling(bounds, num_samples)  # Changed sampling method\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.90 + best_sample * 0.10, func.bounds.lb, func.bounds.ub)  # Enhanced narrowing\n            \n        return best_sample\n\n    def _latin_hypercube_sampling(self, bounds, num_samples):  # Implemented Latin Hypercube Sampling\n        samples = []\n        for dim in range(bounds.shape[0]):\n            sample = np.random.permutation(num_samples) / num_samples\n            sample = bounds[dim, 0] + sample * (bounds[dim, 1] - bounds[dim, 0])\n            samples.append(sample)\n        return np.array(samples).T", "name": "HybridOptimizer", "description": "Enhanced sampling and adaptive boundary narrowing for improved local exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.8070015390772696, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.7674167061699821, 0.8508505018027023, 0.8027374092591246], "final_y": [1.5851489130961406e-07, 1.6978729855607054e-08, 1.0204601093207712e-07]}, "mutation_prompt": null}
{"id": "b482dd04-cc52-46f6-b897-8043aa1da5d6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.90 + best_sample * 0.10, func.bounds.lb, func.bounds.ub)  # Enhanced adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Refined HybridOptimizer with enhanced adaptive boundary narrowing and strategic initialization for improved performance.", "configspace": "", "generation": 6, "fitness": 0.8160921628977819, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.038. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.8694867605090113, 0.785791057819824, 0.7929986703645105], "final_y": [1.2133425661787161e-08, 1.1763922729820385e-07, 3.723245736266647e-08]}, "mutation_prompt": null}
{"id": "c85d1610-91e2-410e-a80d-4302fd6e0721", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(10 * self.dim * (self.budget / (20 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.95 + best_sample * 0.05, func.bounds.lb, func.bounds.ub)  # Adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with adaptive boundary narrowing and dynamic initial sampling ensuring robust performance.", "configspace": "", "generation": 7, "fitness": 0.8324144423152745, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.028. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.8029206029159287, 0.823622715192174, 0.8707000088377205], "final_y": [4.639630464951407e-08, 2.695024198481735e-09, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "805b5054-fccd-4067-831f-15f539ac516f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(2, int(5 * self.dim * (self.budget / (10 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.90 + best_sample * 0.10, func.bounds.lb, func.bounds.ub)  # Enhanced adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Improved HybridOptimizer with enhanced adaptive boundary narrowing and more robust initial sample selection.", "configspace": "", "generation": 8, "fitness": 0.8300824610452092, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.031. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.7955609136899622, 0.823986460607945, 0.8707000088377205], "final_y": [9.155199198871324e-08, 2.695024198481735e-09, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "652752b3-b8d4-4afe-8e47-48943af19624", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultistartOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_starts = max(1, int(3 * self.dim * (self.budget / (15 * self.dim))))  # Adjust number of restarts\n        initial_samples = self._uniform_sampling(bounds, num_starts)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            # Optimize with L-BFGS-B method\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Deduct budget by number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n                # Iteratively refine the region around the best sample\n                refined_bounds = self._refine_bounds(best_sample, bounds, factor=0.85)\n                res_refined = minimize(func, best_sample, method='L-BFGS-B', bounds=refined_bounds)\n                self.budget -= res_refined.nfev\n                if res_refined.fun < best_value:\n                    best_value = res_refined.fun\n                    best_sample = res_refined.x\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        return [np.random.uniform(low, high, size=self.dim) for low, high in bounds]\n\n    def _refine_bounds(self, best_sample, bounds, factor):\n        return np.clip(bounds * factor + best_sample * (1 - factor), func.bounds.lb, func.bounds.ub)", "name": "AdaptiveMultistartOptimizer", "description": "Adaptive Multistart Optimizer with Iterative Refinement utilizing local minima exploitation for enhanced convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {}, "mutation_prompt": null}
{"id": "11edcd74-72aa-4de8-8271-1d7c62a9e45a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\nclass AdvancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._bayesian_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = self._adaptive_narrowing(bounds, best_sample, func.bounds)\n            \n        return best_sample\n\n    def _bayesian_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([norm.rvs(loc=(low + high) / 2, scale=(high - low) / 4) for low, high in bounds])\n            sample = np.clip(sample, bounds[:,0], bounds[:,1])\n            samples.append(sample)\n        return samples\n\n    def _adaptive_narrowing(self, bounds, best_sample, original_bounds):\n        new_bounds = bounds * 0.95 + best_sample * 0.05\n        return np.clip(new_bounds, original_bounds.lb, original_bounds.ub)", "name": "AdvancedHybridOptimizer", "description": "Advanced HybridOptimizer using Bayesian exploration for initial sampling and adaptive convergence-driven boundary refinement.", "configspace": "", "generation": 10, "fitness": 0.8183466375941171, "feedback": "The algorithm AdvancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.007. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.8090998308102595, 0.8237197666635496, 0.8222203153085421], "final_y": [7.879546877539332e-08, 4.694907829094138e-08, 6.066861738958278e-08]}, "mutation_prompt": null}
{"id": "692d5cdb-a14b-4c82-a7bc-2a76c53d0791", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(self.budget / (2 * self.dim)))  # Adjusted initial sampling size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            if self.budget > 0:  # Check budget before narrowing\n                bounds = np.clip(bounds * 0.95 + best_sample * 0.05, func.bounds.lb, func.bounds.ub)  # Adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Improved HybridOptimizer with adaptive initial sampling size based on remaining budget and enhanced convergence criteria.", "configspace": "", "generation": 11, "fitness": 0.5980214386286482, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.598 with standard deviation 0.347. And the mean value of best solutions found was 1.151 (0. is the best) with standard deviation 1.628.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.8647351668992993, 0.8207283029944328, 0.10860084599221242], "final_y": [3.4011071699683972e-09, 8.405229053108218e-08, 3.453672503951268]}, "mutation_prompt": null}
{"id": "45f5e900-2687-49b7-baac-4c807c865033", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))  # Dynamic adjustment\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds, options={'gtol': 1e-6}) # Changed line\n            self.budget -= res.nfev  # Ensure budget is decremented by the number of function evaluations\n            if res.fun < best_value:\n                best_value = res.fun\n                best_sample = res.x\n            bounds = np.clip(bounds * 0.95 + best_sample * 0.05, func.bounds.lb, func.bounds.ub)  # Adaptive narrowing\n            \n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples", "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with adaptive sample refinement using gradient information for improved convergence efficiency.", "configspace": "", "generation": 12, "fitness": 0.8120830063821183, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.7953579524267342, 0.828696828843313, 0.8121942378763075], "final_y": [4.3964005578883036e-08, 3.973054269715023e-08, 3.681638537534557e-08]}, "mutation_prompt": null}
{"id": "76f1f879-6146-4732-af90-b8b063c25335", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01  # Define a threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Adaptive Boundary Reduction Optimizer which incrementally refines search space by dynamically adjusting sampling density and radius of convergence based on improvement metrics.", "configspace": "", "generation": 13, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "43605b97-4b22-4fdb-9148-20930e53c2f7", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "d91e742b-fe7e-4a4f-8ff0-1600091f3cfa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.05  # Reduced initial narrowing factor\n        num_samples = max(1, int(10 * self.dim * (self.budget / (10 * self.dim))))  # Increased sample size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01  # Define a threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer that dynamically adjusts sample size and uses a smaller initial radius for precise convergence control.", "configspace": "", "generation": 14, "fitness": 0.8299559617649961, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.8278866378248314, 0.7912812386324362, 0.8707000088377205], "final_y": [2.7327756396054196e-08, 1.1757043601981895e-07, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "420d434f-41fb-4ba0-9f76-7d457ea96184", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01 * (self.budget / 100)  # Adjust threshold based on budget\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "A refined boundary reduction optimizer that incrementally adjusts the improvement threshold dynamically based on the current budget.", "configspace": "", "generation": 15, "fitness": 0.5605078310628028, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.561 with standard deviation 0.377. And the mean value of best solutions found was 7.411 (0. is the best) with standard deviation 10.481.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.813469147631716, 0.840583873015452, 0.027470472541240132], "final_y": [2.6783780212896334e-08, 4.7041830139805624e-08, 22.234229551847534]}, "mutation_prompt": null}
{"id": "05c9b438-fcde-4f8e-a0b8-17c797b1cacd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01  # Define a threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining the radius reduction strategy for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "efd94eed-16af-4ac4-add6-f4fd439d792d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Reduced threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.95  # Slightly slower radius decay for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Adaptive Boundary Reduction Optimizer with improved convergence by adjusting improvement threshold and radius decay.", "configspace": "", "generation": 17, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "4d4801d3-223d-4b73-8bd6-d6ed534a0e98", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                improvement_threshold *= 0.95  # Adaptive threshold reduction\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer that dynamically refines search space and utilizes adaptive improvement threshold for convergence.", "configspace": "", "generation": 18, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "edca9922-fb43-478a-a3e6-66f56dbda651", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.2  # Initial narrowing factor\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Define a threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer which fine-tunes search space refinement using dynamically adjusted convergence metrics and initial radius scaling.", "configspace": "", "generation": 19, "fitness": 0.8359388241818935, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.029. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.7995508517163248, 0.837565611991635, 0.8707000088377205], "final_y": [7.94971257089386e-08, 2.1600782057270087e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "ee56d0de-90f7-480c-b46b-eee31d056bea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.2  # Adjusted initial narrowing factor\n        num_samples = max(2, int(5 * self.dim * (self.budget / (9 * self.dim))))  # Improved sampling strategy\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01  # Define a threshold for significant improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Reduce the search space around the best sample\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Gradually decrease radius for fine-tuning\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic initial radius adjustment and improved sample selection.", "configspace": "", "generation": 20, "fitness": 0.8359388241818935, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.029. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.7995508517163248, 0.837565611991635, 0.8707000088377205], "final_y": [7.94971257089386e-08, 2.1600782057270087e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic radius adaptation based on convergence rate and introduction of a random restart strategy to escape local optima.", "configspace": "", "generation": 21, "fitness": 0.8448443339658854, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.027. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "76f1f879-6146-4732-af90-b8b063c25335", "metadata": {"aucs": [0.812612034627182, 0.8441601571155577, 0.8777608101549167], "final_y": [5.918097744454082e-08, 1.5545216063061547e-08, 1.247999591447608e-09]}, "mutation_prompt": null}
{"id": "dcc18489-8d81-4a4b-aaa6-a2fcadec72f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (8 * self.dim))))  # Adjusted sampling ratio\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart strategy\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Optimized Adaptive Boundary Reduction with enhanced restart strategy and adaptive sampling to improve convergence rate.", "configspace": "", "generation": 22, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "b4331bdd-357c-4b7e-a340-d0f03f6ba1be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:\n                    sample = self._adaptive_mutation(best_sample, bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _adaptive_mutation(self, sample, bounds):\n        mutation_strength = 0.05\n        return np.clip(sample + mutation_strength * np.random.randn(*sample.shape), bounds[:, 0], bounds[:, 1])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with increased exploitation intensity through adaptive mutation to refine solutions more effectively.", "configspace": "", "generation": 23, "fitness": 0.8230456332885053, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8225568532446648, 0.8491692814308496, 0.7974107651900018], "final_y": [7.081621783493403e-08, 3.2375629159132135e-08, 3.9943416997863524e-08]}, "mutation_prompt": null}
{"id": "39df9e9f-0dd4-4b97-a17f-2aa37ed10919", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Adjusted threshold for finer improvements\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer with adaptive improvement threshold and dynamic sample scaling for enhanced convergence.", "configspace": "", "generation": 24, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "2a26af35-956a-40b5-b637-5ab22e1b3353", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.95  # Modified line for increased adaptation\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 3 else 0.9))  # Modified line for increased adaptation\n\n            # Early stopping if improvement is below threshold\n            if best_value < improvement_threshold:\n                break\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Optimizer with increased dynamic radius adaptation and early stopping for improved convergence.", "configspace": "", "generation": 25, "fitness": 0.816985957062564, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.038. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.793946673090193, 0.7863467531585555, 0.8706644449389437], "final_y": [9.948168924415174e-08, 1.4596041895628858e-07, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "188be018-dbdb-459c-9b4f-6842fc56d3a6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        learning_rate = 1.1\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n                learning_rate = 1.1  # Reset learning rate on improvement\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Adaptive restart strategy\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n                    learning_rate = 1.05  # Adjust learning rate slightly after restart\n            initial_radius = max(0.01, initial_radius * learning_rate)\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with learning rate modulation based on recent improvements and adaptive restart strategy for better exploration.", "configspace": "", "generation": 26, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "66ba25f9-2a4c-4bb6-a863-d9d126ff650f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted dynamic radius reduction\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted restart frequency\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved dynamic radius adjustment with adaptive restart frequency based on convergence trends.", "configspace": "", "generation": 27, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "83982a73-3fcb-46c0-916a-3ebf14cb68d8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            gradient_norm = np.linalg.norm(res.jac)  # Added line to compute gradient norm\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9 + 0.1 * gradient_norm  # Modified line for dynamic radius adjustment\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with variable radius adjustment based on local gradient analysis to improve convergence precision.", "configspace": "", "generation": 28, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "84749e5f-f123-48af-bbe1-5d625e6a5ff7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Adjusted improvement threshold\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted adaptation\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic radius adaptation based on convergence rate, adjusted improvement threshold, and introduction of a random restart strategy to escape local optima.", "configspace": "", "generation": 29, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "2a1a5821-33c6-4738-98e3-fe1beacff1ce", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(10 * self.dim * (self.budget / (20 * self.dim))))  # Adjusted sampling size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  \n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer with adaptive adjustment of initial sampling size and improved random restart strategy for better exploration.", "configspace": "", "generation": 30, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "e8235200-7f5d-43e0-aadf-a932531178e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        \n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n            num_samples = min(max(1, num_samples + 1), self.budget)  # Dynamic sampling increment\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer by incorporating a dynamic sampling increment to better handle the exploration-exploitation trade-off.", "configspace": "", "generation": 31, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "92ecf742-b93b-4e95-ba65-a8bf9663b087", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Slightly increased reduction rate\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 3 else 0.9))  # Increased expansion rate\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer with dynamic sampling density based on convergence rate and boundary adaptation.", "configspace": "", "generation": 32, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "d7a29428-a430-4f22-bd77-df6b972f28d2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Changed line for more aggressive radius reduction\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5 and np.random.rand() < 0.5:  # Changed line for adaptive restart probability\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with adaptive radius adjustment based on convergence improvement and adaptive restart probability to improve local optima escape.", "configspace": "", "generation": 33, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "23732da8-e459-439f-ad37-bcad79f0e6e2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n                improvement_threshold *= 0.95  # Adaptive threshold\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n            num_samples = max(1, int(3 * self.dim))  # Strategic sampling after convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with adaptive improvement thresholds and strategic sampling based on convergence dynamics.", "configspace": "", "generation": 34, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "da24aad4-ffb6-40c5-801a-a61019696ef5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(2, int(7 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.001\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            if no_improvement_steps > 5:\n                break  # Early stopping if no improvement is seen\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced boundary reduction algorithm with adaptive sample density and improved early stopping to increase convergence speed.", "configspace": "", "generation": 35, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "b6d9c1ee-d2e1-4ad7-ab34-eefd59249c3a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(3 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted sampling density\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n                improvement_threshold *= 0.95  # Dynamic threshold adjustment\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  \n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n                    improvement_threshold = 0.01  # Reset threshold\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with adaptive sampling density and dynamic improvement threshold based on progress.", "configspace": "", "generation": 36, "fitness": 0.5735566860671671, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.574 with standard deviation 0.405. And the mean value of best solutions found was 13.118 (0. is the best) with standard deviation 18.552.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8762557820189003, 0.8426828484495394, 0.0017314277330618966], "final_y": [1.172778123576638e-09, 5.6387797367030076e-08, 39.35502056172664]}, "mutation_prompt": null}
{"id": "94bf4f5a-a712-401b-ba89-ec62be6b0993", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (7 * self.dim))))\n        initial_samples = self._adaptive_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.001\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.005, initial_radius * (1.15 if no_improvement_steps > 3 else 0.85))\n\n        return best_sample\n\n    def _adaptive_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return np.array(samples)\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer with enhanced dynamic sampling and local search strategy to accelerate convergence and escape local traps.", "configspace": "", "generation": 37, "fitness": 0.8419326780144666, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8091463446490613, 0.8291738821800749, 0.8874778072142635], "final_y": [1.2684675637138944e-08, 2.611741632588292e-08, 1.3967044701857073e-08]}, "mutation_prompt": null}
{"id": "a2ab4a3a-1396-4abf-8021-20b3a77324bf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = 0.05  # New learning rate for momentum\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        velocity = np.zeros(self.dim)  # Initialize momentum\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:\n                    sample = self._momentum_restart(best_sample, velocity, bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n            velocity = self.learning_rate * (sample - best_sample)  # Update momentum\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _momentum_restart(self, sample, velocity, bounds):\n        new_sample = sample + velocity\n        return np.clip(new_sample, bounds[:, 0], bounds[:, 1])  # Clip to bounds", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Refined Boundary Reduction Optimizer with adaptive learning rate and momentum for enhanced convergence in smooth landscapes.", "configspace": "", "generation": 38, "fitness": 0.5576477811430284, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.558 with standard deviation 0.389. And the mean value of best solutions found was 11.443 (0. is the best) with standard deviation 16.183.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8543827692346776, 0.8106734113130059, 0.00788716288140201], "final_y": [4.316550648616809e-08, 1.6258259076422363e-07, 34.328371939453355]}, "mutation_prompt": null}
{"id": "375b0bd7-4b10-4ad8-8dea-4bb902c0f46e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted step for refinement\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Improved restart threshold\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with refined dynamic radius adaptation and improved random restart strategy for escaping local optima.", "configspace": "", "generation": 39, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "c1168bb9-5d32-42eb-bf09-2b23c04a75c9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.02  # Updated parameter\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Updated parameter\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with adaptive improvement threshold and better exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "6b1e91b6-5dd6-42a5-869b-f63a59b856e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        memory_radius = initial_radius * 0.5  # Added line to introduce memory-based radius\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Memory-based restart strategy\n                    sample = self._random_restart(bounds)\n                    initial_radius = memory_radius  # Added line to reset radius to memory\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer by dynamically adjusting the radius and integrating a memory-based restart strategy to enhance convergence.", "configspace": "", "generation": 41, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "79fe3a94-540d-43d7-a44f-45e79e379133", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(10 * np.sqrt(self.dim) * (self.budget / (10 * self.dim))))  # Adjusted initial sampling size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction with adaptive initial sample size to improve early exploration.", "configspace": "", "generation": 42, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "68f7b7fe-ffd0-4182-9efd-24ca894b1d8f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted scaling factor\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 6:  # Changed threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n                if no_improvement_steps > 3 and initial_radius > 0.02:  # Added condition for early stopping\n                    break\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with improved dynamic radius scaling and early stopping based on convergence stability.", "configspace": "", "generation": 43, "fitness": 0.6055141609745615, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.606 with standard deviation 0.368. And the mean value of best solutions found was 1.859 (0. is the best) with standard deviation 2.629.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8238176474527612, 0.08789162336823308, 0.9048332121026899], "final_y": [5.75460293854316e-08, 5.576984655653146, 7.726903038796833e-09]}, "mutation_prompt": null}
{"id": "5a7cc1ac-5747-40e2-a3d6-6e2bd712681e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        restart_threshold = 3  # Reduced threshold for dynamic restart\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for more aggressive convergence\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > restart_threshold:  # Dynamic restart strategy\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.05 if no_improvement_steps > 3 else 0.85))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with a dynamic restart trigger and improved radius adjustment for quick convergence.", "configspace": "", "generation": 44, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "d9a753cc-16b6-4e05-aba9-75d3dee421e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Random restart strategy to escape local optima\n                    sample = self._random_restart(bounds) + np.random.normal(0, 0.05, self.dim)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 3 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by adding adaptive mutation in random restart strategy to improve exploration.", "configspace": "", "generation": 45, "fitness": 0.5668364440860749, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.567 with standard deviation 0.395. And the mean value of best solutions found was 10.970 (0. is the best) with standard deviation 15.514.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8088211412658473, 0.8819005772497215, 0.00978761374265602], "final_y": [6.244171777092066e-08, 8.384560243515212e-09, 32.91025186720649]}, "mutation_prompt": null}
{"id": "27f22c4f-56a0-4e38-8b57-dee1cbcf6029", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Change here: Adjusted random restart condition\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 3 else 0.9))  # Change here: Modified radius update factor\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic radius adaptation based on convergence rate and adaptive random restart strategy to improve exploration.", "configspace": "", "generation": 46, "fitness": 0.541150797013556, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.541 with standard deviation 0.370. And the mean value of best solutions found was 9.216 (0. is the best) with standard deviation 13.033.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8138802065397589, 0.7919333036270007, 0.017638880873908303], "final_y": [3.5932351364626835e-08, 1.6184175404196083e-07, 27.647563584509633]}, "mutation_prompt": null}
{"id": "0a178318-6e83-4eae-bacb-211df8412a67", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer by fine-tuning the random restart strategy and adjusting the convergence rate adaptation to enhance exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.8720399681723651, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ce505e5c-5821-4e33-9f91-ee54e0e93355", "metadata": {"aucs": [0.8820371186164528, 0.9028757126685976, 0.8312070732320448], "final_y": [1.8869440007447414e-08, 4.1362587340133925e-09, 2.4153220143724155e-08]}, "mutation_prompt": null}
{"id": "0d34ec90-11df-48c6-85ab-8070e2915dd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(7 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted sample size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by tuning sample size and random restart strategy to boost convergence.", "configspace": "", "generation": 48, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "f9d711d7-8e4e-4209-b76f-da501691683e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                # Adjusted boundary reduction rate for better exploitation\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius * 0.95)  \n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Fine-tuned boundary reduction rate for enhanced local search exploitation.", "configspace": "", "generation": 49, "fitness": 0.5689137558159786, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.401. And the mean value of best solutions found was 13.118 (0. is the best) with standard deviation 18.552.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8623269912653346, 0.8426828484495394, 0.0017314277330618966], "final_y": [3.365787890767265e-08, 5.6387797367030076e-08, 39.35502056172664]}, "mutation_prompt": null}
{"id": "458c1798-c7c0-4783-afac-3b655b9626b3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(10 * self.dim * (self.budget / (10 * self.dim))))  # Increased initial samples\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.001  # Refined convergence threshold for better accuracy\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by increasing the number of initial samples and refining the convergence check for better solution accuracy.", "configspace": "", "generation": 50, "fitness": 0.8355263438377101, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7926436775133467, 0.8542523421157213, 0.859683011884062], "final_y": [3.859124276550551e-08, 5.738971799989912e-09, 2.286757669334424e-08]}, "mutation_prompt": null}
{"id": "1faee10e-3ba7-4db1-a9a6-c4b1009d5929", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds, options={'ftol': 1e-9})\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.05 if no_improvement_steps > 2 else 0.95))  # Adjusted convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by dynamically adjusting the exploration-exploitation balance based on convergence feedback and utilizing gradual boundary contraction.", "configspace": "", "generation": 51, "fitness": 0.5605078310628028, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.561 with standard deviation 0.377. And the mean value of best solutions found was 7.411 (0. is the best) with standard deviation 10.481.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.813469147631716, 0.840583873015452, 0.027470472541240132], "final_y": [2.6783780212896334e-08, 4.7041830139805624e-08, 22.234229551847534]}, "mutation_prompt": null}
{"id": "e51494ce-90b7-4bcb-8bb8-5fcf78bfe8d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Adjusted exploitation strategy by modifying the convergence rate adaptation to ensure faster convergence.", "configspace": "", "generation": 52, "fitness": 0.8476082563389347, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8671381513453489, 0.8491018985212391, 0.8265847191502161], "final_y": [2.743697807874064e-08, 2.2845596085097478e-08, 2.338897608732287e-08]}, "mutation_prompt": null}
{"id": "bfa8257a-f3e2-454a-a5c1-ecd76236af32", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (10 * self.dim))))  # Increased sample density\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Fine-tuned radius decay rate\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = radius * ((high - low) / 2)  # Improved precision for boundary reduction\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by fine-tuning the radius decay rate, increasing sample density, and improving boundary reduction precision for better convergence.", "configspace": "", "generation": 53, "fitness": 0.8299559617649961, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8278866378248314, 0.7912812386324362, 0.8707000088377205], "final_y": [2.7327756396054196e-08, 1.1757043601981895e-07, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "ba6c9095-22ba-4977-8939-590aef040593", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * np.sqrt(self.dim) * (self.budget / (10 * self.dim))))  # Changed heuristic for num_samples\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Boundary Reduction with Adaptive Sampling to improve convergence and maintain exploration-exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.569190855828368, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.375. And the mean value of best solutions found was 5.805 (0. is the best) with standard deviation 8.209.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8440972702131755, 0.8249706002023584, 0.03850469706957005], "final_y": [2.0754365768092103e-08, 4.4004676828778744e-08, 17.41413752672654]}, "mutation_prompt": null}
{"id": "7fafd52f-04c5-4123-bf5d-1a515f6b0afb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.memory = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.2  # Adjusted initial radius\n        num_samples = max(1, int(7 * self.dim * (self.budget / (12 * self.dim))))  # Adjusted sampling strategy\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Adjusted threshold\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                self.memory.append(best_sample)  # Store successful samples\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._adaptive_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.005, initial_radius * (1.2 if no_improvement_steps > 2 else 0.85))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _adaptive_restart(self, bounds):\n        if self.memory:\n            memory_sample = self.memory[np.random.randint(len(self.memory))]\n            return memory_sample + np.random.normal(0, 0.05, self.dim)  # Perturbation strategy\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced local search with adaptive sampling and memory-based boundary adjustments for improved convergence.", "configspace": "", "generation": 55, "fitness": 0.5523774057994258, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.552 with standard deviation 0.384. And the mean value of best solutions found was 11.197 (0. is the best) with standard deviation 15.835.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8104825432055695, 0.8377849743747269, 0.008864699817981325], "final_y": [1.90606966766704e-09, 3.157985772210374e-08, 33.59148085556123]}, "mutation_prompt": null}
{"id": "62f9266f-6667-4357-83bd-3c01f05d89ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        learning_rate = 0.9\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= learning_rate  # Adjust radius based on learning rate\n                learning_rate = max(0.1, learning_rate * 0.95)  # Decaying learning rate for stability\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Enhanced threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            # Adaptive exploration-exploitation balance\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.8))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "EnhancedBoundaryReductionOptimizer", "description": "Enhanced Boundary Reduction Optimizer with Adaptive Learning Rate and Dynamic Exploration-Exploitation Balance for improved convergence in black box optimization.", "configspace": "", "generation": 56, "fitness": 0.8186419724014473, "feedback": "The algorithm EnhancedBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.006. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8115684421600631, 0.8271784615887023, 0.8171790134555765], "final_y": [3.0292022841155205e-08, 2.8299188059725654e-08, 3.7011424678542744e-08]}, "mutation_prompt": null}
{"id": "f88d890d-a72c-4dd2-9b8d-c0c8cbd14959", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        success_rate = 0.5  # Track success rate of improvements\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n                success_rate = min(1.0, success_rate + 0.1)  # Increase success rate\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > (2 / success_rate):  # Dynamic restart threshold\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n                success_rate = max(0.1, success_rate - 0.05)  # Decrease success rate\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic boundary adjustment based on success rate for better exploration-exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "b745c0af-0064-4bfd-ac72-5cff8bf54957", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by fine-tuning the random restart and radius adjustment strategies.", "configspace": "", "generation": 58, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "c89bbb6b-4539-48dc-b384-0032bd3be3a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (8 * self.dim))))  # Changed line for better sampling\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius * 0.9)  # Changed line for dynamic radius adjustment\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhancing boundary adaptation and sampling strategy for improved convergence balance in black box optimization.", "configspace": "", "generation": 59, "fitness": 0.5537145527987765, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.554 with standard deviation 0.387. And the mean value of best solutions found was 10.970 (0. is the best) with standard deviation 15.514.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7694554674039518, 0.8819005772497215, 0.00978761374265602], "final_y": [2.2028599366155316e-07, 8.384560243515212e-09, 32.91025186720649]}, "mutation_prompt": null}
{"id": "9030b23a-ada4-45bc-a4cd-87cda1ae6820", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (10 * self.dim))))  # Increased sample density\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Refined threshold for more sensitivity\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining sample density and convergence criteria for better exploration and exploitation within budget constraints.", "configspace": "", "generation": 60, "fitness": 0.821984068955809, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8151851197330827, 0.8325251120854494, 0.8182419750488945], "final_y": [6.951645199001928e-08, 4.132819498490336e-08, 4.2968542037474014e-08]}, "mutation_prompt": null}
{"id": "fe90f722-50c3-44c0-8bc2-287317642cf2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius * 0.9)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining the boundary reduction strategy to improve convergence and solution quality.", "configspace": "", "generation": 61, "fitness": 0.553213585698085, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.553 with standard deviation 0.364. And the mean value of best solutions found was 5.806 (0. is the best) with standard deviation 8.211.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8263187576485673, 0.7948276449003965, 0.038494354545291154], "final_y": [4.056219699457051e-08, 4.590304930094947e-08, 17.41823478598087]}, "mutation_prompt": null}
{"id": "814d7b59-f068-4857-bab0-1ada3ab2a8e0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(7 * self.dim * (self.budget / (10 * self.dim))))  # Change: Adjusted sampling density\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds, options={'gtol': 1e-6})  # Change: Increased precision\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved Adaptive Boundary Reduction Optimizer by enhancing local search precision and optimizing initial sampling density for better solution quality.", "configspace": "", "generation": 62, "fitness": 0.8078519545474226, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7843509864953484, 0.7964429475341839, 0.8427619296127355], "final_y": [1.1711039989560057e-07, 1.0603821026421317e-07, 4.717293556867325e-08]}, "mutation_prompt": null}
{"id": "5ff3c3d3-c7bd-420b-ae80-d7eeea0148f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved boundary reduction and restart mechanism for enhanced convergence.", "configspace": "", "generation": 63, "fitness": 0.5740850607394962, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.574 with standard deviation 0.351. And the mean value of best solutions found was 2.448 (0. is the best) with standard deviation 3.462.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8322305672992558, 0.8125730279159792, 0.07745158700325361], "final_y": [2.5205054258409693e-10, 5.739586281907357e-08, 7.343170165498999]}, "mutation_prompt": null}
{"id": "50148f7e-82e7-4ca0-a63e-8eb2c6d76d5f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.15  # Adjusted initial radius for better exploration\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced the AdaptiveBoundaryReductionOptimizer by fine-tuning the initial radius and no improvement threshold for better exploration and exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.7932489794324843, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7986142535800025, 0.8124568582848186, 0.768675826432632], "final_y": [8.810021021710661e-08, 9.058416063148132e-08, 4.33456532321853e-08]}, "mutation_prompt": null}
{"id": "62f3fc71-d575-42d1-88cc-70b94c80da8e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.15  # Adjusted for better initial exploration\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining the initial radius adjustment and improving the exploration-exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.8382008504036333, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8493765550144576, 0.7945259873587218, 0.8707000088377205], "final_y": [6.530324889544202e-09, 4.77533229137424e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "c1d7cf0a-261b-4efc-9231-8a15e83a05f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.85))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by fine-tuning the radius adjustment for improved convergence and modifying random restarts for better exploration.", "configspace": "", "generation": 66, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "2aa90445-ec9d-45a8-80c1-6e1b7b0607fb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.88  # Adjusted for better exploitation\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by refining the algorithm's adjustment of the initial radius to improve exploitation without sacrificing exploration.", "configspace": "", "generation": 67, "fitness": 0.5668364440860749, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.567 with standard deviation 0.395. And the mean value of best solutions found was 10.970 (0. is the best) with standard deviation 15.514.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8088211412658473, 0.8819005772497215, 0.00978761374265602], "final_y": [6.244171777092066e-08, 8.384560243515212e-09, 32.91025186720649]}, "mutation_prompt": null}
{"id": "81f7b032-42d3-461e-b8f3-d8209edc7c51", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Adjusted for better local exploitation\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced the exploitation mechanism by dynamically adjusting the convergence rate factor for reduced boundary exploration.", "configspace": "", "generation": 68, "fitness": 0.8355263438377101, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7926436775133467, 0.8542523421157213, 0.859683011884062], "final_y": [3.859124276550551e-08, 5.738971799989912e-09, 2.286757669334424e-08]}, "mutation_prompt": null}
{"id": "6f14b4bd-9219-426b-aac8-ff1bdbae4ab4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = min((high - low) * radius, (high - low) * 0.5)  # Enhanced boundary reduction logic\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced boundary reduction logic for faster convergence while maintaining exploration and exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "11bce2db-ff64-4dbd-b6b0-2e90cb0368c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.88  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 5:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Further refined boundary reduction and restart strategy for enhanced exploration-exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "2a4c6b76-b0b8-4cd1-bc64-bdf00584a038", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        initial_budget = self.budget\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n            # Dynamically adjust initial_radius based on budget consumption rate\n            initial_radius *= min(1.0, (initial_budget - self.budget) / initial_budget)\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration by dynamically adjusting initial_radius based on the budget consumption rate to balance exploration and exploitation.", "configspace": "", "generation": 71, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "6a5ddafc-e117-427a-9fed-7383ad5ba6eb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(7 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted initial sampling density\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration and convergence by adjusting initial sampling density and adaptive boundary reduction rates.", "configspace": "", "generation": 72, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "0b845a08-a601-45c2-85a0-42302c9b7289", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(2, int(5 * self.dim * (self.budget / (8 * self.dim))))  # Adjusted to increase initial sampling\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining sampling strategy and adjusting convergence adaptation for improved exploration.", "configspace": "", "generation": 73, "fitness": 0.5740850607394962, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.574 with standard deviation 0.351. And the mean value of best solutions found was 2.448 (0. is the best) with standard deviation 3.462.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8322305672992558, 0.8125730279159792, 0.07745158700325361], "final_y": [2.5205054258409693e-10, 5.739586281907357e-08, 7.343170165498999]}, "mutation_prompt": null}
{"id": "7d945f3d-e15f-49d3-adca-92234f2a6c4d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (10 * self.dim))))  # Increased initial samples\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration by slightly increasing the number of initial samples proportionally to the dimension and budget constraints.", "configspace": "", "generation": 74, "fitness": 0.5722631756464852, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.572 with standard deviation 0.405. And the mean value of best solutions found was 13.383 (0. is the best) with standard deviation 18.926.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8929461453041193, 0.8228433816353362, 0.0010000000000000009], "final_y": [8.711945969787228e-09, 6.202684577165162e-08, 40.1484942252442]}, "mutation_prompt": null}
{"id": "4eb010da-8e83-4f24-8e0f-8f8e93d5b3d8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.05 if no_improvement_steps > 2 else 0.9))  # Adjusted refinement\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining the convergence adjustment for improved solution precision.", "configspace": "", "generation": 75, "fitness": 0.8089765613048513, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.010. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8224095273467363, 0.8014392300161293, 0.8030809265516884], "final_y": [4.044954730520289e-08, 8.676936955312465e-08, 1.3538530893263862e-07]}, "mutation_prompt": null}
{"id": "13b16264-7d64-445c-9db5-739f7e48f378", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted sampling multiplier\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Reduced no improvement steps threshold\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 2 else 0.9))  # Adjusted convergence control\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining convergence control and using dynamic sampling for improved exploration-exploitation balance.", "configspace": "", "generation": 76, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "8470eaf8-d855-40fa-a3df-f943a0f06679", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.15  # Changed from 0.1 for better initial exploration\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by tweaking the initial radius multiplier for more effective exploration.", "configspace": "", "generation": 77, "fitness": 0.829154063265011, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.019. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8034681628806434, 0.8476316339619814, 0.836362392952408], "final_y": [9.807026358096867e-08, 2.0972480274696257e-08, 8.857253722481564e-09]}, "mutation_prompt": null}
{"id": "560345ca-a706-443d-b29f-7dae621bc665", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(2, int(6 * self.dim * (self.budget / (8 * self.dim))))  # Adjusted sampling strategy\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps >= 3:  # Adjusted threshold for random restart\n                    sample = self._adaptive_random_restart(bounds)  # Enhanced restart mechanism\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 1 else 0.85))  # Improved convergence control\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _adaptive_random_restart(self, bounds):  # New adaptive restart mechanism\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic sampling strategy and adaptable restart mechanism for improved convergence.", "configspace": "", "generation": 78, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "e33a3c86-78af-411f-b1fd-6c39e0c06453", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Adjusted for refined convergence\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining convergence criteria and dynamic adjustment of exploration parameters for better performance balance.", "configspace": "", "generation": 79, "fitness": 0.8388931642686064, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8343495429706697, 0.8128676551627533, 0.8694622946723961], "final_y": [4.102094183951034e-08, 3.246509757781013e-08, 3.4712623262822563e-09]}, "mutation_prompt": null}
{"id": "b25ebe3d-3289-44d2-bdc2-bb109c81fb26", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by tightening the initial radius adjustment factor for more efficient exploration.", "configspace": "", "generation": 80, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "73f33e57-f7a2-439d-9ae8-bc90cc7885de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted sample size\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with improved initial sample selection and dynamic radius adjustment.", "configspace": "", "generation": 81, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "c4f6bb7d-2fe5-4e52-b10d-630a7daafc9b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.2  # Changed from 0.1 to 0.2\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.80  # Changed from 0.85 to 0.80\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Changed threshold from 4 to 3\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration by adjusting the adaptive radius decay and incorporating a strategic restart mechanism.", "configspace": "", "generation": 82, "fitness": 0.5517925514576532, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.552 with standard deviation 0.363. And the mean value of best solutions found was 5.753 (0. is the best) with standard deviation 8.136.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8007659653986529, 0.8157161258389037, 0.03889556313540288], "final_y": [5.6214372879986965e-08, 3.76558509946781e-08, 17.259997798227893]}, "mutation_prompt": null}
{"id": "de6b9952-8a92-4216-864a-c541db124df2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        dynamic_restart_threshold = 6  # Adjusted threshold for dynamic restart\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > dynamic_restart_threshold:  # Utilize dynamic threshold\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1 + 0.05 * (no_improvement_steps > 2)))  # Adaptive learning rate\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with adaptive learning rate for refining search space and dynamic restart strategy to improve convergence efficiency.", "configspace": "", "generation": 83, "fitness": 0.8078519545474226, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.7843509864953484, 0.7964429475341839, 0.8427619296127355], "final_y": [1.1711039989560057e-07, 1.0603821026421317e-07, 4.717293556867325e-08]}, "mutation_prompt": null}
{"id": "177fe1bf-ae63-4aa3-99b1-0db99a0978c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Adjusted for better exploration-exploitation balance\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved convergence by adjusting the reduction factor of the initial radius for better exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "f81bd477-02e2-4345-9a4e-6c8dd40db333", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.75  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Refined Adaptive Boundary Reduction Optimizer with dynamic sample scaling and enhanced restart strategy for improved convergence.", "configspace": "", "generation": 85, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "bd1575d9-bc52-4c32-8d4b-38feba5506e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        dynamic_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (8 * self.dim))))  # Adjusted for better initial sampling\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        with ThreadPoolExecutor() as executor:  # Parallel execution for initial samples\n            futures = [executor.submit(self._optimize_sample, func, sample, bounds) for sample in initial_samples]\n            for future in futures:\n                res = future.result()\n                self.budget -= res.nfev\n                if res.fun < best_value - improvement_threshold:\n                    best_value = res.fun\n                    best_sample = res.x\n                    bounds = self._reduce_bounds(bounds, best_sample, dynamic_radius)\n                    dynamic_radius *= 0.8  # More aggressive adjustment\n                    no_improvement_steps = 0\n                else:\n                    no_improvement_steps += 1\n                    if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                        sample = self._random_restart(bounds)\n                        no_improvement_steps = 0\n                dynamic_radius = max(0.01, dynamic_radius * (1.05 if no_improvement_steps > 2 else 0.95))  # Fine-tuned radius adjustment\n\n        return best_sample\n\n    def _optimize_sample(self, func, sample, bounds):\n        return minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by introducing dynamic radius adjustment and implementing parallel sampling for enhanced convergence and exploration.", "configspace": "", "generation": 86, "fitness": 0.2070936803160731, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.207 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.18646461515194857, 0.23122532961205244, 0.20359109618421822], "final_y": [0.15662880815378102, 0.0803519220059862, 0.1124781228527033]}, "mutation_prompt": null}
{"id": "94ed6e8b-100b-4f00-9b3c-07decf633402", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.15  # Adjusted initial radius for better initial exploration\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for quicker random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with dynamic initial radius adjustment and improved restart strategy for better exploration-exploitation balance.", "configspace": "", "generation": 87, "fitness": 0.8235912500161334, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8174894134118338, 0.8480100269985785, 0.8052743096379881], "final_y": [7.719875376685067e-08, 3.7644024200615866e-08, 2.049400655717557e-08]}, "mutation_prompt": null}
{"id": "c455b9eb-066d-4d8b-acda-fa0899bfb142", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.88  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Refined convergence control by adjusting the radius scaling factor to balance exploration and exploitation more effectively.", "configspace": "", "generation": 88, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "d7857cce-99ae-4c86-b4a5-bf390e2c265e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n        learning_rate = 0.05  # New line: Introduced a learning rate for adaptive dynamics\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:\n                    sample = self._random_restart(bounds, learning_rate)  # Modified: Added learning_rate to the restart\n                    learning_rate *= 1.1  # New line: Adaptive adjustment of learning rate\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds, learning_rate):  # Modified: Added learning_rate parameter\n        return np.array([np.random.uniform(low * (1 - learning_rate), high * (1 + learning_rate)) for low, high in bounds])  # Modified: Incorporate learning rate", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by introducing adaptive learning for random restart strategy and fine-tuning hyperparameters for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "6544e68c-9b71-4c35-926b-b5610759c84b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(7 * self.dim * (self.budget / (10 * self.dim))))  # Slightly increased sample count\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced convergence by slightly increasing the initial sampling density for better initial exploration.", "configspace": "", "generation": 90, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "506b7b33-5c53-402a-83ed-f21556f7c7a1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Reduced threshold for quicker restarts\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 2 else 0.85))  # Adjusted scaling for radius\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction with a refined restart strategy and adaptive scaling to improve exploration-exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.5740850607394962, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.574 with standard deviation 0.351. And the mean value of best solutions found was 2.448 (0. is the best) with standard deviation 3.462.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8322305672992558, 0.8125730279159792, 0.07745158700325361], "final_y": [2.5205054258409693e-10, 5.739586281907357e-08, 7.343170165498999]}, "mutation_prompt": null}
{"id": "cd78f63c-627f-4cc8-91a9-255fe5ea320f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.15 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Boundary Reduction Optimizer by refining radius adjustment and random restart criteria for improved convergence.", "configspace": "", "generation": 92, "fitness": 0.7993587608103271, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8369849416754593, 0.8054692859058692, 0.7556220548496531], "final_y": [2.0991054393363378e-08, 1.1772790745395264e-07, 1.1908664952362401e-07]}, "mutation_prompt": null}
{"id": "713b37a9-07e6-4195-9f10-1465d94e8595", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(7 * self.dim * (self.budget / (10 * self.dim))))  # Adjusted multiplier for better initial coverage\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for refined exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.88))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer with improved convergence rate and adaptive sample size for efficient exploration and exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "8e06a5ca-85a2-427c-986b-fcc154f497db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.9  # Adjusted for balanced exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for dynamic restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.8))  # Further refined convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration-exploitation balance by refining radius adjustment strategy and dynamic restart condition for improved convergence.", "configspace": "", "generation": 94, "fitness": 0.5735566860671671, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.574 with standard deviation 0.405. And the mean value of best solutions found was 13.118 (0. is the best) with standard deviation 18.552.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8762557820189003, 0.8426828484495394, 0.0017314277330618966], "final_y": [1.172778123576638e-09, 5.6387797367030076e-08, 39.35502056172664]}, "mutation_prompt": null}
{"id": "27ca095a-1f02-4347-8c9e-373de7f1abab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for more gradual exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4 and np.random.rand() < 0.5:  # Introduced dynamic probability for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Optimized Adaptive Boundary Reduction Optimizer by refining step size tuning and introducing dynamic restart probability to enhance performance.", "configspace": "", "generation": 95, "fitness": 0.8476082563389347, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8671381513453489, 0.8491018985212391, 0.8265847191502161], "final_y": [2.743697807874064e-08, 2.2845596085097478e-08, 2.338897608732287e-08]}, "mutation_prompt": null}
{"id": "0c5293c9-edd8-4713-a5d2-3409168dc804", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.8  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced Adaptive Boundary Reduction Optimizer by refining sample selection and dynamic adjustment for better convergence and exploration balance.", "configspace": "", "generation": 96, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
{"id": "783e89cd-b9f4-4945-9c33-a2d84493df4a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(10 * self.dim * (self.budget / (10 * self.dim))))  # Increased sample count for better initial exploration\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Enhanced exploration by increasing initial sample count for better coverage of the search space.", "configspace": "", "generation": 97, "fitness": 0.5668364440860749, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.567 with standard deviation 0.395. And the mean value of best solutions found was 10.970 (0. is the best) with standard deviation 15.514.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8088211412658473, 0.8819005772497215, 0.00978761374265602], "final_y": [6.244171777092066e-08, 8.384560243515212e-09, 32.91025186720649]}, "mutation_prompt": null}
{"id": "fe30818a-7db7-4911-976c-da9752aca41b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(6 * self.dim * (self.budget / (12 * self.dim))))  # Adjusted sample factor\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.005  # Adjusted improvement threshold\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.85  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 4:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.1 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "A refined Adaptive Boundary Reduction Optimizer that enhances exploration and exploitation by adjusting sampling strategy and convergence rate for better performance.", "configspace": "", "generation": 98, "fitness": 0.8419707076186347, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.013. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8373365929111434, 0.8292531019818149, 0.8593224279629458], "final_y": [1.5506032678723673e-08, 4.355508130045926e-08, 3.975624053979662e-08]}, "mutation_prompt": null}
{"id": "40106cce-d530-4d7f-a65d-8e2c171644fe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveBoundaryReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        initial_radius = 0.1\n        num_samples = max(1, int(5 * self.dim * (self.budget / (10 * self.dim))))\n        initial_samples = self._uniform_sampling(bounds, num_samples)\n        best_sample = None\n        best_value = float('inf')\n        improvement_threshold = 0.01\n        no_improvement_steps = 0\n\n        for sample in initial_samples:\n            if self.budget <= 0:\n                break\n            res = minimize(func, sample, method='L-BFGS-B', bounds=bounds)\n            self.budget -= res.nfev\n            if res.fun < best_value - improvement_threshold:\n                best_value = res.fun\n                best_sample = res.x\n                bounds = self._reduce_bounds(bounds, best_sample, initial_radius)\n                initial_radius *= 0.75  # Adjusted for better exploration\n                no_improvement_steps = 0\n            else:\n                no_improvement_steps += 1\n                if no_improvement_steps > 3:  # Adjusted threshold for random restart\n                    sample = self._random_restart(bounds)\n                    no_improvement_steps = 0\n            initial_radius = max(0.01, initial_radius * (1.2 if no_improvement_steps > 2 else 0.9))  # Adjusted to improve convergence\n\n        return best_sample\n\n    def _uniform_sampling(self, bounds, num_samples):\n        samples = []\n        for _ in range(num_samples):\n            sample = np.array([np.random.uniform(low, high) for low, high in bounds])\n            samples.append(sample)\n        return samples\n\n    def _reduce_bounds(self, bounds, best_sample, radius):\n        new_bounds = []\n        for i, (low, high) in enumerate(bounds):\n            center = best_sample[i]\n            range_adjustment = (high - low) * radius\n            new_low = max(low, center - range_adjustment)\n            new_high = min(high, center + range_adjustment)\n            new_bounds.append((new_low, new_high))\n        return np.array(new_bounds)\n\n    def _random_restart(self, bounds):\n        return np.array([np.random.uniform(low, high) for low, high in bounds])", "name": "AdaptiveBoundaryReductionOptimizer", "description": "Improved convergence and exploration-exploitation balance by fine-tuning radius adjustment and restart strategy for better performance.", "configspace": "", "generation": 99, "fitness": 0.8405236204882578, "feedback": "The algorithm AdaptiveBoundaryReductionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0a178318-6e83-4eae-bacb-211df8412a67", "metadata": {"aucs": [0.8191323868543126, 0.8317384657727402, 0.8707000088377205], "final_y": [1.930154900888162e-08, 2.0837831761340702e-08, 2.1952636665709724e-08]}, "mutation_prompt": null}
