{"id": "731c98ea-7acb-4aa8-8a9a-e5a95998c383", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = 0.8   # Differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n            temperature *= 0.99  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This algorithm combines principles of Differential Evolution and Simulated Annealing to explore and exploit the search space efficiently by iteratively mutating and recombining candidate solutions with a temperature-based acceptance criterion for global optimization.", "configspace": "", "generation": 0, "fitness": 0.2486905400209927, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.249 with standard deviation 0.004. And the mean value of best solutions found was 0.053 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": null, "metadata": {"aucs": [0.24342400668620268, 0.2539306359720782, 0.24871697740469723], "final_y": [0.05073340299662235, 0.0442507323641165, 0.06545216339814007]}, "mutation_prompt": null}
{"id": "2c327954-ee1e-445a-bb07-fe83eed9bce6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            CR = 0.9 * (1 - generation / (self.budget - pop_size))  # Dynamic crossover probability\n            F = 0.8 * (1 + generation / (self.budget - pop_size))   # Dynamic differential weight\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n            temperature *= 0.99  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This algorithm augments Differential Evolution and Simulated Annealing by incorporating dynamic scaling of the differential weight (F) and crossover probability (CR) based on the generation number to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.24275186165737417, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.004. And the mean value of best solutions found was 0.070 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "731c98ea-7acb-4aa8-8a9a-e5a95998c383", "metadata": {"aucs": [0.24785087368653047, 0.2381423618169486, 0.24226234946864345], "final_y": [0.07728932493512258, 0.04585303032137185, 0.08756430543140463]}, "mutation_prompt": null}
{"id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = 0.8   # Differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        F = 0.5 + 0.5 * np.abs(best_fitness - trial_fitness)  # Adapt F\n\n            temperature *= 0.99  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This algorithm integrates Differential Evolution with a simulated annealing approach and enhances exploration by introducing a dynamic crossover rate and differential weight adaptation based on current best fitness improvement.", "configspace": "", "generation": 2, "fitness": 0.29993086361688054, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.021. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "731c98ea-7acb-4aa8-8a9a-e5a95998c383", "metadata": {"aucs": [0.27511101043238906, 0.3255175535546898, 0.2991640268635628], "final_y": [0.013468116216168328, 0.005176576216082262, 0.013686397884819377]}, "mutation_prompt": null}
{"id": "ac5777ea-38f1-460b-9f58-6e5a5f7a3a8d", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        num_particles = 10 * self.dim\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        swarm = np.random.uniform(bounds[0], bounds[1], (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_idx]\n        global_best_fitness = personal_best_fitness[global_best_idx]\n\n        omega = 0.5  # Inertia weight\n        phi_p = 1.5  # Personal attraction coefficient\n        phi_g = 1.5  # Global attraction coefficient\n        q_tunneling_intensity = 0.1  # Intensity of quantum tunneling\n\n        for iteration in range(self.budget - num_particles):\n            r_p = np.random.rand(num_particles, self.dim)\n            r_g = np.random.rand(num_particles, self.dim)\n            velocities = (omega * velocities +\n                          phi_p * r_p * (personal_best - swarm) +\n                          phi_g * r_g * (global_best - swarm))\n\n            for i in range(num_particles):\n                if np.random.rand() < q_tunneling_intensity:\n                    # Quantum Tunneling - Jump to a random position\n                    swarm[i] = np.random.uniform(bounds[0], bounds[1], self.dim)\n                else:\n                    # Normal velocity update\n                    swarm[i] = np.clip(swarm[i] + velocities[i], bounds[0], bounds[1])\n                \n                fitness_i = func(swarm[i])\n\n                if fitness_i < personal_best_fitness[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_fitness[i] = fitness_i\n                    if fitness_i < global_best_fitness:\n                        global_best = swarm[i]\n                        global_best_fitness = fitness_i\n\n        return global_best, global_best_fitness", "name": "QuantumInspiredParticleSwarm", "description": "Quantum-Inspired Particle Swarm Optimization combines Quantum Mechanics principles with Particle Swarm Optimization to enhance exploration and balance convergence using quantum superposition and tunneling effects.", "configspace": "", "generation": 3, "fitness": 0.24518067936447707, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.024. And the mean value of best solutions found was 0.077 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "metadata": {"aucs": [0.23360374125808836, 0.2780844876178403, 0.22385380921750253], "final_y": [0.08291450872795877, 0.0509676938386272, 0.09842375920442382]}, "mutation_prompt": null}
{"id": "5cb24c6f-b29b-4205-beb3-8c8f1b8abf87", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = 0.8   # Differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        F = 0.5 + 0.5 * np.abs(best_fitness - trial_fitness)  # Adapt F\n\n            # Add global fitness variance adjustment\n            fitness_variance = np.var(fitness)\n            F = min(1.0, 0.5 * (1 + fitness_variance))\n\n            temperature *= 0.99  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate Differential Evolution with simulated annealing and enhance exploration by dynamically adapting the crossover rate and differential weight based on both current best fitness improvement and global fitness variance.", "configspace": "", "generation": 4, "fitness": 0.2448590637479988, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.046. And the mean value of best solutions found was 0.244 (0. is the best) with standard deviation 0.334.", "error": "", "parent_id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "metadata": {"aucs": [0.2722264700013507, 0.18037997963073893, 0.2819707416119067], "final_y": [0.0021322038599787107, 0.7161645199004436, 0.012977793094582272]}, "mutation_prompt": null}
{"id": "0f159cc9-2249-463e-8d5d-351b6a551e4e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = 0.8   # Differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            # Line change 1: Reduce population size adaptively\n            if generation % 50 == 0 and pop_size > 2:\n                pop_size = max(2, pop_size - 1)\n                pop = pop[:pop_size]\n                fitness = fitness[:pop_size]\n            \n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        F = 0.5 + 0.5 * np.abs(best_fitness - trial_fitness)  # Adapt F\n\n            # Line change 2: Enhance the cooling schedule\n            temperature *= 0.995  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This algorithm refines Differential Evolution with Simulated Annealing by introducing adaptive population size reduction and an enhanced cooling schedule for temperature.", "configspace": "", "generation": 5, "fitness": 0.2670926139455722, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.003. And the mean value of best solutions found was 0.031 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "metadata": {"aucs": [0.2641464232307491, 0.2666727143894615, 0.2704587042165061], "final_y": [0.053021177643932875, 0.020790387945502566, 0.02062161591565195]}, "mutation_prompt": null}
{"id": "2e58a384-453b-427e-a2bd-ffd0a83ccd37", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = np.full(pop_size, 0.9)  # Crossover probabilities per individual\n        F = np.full(pop_size, 0.8)   # Differential weights per individual\n        temperature = 1.0\n        memory = np.zeros(pop_size)  # Memory to track improvements\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                    memory[i] = 1  # Mark improvement\n\n            temperature *= 0.98  # Cool down the temperature\n\n            # Update CR and F based on improvements\n            for i in range(pop_size):\n                if memory[i] == 1:\n                    CR[i] = min(1, CR[i] + 0.05)\n                    F[i] = np.clip(F[i] + 0.05 * (np.random.rand() - 0.5), 0.5, 1.0)\n                else:\n                    CR[i] = max(0.1, CR[i] - 0.05)\n                    F[i] = np.clip(F[i] - 0.05 * (np.random.rand() - 0.5), 0.5, 1.0)\n                memory[i] = 0  # Reset memory\n\n        return best, best_fitness", "name": "AdaptiveDifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm integrates Differential Evolution with simulated annealing and employs adaptive learning to dynamically adjust individual mutation strategies and crossover rates based on historical performance trends within the population.", "configspace": "", "generation": 6, "fitness": 0.26028194239560076, "feedback": "The algorithm AdaptiveDifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.028. And the mean value of best solutions found was 0.031 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "metadata": {"aucs": [0.2873700023646363, 0.27130031113862774, 0.22217551368353827], "final_y": [0.03384823083687337, 0.03141552247050344, 0.026351470837008676]}, "mutation_prompt": null}
{"id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm leverages adaptive learning rates based on the historical success of mutations to enhance search efficiency and adaptability.", "configspace": "", "generation": 7, "fitness": 0.30677428813126334, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.023. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "1db7686e-96a2-4a43-9c98-c94ed3d416ba", "metadata": {"aucs": [0.31032496922651753, 0.33334336420305344, 0.2766545309642191], "final_y": [0.008801397655430504, 0.002052324047606339, 0.01981874105092109]}, "mutation_prompt": null}
{"id": "0222d4ee-cd83-4a63-a97a-5d828a8de7ff", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.99 if (generation % 10 == 0 and generation > 0) else 0.98  # Dynamically adjust cooling\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm dynamically adjusts the cooling rate based on the progression of improvements to balance exploration and exploitation more effectively.", "configspace": "", "generation": 8, "fitness": 0.2642753303832951, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.264 with standard deviation 0.041. And the mean value of best solutions found was 0.080 (0. is the best) with standard deviation 0.081.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.31910003535405707, 0.25212190402693324, 0.22160405176889497], "final_y": [0.010630980513813615, 0.037298218696498145, 0.19338160766182777]}, "mutation_prompt": null}
{"id": "2e324d90-0ab6-4c89-a98f-91cb73cbbe26", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98  # Cool down the temperature\n            pop_size = max(2, int(10 * self.dim * (0.9 ** (generation / 100))))  # Dynamic population size adjustment\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm dynamically adjusts the population size throughout the optimization process to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.21324237871413712, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.065. And the mean value of best solutions found was 0.734 (0. is the best) with standard deviation 1.004.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.2660223721095525, 0.12192970850861762, 0.2517750555242413], "final_y": [0.013442087503150003, 2.1540995422189675, 0.035856593590264045]}, "mutation_prompt": null}
{"id": "4e43c5fa-3347-4922-9358-8546f28e81e1", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  \n        F = np.full(pop_size, 0.8)  \n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.6 + 0.4 * (np.random.rand() * (best_fitness / (best_fitness + trial_fitness + 1e-12)))\n\n                F[i] = 0.5 + 0.5 * np.sin(np.pi * (fitness[i] / (1 + np.abs(best_fitness - fitness[i]))))  \n\n            temperature *= 0.95  \n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "An enhanced hybrid approach utilizing dynamic adaptation of control parameters to improve convergence rates and solution quality.", "configspace": "", "generation": 10, "fitness": 0.24648903177653556, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.006. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.2482395051662416, 0.2523201005869824, 0.23890748957638264], "final_y": [0.009655894469051707, 0.036246449788839806, 0.01215158364714863]}, "mutation_prompt": null}
{"id": "be83b252-7d86-4700-8efb-efbf7907992b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.99  # Slightly slower cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm adaptively adjusts differential vector weights and cooling rate based on fitness improvements to enhance exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.23495092663975403, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.025. And the mean value of best solutions found was 0.071 (0. is the best) with standard deviation 0.073.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.24818891349217564, 0.20052932825150216, 0.2561345381755843], "final_y": [0.014626852835360773, 0.1741181020928308, 0.02329969991884008]}, "mutation_prompt": null}
{"id": "2b569a11-1163-4002-bfa3-3584112620c1", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.95  # Cool down the temperature more aggressively\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This algorithm employs adaptive crossover probability and dynamic temperature cooling to enhance convergence efficiency and solution quality.", "configspace": "", "generation": 12, "fitness": 0.25970849345404085, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.059. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.264.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.1776189319245779, 0.2867439849450938, 0.3147625634924509], "final_y": [0.5674572084784473, 0.0063573391386015365, 0.009361104985042827]}, "mutation_prompt": null}
{"id": "4b603282-cbb6-44e5-a297-e840efb4c602", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n        reinit_interval = self.budget // 10  # New parameter for diversity control\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                if generation % reinit_interval == 0:  # Periodic reinitialization\n                    pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                    fitness[i] = func(pop[i])\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "An enhanced hybrid algorithm that integrates dynamic crossover and differential weight adaptation mechanisms, along with a periodic reinitialization strategy to maintain diversity and improve convergence.", "configspace": "", "generation": 13, "fitness": 0.2796044822637766, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.280 with standard deviation 0.037. And the mean value of best solutions found was 0.034 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.30885065524977495, 0.22789312608452827, 0.3020696654570265], "final_y": [0.002540564945644255, 0.09413913078516713, 0.004192791924521353]}, "mutation_prompt": null}
{"id": "728db847-0cdc-40b8-8b73-3aa78cc61e8a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98  # Cool down the temperature\n            CR = 0.5 + 0.5 * (1 - (generation / self.budget))  # New line: Adapt CR based on generation\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm utilizes adaptive crossover probability based on convergence rate to enhance search efficiency and adaptability.", "configspace": "", "generation": 14, "fitness": 0.20697401895761366, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.207 with standard deviation 0.072. And the mean value of best solutions found was 1.013 (0. is the best) with standard deviation 1.407.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.1156409460722978, 0.21230378311545628, 0.2929773276850869], "final_y": [3.0023954910241657, 0.02523810608086484, 0.011590724785766608]}, "mutation_prompt": null}
{"id": "ea9cceba-49ad-45aa-9120-5ef3b2bc663e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            # Dynamically adjust CR\n            CR = 0.7 + 0.3 * np.tanh(best_fitness)\n\n            temperature *= 0.98  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm introduces an adaptive mutation strategy and a dynamic crossover probability to further enhance search efficiency and solution quality in black box optimization.", "configspace": "", "generation": 15, "fitness": 0.20508022073057572, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.114. And the mean value of best solutions found was 0.571 (0. is the best) with standard deviation 0.566.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.12537761267435554, 0.3668975892310913, 0.1229654602862803], "final_y": [0.3610584830966897, 0.005596832771928108, 1.3449353036332048]}, "mutation_prompt": null}
{"id": "42f0d39d-8990-4910-8dd0-d00966c39bf8", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.96  # Cool down the temperature more aggressively\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This refined algorithm leverages adaptive cooling schedules for temperature to enhance convergence rates and stability in complex optimization landscapes.", "configspace": "", "generation": 16, "fitness": 0.26025265084815014, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.016. And the mean value of best solutions found was 0.009 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.24396052196315, 0.2543036296071398, 0.28249380097416066], "final_y": [0.009214745052160267, 0.010752624257332645, 0.007472771872298676]}, "mutation_prompt": null}
{"id": "f8f1615b-9361-43fc-820f-abe47da6b220", "solution": "import numpy as np\n\nclass AdaptiveDESimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                base_mutant = a + F[i] * (b - c)\n                mutant = np.clip(base_mutant + np.random.normal(0, 0.1, self.dim), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))\n\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98\n\n        return best, best_fitness", "name": "AdaptiveDESimulatedAnnealing", "description": "This enhanced strategy utilizes an adaptive mutation strategy and stochastic acceptance to improve exploration while dynamically adjusting crossover rates based on convergence trends.", "configspace": "", "generation": 17, "fitness": 0.28095693710368563, "feedback": "The algorithm AdaptiveDESimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.006. And the mean value of best solutions found was 0.030 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.28459165929555497, 0.2730279101895584, 0.2852512418259435], "final_y": [0.02349208466870966, 0.027177766797426416, 0.037863830573917866]}, "mutation_prompt": null}
{"id": "5043ed22-2a91-411e-9f54-45654cefcccc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        initial_pop_size = 10 * self.dim\n        pop_size = initial_pop_size\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - initial_pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                if np.random.rand() < 0.5:\n                    F[i] = 0.7 + 0.3 * np.random.rand()  # Dynamic mutability\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))\n                        \n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98\n            if generation % (self.budget // 10) == 0 and pop_size < 20 * self.dim:  # Adaptive population size\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.dim, self.dim))\n                new_fitness = np.array([func(ind) for ind in new_pop])\n                pop = np.vstack((pop, new_pop))\n                fitness = np.hstack((fitness, new_fitness))\n                pop_size = len(pop)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "This enhanced algorithm incorporates dynamic mutability and an adaptive population size to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {}, "mutation_prompt": null}
{"id": "6f12f1a5-acd2-45db-9480-8ac2f4fbcc3a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.3 * (generation / self.budget)  # Dynamic CR adjustment\n                        \n                # Adapt F based on historical success\n                F[i] = 0.5 + 0.5 * (best_fitness - fitness[i]) / (1 + np.abs(best_fitness - fitness[i]))\n\n            temperature *= 0.98  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce dynamic adjustment of the crossover probability to enhance exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.2746212521344668, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.000. And the mean value of best solutions found was 0.014 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.27472570345390357, 0.27494398063941794, 0.274194072310079], "final_y": [0.005943108603399381, 0.030165713241016003, 0.005003959331765936]}, "mutation_prompt": null}
{"id": "8a787920-7f91-4b4a-a00a-67518d968292", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98  # Cool down the temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced adaptive mutation strategy adjusts mutation strength based on the diversity of the population and their historical success rates.", "configspace": "", "generation": 20, "fitness": 0.30708361856082805, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.005. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e84bb47e-7b63-4f03-a7e9-6797b319a579", "metadata": {"aucs": [0.30970068239434023, 0.3007053324975001, 0.3108448407906439], "final_y": [0.004742528766989107, 0.019280091293152442, 0.014878873932240026]}, "mutation_prompt": null}
{"id": "0f67525a-b5ae-4240-966a-cc44de5e6e9c", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + F[i] * (b - c)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Gradient-informed crossover adjustment\n                if np.random.rand() < 0.5:\n                    grad = np.gradient(fitness)  # Mock gradient for illustration\n                    trial = np.clip(trial - F[i] * grad, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                \n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.95  # Adjusted cooling rate\n            \n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Hybrid Differential Evolution-Simulated Annealing with Adaptive Strategy Fusions and Stochastic Gradient Informed Crossover.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (2,) (20,) ').", "error": "ValueError('operands could not be broadcast together with shapes (2,) (20,) ')", "parent_id": "8a787920-7f91-4b4a-a00a-67518d968292", "metadata": {}, "mutation_prompt": null}
{"id": "ccfa9eed-dcfe-48ad-8e58-0d5067248981", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98\n\n            # Perform local search around the current best solution\n            neighborhood = best + np.random.normal(0, 0.05, self.dim)\n            neighborhood = np.clip(neighborhood, func.bounds.lb, func.bounds.ub)\n            neighborhood_fitness = func(neighborhood)\n            if neighborhood_fitness < best_fitness:\n                best = neighborhood\n                best_fitness = neighborhood_fitness\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced adaptive mutation strategy adjusts mutation strength and crossover rate based on diversity and historical success rates, with neighborhood search to accelerate convergence.", "configspace": "", "generation": 22, "fitness": 0.2810168591560048, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.002. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8a787920-7f91-4b4a-a00a-67518d968292", "metadata": {"aucs": [0.2840088702763882, 0.27923135208909633, 0.2798103551025297], "final_y": [0.0024551304966997367, 0.0026687558998957877, 0.005086859375651076]}, "mutation_prompt": null}
{"id": "080c3a71-c982-4d69-8972-fb9b7ea255e2", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive cooling rate for temperature to enhance exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.31300283411902036, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.313 with standard deviation 0.017. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "8a787920-7f91-4b4a-a00a-67518d968292", "metadata": {"aucs": [0.3358129393391187, 0.30949565836683746, 0.29369990465110496], "final_y": [0.0014767041967392515, 0.01664070457976798, 0.02204266773102049]}, "mutation_prompt": null}
{"id": "f023cab2-09c9-4049-ab07-39d2a8e3a280", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = np.ones(pop_size) * 0.9  # Self-adaptive crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n                CR[i] = 0.5 + 0.3 * np.exp(-diversity)  # Adaptive CR based on diversity\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance diversity and convergence by introducing self-adaptive crossover rate and dynamic differential weight strategy.", "configspace": "", "generation": 24, "fitness": 0.2525877355463339, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.070. And the mean value of best solutions found was 0.061 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "080c3a71-c982-4d69-8972-fb9b7ea255e2", "metadata": {"aucs": [0.32163223253001727, 0.2801790318473496, 0.15595194226163478], "final_y": [0.0041178175978982216, 0.030171619943542862, 0.14769714736666395]}, "mutation_prompt": null}
{"id": "f01a5c1a-d5fe-479a-9085-3ce4c57b345b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)  # Self-adaptive F\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a self-adaptive differential weight vector to enhance mutation strategy in Differential Evolution Simulated Annealing.", "configspace": "", "generation": 25, "fitness": 0.288654317173417, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.289 with standard deviation 0.010. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "080c3a71-c982-4d69-8972-fb9b7ea255e2", "metadata": {"aucs": [0.28500807792464966, 0.279241788844073, 0.30171308475152825], "final_y": [0.02950172864245082, 0.0024654577090236986, 0.012479612499837624]}, "mutation_prompt": null}
{"id": "51953252-de73-4337-ae18-d8f91a268d47", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            dynamic_pop_size = int(pop_size * (0.5 + 0.5 * (1 - generation / self.budget)))\n            for i in range(dynamic_pop_size):\n                idxs = [idx for idx in range(dynamic_pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))\n                        \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = max(0.4, min(F[i], 0.9))  # Clamp F to a reasonable range\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance solution diversity and adaptability by introducing dynamic population size and adaptive mutation strategies.", "configspace": "", "generation": 26, "fitness": 0.28344729526684825, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.014. And the mean value of best solutions found was 0.017 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "080c3a71-c982-4d69-8972-fb9b7ea255e2", "metadata": {"aucs": [0.28262236509287875, 0.2661869232920089, 0.3015325974156572], "final_y": [0.022544893450736785, 0.01750808663126936, 0.010853117184498317]}, "mutation_prompt": null}
{"id": "fc5fa4e6-069d-474a-ad57-d490168df114", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted F scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate diversity-based scaling of the differential weight (F) to enhance convergence robustness.", "configspace": "", "generation": 27, "fitness": 0.314161836637174, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.314 with standard deviation 0.011. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "080c3a71-c982-4d69-8972-fb9b7ea255e2", "metadata": {"aucs": [0.32861358274356234, 0.31032205153278136, 0.3035498756351783], "final_y": [0.0018892730574680107, 0.004137751168761794, 0.006574145784765878]}, "mutation_prompt": null}
{"id": "628ffdfd-7971-4434-b4c9-a72845a909ac", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.6 + 0.4 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.4 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted F scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance adaptive strategies for crossover and differential weight to refine convergence and solution quality.", "configspace": "", "generation": 28, "fitness": 0.17216933710585916, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.172 with standard deviation 0.078. And the mean value of best solutions found was 2.084 (0. is the best) with standard deviation 2.412.", "error": "", "parent_id": "fc5fa4e6-069d-474a-ad57-d490168df114", "metadata": {"aucs": [0.08012831411326471, 0.16616979355419603, 0.27020990365011677], "final_y": [5.470973968176435, 0.7440590619300655, 0.038439628486207085]}, "mutation_prompt": null}
{"id": "d563088d-e0e4-4a58-ae26-06457008dbf2", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adapt F based on historical success and diversity\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted F scaling\n\n            temperature *= 0.97 - 0.02 * (generation / self.budget)  # Modified adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhanced adaptive cooling by modifying the temperature decay formula for improved exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.2669210802341019, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.034. And the mean value of best solutions found was 0.101 (0. is the best) with standard deviation 0.135.", "error": "", "parent_id": "fc5fa4e6-069d-474a-ad57-d490168df114", "metadata": {"aucs": [0.22008215134783893, 0.281634021140303, 0.2990470682141637], "final_y": [0.2912443629273494, 0.008624820877865804, 0.002003610270452765]}, "mutation_prompt": null}
{"id": "55b891ee-94e6-465c-8aa7-4c53b522c218", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Adjusted mutation strategy\n                mutant = np.clip(a + F[i] * (b - c + np.random.normal(0, 0.1, self.dim)), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                # Adjusted F scaling\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (0.5 + diversity)  # Adjusted F scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Hybridize adaptive crossover and mutation variance strategies to enhance exploration while maintaining convergence precision.", "configspace": "", "generation": 30, "fitness": 0.29007743752759435, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.290 with standard deviation 0.007. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fc5fa4e6-069d-474a-ad57-d490168df114", "metadata": {"aucs": [0.2796499998784977, 0.2957176859715559, 0.2948646267327294], "final_y": [0.022111481816240217, 0.020124012006584032, 0.016103477680551963]}, "mutation_prompt": null}
{"id": "4d7008b7-77c3-4755-8a1a-62f825bdf4f4", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        CR = 0.5 + 0.5 * (best_fitness / (best_fitness + trial_fitness))  # Adapt CR\n                        \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted F scaling\n                CR = 0.9 - 0.4 * diversity  # Adjusted CR scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)  # Adaptive cooling rate\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance adaptive behavior by modifying the crossover probability based on diversity.", "configspace": "", "generation": 31, "fitness": 0.20207163001619466, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.202 with standard deviation 0.045. And the mean value of best solutions found was 0.347 (0. is the best) with standard deviation 0.205.", "error": "", "parent_id": "fc5fa4e6-069d-474a-ad57-d490168df114", "metadata": {"aucs": [0.2633705129404942, 0.18397193833948822, 0.15887243876860158], "final_y": [0.06741004944818177, 0.5503814020556238, 0.4241918840136416]}, "mutation_prompt": null}
{"id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Dynamic recombination rate based on position in population\n                CR = 0.6 + (0.4 * np.abs(fitness[i] - best_fitness) / (np.max(fitness) - np.min(fitness)))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                # Adaptive F adjustment based on diversity and success\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Hybridize Differential Evolution with Adaptive Annealing and Dynamic Recombination Rate for improved convergence and solution quality.", "configspace": "", "generation": 32, "fitness": 0.33152846422157106, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.332 with standard deviation 0.019. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fc5fa4e6-069d-474a-ad57-d490168df114", "metadata": {"aucs": [0.3144335175327696, 0.3220766294571509, 0.35807524567479265], "final_y": [0.008005663743958683, 0.005464453893106497, 0.0032362632960002908]}, "mutation_prompt": null}
{"id": "b97b3200-aa53-4d9c-b9c1-552f94b4dd5d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Dynamic recombination rate based on position in population\n                CR = 0.6 + (0.4 * np.abs(fitness[i] - best_fitness) / (np.max(fitness) - np.min(fitness)))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                # Adaptive F adjustment based on diversity and success\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= np.exp(-0.02)  # Exponential decay of temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate Exponential Decay of Temperature with a Dynamic Cross Rate for Enhanced Convergence in Differential Evolution Simulated Annealing.", "configspace": "", "generation": 33, "fitness": 0.3261382665502916, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.326 with standard deviation 0.032. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "metadata": {"aucs": [0.3015517841089961, 0.37205815454027646, 0.3048048610016022], "final_y": [0.00872749586755865, 0.002334034345145687, 0.0029657741745029442]}, "mutation_prompt": null}
{"id": "21f25e5c-6148-4270-88cf-b1373f82e1f0", "solution": "import numpy as np\nfrom scipy.stats import levy\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce Levy Flight with 10% probability\n                    mutant += levy.rvs(size=self.dim)\n\n                CR = 0.6 + (0.4 * np.abs(fitness[i] - best_fitness) / (np.max(fitness) - np.min(fitness)))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate Levy Flight mechanism into Differential Evolution Simulated Annealing for enhanced exploration and faster convergence.", "configspace": "", "generation": 34, "fitness": 0.2399452669778187, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.065. And the mean value of best solutions found was 0.396 (0. is the best) with standard deviation 0.549.", "error": "", "parent_id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "metadata": {"aucs": [0.287989221483011, 0.28356539427659866, 0.14828118517384647], "final_y": [0.00458526417786791, 0.012214857892643913, 1.1724320848261574]}, "mutation_prompt": null}
{"id": "c9e7ac94-bed3-4615-aeeb-1d773b16f805", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        num_subpops = 3  # Using multiple subpopulations\n        subpop_size = (10 * self.dim) // num_subpops\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_subpops * subpop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(num_subpops * subpop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - num_subpops * subpop_size):\n            for subpop in range(num_subpops):\n                for i in range(subpop * subpop_size, (subpop + 1) * subpop_size):\n                    idxs = [idx for idx in range(subpop * subpop_size, (subpop + 1) * subpop_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    F[i] = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n                    mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                    \n                    cross_points = np.random.rand(self.dim) < CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    trial_fitness = func(trial)\n\n                    if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                        pop[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_fitness = trial_fitness\n                            best = trial\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a multi-population strategy with adaptive mutation scaling to enhance exploration and exploitation balance in the optimization process.", "configspace": "", "generation": 35, "fitness": 0.2766913952240247, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.277 with standard deviation 0.036. And the mean value of best solutions found was 0.030 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "metadata": {"aucs": [0.31008980868925995, 0.29290602515507846, 0.22707835182773572], "final_y": [0.01576082468619159, 0.007462959393445594, 0.06746156122931024]}, "mutation_prompt": null}
{"id": "4a0035b3-bb6c-4e62-988c-59de5337f75b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                \n                # Levy flight for mutation\n                step = np.random.normal(0, 1, self.dim) * (np.random.normal(0, 1) ** (-1 / 1.5))\n                mutant = np.clip(a + step * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Dynamic recombination rate based on position in population\n                CR = 0.6 + (0.4 * np.abs(fitness[i] - best_fitness) / (np.max(fitness) - np.min(fitness)))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                # Adaptive F adjustment based on diversity and success\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by incorporating Levy flight mechanism for mutation in Differential Evolution.", "configspace": "", "generation": 36, "fitness": 0.2526177705995129, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.007. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "metadata": {"aucs": [0.24818066707239606, 0.2618366529391192, 0.24783599178702342], "final_y": [0.01459634522996904, 0.030692107824654813, 0.05062777937416114]}, "mutation_prompt": null}
{"id": "7ebacf6a-00dd-4fde-9c6a-d27f4b47792d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Dynamic recombination rate based on position in population\n                CR = 0.6 + (0.4 * np.abs(fitness[i] - best_fitness) / (np.max(fitness) - np.min(fitness)))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                # Adaptive F adjustment based on diversity and success\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)  # Ensure F stays within a realistic range\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive mutation scaling for enhanced exploration in Differential Evolution Simulated Annealing.", "configspace": "", "generation": 37, "fitness": 0.34418035889357607, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.344 with standard deviation 0.024. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "718a2772-1dbd-4dec-bbd5-7c2c8c248a19", "metadata": {"aucs": [0.31075466176431255, 0.35581939520967076, 0.36596701970674483], "final_y": [0.011458074162399846, 0.001891151551489308, 0.004418906061175374]}, "mutation_prompt": null}
{"id": "9bbeec73-e451-4a41-8059-cc78d82156e9", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        sub_pop_size = pop_size // 2  # Multi-population strategy\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for sp_start in range(0, pop_size, sub_pop_size):\n                sub_pop = pop[sp_start:sp_start + sub_pop_size]\n                sub_fitness = fitness[sp_start:sp_start + sub_pop_size]\n                local_best_idx = np.argmin(sub_fitness)\n                local_best = sub_pop[local_best_idx]\n\n                for i in range(sp_start, sp_start + sub_pop_size):\n                    idxs = [idx for idx in range(sp_start, sp_start + sub_pop_size) if idx != i]\n                    a, b, c = sub_pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                    \n                    CR = 0.6 + (0.4 * np.abs(sub_fitness[i-sp_start] - local_best_idx) / (np.max(sub_fitness) - np.min(sub_fitness)))\n\n                    cross_points = np.random.rand(self.dim) < CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    trial_fitness = func(trial)\n\n                    if trial_fitness < sub_fitness[i - sp_start] or np.random.rand() < np.exp((sub_fitness[i - sp_start] - trial_fitness) / temperature):\n                        pop[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_fitness = trial_fitness\n                            best = trial\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a multi-population strategy and adaptive local search to explore diverse regions and refine solutions in Differential Evolution Simulated Annealing.", "configspace": "", "generation": 38, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 10')", "parent_id": "7ebacf6a-00dd-4fde-9c6a-d27f4b47792d", "metadata": {}, "mutation_prompt": null}
{"id": "9598cf01-9e38-4f1a-a1b7-119e6921f4ee", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Base crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            temp_factor = 1.0 - generation / self.budget\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Adaptive recombination rate based on population diversity\n                diversity = np.std(pop, axis=0).mean()\n                CR = 0.6 + (0.3 * diversity / (1 + diversity))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                # Adaptive F adjustment based on diversity and success\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)  # Ensure F stays within a realistic range\n\n            temperature *= temp_factor  # Dynamic temperature scaling\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive crossover probability and dynamic temperature scaling for enhanced convergence in Differential Evolution Simulated Annealing.", "configspace": "", "generation": 39, "fitness": 0.28643712930262727, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.286 with standard deviation 0.015. And the mean value of best solutions found was 0.020 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "7ebacf6a-00dd-4fde-9c6a-d27f4b47792d", "metadata": {"aucs": [0.3067785336185569, 0.2703431043316653, 0.28218974995765955], "final_y": [0.008048279814618127, 0.04170875546997602, 0.01148370352206575]}, "mutation_prompt": null}
{"id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic crossover probability and enhance diversity by dynamically adjusting population size.", "configspace": "", "generation": 40, "fitness": 0.364924264620891, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.365 with standard deviation 0.091. And the mean value of best solutions found was 0.009 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7ebacf6a-00dd-4fde-9c6a-d27f4b47792d", "metadata": {"aucs": [0.3371970624682138, 0.48755851840249287, 0.27001721299196635], "final_y": [0.008002994521411504, 9.004578232222676e-05, 0.018936070550403056]}, "mutation_prompt": null}
{"id": "305d1a57-3213-4629-8f15-f382735dba97", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n                improvement_rate = (fitness[i] - trial_fitness) / fitness[i] # Adaptive F based on improvement\n                F[i] = max(0.5, min(1.0, F[i] + 0.1 * improvement_rate))\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation strategy by varying F based on fitness improvement rate.", "configspace": "", "generation": 41, "fitness": 0.3078865710105502, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.308 with standard deviation 0.013. And the mean value of best solutions found was 0.016 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3224906835288647, 0.3111083009965161, 0.29006072850626985], "final_y": [0.004869660100699369, 0.016932681313109557, 0.02612053668135776]}, "mutation_prompt": null}
{"id": "d76ecc23-6611-47cd-b8fe-657a46a9b168", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n            # Adjust mutation factor based on population diversity\n            if diversity < 0.05:\n                F = np.full(pop_size, 0.6)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation factor based on population diversity to improve convergence and exploration balance.", "configspace": "", "generation": 42, "fitness": 0.3053407938808097, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.305 with standard deviation 0.007. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3137847654427335, 0.29788964184363886, 0.30434797435605676], "final_y": [0.010710185469976607, 0.017377571288866665, 0.007752169850274968]}, "mutation_prompt": null}
{"id": "46688a4e-49ef-47d7-aaee-859efacea124", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0 + (1 - fitness[i] / best_fitness) * 0.5)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation based on fitness improvement to enhance exploration.", "configspace": "", "generation": 43, "fitness": 0.22784859296649254, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.006. And the mean value of best solutions found was 0.100 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.22818546426038566, 0.23556193656163604, 0.21979837807745595], "final_y": [0.10374117875830473, 0.034450637184749534, 0.1607494486545741]}, "mutation_prompt": null}
{"id": "994a460a-4fba-48e7-a4fc-559df23fede9", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            inertia_weight = 0.9 - 0.5 * (generation / self.budget)  # Added line\n\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(inertia_weight * (a + F[i] * (b - c)), func.bounds.lb, func.bounds.ub)  # Modified line\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by incorporating a weighted inertia factor to balance diversification and intensification in the mutation strategy.", "configspace": "", "generation": 44, "fitness": 0.1647411943045413, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.165 with standard deviation 0.038. And the mean value of best solutions found was 1.361 (0. is the best) with standard deviation 1.227.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.18202231599004415, 0.20034701516110764, 0.1118542517624721], "final_y": [0.6317026086140163, 0.36186091773131684, 3.0896730447518475]}, "mutation_prompt": null}
{"id": "d235cec5-7b80-4a7d-898b-dd341827f442", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 15 * self.dim  # Increase initial population size\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                # Improved trial vector selection probability\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / (temperature * 0.9)):  \n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance solution exploration by adjusting the initial population size and improving the probability of selecting the trial vector.", "configspace": "", "generation": 45, "fitness": 0.27755302208095345, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.278 with standard deviation 0.020. And the mean value of best solutions found was 0.025 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.25104281641458603, 0.28415542080079326, 0.29746082902748106], "final_y": [0.043670245204085335, 0.012330116935014328, 0.018257998550080555]}, "mutation_prompt": null}
{"id": "ff74a986-0c3d-4556-aaf8-4468390435a6", "solution": "import numpy as np\n\nclass DifferentialEvolutionLevySA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def levy_flight(self, size, beta=1.5):\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        pop_size = 12 * self.dim  # Changed from 10 * dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        CR = 0.8  # Adjusted crossover probability\n        F = np.full(pop_size, 0.7)  # Modified differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                if np.random.rand() < 0.2:  # Introduce Levy flight with some probability\n                    step = 0.01 * self.levy_flight(self.dim)\n                    mutant = np.clip(pop[i] + step, func.bounds.lb, func.bounds.ub)\n                else:\n                    idxs = [idx for idx in range(pop_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.6))))  # Adjusted dynamic CR\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n            temperature *= 0.97 - 0.03 * (generation / self.budget)  # Adjusted cooling schedule\n\n        return best, best_fitness", "name": "DifferentialEvolutionLevySA", "description": "Enhance exploration by integrating Levy flights and adaptive mutation strategies into a hybrid Differential Evolution and Simulated Annealing framework.", "configspace": "", "generation": 46, "fitness": 0.253837855773893, "feedback": "The algorithm DifferentialEvolutionLevySA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.254 with standard deviation 0.012. And the mean value of best solutions found was 0.025 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.23739130078872128, 0.2570184417218434, 0.2671038248111143], "final_y": [0.020188944933201773, 0.016877306353152745, 0.03840783040985006]}, "mutation_prompt": null}
{"id": "dff5a2ad-4426-4848-9464-ba3ca51589dc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n        archive = []\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        archive.append(trial)  # Add to elite archive\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            if len(archive) > 5 * self.dim:  # Limit archive size\n                archive = archive[-(5 * self.dim):]\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive differential weight and an elite archive to improve exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.2792043175051101, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.279 with standard deviation 0.008. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.28708026928872643, 0.2680092713767622, 0.28252341184984164], "final_y": [0.014789085145126722, 0.001344419196955636, 0.0215550886905319]}, "mutation_prompt": null}
{"id": "98b2b169-011c-4887-8c0e-6e2736f54e9d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5 + 0.2 * (1 - generation / self.budget), 1.0)  # Adaptive mutation scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = max(pop_size - 1, self.dim + 2)  # Decrease population based on temperature\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by adding adaptive mutation scaling and improve convergence with temperature-based population decrease.", "configspace": "", "generation": 48, "fitness": 0.27963778508980164, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.280 with standard deviation 0.012. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.29607725382120287, 0.27166851191754593, 0.2711675895306561], "final_y": [0.00788140202258492, 0.017229580501346514, 0.011518386826008873]}, "mutation_prompt": null}
{"id": "59f39b54-8a9f-4b2b-be76-9df7312af49a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.5 + (0.5 * (1 - (generation / (self.budget * 0.5))))  # Aggressive dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Adjust dynamic crossover probability more aggressively to enhance exploration.", "configspace": "", "generation": 49, "fitness": 0.29988146471067917, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.016. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3041600663593089, 0.31673305298827914, 0.2787512747844495], "final_y": [0.01588260774522062, 0.010556661502176391, 0.017380384098250493]}, "mutation_prompt": null}
{"id": "4d3eec7d-4cda-407e-8634-fe7b61e99f43", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * ((best_fitness - fitness[i]) / (1 + diversity)) * (0.9 - 0.5 * generation / self.budget)  # Adjust F\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Fine-tune mutation strategy by dynamically updating F based on diversity and iteration count.", "configspace": "", "generation": 50, "fitness": 0.27996140062813146, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.280 with standard deviation 0.025. And the mean value of best solutions found was 0.016 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.24482999854019882, 0.2926416030908685, 0.30241260025332706], "final_y": [0.02798877859514484, 0.01487596160530472, 0.004431924234324208]}, "mutation_prompt": null}
{"id": "4c77dc20-da7b-43cc-9603-5706d651a344", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.4, 1.2)  # Expanding adaptive range for F\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by dynamically adjusting the differential weight and incorporating elitism to preserve the best solution.", "configspace": "", "generation": 51, "fitness": 0.29954625216184716, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.006. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.29122648020978337, 0.3014465232310649, 0.3059657530446932], "final_y": [0.009706508998918353, 0.006718360148649728, 0.006582133856138038]}, "mutation_prompt": null}
{"id": "e91c709b-64bf-457c-a8be-251cfe9f5030", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c) * (1 + temperature), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance mutation strategy by introducing a temperature-based scaling factor to increase exploration.", "configspace": "", "generation": 52, "fitness": 0.27215363230084294, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.033. And the mean value of best solutions found was 0.027 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.24778982722926735, 0.2496559225108601, 0.3190151471624013], "final_y": [0.04654680141531824, 0.03065163053639264, 0.003371635771968441]}, "mutation_prompt": null}
{"id": "f09fb927-66cd-4195-a8e7-35fd8fd069c0", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5 + 0.4 * (generation / self.budget), 1.0)  # Self-adaptive mutation factor\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a self-adaptive mutation factor to enhance exploration capabilities further.", "configspace": "", "generation": 53, "fitness": 0.321486672257899, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.025. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.35675964686520834, 0.2998328818704916, 0.30786748803799713], "final_y": [0.0006324816765865923, 0.0030898949182589673, 0.01372940803238544]}, "mutation_prompt": null}
{"id": "0818c863-6cee-4da3-bc8c-cf2a3a67f527", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive differential weight based on generation progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.31117638969648137, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.311 with standard deviation 0.025. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3356188092646033, 0.32115272367771475, 0.276757636147126], "final_y": [0.002587643048481961, 0.004093123554387405, 0.007894964895937377]}, "mutation_prompt": null}
{"id": "76f96d85-19e8-41bf-9168-393f6b2c6451", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget) * (1 + diversity)  # Adaptive temperature adjustment\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive temperature control based on diversity to enhance exploration capabilities.", "configspace": "", "generation": 55, "fitness": 0.29235220155666486, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.292 with standard deviation 0.013. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.28109368575887717, 0.28595918704571077, 0.31000373186540664], "final_y": [0.026699377092560345, 0.018606624729859595, 0.008944014520205205]}, "mutation_prompt": null}
{"id": "980672df-9eb7-4235-9cc6-b1ea6cfda844", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n        base_F = 0.5\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.5 + (0.5 * np.cos(np.pi * generation / self.budget))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = base_F + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)  # Adaptive mutation\n                F[i] = np.clip(F[i], 0.4, 1.2)  # Adjust mutation range\n\n            temperature *= 0.97 - 0.02 * (generation / self.budget)\n            if generation % (self.budget // 10) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 2, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation strategies and improve convergence by adjusting selection pressure dynamically.", "configspace": "", "generation": 56, "fitness": 0.3326799406655452, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.333 with standard deviation 0.008. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.33564406387886603, 0.32214789361891416, 0.34024786449885536], "final_y": [0.006473282265196436, 0.004654244622614584, 0.0009523236910357699]}, "mutation_prompt": null}
{"id": "7d7cd465-30df-4eaa-9dba-3cdeba915e88", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0) * (0.7 + 0.3 * (generation / self.budget))  # Adaptive scaling\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration-exploitation balance by introducing adaptive scaling for differential weight vector based on convergence status.", "configspace": "", "generation": 57, "fitness": 0.25238055503128193, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.072. And the mean value of best solutions found was 0.380 (0. is the best) with standard deviation 0.530.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.1510228081040691, 0.3018957390999635, 0.30422311788981315], "final_y": [1.1300748595871404, 0.007274227253979908, 0.004096431429396539]}, "mutation_prompt": null}
{"id": "83809702-0fc6-4cce-b4d6-5bb322a8d142", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                diversity = np.std(pop, axis=0).mean()\n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5)))) * (1 + diversity) / 2  # Adjusted CR\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by adjusting crossover probability based on both generation progress and solution diversity.", "configspace": "", "generation": 58, "fitness": 0.301146496016417, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.024. And the mean value of best solutions found was 0.014 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.27925931288930383, 0.33444189017578896, 0.2897382849841582], "final_y": [0.018781223725009972, 0.006240983944390882, 0.01599176772718678]}, "mutation_prompt": null}
{"id": "2d03674c-9762-4abd-abba-a3bb470820bd", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n                if generation % int(self.budget * 0.1) == 0:  # Apply elitism\n                    pop[i] = best\n\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + (0.3 * (best_fitness - fitness[i]) / (1 + diversity)) * (1 - generation / self.budget)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Refine selection strategy with elitism and adjust differential weight based on iteration.", "configspace": "", "generation": 59, "fitness": 0.1555619218843909, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.156 with standard deviation 0.056. And the mean value of best solutions found was 2.318 (0. is the best) with standard deviation 2.237.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.14636232494042123, 0.2287260763203972, 0.09159736439235433], "final_y": [1.6016715278358686, 0.007231779519311543, 5.343720736839893]}, "mutation_prompt": null}
{"id": "627f010a-e345-4ebd-8f59-52b9d0cd6d9e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Adaptive mutation factor based on generation\n                mutant = np.clip(a + (F[i] * (1 + generation / self.budget)) * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive mutation factor that increases diversity by scaling with the generation count.", "configspace": "", "generation": 60, "fitness": 0.31045111851345425, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.011. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.29627994778654154, 0.31235510556501067, 0.3227183021888106], "final_y": [0.01931062021646504, 0.011885759180162797, 0.008908705112256016]}, "mutation_prompt": null}
{"id": "fcf2b6db-1a9d-4d33-8cf4-58787b760edf", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                rand_scale = np.random.uniform(0.9, 1.1)  # Random scaling factor\n                mutant = np.clip(a + F[i] * (b - c) * rand_scale, func.bounds.lb, func.bounds.ub)  # Incorporate random scaling\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance the mutation strategy by introducing a random scaling factor to the mutant vector.", "configspace": "", "generation": 61, "fitness": 0.3022175713458059, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.302 with standard deviation 0.014. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3171315603926296, 0.2831694073797276, 0.30635174626506045], "final_y": [0.00958195146444626, 0.006823689533866245, 0.020243906170849972]}, "mutation_prompt": null}
{"id": "95c49ad0-8d8a-405d-9f77-b0bd0ffbf8e3", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                diversity = np.std(pop, axis=0).mean()\n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5)))) * (1 - diversity)  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance solution refinement by introducing adaptive mutation and crossover strategies based on population diversity.", "configspace": "", "generation": 62, "fitness": 0.21687391919971064, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.012. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.20059443572625557, 0.22468599150872248, 0.22534133036415382], "final_y": [0.24189928852781628, 0.1454762058630988, 0.11590705569679433]}, "mutation_prompt": null}
{"id": "6534e97a-5b05-4947-863c-e501212c2792", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / (temperature * 0.9)):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.97 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance annealing effect by modifying temperature decay and trial acceptance for better convergence.", "configspace": "", "generation": 63, "fitness": 0.23774456971594163, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.238 with standard deviation 0.084. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.11935374148257549, 0.3065812388295367, 0.2872987288357127], "final_y": [0.04264845262861677, 0.00404567788043731, 0.008767079867036709]}, "mutation_prompt": null}
{"id": "4f5fd9aa-dccc-4dc1-8c74-b0e73ea498e5", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.5 + 0.5 * np.exp(-diversity)  # Adaptive CR based on diversity\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.4 + 0.6 * np.tanh(best_fitness - fitness[i])  # Dynamic F based on fitness\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance the balance between exploration and exploitation by introducing a dynamic mutation factor and adaptive crossover rate based on diversity and temperature.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'diversity' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'diversity' referenced before assignment\")", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {}, "mutation_prompt": null}
{"id": "e2de6a41-9649-4f55-be9e-5a151960d680", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.4, 1.2)  # Modified mutation factor range\n\n            temperature *= 0.95 - 0.01 * (generation / self.budget)  # Adjusted temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation factor and temperature scaling to enhance exploration and convergence balance.", "configspace": "", "generation": 65, "fitness": 0.32120800867899835, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.010. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3357889037472196, 0.31277275215566924, 0.3150623701341062], "final_y": [0.001501176590105158, 0.007202180095489897, 0.007923555160935155]}, "mutation_prompt": null}
{"id": "01664465-793a-4978-aa0c-44cf64eeddea", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                        # Local search refinement on the best solution found\n                        local_refinement = best + np.random.normal(0, 0.01, self.dim)\n                        local_refinement = np.clip(local_refinement, func.bounds.lb, func.bounds.ub)\n                        local_fitness = func(local_refinement)\n                        if local_fitness < best_fitness:\n                            best_fitness = local_fitness\n                            best = local_refinement\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Hybridize the algorithm by introducing a local search mechanism to refine promising solutions.", "configspace": "", "generation": 66, "fitness": 0.28454398790489416, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.285 with standard deviation 0.007. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2825614272925614, 0.29440257892995625, 0.2766679574921649], "final_y": [0.009153871137982673, 0.0045503458338282165, 0.010961151896503839]}, "mutation_prompt": null}
{"id": "69ddaebb-41df-4dca-9785-481a06e6de3b", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial += np.random.uniform(-0.01, 0.01, self.dim)  # Small random perturbation\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by introducing a small random perturbation to the trial vector.", "configspace": "", "generation": 67, "fitness": 0.2845937793770556, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.285 with standard deviation 0.032. And the mean value of best solutions found was 0.024 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.31860514328857026, 0.2415264577212337, 0.2936497371213629], "final_y": [0.01551956942664426, 0.03923388676137215, 0.016954544777880453]}, "mutation_prompt": null}
{"id": "eb403388-8b70-401b-ad16-7560c03df5af", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        temperature = 1.0\n        \n        adaptive_F = np.linspace(0.5, 1.0, pop_size)\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                \n                # Fitness-based mutation strategy\n                weighted_diff = adaptive_F[i] * (b - c)\n                mutant = np.clip(a + weighted_diff, func.bounds.lb, func.bounds.ub)\n\n                CR = 0.2 + (0.7 * (1 - (generation / self.budget)))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n            # Update adaptive_F based on current generation\n            adaptive_F = 0.5 + 0.5 * np.exp(-np.linspace(0, 1, pop_size) * (generation / self.budget))\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive learning rates and a fitness-based mutation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 68, "fitness": 0.24802548683089468, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.010. And the mean value of best solutions found was 0.055 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.24694409464112654, 0.2603709088413647, 0.2367614570101928], "final_y": [0.033555181144219196, 0.03006600167596718, 0.1001028333346642]}, "mutation_prompt": null}
{"id": "e68a1e12-9e8d-4c3f-8798-bc928dffc9f6", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.75))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.3, 1.0)  # Adjusted differential weight range\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Refine crossover and differential weight adjustment with enhanced exploration via adaptive mutation.", "configspace": "", "generation": 69, "fitness": 0.29677295273313176, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.030. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2913662401354469, 0.33565117835254765, 0.26330143971140074], "final_y": [0.003573908593680977, 0.004436531725727819, 0.01724283794271686]}, "mutation_prompt": null}
{"id": "35159cfd-3d99-4c70-891e-8f7e33bc57d4", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        # Chaotic initialization for enhanced exploration\n        pop = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * np.random.standard_normal((pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                # Adaptive step size reduction for convergence acceleration\n                step_size = np.exp(-generation / self.budget)\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = (1 - step_size) * pop[i] + step_size * trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance adaptive strategies with chaotic initialization and step size scaling for improved exploration.", "configspace": "", "generation": 70, "fitness": 0.3446710409043168, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.345 with standard deviation 0.017. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.36660946146520124, 0.3259230463306667, 0.3414806149170826], "final_y": [0.0009174341923504282, 0.012125403968825882, 0.003770941399785372]}, "mutation_prompt": null}
{"id": "da0ea020-9d7e-4895-89a3-61eaa583fc64", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.97 - 0.02 * (generation / self.budget)  # Refined temperature decay\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic crossover probability and enhance diversity by dynamically adjusting population size, with refined temperature decay.", "configspace": "", "generation": 71, "fitness": 0.3056483375550619, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.306 with standard deviation 0.020. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.33339532081117274, 0.2979646754885772, 0.28558501636543565], "final_y": [0.002192565299283001, 0.019879734400929973, 0.01688077547119594]}, "mutation_prompt": null}
{"id": "35f40b09-1724-4ecb-90fa-25c553496363", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity) * (1 - generation / self.budget)  # Dynamic scaling adjustment\n                F[i] = np.clip(F[i], 0.4, 1.0)  # Adjusted bounds\n\n            temperature *= 0.97 - 0.03 * (generation / self.budget)  # Fine-tuned temperature decay\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by introducing a dynamic scaling factor and improve convergence by fine-tuning temperature decay.", "configspace": "", "generation": 72, "fitness": 0.32417479025528384, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.324 with standard deviation 0.001. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.32519009995292814, 0.32308212864629005, 0.32425214216663334], "final_y": [0.006588205672584333, 0.010971275173385739, 0.005158812173518343]}, "mutation_prompt": null}
{"id": "27fb73f7-d32f-42f2-a8df-c7e5f948ae08", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                step_size = 0.5 + 0.5 * (1 - generation / self.budget)  # Dynamic step size\n                mutant = np.clip(a + F[i] * step_size * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic step size based on generation count to further enhance exploration.", "configspace": "", "generation": 73, "fitness": 0.27964980719417387, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.280 with standard deviation 0.028. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.24203278145323082, 0.2871563774681547, 0.3097602626611361], "final_y": [0.007366580327352156, 0.005208227507556399, 0.009860378286514688]}, "mutation_prompt": null}
{"id": "e3a4f7ed-0924-4992-a3e6-c43853c6ccc2", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i] + 0.1 * np.random.rand(), 0.5, 1.0)  # Adaptive F scaling\n\n            temperature *= (0.98 - 0.02 * (generation / self.budget))\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n                if np.std(fitness) < 0.01:  # Clustering-based reinitialization\n                    kmeans = KMeans(n_clusters=2).fit(pop)\n                    centers = kmeans.cluster_centers_\n                    pop = np.vstack([centers, pop])\n                    fitness = np.append(fitness, [func(c) for c in centers])\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive scaling of mutation factor and temperature with clustering-based reinitialization for fostering exploration and exploitation balance.", "configspace": "", "generation": 74, "fitness": 0.29657358411282425, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.013. And the mean value of best solutions found was 0.009 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.29099447476260587, 0.31440567022714294, 0.2843206073487239], "final_y": [0.0020727093768784246, 0.00937423144603296, 0.014730340398852824]}, "mutation_prompt": null}
{"id": "a63ba849-bd7c-4c92-ace9-ca9033c3970d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive scaling of differential weight based on generation progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.29621437135018774, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.296 with standard deviation 0.025. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3292821381908475, 0.2680862927916374, 0.29127468306807835], "final_y": [0.016610089986116107, 0.01288648505708812, 0.0034788178770005216]}, "mutation_prompt": null}
{"id": "4e373831-690b-4bc1-9671-9b114891356d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.5 + (0.4 * np.cos((generation / self.budget) * np.pi))  # Modified dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance the dynamic crossover probability adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 76, "fitness": 0.28059028657344337, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.016. And the mean value of best solutions found was 0.022 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2933820292280971, 0.25858655575506273, 0.28980227473717024], "final_y": [0.027331181238710752, 0.027318981716424485, 0.010240116463784758]}, "mutation_prompt": null}
{"id": "01319442-ac36-4fb6-9885-8782ec7ecebd", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n        success_rates = np.zeros(pop_size)\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                \n                # Adaptive mutation based on success history\n                scaling_factor = 0.5 + 0.3 * success_rates[i]\n                mutant = np.clip(a + scaling_factor * F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    success_rates[i] = 1  # Mark success for adaptive scaling\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                else:\n                    success_rates[i] = 0  # Mark failure\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = np.clip(0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity), 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by introducing adaptive mutation strategies and a dynamic scaling factor based on success history.", "configspace": "", "generation": 77, "fitness": 0.31008775332894095, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.020. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.30837946920014625, 0.28658959530800987, 0.3352941954786668], "final_y": [0.01687888109500055, 0.01586933033086119, 0.0029913885636662987]}, "mutation_prompt": null}
{"id": "db1a66cb-953d-46b3-8426-b4eaa89929ec", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.6 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)  # Slightly increase dynamic adjustment\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Slightly increase the differential weight's dynamic adjustment for enhanced exploration.", "configspace": "", "generation": 78, "fitness": 0.3102045022969439, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.020. And the mean value of best solutions found was 0.014 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2897688341626413, 0.30277124305908854, 0.3380734296691019], "final_y": [0.016460125972842205, 0.020881954350483276, 0.004670314357415265]}, "mutation_prompt": null}
{"id": "d07aafea-1bee-420f-9b1e-85a261b55207", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            if generation % (self.budget // 5) == 0:  # Restart mechanism\n                pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n                fitness = np.array([func(ind) for ind in pop])\n                \n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_factor = 0.1 + 0.5 * np.exp(-fitness[i] / np.std(fitness))\n                mutant = np.clip(a + adaptive_factor * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration by introducing adaptive mutation factor and restart mechanism for population diversity.", "configspace": "", "generation": 79, "fitness": 0.13363564468291975, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.134 with standard deviation 0.032. And the mean value of best solutions found was 2.469 (0. is the best) with standard deviation 1.485.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.10008358551007324, 0.17749153627884862, 0.12333181225983736], "final_y": [4.227721447499502, 0.5965275799560259, 2.583242742669644]}, "mutation_prompt": null}
{"id": "f2d6ad1c-bea4-4bdc-97dd-0979c700668a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.995 - 0.02 * (generation / self.budget)  # Adjust cooling schedule\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic cooling schedule to enhance exploration and exploitation balance.", "configspace": "", "generation": 80, "fitness": 0.3018517791018411, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.302 with standard deviation 0.018. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.30216607886540414, 0.2800371374842464, 0.3233521209558726], "final_y": [0.019502835919534903, 0.01199258333066887, 0.0027208303662844793]}, "mutation_prompt": null}
{"id": "57825637-06fa-426f-a292-a0641cf79c91", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            fitness_variance = np.var(fitness)\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity + fitness_variance)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Dynamic mutation scaling based on fitness variance and adaptive temperature scaling to balance exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.2942346312346672, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.009. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2924289867122968, 0.30634950756094825, 0.28392539943075656], "final_y": [0.014765225529203438, 0.005755679322707369, 0.003229954989179138]}, "mutation_prompt": null}
{"id": "6f4df671-9bcf-4749-b933-42c2b0aeec79", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted mutation scaling factor\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Incorporate adaptive mutation scaling to enhance convergence by altering mutation factor based on population diversity.", "configspace": "", "generation": 82, "fitness": 0.28179230286611606, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.282 with standard deviation 0.012. And the mean value of best solutions found was 0.014 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2990278467205032, 0.27212749748231624, 0.2742215643955288], "final_y": [0.016972632974177695, 0.008330214095932114, 0.018008232663739375]}, "mutation_prompt": null}
{"id": "7d732094-7267-4764-8496-7d4c681627f2", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0) if trial_fitness < fitness[i] else np.clip(F[i], 0.6, 1.0) # Adjusted line\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive differential weight strategy based on fitness improvement to enhance convergence.", "configspace": "", "generation": 83, "fitness": 0.28264749838770337, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.008. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.2720093953389673, 0.28781207321142954, 0.2881210266127133], "final_y": [0.03372407903397846, 0.017442078001009633, 0.003228911607245503]}, "mutation_prompt": null}
{"id": "9e1d0210-20ee-4d42-a988-25f3a1888449", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n        \n        F = np.clip(F * (0.5 + 0.5 * generation / self.budget), 0.5, 1.0)  # Adaptive mutation strategy\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce an adaptive mutation strategy by adjusting the variant F based on the generational progress.", "configspace": "", "generation": 84, "fitness": 0.30068606855880164, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.010. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.3006048140827148, 0.28846932641791856, 0.3129840651757716], "final_y": [0.017885846476263276, 0.015304716289142099, 0.001465157398477748]}, "mutation_prompt": null}
{"id": "3b0097d8-d752-494e-b7b0-9ecd00b0114e", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= (0.98 - 0.02 * (generation / self.budget)) * (1 + 0.01 * np.log1p(generation))\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Improve convergence by adjusting the cooling schedule for temperature decay to be more adaptive based on generation.", "configspace": "", "generation": 85, "fitness": 0.3032931392253696, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.005. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.30379191566811203, 0.3096376772937135, 0.29644982471428327], "final_y": [0.01822134787039641, 0.017343885420861502, 0.004111110732593713]}, "mutation_prompt": null}
{"id": "be23c086-8af2-4983-bb3c-6cc65b8e78b0", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + np.std(pop) / pop_size)  # Adaptive mutation scaling\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and pop_size > 5 * self.dim:  # Adaptive pop contraction\n                pop_size -= 1\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce adaptive mutation scaling and enhanced exploitation via adaptive population contraction.", "configspace": "", "generation": 86, "fitness": 0.3105202071074467, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.311 with standard deviation 0.020. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.29381805588753496, 0.33923860390682015, 0.2985039615279851], "final_y": [0.011237600323883648, 0.005679850767382678, 0.008325323224752662]}, "mutation_prompt": null}
{"id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance selection pressure by modifying the trial acceptance condition to favor improvements during the optimization process.", "configspace": "", "generation": 87, "fitness": 0.4761990517796522, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.476 with standard deviation 0.031. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "39a289fb-7538-4f26-9bcc-1789e76a718f", "metadata": {"aucs": [0.45273007701332113, 0.4558391975492033, 0.5200278807764322], "final_y": [7.526533663813823e-07, 3.060261483391775e-07, 2.5352190954958853e-08]}, "mutation_prompt": null}
{"id": "62ac3ed6-e6c6-4c3f-ab3a-1183ef1cf8b9", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.4 * (best_fitness - fitness[i]) / (1 + diversity)  # Adjusted F calculation\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance the adaptive mutation by dynamically adjusting the differential weight based on the best-found fitness improvement ratio.", "configspace": "", "generation": 88, "fitness": 0.4760722347408343, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.476 with standard deviation 0.050. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "metadata": {"aucs": [0.4197800700257528, 0.5412811520211516, 0.46715548217559855], "final_y": [2.9410501115960173e-06, 2.8380761034167838e-08, 2.901638129915507e-07]}, "mutation_prompt": null}
{"id": "5c993d16-22ff-432e-80fc-bf4e278f09e3", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n\n                CR = 0.5 + (0.4 * np.sin((np.pi/2) * (generation / self.budget)))  # Adaptive CR based on generation\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a more adaptive strategy for the crossover probability (CR) based on generation counter to enhance exploration and exploitation balance.", "configspace": "", "generation": 89, "fitness": 0.2793587005164721, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.279 with standard deviation 0.007. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "metadata": {"aucs": [0.2869453075110767, 0.28107642021234214, 0.2700543738259975], "final_y": [0.0032684214879203683, 0.0064031775984358125, 0.008780021887604945]}, "mutation_prompt": null}
{"id": "c6c41cf4-9e10-42c2-8f68-770f06c73760", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.8)\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Introduce elite guidance by incorporating the best individual\n                mutant = np.clip(a + F[i] * (b - c) + 0.5 * (best - a), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.02 * (generation / self.budget)\n            # Preserve the elite by reintroducing the best individual\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce elite preservation and guided mutation to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 90, "fitness": 0.2550071970273728, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.273. And the mean value of best solutions found was 6.354 (0. is the best) with standard deviation 5.085.", "error": "", "parent_id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "metadata": {"aucs": [0.07225932294908932, 0.05215806278667279, 0.6406042053463563], "final_y": [6.614305378393697, 12.448314498842274, 1.9411739153721837e-08]}, "mutation_prompt": null}
{"id": "27e588fe-3785-4e28-8cd4-79dc23811438", "solution": "import numpy as np\n\nclass DynamicEnsembleDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 12 * self.dim  # Adjusted population size for diversity\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9\n        F = np.full(pop_size, 0.7)  # Adjusted starting differential weight\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n\n                CR = 0.5 + (0.5 * (1 - (generation / (self.budget * 0.4))))  # Different CR evolution\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.93 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n\n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.25 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.4, 1.0)\n\n            temperature *= 0.97 - 0.03 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DynamicEnsembleDifferentialEvolution", "description": "Dynamic Ensemble Differential Evolution optimizes trial acceptance by adapting parameters and leveraging ensemble strategies for diverse exploration.", "configspace": "", "generation": 91, "fitness": 0.4266866522304877, "feedback": "The algorithm DynamicEnsembleDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.427 with standard deviation 0.056. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "metadata": {"aucs": [0.48616581797007086, 0.4419420258590252, 0.35195211286236705], "final_y": [6.27352311700241e-07, 1.8281099564923587e-06, 8.573438759123632e-06]}, "mutation_prompt": null}
{"id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Integrate adaptive temperature scaling by adjusting the cooling rate based on the generation progress to maintain exploration and exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.49004145943114635, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.490 with standard deviation 0.011. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0381f2fc-d2a5-414e-8c74-100942f12b8a", "metadata": {"aucs": [0.4775251123471984, 0.5038465658686648, 0.48875270007757576], "final_y": [1.6005987498741676e-07, 9.388163221876007e-08, 2.185142942235439e-07]}, "mutation_prompt": null}
{"id": "55e019b5-999a-4386-b717-4b47a77da300", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n                if trial_fitness < fitness.mean():\n                    F[i] *= 1.05  # Increase F to encourage exploration\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic adaptation of the mutation factor and crossover probability based on fitness improvement rate and use elite solutions to guide the search.", "configspace": "", "generation": 93, "fitness": 0.4719450073983538, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.472 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.46855557585862595, 0.4551896798437345, 0.4920897664927011], "final_y": [5.7933618901120936e-08, 1.220377643974701e-06, 1.954182155578536e-07]}, "mutation_prompt": null}
{"id": "78540141-fea9-43af-a6a4-15575f791c44", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.6, 1.2)  # Adjusted mutation scaling\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                new_pop_size = min(pop_size + 2, self.budget - generation)  # Increased dynamic adjustment\n                if new_pop_size > pop_size:\n                    additional_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (new_pop_size - pop_size, self.dim))\n                    pop = np.vstack((pop, additional_pop))\n                    fitness = np.append(fitness, [func(ind) for ind in additional_pop])\n                pop_size = new_pop_size\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce dynamic population size management and adaptive mutation scaling to enhance exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.4365369562624027, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.437 with standard deviation 0.062. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.4693863571363599, 0.49075383864017463, 0.3494706730106736], "final_y": [8.509830606312744e-07, 1.431466979948784e-06, 1.8090216323755334e-06]}, "mutation_prompt": null}
{"id": "01fed665-e24a-484b-9070-db829ad7c870", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n            \n            # Adjust mutation strategy\n            F = 0.5 + 0.3 * (1 - (best_fitness - np.min(fitness)) / (1 + diversity))\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance convergence by adjusting mutation strategy based on best individual's historical fitness improvement.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {}, "mutation_prompt": null}
{"id": "6e0dd5d8-fbd6-4b9b-9163-3695440f9bee", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i] + 0.1 * np.random.rand(), 0.5, 1.0)  # Dynamic mutation factor adjustment\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a dynamic mutation factor adjustment for enhanced diversity and exploration.", "configspace": "", "generation": 96, "fitness": 0.47523611830253243, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.475 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.4441516420751238, 0.48323535426112263, 0.49832135857135096], "final_y": [9.58704880763476e-07, 7.631981707307542e-07, 1.6489285993440753e-07]}, "mutation_prompt": null}
{"id": "9fa6818b-ef25-4bcc-b849-6ba70e9e07bc", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.015 * (generation / self.budget)  # Adjusted temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Introduce a slight temperature decay adjustment to enhance convergence speed and balance exploration-exploitation trade-off.", "configspace": "", "generation": 97, "fitness": 0.46249169180238975, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.462 with standard deviation 0.005. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.46375167443850107, 0.4679685871706275, 0.4557548137980405], "final_y": [4.6530061824951757e-07, 3.158272748936412e-07, 6.950086075300014e-07]}, "mutation_prompt": null}
{"id": "0433126f-80cf-4c32-8bef-607bfa9cf14c", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + (0.4 * (1 - (generation / (self.budget * 0.5))))  # Dynamic CR adjustment\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                diversity = np.std(pop, axis=0).mean()\n                F[i] = 0.5 + 0.3 * (best_fitness - trial_fitness) / (1 + diversity)  # Line changed\n                F[i] = np.clip(F[i], 0.5, 1.0)\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)  # Adaptive temperature scaling\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:  # Dynamic population size adjustment\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Enhance exploration-exploitation balance by introducing adaptive F scaling based on population diversity.", "configspace": "", "generation": 98, "fitness": 0.40626720302340874, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.406 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.40843389514015604, 0.39486313109353655, 0.4155045828365336], "final_y": [5.696481468170448e-06, 5.61231655104745e-06, 8.203352957092248e-07]}, "mutation_prompt": null}
{"id": "22210422-90b6-4bb0-92cc-c77f93fdde4d", "solution": "import numpy as np\n\nclass DifferentialEvolutionSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        CR = 0.9  # Crossover probability\n        F = np.full(pop_size, 0.8)  # Differential weight vector\n        temperature = 1.0\n\n        for generation in range(self.budget - pop_size):\n            diversity = np.std(pop, axis=0).mean()\n            for i in range(pop_size):\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F[i] * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                CR = 0.6 + 0.4 * (1 - diversity)  # Adjust CR based on diversity\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature) and trial_fitness < 0.95 * best_fitness:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best = trial\n                \n                F[i] = 0.5 + 0.3 * (best_fitness - fitness[i]) / (1 + diversity)\n                F[i] = np.clip(F[i], 0.5, 1.2)  # Increase upper bound of mutation factor\n\n            temperature *= 0.98 - 0.01 * (generation / self.budget)\n            if generation % int(self.budget * 0.1) == 0 and generation > 0:\n                pop_size = min(pop_size + 1, self.budget - generation)\n\n        return best, best_fitness", "name": "DifferentialEvolutionSimulatedAnnealing", "description": "Incorporate dynamic crossover probability adjustment based on diversity, and increase mutation factor adaptively to enhance exploration and convergence speed.", "configspace": "", "generation": 99, "fitness": 0.14988340553301527, "feedback": "The algorithm DifferentialEvolutionSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.150 with standard deviation 0.023. And the mean value of best solutions found was 1.084 (0. is the best) with standard deviation 0.637.", "error": "", "parent_id": "b75f1b87-1b11-4a2c-8a56-a5d4771b374d", "metadata": {"aucs": [0.12391897216003611, 0.14528326308643313, 0.18044798135257656], "final_y": [1.9847929791636152, 0.6497453246263719, 0.6170565051734366]}, "mutation_prompt": null}
