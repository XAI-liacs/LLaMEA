{"id": "0449e3b0-eb13-447f-98f5-ddd1573c4bf9", "solution": "import numpy as np\n\nclass DynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] \n                                 + cognitive_velocity \n                                 + social_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "DynamicParticleSwarm", "description": "A novel metaheuristic algorithm inspired by the dynamic balance between exploration and exploitation, utilizing adaptive particle swarm concepts to optimize black box functions efficiently.", "configspace": "", "generation": 0, "fitness": 0.6291944736663807, "feedback": "The algorithm DynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.629 with standard deviation 0.152. And the mean value of best solutions found was 0.326 (0. is the best) with standard deviation 0.083.", "error": "", "parent_id": null, "metadata": {"aucs": [0.44974590421776484, 0.8203512915321943, 0.6174862252491831], "final_y": [0.4269984274764822, 0.2239343761376491, 0.3271281057326343]}, "mutation_prompt": null}
{"id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Optimized Dynamic Particle Swarm that leverages adaptive inertia weight and velocity clamping to enhance convergence and stability in black box optimization problems.", "configspace": "", "generation": 1, "fitness": 0.7939065544128029, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.068. And the mean value of best solutions found was 0.235 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "0449e3b0-eb13-447f-98f5-ddd1573c4bf9", "metadata": {"aucs": [0.7232979282664977, 0.7726470157291002, 0.8857747192428106], "final_y": [0.2682704986055332, 0.24444201474260718, 0.19224044629840953]}, "mutation_prompt": null}
{"id": "0092f147-5b7c-4444-80e5-5b90061b47cf", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            dynamic_cognitive_param = self.cognitive_param + 0.5 * (1 - evaluations / self.budget)  # Modified\n            dynamic_social_param = self.social_param + 0.5 * (evaluations / self.budget)  # Modified\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = dynamic_cognitive_param * r1 * (personal_best_positions[i] - particles[i])  # Modified\n                social_velocity = dynamic_social_param * r2 * (self.best_global_position - particles[i])  # Modified\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Particle Swarm Optimization incorporating dynamic cognitive and social parameters to boost convergence and exploration.", "configspace": "", "generation": 2, "fitness": 0.7717262327046464, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.060. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.7098500117579946, 0.75165634625083, 0.8536723401051144], "final_y": [0.2700261005775464, 0.25455248019902266, 0.20302107329064434]}, "mutation_prompt": null}
{"id": "0f44334b-81f1-4e11-8f54-5aa86ffee9a4", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n        \n        evaluations = 0\n        elite_particle = None  # Added line\n        elite_value = float('-inf')  # Added line\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n                if value > elite_value:  # Added line\n                    elite_value = value  # Added line\n                    elite_particle = particles[i]  # Added line\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n            \n            if elite_particle is not None and evaluations % 10 == 0:  # Added line\n                particles[0] = elite_particle  # Added line\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with elitism strategy and dynamic particle count to improve exploration and exploitation balance in black box optimization.", "configspace": "", "generation": 3, "fitness": 0.7372772090021894, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.737 with standard deviation 0.025. And the mean value of best solutions found was 0.262 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.7232979282664977, 0.7726470157291002, 0.7158866830109704], "final_y": [0.2682704986055332, 0.24444201474260718, 0.2719640843439751]}, "mutation_prompt": null}
{"id": "75d3858c-017a-4b28-b9d2-e66ce932ad43", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n        self.success_threshold = 0.05  # Threshold to adaptively adjust velocity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n        neighborhood_size = self.num_particles // 5\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                neighborhood = np.random.choice(self.num_particles, size=neighborhood_size, replace=False)\n                local_best_position = max(neighborhood, key=lambda x: personal_best_values[x])\n                local_best_position = personal_best_positions[local_best_position]\n                \n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                \n                if personal_best_values[i] < self.best_global_value * (1 - self.success_threshold):\n                    velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                else:\n                    velocities[i] = (inertia_weight * velocities[i] + \n                                     self.cognitive_param * r1 * (local_best_position - particles[i]) +\n                                     social_velocity)\n                    \n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Particle Swarm Optimization with Adaptive Neighborhoods and Success-Based Velocity Adaptation for improved exploration-exploitation balance in black box optimization.", "configspace": "", "generation": 4, "fitness": 0.7887409488141602, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.074. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.8600514039844998, 0.6865739024162276, 0.8195975400417532], "final_y": [0.2076918119234742, 0.2875162476401256, 0.2163136050108092]}, "mutation_prompt": null}
{"id": "a7cb60d9-df95-481c-a87c-cc28a04c7c25", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Influence of parent solution\n        self.beta = 0.5   # Influence of global best solution\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        evaluations = 0\n\n        def quantum_bit_to_real(alpha, beta, parent, global_best):\n            q = np.random.choice([alpha, beta], size=self.dim, p=[0.5, 0.5])\n            return np.clip(q * parent + (1 - q) * global_best, lb, ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                parent = population[i]\n                child = quantum_bit_to_real(self.alpha, self.beta, parent, self.best_global_position if self.best_global_position is not None else parent)\n                value = func(child)\n                evaluations += 1\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = child\n\n            population = np.array([quantum_bit_to_real(self.alpha, self.beta, ind, self.best_global_position) for ind in population])\n\n        return self.best_global_position", "name": "QuantumInspiredEvolutionaryAlgorithm", "description": "Quantum-Inspired Evolutionary Algorithm that employs quantum superposition principles to enhance exploration and exploitation in black box optimization.", "configspace": "", "generation": 5, "fitness": 0.773899749733426, "feedback": "The algorithm QuantumInspiredEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.084. And the mean value of best solutions found was 0.250 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.7753414588731916, 0.6704658628788644, 0.8758919274482222], "final_y": [0.24651986104852797, 0.2982929897342247, 0.20561908296482811]}, "mutation_prompt": null}
{"id": "1b5872c6-e0fa-45ef-8e2e-e60549f01a09", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.initial_cognitive_param = 1.5\n        self.initial_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            cognitive_param = self.initial_cognitive_param + (0.5 - evaluations / self.budget) * self.initial_cognitive_param  # Changed line\n            social_param = self.initial_social_param + (evaluations / self.budget) * self.initial_social_param  # Changed line\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive cognitive and social parameters to improve convergence by focusing on promising areas.", "configspace": "", "generation": 6, "fitness": 0.7679157199692145, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.068. And the mean value of best solutions found was 0.246 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.6935769860417312, 0.7527079924792957, 0.8574621813866169], "final_y": [0.28338779835058114, 0.2486007260234745, 0.20575812991234965]}, "mutation_prompt": null}
{"id": "fbbc1d4b-cb98-4700-a369-d1233c9f5445", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n            \n            elite_indices = personal_best_values.argsort()[-5:]\n            particles[elite_indices] = personal_best_positions[elite_indices]  # Elitism\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive parameter tuning and elitism to improve convergence and exploration efficiency in black box optimization.", "configspace": "", "generation": 7, "fitness": 0.7680382214243027, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.083. And the mean value of best solutions found was 0.241 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.692019536788715, 0.7287003923733033, 0.8833947351108898], "final_y": [0.28467819152831175, 0.24677968308944387, 0.1925080186473198]}, "mutation_prompt": null}
{"id": "ec9000db-edfd-4a34-9ce5-766c43d8f485", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param_max = 2.5  # Updated for adaptive approach\n        self.cognitive_param_min = 1.0  # Updated for adaptive approach\n        self.social_param_max = 2.5  # Updated for adaptive approach\n        self.social_param_min = 1.0  # Updated for adaptive approach\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            cognitive_param = self.cognitive_param_max - (self.cognitive_param_max - self.cognitive_param_min) * (evaluations / self.budget)  # Adaptive update\n            social_param = self.social_param_max - (self.social_param_max - self.social_param_min) * (evaluations / self.budget)  # Adaptive update\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])  # Change due to adaptive parameters\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])  # Change due to adaptive parameters\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive cognitive and social parameters for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.7776999259627795, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.064. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.6913090162969382, 0.7981814723252186, 0.8436092892661817], "final_y": [0.2785372836922212, 0.22361284015344596, 0.20815794913512198]}, "mutation_prompt": null}
{"id": "07e707ce-033f-40fb-813c-450b5e71cea0", "solution": "import numpy as np\n\nclass EnhancedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.local_param = 1.2  # New local influence parameter\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        # Neighborhood structure\n        neighborhoods = [list(range(i, i+3)) for i in range(self.num_particles - 2)] + [list(range(self.num_particles - 2, self.num_particles)) + [0]]\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(3)\n                local_best_position = max(neighborhoods[i], key=lambda idx: personal_best_values[idx])\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                local_velocity = self.local_param * r3 * (personal_best_positions[local_best_position] - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity + local_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "EnhancedDynamicParticleSwarm", "description": "Enhanced Particle Swarm Optimization with adaptive learning strategies and dynamic topology to improve solution diversity and convergence rate in complex optimization landscapes.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {}, "mutation_prompt": null}
{"id": "d282fac2-3d15-455f-af44-40e2817eec90", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive cognitive and social parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8030442206778478, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.059. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "0a9a26e5-4294-4aa0-8d57-c18ebe1133b5", "metadata": {"aucs": [0.7227365552135663, 0.8242548309799862, 0.8621412758399905], "final_y": [0.26855365208371207, 0.21948825558288398, 0.20026984191233566]}, "mutation_prompt": null}
{"id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce diversity maintenance through random reinitialization of particles to enhance global exploration in the swarm.", "configspace": "", "generation": 11, "fitness": 0.8301201859534141, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.029. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d282fac2-3d15-455f-af44-40e2817eec90", "metadata": {"aucs": [0.8682451005333746, 0.7980319496471467, 0.8240835076797208], "final_y": [0.202546514077381, 0.2103016735964044, 0.22247011769647917]}, "mutation_prompt": null}
{"id": "c92ee8f9-8156-4317-90be-d072611a1950", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            # Adaptive parameter tuning\n            self.cognitive_param = 1.0 + 1.5 * (evaluations / self.budget)\n            self.social_param = 2.0 - 1.5 * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce adaptive parameter tuning for cognitive and social components based on convergence progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7952678119320028, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.004. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7899444086323422, 0.8004433068802931, 0.7954157202833729], "final_y": [0.20536648054729678, 0.22818655010099353, 0.20282075651910403]}, "mutation_prompt": null}
{"id": "e7a6f456-8ce1-4310-ab9f-97436e6412fa", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                velocities[i] *= 0.98  # Apply velocity damping\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce velocity damping to stabilize particle movements and prevent premature convergence in particle swarm optimization.", "configspace": "", "generation": 13, "fitness": 0.8068635800053503, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.062. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.868963051733608, 0.7213785960653389, 0.8302490922171039], "final_y": [0.20226143942717834, 0.2460440798253264, 0.219921424874168]}, "mutation_prompt": null}
{"id": "ca1f027d-dd38-4003-8ff3-7e891f2e16c3", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                harmonic_mean = 2 / ((1/(self.cognitive_param + adaptive_factor)) + (1/(self.social_param - adaptive_factor)))\n                cognitive_velocity = harmonic_mean * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = harmonic_mean * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance local search by dynamically adjusting particle velocity using a harmonic mean of cognitive and social parameters.", "configspace": "", "generation": 14, "fitness": 0.7991985892824288, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.065. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8668154010116305, 0.7116555631514905, 0.8191248036841656], "final_y": [0.20308038808726803, 0.2064279738906546, 0.22456337513109192]}, "mutation_prompt": null}
{"id": "2afb4b86-4163-4a3a-a737-b781821d4f34", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            diversity = np.mean(np.std(particles, axis=0))\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                dynamic_cognitive = self.cognitive_param + adaptive_factor * diversity\n                dynamic_social = self.social_param - adaptive_factor * diversity\n                cognitive_velocity = dynamic_cognitive * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = dynamic_social * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance convergence speed by dynamically adjusting cognitive and social parameters based on the swarm's diversity.", "configspace": "", "generation": 15, "fitness": 0.6990791884970508, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.699 with standard deviation 0.103. And the mean value of best solutions found was 0.276 (0. is the best) with standard deviation 0.051.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.595910482654971, 0.6608683030324292, 0.8404587798037519], "final_y": [0.33292376166231463, 0.28476704942610664, 0.20997921404249265]}, "mutation_prompt": null}
{"id": "4076fb25-cfa0-48ab-9dce-71b7f438b1e0", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity \n                if np.random.rand() < 0.05 * (1 - adaptive_factor):  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce a dynamic reinitialization probability to maintain diversity and adapt based on convergence progress.", "configspace": "", "generation": 16, "fitness": 0.8061529282970086, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.059. And the mean value of best solutions found was 0.228 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8682451005333746, 0.7261301766779302, 0.8240835076797208], "final_y": [0.202546514077381, 0.25979041466965325, 0.22247011769647917]}, "mutation_prompt": null}
{"id": "fdded1ef-a3b3-40cd-b0f5-861970088594", "solution": "import numpy as np\n\nclass OptimizedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n        \n        evaluations = 0\n        learning_rate = 0.5\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n                    learning_rate = max(0.1, learning_rate * 0.9)  # Adjust learning rate\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + learning_rate * (cognitive_velocity + social_velocity)\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < 0.05:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedAdaptiveParticleSwarm", "description": "Integrate an adaptive learning rate mechanism in particle movement to balance exploration and exploitation dynamically.", "configspace": "", "generation": 17, "fitness": 0.7907135203524464, "feedback": "The algorithm OptimizedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.023. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7915088335473001, 0.7622426908363387, 0.8183890366737004], "final_y": [0.23150085424515365, 0.24351260905952843, 0.21898295910328525]}, "mutation_prompt": null}
{"id": "44e521f8-73ca-4c1a-afbf-9d3e64b2d85d", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        no_improvement_count = 0  # Track stagnation in improvement\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n                    no_improvement_count = 0  # Reset if improvement\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity\n                if np.random.rand() < 0.05 + 0.1 * no_improvement_count:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    \n            if not np.any(personal_best_values > self.best_global_value):  # Check for global improvement\n                no_improvement_count += 1\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance particle swarm diversity with adaptive reinitialization probability influenced by stagnation in solution improvement.", "configspace": "", "generation": 18, "fitness": 0.8183652841152119, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.043. And the mean value of best solutions found was 0.220 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8682451005333746, 0.7627672441325406, 0.8240835076797208], "final_y": [0.202546514077381, 0.23622953027359028, 0.22247011769647917]}, "mutation_prompt": null}
{"id": "f49a7cac-2c88-4f12-8bb6-e7bf7e80a2aa", "solution": "import numpy as np\n\nclass EnhancedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_num_particles = 30\n        self.num_particles = self.initial_num_particles\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n\n            if evaluations % (self.budget // 10) == 0 and self.num_particles < 60:\n                additional_particles = 5\n                new_particles = np.random.uniform(lb, ub, (additional_particles, self.dim))\n                new_velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (additional_particles, self.dim))\n                particles = np.vstack((particles, new_particles))\n                velocities = np.vstack((velocities, new_velocities))\n                personal_best_positions = np.vstack((personal_best_positions, new_particles))\n                personal_best_values = np.concatenate((personal_best_values, np.full(additional_particles, float('-inf'))))\n                self.num_particles += additional_particles\n\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive swarm size and local search for improved exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.8200613890616344, "feedback": "The algorithm EnhancedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.024. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8526890992205309, 0.7957197660251899, 0.8117753019391825], "final_y": [0.19291368696101374, 0.2134076329704564, 0.2262100659372721]}, "mutation_prompt": null}
{"id": "af8701dd-579e-4aaf-ab87-12a1e605f414", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            adaptive_cognitive = self.cognitive_param * (1 - adaptive_factor)\n            adaptive_social = self.social_param * adaptive_factor\n            \n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = adaptive_cognitive * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = adaptive_social * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Energy-based reinitialization for diversity \n                if np.linalg.norm(velocities[i]) < 0.01:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance the particle swarm optimization by implementing a self-adaptive strategy for cognitive and social parameters, and introduce energy-based reinitialization to maintain diversity.", "configspace": "", "generation": 20, "fitness": 0.6997440490187268, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.700 with standard deviation 0.018. And the mean value of best solutions found was 0.262 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.708202882933768, 0.7163147068917796, 0.6747145572306326], "final_y": [0.2575570219354435, 0.26814112601048945, 0.2605685748630173]}, "mutation_prompt": null}
{"id": "82e60551-c4c8-4807-a0e1-856a49110bb5", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            self.cognitive_param = 1.5 * (1 + adaptive_factor)  # Adjusted line\n            self.social_param = 1.5 * (1 - adaptive_factor)  # Adjusted line\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance local exploitation by dynamically adjusting cognitive and social parameters based on convergence.", "configspace": "", "generation": 21, "fitness": 0.8129197264824631, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.055. And the mean value of best solutions found was 0.225 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8699027760676787, 0.7380786153082706, 0.8307777880714402], "final_y": [0.20193363218222504, 0.25402483638843165, 0.21970151437790175]}, "mutation_prompt": null}
{"id": "2f20dfe8-eae2-42a3-9f8f-a40c8a9f809b", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        elite_count = 3  # Number of elite particles\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            elite_indices = np.argsort(personal_best_values)[-elite_count:]  # Identify elite particles\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                \n                if i not in elite_indices:  # Prevent modification of elite particles\n                    particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance convergence by integrating elitism to preserve top solutions across iterations.", "configspace": "", "generation": 22, "fitness": 0.8169001332452952, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.024. And the mean value of best solutions found was 0.214 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.800032236306776, 0.8001207167234533, 0.8505474467056562], "final_y": [0.21047798293760833, 0.22315004514502368, 0.20707177273541255]}, "mutation_prompt": null}
{"id": "b7bca337-6fde-4167-b26b-b0972997530e", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            prev_best_value = self.best_global_value\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            improvement_rate = (self.best_global_value - prev_best_value) / (abs(prev_best_value) + 1e-9)\n            reinit_prob = max(0.01, min(0.1, 0.1 - improvement_rate * 0.1))\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Dynamically adjust reinitialization probability\n                if np.random.rand() < reinit_prob:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance exploration capabilities by dynamically adjusting the random reinitialization probability based on the improvement rate of the global best solution.", "configspace": "", "generation": 23, "fitness": 0.8109726440668757, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.041. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7531667917264173, 0.8317679869836394, 0.8479831534905705], "final_y": [0.19499623093192076, 0.19982468101526252, 0.2130058710415077]}, "mutation_prompt": null}
{"id": "7fde03a4-549c-4518-b207-7aaa47457548", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        stagnation_counter = 0  # New addition for stagnation detection\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n                    stagnation_counter = 0  # Reset if improvement is found\n                else:\n                    stagnation_counter += 1  # Increment if no improvement\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity \n                if np.random.rand() < min(0.05 + stagnation_counter / self.budget, 0.2):  # Changed line\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce an adaptive reinitialization probability to improve exploration based on stagnation detection.", "configspace": "", "generation": 24, "fitness": 0.8110601298417142, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.027. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7768935052841325, 0.8430387991779847, 0.8132480850630254], "final_y": [0.2313547912034446, 0.1927060492444277, 0.2202008754039464]}, "mutation_prompt": null}
{"id": "5f109c5e-6456-45cb-8b0e-02daa095dacd", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        learning_rates = np.ones(self.num_particles)\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n                    learning_rates[i] *= 1.05  \n                else:\n                    learning_rates[i] *= 0.95  \n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = learning_rates[i] * (self.cognitive_param) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = learning_rates[i] * (self.social_param) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random restart for enhanced exploration\n                if np.random.rand() < 0.1:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Leverage adaptive learning rates and a diversity-driven restart mechanism to enhance global exploration in the swarm.", "configspace": "", "generation": 25, "fitness": 0.7904175793234011, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.041. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7653859694185261, 0.758174502214123, 0.8476922663375542], "final_y": [0.23555626416560915, 0.24084264758299478, 0.2131291274649636]}, "mutation_prompt": null}
{"id": "07e079e7-97c4-458d-ae99-776a79eff8b0", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity \n                reinit_prob = np.linalg.norm(particles[i] - self.best_global_position) / np.linalg.norm(ub - lb)\n                if np.random.rand() < reinit_prob:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance exploration by adjusting reinitialization probability based on particle's distance from global best.", "configspace": "", "generation": 26, "fitness": 0.7690416350747764, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.035. And the mean value of best solutions found was 0.227 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7545738177540497, 0.7349173048462851, 0.8176337826239946], "final_y": [0.23895783063729858, 0.22766661827297086, 0.21586912837063899]}, "mutation_prompt": null}
{"id": "b2e5dd11-9273-4402-b6ba-b25c572d7ae6", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        stagnation_threshold = 10  # Track stagnation\n        stagnation_count = np.zeros(self.num_particles)\n        \n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n                    stagnation_count[i] = 0  # Reset stagnation\n                else:\n                    stagnation_count[i] += 1\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Adaptive reinitialization based on stagnation\n                if stagnation_count[i] > stagnation_threshold:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    stagnation_count[i] = 0  # Reset stagnation after reinitialization\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance swarm intelligence by introducing adaptive reinitialization based on particle stagnation to improve exploration.", "configspace": "", "generation": 27, "fitness": 0.7874546213548479, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.026. And the mean value of best solutions found was 0.225 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.7568805612116278, 0.7852493420765526, 0.8202339607763633], "final_y": [0.22176000618205283, 0.23837348215085108, 0.21348325915955446]}, "mutation_prompt": null}
{"id": "3e433b7f-557b-40df-8e26-05f4a27b327d", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity \n                if np.random.rand() < (0.05 + 0.1 * (evaluations / self.budget)):  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Adaptively adjust particle reinitialization probability based on local search improvement rate.", "configspace": "", "generation": 28, "fitness": 0.8058726535617441, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.071. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8578642912458221, 0.7053864342479563, 0.8543672351914537], "final_y": [0.2033144285560068, 0.2534855594963584, 0.2100108101046242]}, "mutation_prompt": null}
{"id": "ffdd47f4-3954-40e5-9127-69f5ccc0d8c2", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                # Adaptive cognitive and social parameters\n                cognitive_velocity = (self.cognitive_param + adaptive_factor * (1.0 if personal_best_values[i] > self.best_global_value else 0.5)) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor * (1.0 if personal_best_values[i] < self.best_global_value else 0.5)) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce adaptive cognitive and social parameters based on particle history to enhance solution quality.", "configspace": "", "generation": 29, "fitness": 0.7949902269031518, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.073. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8677487001358221, 0.694881644267237, 0.8223403363063965], "final_y": [0.20273705267206554, 0.2641202090908509, 0.2232034911465144]}, "mutation_prompt": null}
{"id": "1d51e9ec-73be-4cf4-b5f0-4a78a1cbf7b9", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for diversity \n                if np.random.rand() < 0.05 * (1 - inertia_weight):  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance exploration by adapting the probability of reinitialization based on adaptive factor and inertia weight.", "configspace": "", "generation": 30, "fitness": 0.7529141406665869, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.076. And the mean value of best solutions found was 0.249 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.6900612617222431, 0.7094594787668591, 0.8592216815106583], "final_y": [0.27609896941716217, 0.26123502275160004, 0.20819181830014044]}, "mutation_prompt": null}
{"id": "9ef575ec-0e63-49bc-ae5b-54498d652e65", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                adaptive_cognitive_param = self.cognitive_param + 0.5 * (1 - adaptive_factor)\n                cognitive_velocity = adaptive_cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance velocity update rule by introducing an adaptive personal influence factor to balance local and global searches dynamically.", "configspace": "", "generation": 31, "fitness": 0.8139144291776935, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.040. And the mean value of best solutions found was 0.221 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.75792309509938, 0.8382890586266394, 0.8455311338070615], "final_y": [0.23871712063246864, 0.2114309955159538, 0.21373585732949685]}, "mutation_prompt": null}
{"id": "1f3f0dcb-4f4f-494b-be25-9ebaabfeb2d6", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Adaptively adjust reinitialization probability based on evaluations\n                if np.random.rand() < (0.05 + 0.45 * (1 - adaptive_factor)):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance the global exploration by adaptively adjusting the diversity reinitialization probability based on the current evaluation progress.", "configspace": "", "generation": 32, "fitness": 0.8169829704729352, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.002. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.8191954042013926, 0.8149493207799136, 0.8168041864374996], "final_y": [0.21952325951850826, 0.21596013108430268, 0.21690052495028433]}, "mutation_prompt": null}
{"id": "43f6cf18-f2f9-4ec6-a678-99edb07f0da3", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def chaotic_initialization(self, lb, ub):\n        chaotic_map = np.random.uniform(0, 1, (self.num_particles, self.dim))\n        chaotic_map = np.sin(np.pi * chaotic_map)\n        return lb + chaotic_map * (ub - lb)\n\n    def adaptive_neighborhood(self, particle_index, particles, personal_best_positions):\n        neighborhood_size = min(5, self.num_particles - 1)\n        indices = np.random.choice(np.delete(np.arange(self.num_particles), particle_index), neighborhood_size, replace=False)\n        neighborhood_best = max(indices, key=lambda i: func(personal_best_positions[i]))\n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                neighborhood_best = personal_best_positions[self.adaptive_neighborhood(i, particles, personal_best_positions)]\n                cognitive_velocity = self.cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.social_param * r2 * (neighborhood_best - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Utilize adaptive neighborhood topology and chaotic map initialization to enhance exploration and convergence in the particle swarm.", "configspace": "", "generation": 33, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {}, "mutation_prompt": null}
{"id": "cf579d99-a604-4444-b368-83e7266a75d1", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            mutation_rate = 0.1 * (1 - evaluations / self.budget)  # Adaptive mutation rate\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + evaluations / self.budget) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - evaluations / self.budget) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Adaptive mutation for exploration\n                if np.random.rand() < mutation_rate:  \n                    particles[i] += np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance particle diversity and convergence by integrating adaptive mutation and improved velocity adjustment strategies.", "configspace": "", "generation": 34, "fitness": 0.7437667595903316, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.744 with standard deviation 0.095. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.6191249585193275, 0.7639385037866261, 0.8482368164650415], "final_y": [0.32133940752373924, 0.23411537285749806, 0.21290419198205057]}, "mutation_prompt": null}
{"id": "9b186f93-bfbe-4df3-b599-4af233b29425", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Utilize dynamic velocity scaling based on global best improvements to balance exploration and exploitation.", "configspace": "", "generation": 35, "fitness": 0.8308264249736159, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.028. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "634b0725-2bda-47f9-98a0-6efaf143c11e", "metadata": {"aucs": [0.86831080613793, 0.7998489526784156, 0.8243195161045024], "final_y": [0.2025207574928879, 0.2091924614411309, 0.22237133399865872]}, "mutation_prompt": null}
{"id": "b7fbc6c5-33ed-4cc3-9859-6e58439a9704", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i] or np.random.rand() < 0.01:  # Random reset of personal best\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce a small probability of random personal best position reset to enhance exploration.", "configspace": "", "generation": 36, "fitness": 0.7668208047252164, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.047. And the mean value of best solutions found was 0.228 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "9b186f93-bfbe-4df3-b599-4af233b29425", "metadata": {"aucs": [0.7009712426223431, 0.8006875560869382, 0.7988036154663681], "final_y": [0.2528182841565497, 0.2317843181692908, 0.1987246967020475]}, "mutation_prompt": null}
{"id": "816cf880-bd68-48e5-9f45-c220de0f9099", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            decay_factor = 1 - (evaluations / self.budget)  # Decay for cognitive and social parameters\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param * decay_factor + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param * decay_factor - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Introduce a decay mechanism to the cognitive and social parameters to enhance convergence by reducing their influence over time.", "configspace": "", "generation": 37, "fitness": 0.7808674657111214, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.092. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "9b186f93-bfbe-4df3-b599-4af233b29425", "metadata": {"aucs": [0.86738093750993, 0.6541433739515528, 0.8210780856718815], "final_y": [0.2029001895105732, 0.30173932750603605, 0.2237340764692538]}, "mutation_prompt": null}
{"id": "a4d646c1-0e39-47d6-93f7-b2164e4b9694", "solution": "import numpy as np\n\nclass EnhancedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 2.0  # Increased cognitive parameter for better personal exploration\n        self.social_param = 2.0    # Increased social parameter for enhanced convergence\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)  # Chaotic initialization\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param - adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param + adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive mutation for maintaining diversity\n                if np.random.rand() < 0.05 + (0.95 * (1 - evaluations / self.budget)):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedDynamicParticleSwarm", "description": "Enhanced Dynamic Particle Swarm with adaptive learning rates and chaotic initialization to improve exploration and convergence.", "configspace": "", "generation": 38, "fitness": 0.7404222781450742, "feedback": "The algorithm EnhancedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.027. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9b186f93-bfbe-4df3-b599-4af233b29425", "metadata": {"aucs": [0.7036252734827202, 0.7488186953736227, 0.7688228655788799], "final_y": [0.2186499779657688, 0.21283097166951637, 0.2174688006942267]}, "mutation_prompt": null}
{"id": "9675124d-3e3a-4fbc-bfef-68308732fe49", "solution": "import numpy as np\n\nclass OptimizedDynamicParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = (self.cognitive_param + adaptive_factor) * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = (self.social_param - adaptive_factor) * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Introduce adaptive random reinitialization for increased diversity\n                if np.random.rand() < 0.05 + 0.05 * adaptive_factor:  \n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "OptimizedDynamicParticleSwarm", "description": "Enhance the algorithm by increasing diversity through random reinitialization based on adaptive probability.", "configspace": "", "generation": 39, "fitness": 0.8127898733426794, "feedback": "The algorithm OptimizedDynamicParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.051. And the mean value of best solutions found was 0.224 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "9b186f93-bfbe-4df3-b599-4af233b29425", "metadata": {"aucs": [0.86831080613793, 0.7457392977856058, 0.8243195161045024], "final_y": [0.2025207574928879, 0.24666546481828744, 0.22237133399865872]}, "mutation_prompt": null}
{"id": "581585dc-821f-40a5-889e-888bf66b07a1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance particle swarm optimization by integrating randomized reinitialization and adaptive control of cognitive and social parameters for improved exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.8393144666364764, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.034. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9b186f93-bfbe-4df3-b599-4af233b29425", "metadata": {"aucs": [0.8818208195088106, 0.7993438206317712, 0.8367787597688474], "final_y": [0.19638157676967505, 0.21667887955312448, 0.21354903753543086]}, "mutation_prompt": null}
{"id": "0a073187-e0fd-4ec4-9e35-1d16e07e3728", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.num_particles = int(30 + 10 * (evaluations / self.budget))  # Dynamic population size\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            improvement_factor = np.exp(-0.05 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] * improvement_factor + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce random reinitialization for diversity \n                if np.random.rand() < 0.05:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Further enhance exploration by introducing a dynamic population size based on budget utilization.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "581585dc-821f-40a5-889e-888bf66b07a1", "metadata": {}, "mutation_prompt": null}
{"id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve particle swarm optimization by introducing Lévy flight for enhanced exploitation and a dynamic restart mechanism to maintain exploration.", "configspace": "", "generation": 42, "fitness": 0.844471675528132, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.014. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "581585dc-821f-40a5-889e-888bf66b07a1", "metadata": {"aucs": [0.8247914295933731, 0.8500857518652034, 0.8585378451258194], "final_y": [0.20573798316764458, 0.18350258125283103, 0.19343597367244658]}, "mutation_prompt": null}
{"id": "2e12b4a2-3068-4418-9696-020ba8deb992", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def differential_evolution(self, particles, lb, ub, F=0.5, CR=0.9):\n        trial_vectors = np.copy(particles)\n        for i in range(self.num_particles):\n            a, b, c = particles[np.random.choice(self.num_particles, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < CR\n            trial_vectors[i] = np.where(cross_points, mutant, particles[i])\n        return trial_vectors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n            if evaluations % 10 == 0:\n                particles = self.differential_evolution(particles, lb, ub)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate Adaptive Differential Evolution with Enhanced Particle Swarm Optimization to balance exploration and exploitation dynamically.", "configspace": "", "generation": 43, "fitness": 0.7151388004245461, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.715 with standard deviation 0.036. And the mean value of best solutions found was 0.239 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7566643857882447, 0.6689259129880147, 0.7198261024973789], "final_y": [0.2394611998459567, 0.24964427298921543, 0.22927168681767685]}, "mutation_prompt": null}
{"id": "312af75e-6ea2-4e95-a103-8e652386fe4d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * np.cos(np.pi * evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.cos(np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance multi-layered particle exploration and exploitation through adaptive inertia and dynamic parameter tuning in particle swarm optimization.  ", "configspace": "", "generation": 44, "fitness": 0.8047487299280842, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.018. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.8035601510169701, 0.7838098927497551, 0.8268761460175276], "final_y": [0.2055312848211993, 0.22931836172922115, 0.21337461373106303]}, "mutation_prompt": null}
{"id": "44cef3c3-8525-4226-86d9-de1555d07753", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            self.max_velocity = 0.05 + 0.05 * np.sin(np.pi * (evaluations / self.budget)) * (ub - lb)  # Dynamic velocity limit\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.08:  # Slightly increased random reset chance for exploration\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance exploration and convergence rate by using a dynamic adaptive velocity limit and random reset of stagnated particles.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"bad operand type for unary -: 'NoneType'\").", "error": "TypeError(\"bad operand type for unary -: 'NoneType'\")", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {}, "mutation_prompt": null}
{"id": "bf228229-34f4-4e97-ae7d-48dc1eda9358", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * np.random.rand()\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic inertia weight adjustment to balance exploration and exploitation more effectively.", "configspace": "", "generation": 46, "fitness": 0.8028711139160049, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.042. And the mean value of best solutions found was 0.226 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7942442428824316, 0.7566139840434406, 0.8577551148221425], "final_y": [0.22984362945781667, 0.2429496182228288, 0.2040476974815929]}, "mutation_prompt": null}
{"id": "455aebc6-2dc2-471b-a8c0-ad4de370a31f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - 0.9 * (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm Optimization with adaptive inertia weight deceleration for improved convergence.", "configspace": "", "generation": 47, "fitness": 0.8148496246663273, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.031. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.784661887853397, 0.8026804587863556, 0.8572065273592295], "final_y": [0.21068003022451465, 0.20137560416759215, 0.19976310655417207]}, "mutation_prompt": null}
{"id": "a2d685cd-5486-487a-8853-e26f5e44f284", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i] * (1 + 0.1 * np.std(velocities)), lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Diversity-based restart mechanism\n                if np.random.rand() < 0.05 + 0.1 * (np.std(personal_best_values) / np.abs(np.mean(personal_best_values) + 1e-10)):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Refine EnhancedAdaptiveParticleSwarm by incorporating adaptive velocity scaling and a diversity-based restart mechanism for improved convergence. ", "configspace": "", "generation": 48, "fitness": 0.8029235709905178, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.052. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7321687149766074, 0.8223007221318346, 0.8543012758631117], "final_y": [0.2289041086759238, 0.21630470433517313, 0.2094403162172409]}, "mutation_prompt": null}
{"id": "f32fa882-fd3b-414a-b665-aa4bb4efdb34", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def stochastic_perturbation(self, L):\n        return 0.02 * np.random.standard_normal(size=L)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] *= (0.8 + 0.2 * np.random.rand())  # Adaptive velocity damping\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Enhanced global exploration with stochastic perturbation\n                if evaluations > self.budget * 0.5:\n                    particles[i] += self.stochastic_perturbation(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance particle swarm optimization with adaptive velocity damping and stochastic perturbation for better global search capability and convergence speed.", "configspace": "", "generation": 49, "fitness": 0.8365567401002602, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.039. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.8885683699943464, 0.7932225145440995, 0.8278793357623347], "final_y": [0.17604913267778421, 0.21625091648202144, 0.20856690473214667]}, "mutation_prompt": null}
{"id": "17a12e33-f2d5-4051-994e-2287b1881206", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        chaotic_factor = np.random.rand()\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                chaotic_factor = self.chaotic_map(chaotic_factor) # Use chaotic map\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + chaotic_factor * (cognitive_velocity + social_velocity)\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive learning rate for Lévy flight\n                if evaluations > self.budget * 0.7:\n                    learning_rate = 0.01 * (1 - evaluations / self.budget) \n                    particles[i] += learning_rate * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance particle swarm optimization by introducing chaotic maps for improved exploration and adaptive learning rates for better exploitation.", "configspace": "", "generation": 50, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'EnhancedAdaptiveParticleSwarm' object has no attribute 'levy_flight'\").", "error": "AttributeError(\"'EnhancedAdaptiveParticleSwarm' object has no attribute 'levy_flight'\")", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {}, "mutation_prompt": null}
{"id": "6ee3f511-b5e2-42e0-bc18-5e255bea4ec3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve particle swarm optimization by introducing Lévy flight for enhanced exploitation and a dynamic restart mechanism to maintain exploration.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.8247914295933731, 0.8500857518652034, 0.8585378451258194], "final_y": [0.20573798316764458, 0.18350258125283103, 0.19343597367244658]}, "mutation_prompt": null}
{"id": "d76dcf08-fa3b-42a3-8f20-b5b3422ab36c", "solution": "import numpy as np\n\nclass ImprovedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        stagnation_counter = 0\n        last_best_value = self.best_global_value\n        stagnation_limit = 50\n\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.cos(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.5:\n                    particles[i] += 0.02 * self.levy_flight(self.dim)\n\n                # Refined dynamic restart mechanism to maintain exploration\n                if stagnation_counter > stagnation_limit:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    stagnation_counter = 0\n\n        return self.best_global_position", "name": "ImprovedAdaptiveParticleSwarm", "description": "A refined Particle Swarm Optimization using Lévy flight for intensified local search, adaptive parameter tuning for diverse exploration, and a refined restart mechanism to mitigate stagnation.", "configspace": "", "generation": 52, "fitness": 0.6943909615937603, "feedback": "The algorithm ImprovedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.694 with standard deviation 0.061. And the mean value of best solutions found was 0.279 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.6424858757364897, 0.6611203688417633, 0.7795666402030279], "final_y": [0.3120625462303924, 0.28380645947089944, 0.24044897186128944]}, "mutation_prompt": null}
{"id": "ceb21a31-3bb5-4632-ae56-222300ad8ec6", "solution": "import numpy as np\n\nclass HybridBeeParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_bees = 30\n        self.num_particles = 30\n        self.best_solution = None\n        self.best_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        bees = np.random.uniform(lb, ub, (self.num_bees, self.dim))\n        bee_values = np.full(self.num_bees, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_value:\n                    self.best_value = value\n                    self.best_solution = particles[i]\n\n            for i in range(self.num_bees):\n                value = func(bees[i])\n                evaluations += 1\n                \n                if value > bee_values[i]:\n                    bee_values[i] = value\n\n                if value > self.best_value:\n                    self.best_value = value\n                    self.best_solution = bees[i]\n            \n            # Particle Swarm Update\n            inertia_weight = 0.5 + 0.4 * np.random.random()\n            cognitive_param = 1.5\n            social_param = 1.5\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_solution - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n            # Bee Phase: Random exploration and exploitation\n            best_bee_idx = np.argmax(bee_values)\n            for i in range(self.num_bees):\n                if i == best_bee_idx:\n                    continue\n                phi = np.random.uniform(-1, 1, self.dim)\n                bees[i] = np.clip(bees[i] + phi * (bees[i] - bees[best_bee_idx]), lb, ub)\n                \n            # Scout bee phase: Random reset\n            if evaluations / self.budget > 0.7:\n                for i in range(self.num_bees):\n                    if np.random.rand() < 0.1:\n                        bees[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_solution", "name": "HybridBeeParticleSwarm", "description": "Hybrid Bee-Particle Swarm Optimization combines the foraging behavior of artificial bees with the collaborative dynamics of particle swarms to enhance exploration and exploitation for black-box optimization problems.", "configspace": "", "generation": 53, "fitness": 0.8116770063649942, "feedback": "The algorithm HybridBeeParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.057. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.740900361040345, 0.8811179582948246, 0.8130126997598129], "final_y": [0.2401477395470334, 0.18599467250574586, 0.21921436173317843]}, "mutation_prompt": null}
{"id": "93f2d6ce-d753-451c-824f-492243922c92", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.65:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.03 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance the diversity and convergence of the EnhancedAdaptiveParticleSwarm algorithm by modifying the restart probability and particle update strategy.", "configspace": "", "generation": 54, "fitness": 0.8086643872054169, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.019. And the mean value of best solutions found was 0.214 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7860396208679685, 0.8326756333762573, 0.8072779073720249], "final_y": [0.20561246125291188, 0.20816207318998892, 0.2285867046905008]}, "mutation_prompt": null}
{"id": "a6ec0410-6ab7-4b5f-8657-110121f32a77", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / (self.budget + 50))\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity * (1 + evaluations / self.budget), self.max_velocity * (1 + evaluations / self.budget))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance exploration with adaptive velocity clamping and improved inertia weight decay.  ", "configspace": "", "generation": 55, "fitness": 0.8031972710095454, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.012. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.8147336913529133, 0.7871201439240152, 0.8077379777517079], "final_y": [0.20916054848957621, 0.21557145037688996, 0.22244855067789093]}, "mutation_prompt": null}
{"id": "1b3b41a5-ff22-49e8-a9f5-e08a894323af", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + \\\n                             (self.max_inertia_weight - self.min_inertia_weight) * np.exp(-4 * evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate adaptive inertia weight scaling with dynamically adjusted velocity clamping to enhance convergence speed and solution quality.", "configspace": "", "generation": 56, "fitness": 0.8275196564194718, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.039. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7960630660964274, 0.8830843625654504, 0.8034115405965375], "final_y": [0.1991269743576508, 0.1880830857606306, 0.22498799108985723]}, "mutation_prompt": null}
{"id": "6d760cbd-5b1c-45aa-8b94-db2c6614319c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.2 * (1 - evaluations / self.budget):  # Updated restart probability\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve global exploration by incorporating adaptive dynamic coefficients in both velocity update and restart probability.", "configspace": "", "generation": 57, "fitness": 0.8147158016930103, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.025. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.7817947646629788, 0.8206963809479302, 0.8416562594681216], "final_y": [0.2181804493360966, 0.19731638786933647, 0.19824964593035188]}, "mutation_prompt": null}
{"id": "4fba4ac8-ab42-43a9-b48b-7ea329171c27", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.random(3)  # Added randomness for hybrid mutation\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration with mutation\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim) + r3 * (self.best_global_position - lb)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve particle swarm optimization by integrating self-adaptive particle interaction and hybrid mutation dynamics for enhanced exploration and exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.6373372052923504, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.637 with standard deviation 0.014. And the mean value of best solutions found was 0.293 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.6260646139034736, 0.6565733962696354, 0.6293736057039421], "final_y": [0.3207342041893303, 0.29942348625940074, 0.2599918671405236]}, "mutation_prompt": null}
{"id": "2f15e187-448a-44fc-b906-fea13001e43d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * np.exp(-0.01 * evaluations)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(2 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploitation\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Dynamic restart mechanism to maintain exploration \n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a non-linear decay for the inertia weight for better convergence control in enhanced adaptive particle swarm optimization.", "configspace": "", "generation": 59, "fitness": 0.8319494413924703, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.039. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.886504651563574, 0.811320710217508, 0.798022962396329], "final_y": [0.18826617066049978, 0.19548465837961249, 0.2169295635788553]}, "mutation_prompt": null}
{"id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance adaptability by introducing a nonlinear time-varying cognitive and social parameter schedule for improved convergence.", "configspace": "", "generation": 60, "fitness": 0.8469581733508674, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ca20620-6da7-42ff-8242-6b2d5d89d1ad", "metadata": {"aucs": [0.8388485699529262, 0.8446268104269213, 0.8573991396727548], "final_y": [0.18729006204172216, 0.1996648668368428, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "e4964c6e-7ff4-43a5-a498-8b88062098f5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L, adaptive_factor):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return adaptive_factor * (u / np.abs(v) ** (1 / beta))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim, adaptive_factor)\n\n                if np.random.rand() < 0.05 + 0.1 * np.exp(-5 * (evaluations / self.budget)):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance adaptability by incorporating a dynamic Levy flight factor and adaptive mutation rate to improve exploration and convergence.", "configspace": "", "generation": 61, "fitness": 0.7724824605971058, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.030. And the mean value of best solutions found was 0.239 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7339693873462074, 0.7777933037855618, 0.805684690659548], "final_y": [0.24926844252317748, 0.24057865325380168, 0.22723200971649649]}, "mutation_prompt": null}
{"id": "53431f15-36c8-43d9-bf04-d109dcfb86af", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Introduce adaptive mutation\n                if np.random.rand() < 0.1 + 0.1 * (1 - evaluations / self.budget):\n                    mutation_strength = 0.2 * (ub - lb) * (0.5 - np.random.rand(self.dim))\n                    particles[i] = np.clip(particles[i] + mutation_strength, lb, ub)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce an adaptive mutation mechanism to enhance exploration and escape local optima in the search space.", "configspace": "", "generation": 62, "fitness": 0.779907154167366, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.023. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7479906450512899, 0.7945454038856572, 0.7971854135651508], "final_y": [0.24581551816553515, 0.22338865488278437, 0.23139878617583098]}, "mutation_prompt": null}
{"id": "a39c58a9-8498-4f10-bb6e-42482365c98f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n        self.resets = 0  # New parameter for restart mechanism\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            diversity = np.std(particles, axis=0).mean()  # Calculate diversity of the swarm\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (diversity / self.dim)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n                # Restart mechanism to escape local optima\n                if evaluations % (self.budget // 3) == 0:\n                    if self.resets < 2:\n                        self.resets += 1\n                        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance convergence by dynamically adjusting inertia based on diversity and introducing a restart mechanism to escape local optima.", "configspace": "", "generation": 63, "fitness": 0.8464532979049384, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.037. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7970207296098886, 0.8576803031587588, 0.8846588609461681], "final_y": [0.18878647800613835, 0.19853756114783339, 0.1849297997242354]}, "mutation_prompt": null}
{"id": "2b1a2715-9dca-4c78-82b1-48a7ce43b9a2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            temperature = max(0.1, 1 - evaluations / self.budget)  # Introduced temperature control\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] *= temperature  # Apply temperature scaling to the velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Incorporate temperature-based control in velocity update to enhance exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.7916095879279986, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.027. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7649687106959091, 0.8284328726140018, 0.7814271804740853], "final_y": [0.23332922625613683, 0.19155089199451514, 0.23234383041153606]}, "mutation_prompt": null}
{"id": "018c68a8-4320-4320-96c4-695ebcbac63e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Change: Introduced dynamic adjustment of max_velocity.\n        self.max_velocity = 0.1 * (ub - lb) * (1 - (0.5 * np.sin(np.pi * (np.arange(self.dim) / self.dim))))\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce dynamic adjustment of maximum velocity based on evaluations to enhance exploration-exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.8263782251300618, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.023. And the mean value of best solutions found was 0.201 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.793257583077192, 0.8439404936241295, 0.8419365986888638], "final_y": [0.20941705982580228, 0.18537994652876721, 0.20839743577626968]}, "mutation_prompt": null}
{"id": "bd2d1b80-9046-4da6-98fc-70cfaeea1779", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = (self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * \n                              (0.5 * (1 + np.cos(np.pi * evaluations / self.budget))))\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a nonlinear time-varying inertia weight update using a cosine function for better exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.8446663595194366, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.025. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8105029464567062, 0.8551203510070944, 0.8683757810945093], "final_y": [0.21967649168632053, 0.19127744929321444, 0.19930911069672919]}, "mutation_prompt": null}
{"id": "9fdbd335-0702-4c30-9cf8-fb889ccaf978", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim) * (1 - evaluations / self.budget)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce adaptive Levy flight scaling to enhance exploration during late search stages.", "configspace": "", "generation": 67, "fitness": 0.8469244806183364, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8388485699529262, 0.8445257322293281, 0.8573991396727548], "final_y": [0.18729006204172216, 0.1997890972070977, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "309928ca-4205-463d-9ada-900575e2d182", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    \n                if evaluations % 100 == 0 and personal_best_values[i] < self.best_global_value * 0.95:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce dynamic particle re-initialization based on performance thresholds for enhanced exploration and convergence.", "configspace": "", "generation": 68, "fitness": 0.814149864741057, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.035. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7763086809437643, 0.8613836867946005, 0.8047572264848062], "final_y": [0.21022674520649443, 0.19602018906800966, 0.20458375488654224]}, "mutation_prompt": null}
{"id": "0b817fa8-4ce6-4c3f-a1f8-bd6db5249d08", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * np.cos(np.pi * evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim) + np.random.normal(0, 0.01, self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce nonlinear inertia weight adaptation and a hybrid mutation strategy combining Gaussian and Lévy perturbations for enhanced exploration and exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.8448554152543258, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.019. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8203948818943892, 0.865133909722076, 0.849037454146512], "final_y": [0.1992627935823057, 0.18801676979394788, 0.20220630250808747]}, "mutation_prompt": null}
{"id": "67817822-822c-46fa-96d9-9508a0d0ef5b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * np.exp(-5 * evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance exploration by adjusting the inertia weight's exponential decay for improved diversity in later stages.", "configspace": "", "generation": 70, "fitness": 0.824956948823778, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.037. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7755903247318567, 0.8634839165213095, 0.8357966052181678], "final_y": [0.2291910160033126, 0.19527132456937457, 0.20654393007104066]}, "mutation_prompt": null}
{"id": "8cf85e42-b2e5-4f7b-84b8-120e993044ee", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(20, int(30 * (dim / 10)))  # Adjust swarm size based on dimension\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * np.random.normal(0, 1, self.dim)  # Use Gaussian perturbation\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce dynamic swarm size adjustment and replace Levy flight with Gaussian perturbation for enhanced exploration and convergence.", "configspace": "", "generation": 71, "fitness": 0.8423859050066363, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.011. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8388485699529262, 0.8308364202311436, 0.8574727248358393], "final_y": [0.18729006204172216, 0.2173484184760427, 0.17945668987259622]}, "mutation_prompt": null}
{"id": "9bf13ba9-a17d-4ff9-9636-d7c652803c74", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def adaptive_local_search(self, position, step_size):\n        return position + step_size * np.random.normal(0, 1, self.dim)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n                if np.random.rand() < 0.1:\n                    step_size = 0.1 * (1 - evaluations / self.budget)\n                    particles[i] = np.clip(self.adaptive_local_search(particles[i], step_size), lb, ub)\n        \n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce adaptive local search with dynamic perturbation and reinforcement learning-inspired parameter tuning for improved exploration and exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.808305503270596, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.030. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7704978791109985, 0.8100140503415474, 0.8444045803592417], "final_y": [0.2087039812601259, 0.2180995287598163, 0.20583010694153736]}, "mutation_prompt": null}
{"id": "0cd3c1c3-1256-443f-9e52-28b57c354b05", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.2 * (ub - lb)  # Increased max velocity for better exploration\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.1:  # Increased mutation chance for diversity\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarmImproved", "description": "Integrate diversity-promoting mutation strategy and adaptive velocity bounds to enhance global exploration and convergence.", "configspace": "", "generation": 73, "fitness": 0.8007517510535019, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.016. And the mean value of best solutions found was 0.221 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8026611726915889, 0.8189635912925357, 0.780630489176381], "final_y": [0.21351296994726165, 0.21083669228881252, 0.24009349473923058]}, "mutation_prompt": null}
{"id": "f593d3d8-7172-4cc0-88f4-e190b7413530", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n                # Adaptive mutation with differential evolution strategy\n                if np.random.rand() < 0.1:\n                    a, b, c = particles[np.random.choice(self.num_particles, 3, replace=False)]\n                    F = 0.8  # mutation factor\n                    new_position = a + F * (b - c)\n                    particles[i] = np.clip(new_position, lb, ub)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce adaptive mutation and enhanced exploration by hybridizing adaptive PSO with a differential evolution strategy for improved optimization performance.", "configspace": "", "generation": 74, "fitness": 0.8113224309611048, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.026. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8018872409382387, 0.8468666835953371, 0.7852133683497386], "final_y": [0.21799981187510742, 0.2046921876769907, 0.21366640060369102]}, "mutation_prompt": null}
{"id": "b986d014-fd86-4080-a582-071ecc419206", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.2  # Changed from 0.4 to 0.2\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.2 * (ub - lb)  # Changed from 0.1 to 0.2\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        dynamic_factor = lambda x: 0.1 + 0.9 * (x / self.budget)  # New dynamic factor\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity * dynamic_factor(evaluations) + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.85:  # Changed from 0.7 to 0.85\n                    particles[i] += 0.02 * self.levy_flight(self.dim)  # Changed from 0.01 to 0.02\n\n                if np.random.rand() < 0.07 + 0.1 * (1 - evaluations / self.budget):  # Changed from 0.05\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a novel dynamic exploration-exploitation scheme using variable learning rates and adaptive inertia to enhance convergence in particle swarm optimization.", "configspace": "", "generation": 75, "fitness": 0.802097390472737, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.049. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.7517099301056499, 0.7864747394629665, 0.8681075018495945], "final_y": [0.19862984385425064, 0.2110844355139585, 0.20635282700486735]}, "mutation_prompt": null}
{"id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce an adaptive mutation strategy based on diversity to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 76, "fitness": 0.8473449930692394, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "75d017a5-73a5-463f-84d7-10a6f2ad9d37", "metadata": {"aucs": [0.8388485699529262, 0.8457872695820371, 0.8573991396727548], "final_y": [0.18729006204172216, 0.19824412445658834, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "4f1ff3e7-1b99-4dc2-b0b0-974021a0fa18", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            current_num_particles = int(self.num_particles * (1 - evaluations / self.budget)) + 10  # Dynamic particle count\n            for i in range(current_num_particles):  # Change loop limit\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(current_num_particles):  # Change loop limit\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic particle count and adaptive exploration-exploitation balancing to enhance performance.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {}, "mutation_prompt": null}
{"id": "267e9e17-4e0c-4de5-aa45-2f113cc93c94", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n        self.memory = np.full((self.num_particles, self.dim), np.inf)  # Add dynamic memory\n        \n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n                    self.memory[i] = particles[i]  # Store in memory\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                local_memory_velocity = np.random.uniform(-0.5, 0.5) * (self.memory[i] - particles[i])  # Neighborhood search\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity + local_memory_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Implement a neighborhood search strategy and a dynamic memory mechanism to enhance global exploration and exploitation balance.", "configspace": "", "generation": 78, "fitness": 0.8224511376519029, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.007. And the mean value of best solutions found was 0.201 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.8316163433119539, 0.8158012139987578, 0.8199358556449969], "final_y": [0.20273430389552827, 0.18761895266499562, 0.21284161835026671]}, "mutation_prompt": null}
{"id": "4b54741f-bbb4-4bdc-96b2-d1841323edbe", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n        \n    def hybrid_flight(self, L):\n        levy_part = self.levy_flight(L)\n        gaussian_part = np.random.normal(0, 0.01, size=L)\n        return levy_part + gaussian_part\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.7 * np.cos(2 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.7 * np.cos(2 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.hybrid_flight(self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve exploration by introducing adaptive dynamic group strategies and hybridization of Lévy flights with Gaussian walks.", "configspace": "", "generation": 79, "fitness": 0.7497266804086377, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.750 with standard deviation 0.053. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.7164341603924724, 0.708332392845112, 0.8244134879883286], "final_y": [0.2689240038552978, 0.27453569035128533, 0.22339437443488275]}, "mutation_prompt": null}
{"id": "d00802e9-e736-4ca5-a759-7a6cf05f72ee", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure) * (1 - evaluations / self.budget)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a time-varying mutation strength decreasing over evaluations to enhance exploration-exploitation balance.", "configspace": "", "generation": 80, "fitness": 0.8470757408115895, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.8388485699529262, 0.8449795128090876, 0.8573991396727548], "final_y": [0.18729006204172216, 0.1992319819764824, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "31f73b01-8e3d-424a-8be4-141b87332075", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def chaotic_mapping(self, x):\n        return 4 * x * (1 - x)\n\n    def adaptive_learning_rate(self, evaluations):\n        return 0.01 + 0.2 * (evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        chaotic_sequence = np.random.rand(self.num_particles, self.dim)\n\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            adaptive_learning = self.adaptive_learning_rate(evaluations)\n            cognitive_param = self.base_cognitive_param + adaptive_learning * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - adaptive_learning * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    \n                chaotic_sequence[i] = self.chaotic_mapping(chaotic_sequence[i])\n                particles[i] += adaptive_learning * chaotic_sequence[i]\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate a chaos-driven search and adaptive learning mechanism to enhance exploration and convergence.", "configspace": "", "generation": 81, "fitness": 0.8126720661175723, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.047. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.7506695747396102, 0.8640145233479481, 0.8233321002651586], "final_y": [0.21430355096822717, 0.2017870287952418, 0.18354724748166762]}, "mutation_prompt": null}
{"id": "a4961cde-e5a8-4c9d-8304-178fafd33ad5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def chaotic_map(self, t, max_t):\n        return 0.7 + 0.2 * np.sin(np.pi * t / max_t)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                velocities[i] *= self.chaotic_map(evaluations, self.budget)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate chaos-based perturbation and adaptive velocity scaling to enhance global exploration and convergence.", "configspace": "", "generation": 82, "fitness": 0.8317362122641191, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.037. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.7791215880935558, 0.8543516726943102, 0.8617353760044912], "final_y": [0.2349401848935272, 0.19594915845940564, 0.1982370511132131]}, "mutation_prompt": null}
{"id": "32387a38-4c4a-4aab-8579-d6ee8be2ab05", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_factor = evaluations / self.budget\n            \n            # Dynamic particles adjustment\n            current_particles = int(self.num_particles * (1 + 0.2 * np.sin(2 * np.pi * adaptive_factor)))\n\n            for i in range(current_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic particle count adjustment based on evaluation progress to balance exploration and exploitation.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {}, "mutation_prompt": null}
{"id": "65d14f0d-6231-4b68-b25f-db958f643e9f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.1 * (1 - diversity_measure)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n            if diversity_measure < 0.1:  # Adding a perturbation step based on diversity\n                particles += np.random.normal(0, 0.1, particles.shape)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a perturbation based on the diversity measure to boost exploration when diversity is low.", "configspace": "", "generation": 84, "fitness": 0.8473449930692394, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.8388485699529262, 0.8457872695820371, 0.8573991396727548], "final_y": [0.18729006204172216, 0.19824412445658834, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic threshold for mutation strength to balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 85, "fitness": 0.8474950442727692, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.008. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e4c99e0f-f8c8-4cc7-a6f4-6a2c03873f62", "metadata": {"aucs": [0.8388485699529262, 0.8462374231926266, 0.8573991396727548], "final_y": [0.18729006204172216, 0.1976957297574089, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "c362f7b1-2544-4f05-b297-468a1e8be2f8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * np.exp(-4 * evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.cos(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.cos(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.3 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.6:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Use dynamic inertia and adaptive parameter scaling with diversity feedback to improve convergence and global search capability.", "configspace": "", "generation": 86, "fitness": 0.8339399805805372, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.026. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.8037887296114782, 0.8309325270287452, 0.8670986851013881], "final_y": [0.22361577968423973, 0.19729990363366856, 0.1890521460473623]}, "mutation_prompt": null}
{"id": "b9f31ab0-96a1-4d18-b4ae-a23b3d356959", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (np.sin(np.pi * evaluations / self.budget)) \n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.05 + 0.25 * (1 - diversity_measure) ** 2\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate a nonlinear mapping for inertia weight and adaptive mutation strategy to enhance convergence and diversity.", "configspace": "", "generation": 87, "fitness": 0.8365571415288726, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.054. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.7654599867205724, 0.894692552782273, 0.8495188850837726], "final_y": [0.23681393332238376, 0.1881553018302191, 0.2062346570552136]}, "mutation_prompt": null}
{"id": "f1dc59d2-28c2-431a-8303-fd84b2550039", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Integrate local search refinement\n                if np.random.rand() < 0.1:\n                    local_search_step = np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate_position = np.clip(personal_best_positions[i] + local_search_step, lb, ub)\n                    candidate_value = func(candidate_position)\n                    evaluations += 1\n                    if candidate_value > personal_best_values[i]:\n                        personal_best_values[i] = candidate_value\n                        personal_best_positions[i] = candidate_position\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Integrate local search within particles' personal best known positions to refine solutions and improve convergence.", "configspace": "", "generation": 88, "fitness": 0.8098276223343245, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.025. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.7885921227768805, 0.796006037103502, 0.8448847071225909], "final_y": [0.21640762185946005, 0.21389829082288925, 0.19925855661333558]}, "mutation_prompt": null}
{"id": "45413b64-e41d-4c61-b9e8-9183302ddca8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.cos(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.cos(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.15 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.6:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.03 + 0.08 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance the existing algorithm by introducing adaptive velocity regulation and a novel convergence acceleration mechanism to improve exploration-exploitation balance.", "configspace": "", "generation": 89, "fitness": 0.8006110438361356, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.113. And the mean value of best solutions found was 0.228 (0. is the best) with standard deviation 0.055.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.6417301088041253, 0.8910098565312717, 0.8690931661730099], "final_y": [0.3055968962667859, 0.1854514249329925, 0.19289714187939266]}, "mutation_prompt": null}
{"id": "6bb3db05-5291-4622-880d-3e534da825d1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (np.sin(2 * np.pi * evaluations / self.budget)) ** 2\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce adaptive inertia weight oscillation to enhance balance between exploration and exploitation.", "configspace": "", "generation": 90, "fitness": 0.8439334093080557, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.018. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.8516553538538152, 0.8616304892584827, 0.818514384811869], "final_y": [0.1814735455690346, 0.1912373317493915, 0.19644905610014696]}, "mutation_prompt": null}
{"id": "8112efc9-6f57-4092-a820-6226c370bda9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n        self.dynamic_population = 30\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.dynamic_population, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.dynamic_population, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.dynamic_population, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.dynamic_population = int(30 + 20 * (1 - evaluations / self.budget))\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.dynamic_population):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            dynamic_velocity = 0.02 + 0.3 * (1 - diversity_measure) * evaluations / self.budget\n\n            for i in range(self.dynamic_population):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += dynamic_velocity * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic adaptive velocity strategy and dynamic population size to enhance exploration and exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {}, "mutation_prompt": null}
{"id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Adjust the mutation strength calculation to improve exploration by incorporating a dynamic factor based on particle velocities.  ", "configspace": "", "generation": 92, "fitness": 0.8490439016674629, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.008. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4b083ca3-7334-4faf-a5b8-89ef5172da28", "metadata": {"aucs": [0.8388485699529262, 0.8508839953767078, 0.8573991396727548], "final_y": [0.18729006204172216, 0.19212298243399972, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "1290dcbb-9775-412f-888f-4522bae97067", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * ((evaluations / self.budget) * (self.best_global_value + 1) / 2)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce a dynamic inertia weight based on performance improvement, enhancing exploration and exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.5535008192173957, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.554 with standard deviation 0.002. And the mean value of best solutions found was 0.367 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.5565436979218147, 0.5514744198694304, 0.552484339860942], "final_y": [0.3642739562548667, 0.3685812186769416, 0.36754898282998394]}, "mutation_prompt": null}
{"id": "32a4ecf7-8ebc-4652-b23e-4cbf17426b3a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                random_factor = np.random.uniform(-0.1, 0.1)  # Added line for randomness\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity + random_factor\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Introduce randomness in velocity updates to enhance exploration by incorporating a dynamic factor.", "configspace": "", "generation": 94, "fitness": 0.7968786073432659, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.014. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.8156811511038135, 0.794008570977786, 0.7809460999481981], "final_y": [0.20095993395443146, 0.23245054207920657, 0.2156972800623208]}, "mutation_prompt": null}
{"id": "f7b922eb-fd0b-40b7-9e65-3d2ef4f0945e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        prev_best_value = float('-inf')\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            \n            convergence_speed = self.best_global_value - prev_best_value\n            prev_best_value = self.best_global_value\n\n            dynamic_learning_factor = 1 + np.tanh(convergence_speed)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += dynamic_learning_factor * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Improve exploration and exploitation balance by introducing a dynamic learning factor based on convergence speed.", "configspace": "", "generation": 95, "fitness": 0.8489146866545846, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.008. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.8388485699529262, 0.8504963503380729, 0.8573991396727548], "final_y": [0.18729006204172216, 0.1925818265939283, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "4fe1a2ee-c071-4e7c-9e4f-2eb206ca0199", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i] + mutation_strength, -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.6:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.07 + 0.12 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Incorporate adaptive mutation with diversity-driven velocity adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.7925378449917669, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.022. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.7624497807567814, 0.8160839774341733, 0.7990797767843458], "final_y": [0.24027339852553375, 0.21713513374743232, 0.17718480720096674]}, "mutation_prompt": null}
{"id": "60cff5f6-ea3b-4905-8646-109223762e10", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance global position updating by applying a weighted average of the best global and personal best positions for move determination.", "configspace": "", "generation": 97, "fitness": 0.8490439016674629, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.008. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.8388485699529262, 0.8508839953767078, 0.8573991396727548], "final_y": [0.18729006204172216, 0.19212298243399972, 0.19729543309726705]}, "mutation_prompt": null}
{"id": "39059099-a3e5-438b-896c-442d24b73ae3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            diversity_measure = self.diversity(particles, lb, ub)\n            inertia_weight = (self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * \n                              (1 - diversity_measure) * (evaluations / self.budget))\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance global exploration by integrating a dynamic inertia weight update mechanism based on population diversity. ", "configspace": "", "generation": 98, "fitness": 0.8306456957956962, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.034. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.7847983419110873, 0.8392653376181511, 0.86787340785785], "final_y": [0.21791890922935497, 0.19769131290446074, 0.19283337760710573]}, "mutation_prompt": null}
{"id": "ea555e06-6eb2-4685-be35-b73e444e57ce", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.max_inertia_weight = 0.9\n        self.min_inertia_weight = 0.4\n        self.base_cognitive_param = 1.5\n        self.base_social_param = 1.5\n        self.best_global_position = None\n        self.best_global_value = float('-inf')\n        self.max_velocity = None\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return u / np.abs(v) ** (1 / beta)\n\n    def diversity(self, particles, lb, ub):\n        return np.mean(np.std(particles, axis=0) / (ub - lb))\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.uniform(0, 1, self.dim)\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.max_velocity = 0.1 * (ub - lb)\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.max_velocity, self.max_velocity, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.num_particles, float('-inf'))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > self.best_global_value:\n                    self.best_global_value = value\n                    self.best_global_position = particles[i]\n\n            adaptive_factor = evaluations / self.budget\n            cognitive_param = self.base_cognitive_param + 0.5 * np.sin(3 * np.pi * adaptive_factor)\n            social_param = self.base_social_param - 0.5 * np.sin(3 * np.pi * adaptive_factor)\n\n            diversity_measure = self.diversity(particles, lb, ub)\n            mutation_strength = 0.01 + 0.2 * (1 - diversity_measure) * evaluations / self.budget * np.mean(np.abs(velocities))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(2)\n                cognitive_velocity = cognitive_param * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = social_param * r2 * (self.best_global_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if evaluations > self.budget * 0.7:\n                    particles[i] += mutation_strength * self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05 + 0.1 * (1 - evaluations / self.budget):\n                    particles[i] = self.crossover(particles[i], np.random.uniform(lb, ub, self.dim))\n\n        return self.best_global_position", "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhance particle swarm with adaptive crossover and mutation strategies inspired by genetic algorithms to improve exploration and exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.8117924152398551, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "40357263-4077-4a7a-93f9-ad5d91f1960f", "metadata": {"aucs": [0.8331588188696011, 0.7747117054840542, 0.8275067213659102], "final_y": [0.21657723826657072, 0.21349963251748905, 0.2139750578211853]}, "mutation_prompt": null}
