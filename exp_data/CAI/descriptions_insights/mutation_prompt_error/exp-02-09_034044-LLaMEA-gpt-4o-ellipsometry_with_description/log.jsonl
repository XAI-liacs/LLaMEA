{"id": "bd7eea02-f05a-4b3b-9fd0-caa564363642", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.1\n        self.local_search_steps = 10\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "A Hybrid Particle Swarm Optimization (PSO) enhanced with a Local Search mechanism to efficiently explore and exploit the search space for high-dimensional black box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.26375167688682954, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.264 with standard deviation 0.012. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": null, "metadata": {"aucs": [0.28048955269500064, 0.2504608612839212, 0.2603046166815668], "final_y": [0.014766920629139106, 0.046562557503444416, 0.03397243237375854]}, "mutation_prompt": null}
{"id": "b87f8c79-4fbf-456f-9520-150356e73092", "solution": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temperature = 1.0\n        self.final_temperature = 1e-3\n        self.alpha = 0.9  # Cooling rate\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize solution\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_score = func(current_solution)\n        num_evaluations += 1\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n\n        temperature = self.initial_temperature\n\n        while num_evaluations < self.budget and temperature > self.final_temperature:\n            # Generate a new candidate solution\n            candidate_solution = current_solution + np.random.uniform(-temperature, temperature, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_score = func(candidate_solution)\n            num_evaluations += 1\n\n            # Decide whether to accept the candidate solution\n            acceptance_probability = np.exp((current_score - candidate_score) / temperature)\n            if candidate_score < current_score or np.random.rand() < acceptance_probability:\n                current_solution = candidate_solution\n                current_score = candidate_score\n\n            # Update the best solution found so far\n            if current_score < best_score:\n                best_solution = np.copy(current_solution)\n                best_score = current_score\n\n            # Reduce the temperature\n            temperature *= self.alpha\n\n        return best_solution", "name": "AdaptiveSimulatedAnnealing", "description": "Adaptive Simulated Annealing (ASA) with Dynamic Cooling Schedule for Efficient Black Box Optimization, combining global exploration with focused local refinement through adaptive temperature control.", "configspace": "", "generation": 1, "fitness": 0.08494847398848893, "feedback": "The algorithm AdaptiveSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.085 with standard deviation 0.065. And the mean value of best solutions found was 11.496 (0. is the best) with standard deviation 7.563.", "error": "", "parent_id": "bd7eea02-f05a-4b3b-9fd0-caa564363642", "metadata": {"aucs": [0.03879281403623058, 0.03917909092455918, 0.17687351700467702], "final_y": [16.882082896170736, 16.804908848599375, 0.8004243807014699]}, "mutation_prompt": null}
{"id": "ada08d22-6b8a-4fb9-8766-48204d1db5ab", "solution": "import numpy as np\n\nclass HybridDESimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # DE parameters\n        self.population_size = 50\n        self.crossover_rate = 0.9\n        self.differential_weight = 0.8\n        \n        # Simulated Annealing parameters\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        num_evaluations += self.population_size\n\n        best_index = np.argmin(scores)\n        best_solution = population[best_index]\n        best_score = scores[best_index]\n\n        temperature = self.initial_temperature\n\n        while num_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = x1 + self.differential_weight * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Evaluate trial and simulated annealing acceptance\n                trial_score = func(trial)\n                num_evaluations += 1\n                \n                if trial_score < scores[i] or np.exp((scores[i] - trial_score) / temperature) > np.random.rand():\n                    population[i] = trial\n                    scores[i] = trial_score\n\n                    # Update best solution\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial\n\n                if num_evaluations >= self.budget:\n                    return best_solution\n\n            # Cool down temperature\n            temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDESimulatedAnnealing", "description": "A Differential Evolution (DE) algorithm hybridized with a Simulated Annealing (SA) inspired acceptance mechanism for enhanced exploration and exploitation in black box optimization.", "configspace": "", "generation": 2, "fitness": 0.16571150802262066, "feedback": "The algorithm HybridDESimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.166 with standard deviation 0.020. And the mean value of best solutions found was 0.510 (0. is the best) with standard deviation 0.337.", "error": "", "parent_id": "bd7eea02-f05a-4b3b-9fd0-caa564363642", "metadata": {"aucs": [0.18456090707790263, 0.13793547424316965, 0.17463814274678968], "final_y": [0.4895665706974659, 0.9333534304070762, 0.10847346754526209]}, "mutation_prompt": null}
{"id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05  # Reduced search radius\n        self.local_search_steps = 15  # Increased search steps\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved Hybrid PSO with Adaptive Inertia Weight and Dynamic Local Search for enhanced exploitation and exploration balance.", "configspace": "", "generation": 3, "fitness": 0.44887272204488254, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.449 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bd7eea02-f05a-4b3b-9fd0-caa564363642", "metadata": {"aucs": [0.45401793813482827, 0.46720006977262496, 0.42540015822719446], "final_y": [1.7944312832335246e-07, 2.4143988957659252e-08, 1.1299902154385202e-07]}, "mutation_prompt": null}
{"id": "830e131e-b51f-48e9-a7e3-94b63de2b837", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05  # Reduced search radius\n        self.local_search_steps = 15  # Increased search steps\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        early_convergence_threshold = 0.001  # Added early convergence detection threshold\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Early convergence detection\n            if global_best_score < early_convergence_threshold:\n                return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved Hybrid PSO with Early Convergence Detection to avoid unnecessary evaluations and improve efficiency.", "configspace": "", "generation": 4, "fitness": 0.36265925936278903, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.363 with standard deviation 0.016. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "metadata": {"aucs": [0.36217413596432124, 0.3431815483990748, 0.3826220937249709], "final_y": [0.0006114318956835285, 0.0008646227258560375, 0.0008447182692616817]}, "mutation_prompt": null}
{"id": "0fbfa32e-c1d5-4bac-87d8-81d23f07dbf8", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05  # Reduced search radius\n        self.local_search_steps = 15  # Increased search steps\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Adaptive Learning Rate for Optimized Exploration and Exploitation.", "configspace": "", "generation": 5, "fitness": 0.4467005329061872, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.447 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "metadata": {"aucs": [0.41609092365908007, 0.4301523636252417, 0.49385831143423997], "final_y": [3.150652438087034e-07, 2.427918719460847e-07, 5.286721551048159e-08]}, "mutation_prompt": null}
{"id": "d35c12e4-b0dd-412c-a8ad-2c11a4e1057d", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # Differential Evolution parameters\n        self.population_size = 30\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.5\n\n        # Quantum parameters\n        self.entanglement_factor = 0.1\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        num_evaluations += self.population_size\n        \n        best_index = np.argmin(scores)\n        best_position = population[best_index]\n        \n        while num_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Quantum-inspired entanglement\n                E = np.random.uniform(0, self.entanglement_factor, self.dim)\n                entangled_vector = (1 - E) * population[i] + E * best_position\n\n                # Mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[indices]\n                mutant_vector = a + self.differential_weight * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                # Crossover\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, entangled_vector)\n                \n                # Evaluate trial solution\n                trial_score = func(trial_vector)\n                num_evaluations += 1\n                \n                # Selection\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n\n                    # Update best solution\n                    if trial_score < scores[best_index]:\n                        best_index = i\n                        best_position = population[best_index]\n\n                if num_evaluations >= self.budget:\n                    return best_position\n\n        return best_position", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-inspired Differential Evolution (QiDE) with Entangled Population for enhanced exploration and convergence in black-box optimization.", "configspace": "", "generation": 6, "fitness": 0.25179056551106765, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.018. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "metadata": {"aucs": [0.2589657031762955, 0.22666884544293275, 0.26973714791397463], "final_y": [0.003480944930684718, 0.01642243791485103, 0.0043639865272663845]}, "mutation_prompt": null}
{"id": "cf71e8d3-8fed-4fc0-a4f8-394073d74b24", "solution": "import numpy as np\n\nclass AdvancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        \n        # Dynamic parameters\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 20  # Increased search steps\n        self.learning_rate_decay = 0.98  # Adaptive learning rate decay\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (1 - num_evaluations / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Enhanced Local Search on the best solution found so far\n            new_best_position = self.enhanced_local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def enhanced_local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for step in range(self.local_search_steps):\n            adaptive_radius = self.local_search_radius * (self.learning_rate_decay**step)\n            candidate_position = best_position + np.random.uniform(-adaptive_radius, adaptive_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "AdvancedHybridPSO", "description": "Advanced Hybrid PSO with Adaptive Learning Rates and Enhanced Local Search to Boost Convergence and Solution Quality.", "configspace": "", "generation": 7, "fitness": 0.24078981011407632, "feedback": "The algorithm AdvancedHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.015. And the mean value of best solutions found was 0.034 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "metadata": {"aucs": [0.2579364518053776, 0.22108366110917266, 0.24334931742767874], "final_y": [0.014916650818925327, 0.040197214379297415, 0.04746997988662947]}, "mutation_prompt": null}
{"id": "1d0bb581-5baf-4ccd-9d87-ca8a2ee97671", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_param = 1.7  # Optimized cognitive parameter\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05  # Reduced search radius\n        self.local_search_steps = 15  # Increased search steps\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Optimized Cognitive Parameter for improved convergence speed and precision.", "configspace": "", "generation": 8, "fitness": 0.45866690112612823, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.459 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "083f21c0-310d-4ad9-9d1e-8ee2fa62eeaa", "metadata": {"aucs": [0.44946841384020497, 0.45868899414675446, 0.4678432953914252], "final_y": [1.809290057007441e-07, 6.052544165309424e-08, 4.159780886824336e-08]}, "mutation_prompt": null}
{"id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Adaptive Neighborhood Search to improve the exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.46296331643275535, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.463 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1d0bb581-5baf-4ccd-9d87-ca8a2ee97671", "metadata": {"aucs": [0.4725129662017281, 0.4402840172231085, 0.47609296587342953], "final_y": [1.8252783387043657e-08, 5.320883830736468e-09, 1.1391406800354247e-07]}, "mutation_prompt": null}
{"id": "06be283e-2bd8-49ae-9f6a-d3e7a90be274", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n        self.qpso_beta = 0.5  # New parameter for QPSO\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # QPSO updates\n                self.inertia_weight *= 0.99\n                mbest = np.mean(personal_best_positions, axis=0)\n                phi = np.random.rand(self.dim)\n                p = self.qpso_beta * global_best_position + (1 - self.qpso_beta) * mbest\n                positions[i] = np.clip(p + phi * np.abs(global_best_position - positions[i]) * np.log(1/np.random.rand(self.dim)), lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduced Quantum Particle Swarm Optimization (QPSO) with a shrinking boundary strategy to enhance global exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.21509685672267945, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.215 with standard deviation 0.055. And the mean value of best solutions found was 0.532 (0. is the best) with standard deviation 0.501.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.2855770034498234, 0.2076322722304096, 0.15208129448780539], "final_y": [0.01686142701686917, 0.3688693554891625, 1.210188970170831]}, "mutation_prompt": null}
{"id": "fd94cdee-560d-4263-b898-b2051fc6ce5d", "solution": "import numpy as np\n\nclass DualSwarmDynamicMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles_main = 20\n        self.num_particles_aux = 15\n        self.inertia_weight = 0.8\n        self.cognitive_param = 1.5\n        self.social_param = 1.5\n        self.memory_factor = 0.05\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize main and auxiliary swarms\n        main_positions = np.random.uniform(lb, ub, (self.num_particles_main, self.dim))\n        main_velocities = np.random.uniform(-1, 1, (self.num_particles_main, self.dim))\n        aux_positions = np.random.uniform(lb, ub, (self.num_particles_aux, self.dim))\n        personal_best_positions = np.copy(main_positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles_main)\n\n        # Evaluate initial solutions for main swarm\n        for i in range(self.num_particles_main):\n            score = func(main_positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return main_positions[i]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for swarm, positions, velocities, num_particles in (\n                ('main', main_positions, main_velocities, self.num_particles_main), \n                ('aux', aux_positions, np.zeros_like(aux_positions), self.num_particles_aux)\n            ):\n                for i in range(num_particles):\n                    # Update velocity and position\n                    if swarm == 'main':\n                        r1, r2 = np.random.rand(), np.random.rand()\n                        velocities[i] = (self.inertia_weight * velocities[i] +\n                                         self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                         self.social_param * r2 * (global_best_position - positions[i]))\n                    else:\n                        velocities[i] = self.memory_factor * (global_best_position - positions[i])\n\n                    positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                    # Evaluate\n                    score = func(positions[i])\n                    num_evaluations += 1\n\n                    if swarm == 'main' and score < personal_best_scores[i]:\n                        personal_best_scores[i] = score\n                        personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = positions[i]\n\n                    if num_evaluations >= self.budget:\n                        return global_best_position\n\n        return global_best_position", "name": "DualSwarmDynamicMemory", "description": "Dual-Swarm Particle Evolution with Dynamic Memory to balance global exploration and local refinement using memory-enhanced particles.", "configspace": "", "generation": 11, "fitness": 0.20530635183109433, "feedback": "The algorithm DualSwarmDynamicMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.003. And the mean value of best solutions found was 0.208 (0. is the best) with standard deviation 0.081.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.20094929666905115, 0.20552622287405797, 0.20944353595017384], "final_y": [0.242411928886157, 0.09577359571540543, 0.2858842390990748]}, "mutation_prompt": null}
{"id": "7f18c819-9896-4df4-ad79-2939b785bfc3", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                self.cognitive_param *= 1.01  # Dynamic learning rate adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Dynamic Learning Rates for better exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.26569491557774977, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.266 with standard deviation 0.013. And the mean value of best solutions found was 0.030 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.28360064927330264, 0.2545065206400611, 0.25897757681988554], "final_y": [0.013443371540587869, 0.06470342141330661, 0.011405257338679572]}, "mutation_prompt": null}
{"id": "225aeb2f-2986-4d3a-ab13-07d80939dc84", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Dynamic Local Search on the best solution found so far\n            step_size = max(self.local_search_radius * (0.5 ** (num_evaluations / self.budget)), 0.01)\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations, step_size)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations, step_size):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-step_size, step_size, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved Hybrid PSO with Dynamic Local Search incorporating adaptive step size and varied local search steps based on convergence.", "configspace": "", "generation": 13, "fitness": 0.4438070418065842, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.444 with standard deviation 0.012. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4540261407067665, 0.42742356117446656, 0.4499714235385195], "final_y": [2.041790064706644e-07, 6.31078314474344e-08, 2.1826938277213431e-07]}, "mutation_prompt": null}
{"id": "f021116a-1d41-4f0a-9186-57e7e8af8eef", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            self.local_search_radius *= 0.95  # Dynamic adjustment of local search radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Dynamic Local Search Radius for better exploration-exploitation adaptability.", "configspace": "", "generation": 14, "fitness": 0.441094169617807, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.441 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4726233028375696, 0.3864947914623318, 0.46416441455351953], "final_y": [7.029861620153529e-08, 5.487689095444234e-07, 1.806438706483717e-08]}, "mutation_prompt": null}
{"id": "72941d37-fe37-49fa-866a-2904f17bd2ba", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            self.local_search_radius *= 0.95 # Dynamically adjust radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Adaptive Neighborhood Search and Dynamic Local Search Radius for improved exploration-exploitation.", "configspace": "", "generation": 15, "fitness": 0.441094169617807, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.441 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4726233028375696, 0.3864947914623318, 0.46416441455351953], "final_y": [7.029861620153529e-08, 5.487689095444234e-07, 1.806438706483717e-08]}, "mutation_prompt": null}
{"id": "a1c8d912-3fd2-4090-86a7-6180f763ba1b", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations, global_best_score)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations, best_score):\n        best_position = position\n        local_radius = self.local_search_radius * (0.5 + 0.5 * (best_score < 0.01))\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introducing dynamic local search radius adjustment and elitism to improve local convergence and stability.", "configspace": "", "generation": 16, "fitness": 0.3991709816596302, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.399 with standard deviation 0.064. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4621883665132859, 0.4242032325851046, 0.3111213458805001], "final_y": [9.711908471288348e-08, 3.3212479457281843e-07, 0.00012775772811500418]}, "mutation_prompt": null}
{"id": "69dfb793-5b9d-4d2b-bce1-1d0bfc557996", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Dynamic Local Search on the best solution found so far\n            current_radius = self.local_search_radius * (num_evaluations / self.budget)\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations, current_radius)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations, current_radius):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-current_radius, current_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved Hybrid PSO with Dynamic Local Search Radius to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.44766063911336196, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.448 with standard deviation 0.026. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4390730961759053, 0.42081744186671843, 0.48309137929746215], "final_y": [7.351238203808017e-08, 1.3630897150148023e-07, 5.620718847653782e-08]}, "mutation_prompt": null}
{"id": "c085eb30-2138-49a5-a4c1-ce9463437205", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.4 + 0.5 * (1 - num_evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            self.local_search_radius = 0.05 * (1 - num_evaluations / self.budget)  # Adaptive local search radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Dynamic Inertia and Adaptive Local Search Radius for improved convergence and precision.", "configspace": "", "generation": 18, "fitness": 0.22936400240980817, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.014. And the mean value of best solutions found was 0.048 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.211412419492654, 0.24600555955065584, 0.2306740281861147], "final_y": [0.08769533979347793, 0.04253483492108896, 0.01293955258935263]}, "mutation_prompt": null}
{"id": "222fd4e9-c194-412d-9fd4-d993653dd034", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # QIPSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        self.quantum_probability = 0.1\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Quantum rotation gate application\n                if np.random.rand() < self.quantum_probability:\n                    rotation_angle = np.random.uniform(-np.pi, np.pi, self.dim)\n                    positions[i] = self.apply_quantum_rotation(positions[i], rotation_angle, lb, ub)\n\n                # Update velocity and position\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n        return global_best_position\n\n    def apply_quantum_rotation(self, position, rotation_angle, lb, ub):\n        # Apply a quantum-inspired rotation to the position\n        new_position = position * np.cos(rotation_angle) + np.sin(rotation_angle)\n        return np.clip(new_position, lb, ub)", "name": "QuantumInspiredPSO", "description": "Quantum-inspired Particle Swarm Optimization (QIPSO) with Quantum Rotation Gates for Enhanced Exploration in High-dimensional Black-Box Optimization.", "configspace": "", "generation": 19, "fitness": 0.37903497686711435, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.379 with standard deviation 0.081. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.4420536754172507, 0.4304638734428934, 0.2645873817411988], "final_y": [5.659704985926999e-05, 1.2298980225988367e-06, 0.0011073280681606955]}, "mutation_prompt": null}
{"id": "a978381d-5de6-4c83-b5e4-626e2241e12f", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.final_inertia_weight = 0.4  # Added for dynamic inertia\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n\n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 20  # Increased local search steps\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                # Dynamic inertia weight adjustment\n                self.inertia_weight = self.final_inertia_weight + (0.9 - self.final_inertia_weight) * ((self.budget - num_evaluations) / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced Hybrid PSO with Adaptive Exploration via Dynamic Inertia and Extended Local Search for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.22147367670200402, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.009. And the mean value of best solutions found was 0.047 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.22098066971024988, 0.21039066448145738, 0.2330496959143048], "final_y": [0.04961457309331412, 0.05271877020772208, 0.039184530202230894]}, "mutation_prompt": null}
{"id": "b6998775-c979-4296-bb74-63fc73e2fb99", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved exploration by slightly increasing particle velocity randomness.", "configspace": "", "generation": 21, "fitness": 0.5127060278163308, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.513 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a678b9e1-63b5-48b5-bb60-a482f2b48517", "metadata": {"aucs": [0.5521963685795437, 0.4812772418735064, 0.5046444729959421], "final_y": [7.284758196027006e-09, 2.9088299723019808e-08, 8.846519244654341e-08]}, "mutation_prompt": null}
{"id": "3bb38aca-c84a-45d1-ad2a-36d0fdac4422", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        adaptive_radius = self.local_search_radius * (1 - (num_evaluations / self.budget))\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-adaptive_radius, adaptive_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Refined hybrid approach with adaptive velocity adjustment and improved local search for enhanced convergence.", "configspace": "", "generation": 22, "fitness": 0.4464074645855594, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.446 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.4906138065885153, 0.43702809311594126, 0.41158049405222163], "final_y": [2.3430584795842246e-08, 4.388095792438937e-07, 2.5736291147692407e-07]}, "mutation_prompt": null}
{"id": "35b6e271-1c42-4007-b921-3abc73415970", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            self.local_search_radius *= 0.9  # Adaptive radius decrease\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced local search by introducing adaptive radius based on convergence.", "configspace": "", "generation": 23, "fitness": 0.3999327177123992, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.400 with standard deviation 0.054. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.3263649774369951, 0.41751861292801695, 0.45591456277218545], "final_y": [0.0001086732275796675, 7.24445216275092e-09, 1.6707115989489745e-07]}, "mutation_prompt": null}
{"id": "0f893b4f-d16e-4ed6-baee-33d7db745fb3", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = max(3, int(self.num_particles * 0.2))  # Adapt neighborhood size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position with dynamic learning rate\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced particle dynamics by integrating a dynamic learning rate and refined neighborhood selection.", "configspace": "", "generation": 24, "fitness": 0.45248418663063045, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.452 with standard deviation 0.013. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.4362989262866651, 0.4525133846313686, 0.4686402489738577], "final_y": [2.833768720559839e-07, 2.701501965916649e-07, 1.4580720086732787e-07]}, "mutation_prompt": null}
{"id": "7be1129e-e0bb-456d-be69-b1c7a780a93c", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight += 0.01 * (global_best_score - personal_best_scores[i])\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i] + 0.01 * np.random.uniform(-1, 1, self.dim)\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introducing mutation in personal bests and adaptive inertia weight for enhanced exploration.", "configspace": "", "generation": 25, "fitness": 0.1522191874599117, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.152 with standard deviation 0.008. And the mean value of best solutions found was 1.320 (0. is the best) with standard deviation 0.244.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.14300934806875043, 0.15075774209880322, 0.16289047221218145], "final_y": [1.6080172432276092, 1.3398744376338825, 1.0109210550651941]}, "mutation_prompt": null}
{"id": "58f4851a-b664-41e8-a8a9-48607df281c4", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        success_count = 0\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                success_count += 1\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        self.local_search_radius = min(0.1, self.local_search_radius * (1.1 if success_count > 0 else 0.9))\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced local search with dynamic radius adjustment based on success rate.", "configspace": "", "generation": 26, "fitness": 0.4489268760474919, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.449 with standard deviation 0.012. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.45870031630326724, 0.45600509603936634, 0.4320752157998421], "final_y": [5.053358188761758e-08, 2.8263513601342115e-08, 2.1711390729259377e-07]}, "mutation_prompt": null}
{"id": "80bfcb02-37e3-4a71-97fa-5339fe2041ab", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                # Dynamic adjustment of cognitive and social parameters\n                self.cognitive_param = 1.5 + 0.5 * (1 - num_evaluations / self.budget)\n                self.social_param = 1.5 + 0.5 * (num_evaluations / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced PSO with dynamic cognitive and social parameters for improved exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.40963256419946076, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.410 with standard deviation 0.019. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.3993929648102996, 0.3935551547396029, 0.4359495730484798], "final_y": [9.820895572060176e-06, 1.7097075229460666e-06, 3.0640705087802704e-07]}, "mutation_prompt": null}
{"id": "ff68d4f9-0ac6-4fdb-97c8-df74d39a9d37", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            diversity = np.std(personal_best_positions, axis=0).mean()\n            self.local_search_radius = 0.1 if diversity > 0.1 else 0.05  # Dynamic adjustment\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduced a dynamic local search radius that adapts based on the diversity of the swarm to enhance local exploration efficiency.", "configspace": "", "generation": 28, "fitness": 0.442882933403431, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.443 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.45774144659545424, 0.44939655660651234, 0.4215107970083264], "final_y": [6.543008225749213e-08, 9.393195816257797e-08, 4.822103520852333e-07]}, "mutation_prompt": null}
{"id": "705f7a42-1ad8-44de-bda1-e943711b4391", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                self.cognitive_param *= 0.99  # Introduced decay for cognitive parameter\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduced decay to cognitive parameter for balanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.3201782623073622, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.320 with standard deviation 0.103. And the mean value of best solutions found was 0.072 (0. is the best) with standard deviation 0.061.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.23461030190344567, 0.4645774203601144, 0.26134706465852653], "final_y": [0.14940399952565306, 2.8733847433015622e-08, 0.06719591694055653]}, "mutation_prompt": null}
{"id": "886261e9-0d43-45e7-b93d-f42db73dc408", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + 0.4 * (np.random.rand())  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            if num_evaluations + self.local_search_steps < self.budget:  # Ensure budget adherence\n                new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n                if new_best_position is not None:\n                    global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced exploration through adaptive inertia weight and local search based on score improvement.", "configspace": "", "generation": 30, "fitness": 0.2662755873531833, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.266 with standard deviation 0.035. And the mean value of best solutions found was 0.080 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.2462908940841314, 0.31599944339608554, 0.23653642457933288], "final_y": [0.061596943495103765, 0.014181344295589966, 0.1650796143303682]}, "mutation_prompt": null}
{"id": "e0515d30-0662-46ac-8806-4151cc171291", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim)) \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                \n                # Introduce mutation-based perturbation\n                if np.random.rand() < 0.1:\n                    velocities[i] += np.random.normal(0, 0.1, self.dim)\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced particle diversity by introducing mutation-based velocity perturbation.", "configspace": "", "generation": 31, "fitness": 0.37969491627447943, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.380 with standard deviation 0.035. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.34884019421992196, 0.3612674295567181, 0.4289771250467983], "final_y": [0.00014567925382237359, 2.1164439883611953e-05, 5.223364802130971e-06]}, "mutation_prompt": null}
{"id": "373afb33-fc89-475f-8500-b52438cf125e", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                self.local_search_radius *= 1.1  # Increase radius when improving\n                best_position, best_score = candidate_position, candidate_score\n            else:\n                self.local_search_radius *= 0.9  # Reduce radius when not improving\n\n            if num_evaluations >= self.budget:\n                return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced local search by adaptive radius adjustment based on solution improvement rate.", "configspace": "", "generation": 32, "fitness": 0.4704998947073644, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.470 with standard deviation 0.004. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.47354584303111824, 0.47326445529147654, 0.4646893857994986], "final_y": [1.8863199572845072e-08, 9.49095994046634e-09, 3.147816424353835e-08]}, "mutation_prompt": null}
{"id": "ab9cbf60-1f1c-4400-b51c-ab846a0fc657", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.4 + (0.5 * (self.budget - num_evaluations) / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            adaptive_radius = self.local_search_radius * (self.budget - num_evaluations) / self.budget  # Adaptive radius\n            candidate_position = best_position + np.random.uniform(-adaptive_radius, adaptive_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduced a dynamic inertia weight and an adaptive local search radius to improve convergence.", "configspace": "", "generation": 33, "fitness": 0.25709750267725234, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.020. And the mean value of best solutions found was 0.037 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.23162493309633625, 0.2596663927734443, 0.28000118216197656], "final_y": [0.05542657142000132, 0.053294928156058644, 0.0012858041874587189]}, "mutation_prompt": null}
{"id": "88a92e67-c6ae-4c43-b13b-04bb0ebc9b02", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n\n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))  # Slightly increased velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n\n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n\n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + 0.4 * (self.budget - num_evaluations) / self.budget  # Dynamic inertia update\n                dynamic_cognitive_param = self.cognitive_param * (1 + 0.5 * r1)  # Adaptive cognitive component\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 dynamic_cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.5 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced velocity update by incorporating an adaptive cognitive component and dynamic inertia reduction, optimizing global exploration.", "configspace": "", "generation": 34, "fitness": 0.25692793359560545, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.029. And the mean value of best solutions found was 0.027 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.23953011710937433, 0.23306786308312633, 0.29818582059431564], "final_y": [0.024455833973732327, 0.034334843766990794, 0.022383040798213762]}, "mutation_prompt": null}
{"id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhanced global-local search synergy by introducing a dynamic adaptive exploration and exploitation balance, improving convergence speed and solution quality.", "configspace": "", "generation": 35, "fitness": 0.5231710420742507, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.523 with standard deviation 0.027. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b6998775-c979-4296-bb74-63fc73e2fb99", "metadata": {"aucs": [0.556408044700985, 0.4903738794815451, 0.5227312020402218], "final_y": [4.230507346236647e-09, 4.280401984578976e-08, 1.0999055782617153e-07]}, "mutation_prompt": null}
{"id": "32531a6a-0411-49b9-a1c5-087ab216cf5f", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                adaptive_learning_rate = np.clip(1.0 / (1.0 + num_evaluations / self.budget), 0.1, 1.0)  # Adaptive learning rate\n                velocities[i] = (adaptive_learning_rate * self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Enhanced Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Combining Particle Swarm Optimization with adaptive learning rate and enhanced local search for improved convergence and solution quality.", "configspace": "", "generation": 36, "fitness": 0.23908329046267265, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.014. And the mean value of best solutions found was 0.028 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.22366527350158627, 0.23572742150472448, 0.25785717638170724], "final_y": [0.015226302296167954, 0.01872000758368196, 0.05097328047780141]}, "mutation_prompt": null}
{"id": "fd246977-7f56-4b46-808a-6fe13f763efc", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.5  # Adjusted for better cognitive exploration\n        self.social_param = 1.7  # Adjusted for improved social influence\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Refined balance between exploration and exploitation by modifying the cognitive and social parameters, enhancing search efficiency and convergence.", "configspace": "", "generation": 37, "fitness": 0.471482245906274, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.471 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.4460926395817736, 0.48432407511016284, 0.4840300230268857], "final_y": [5.392714257270418e-07, 1.7103991340807774e-07, 1.0638051364513716e-07]}, "mutation_prompt": null}
{"id": "6ad30e48-773d-4c2b-855b-e8d3bd52a76d", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # Mutation probability\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] = np.clip(positions[i] + mutation, lb, ub)\n                \n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best with elitism\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improved exploration-exploitation balance by introducing adaptive mutation and elitism to enhance convergence stability and solution refinement.", "configspace": "", "generation": 38, "fitness": 0.406631586841465, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.407 with standard deviation 0.045. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.463593944757413, 0.4016910243963836, 0.35460979137059834], "final_y": [3.683724439687253e-06, 0.000248129183875217, 0.002179404172928497]}, "mutation_prompt": null}
{"id": "44fdb740-5ef8-49cc-ac93-85bea4c64768", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.modified_local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def modified_local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            step = np.random.standard_cauchy(self.dim) * self.local_search_radius  # Implementing Lévy flight\n            candidate_position = best_position + step\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Integrate a modified local search using Lévy flight for enhanced exploration and faster convergence.", "configspace": "", "generation": 39, "fitness": 0.5034326522325898, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.503 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.5020963047803464, 0.5320721095342875, 0.47612954238313565], "final_y": [1.352661719706167e-08, 8.165021560469665e-09, 1.69065667332814e-08]}, "mutation_prompt": null}
{"id": "b1e020e6-2419-4dd1-9ee7-b74d46603eb0", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n\n                if np.random.rand() < 0.1:  # Diversity preservation mechanism\n                    velocities[i] += np.random.uniform(-0.05, 0.05, self.dim)\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduced a diversity preservation mechanism through controlled random perturbation, enhancing exploration and convergence reliability.", "configspace": "", "generation": 40, "fitness": 0.4672923617719724, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.467 with standard deviation 0.037. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.4935683261534184, 0.4940199735252473, 0.41428878563725147], "final_y": [2.7748231175104397e-08, 4.0374844447828183e-07, 3.3060447028686005e-05]}, "mutation_prompt": null}
{"id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  # If stagnation persists, restart some particles\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce a diversity-enhancing restart mechanism to escape local optima and improve solution quality.", "configspace": "", "generation": 41, "fitness": 0.5463341714837348, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.546 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1a82acc7-47de-4d78-b4bd-36ce5a01a53f", "metadata": {"aucs": [0.5760042470183633, 0.5582884387107196, 0.5047098287221213], "final_y": [6.113103644540783e-09, 1.4306269146886913e-09, 2.2860029971912444e-08]}, "mutation_prompt": null}
{"id": "f426bb8c-ffdf-49b3-99b4-3636566f17c2", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                repulsion_force = np.random.uniform(-0.5, 0.5, self.dim)  # New line\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]) + repulsion_force)  # Adjusted line\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  # If stagnation persists, restart some particles\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by introducing a dynamic random particle repulsion mechanism.", "configspace": "", "generation": 42, "fitness": 0.24329071590395276, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.012. And the mean value of best solutions found was 0.082 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.24094616687428905, 0.2586845643188358, 0.23024141651873342], "final_y": [0.09206756265939313, 0.05273259517953662, 0.10202911126668499]}, "mutation_prompt": null}
{"id": "04df6bc5-f06c-4302-bd74-1ce539721210", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Start with high inertia weight\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  \n        adaptive_weight = self.inertia_weight\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                adaptive_weight = 0.4 + 0.5 * (self.budget - num_evaluations) / self.budget  # Adaptive inertia weight\n                velocities[i] = (adaptive_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  \n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce an adaptive inertia weight and multi-guide approach for enhanced exploration and exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.21466922338711592, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.215 with standard deviation 0.015. And the mean value of best solutions found was 0.083 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.19321312092661658, 0.22587064464056972, 0.22492390459416145], "final_y": [0.10124913396763413, 0.10032784015088259, 0.04696003422004952]}, "mutation_prompt": null}
{"id": "07efca10-60a4-4044-a251-184143970ca0", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= np.random.uniform(0.9, 1.1)  # Enhance exploration dynamics\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  # If stagnation persists, restart some particles\n                restart_indices = np.random.choice(self.num_particles, np.random.randint(3, 6), replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (len(restart_indices), self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance particle exploration dynamics by varying velocity scaling and restart strategy.", "configspace": "", "generation": 44, "fitness": 0.5329431049429697, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.533 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.552356905287831, 0.5173784516122031, 0.5290939579288749], "final_y": [1.4379715875092974e-08, 4.467688232902082e-07, 4.536146331116672e-09]}, "mutation_prompt": null}
{"id": "e904a11a-a553-4ddc-94ce-cc5fd834a2b3", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)  # More aggressive inertia decay\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  # If stagnation persists, restart some particles\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps + 5):  # Increase local search depth\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Utilize adaptive inertia weight adjustment and dynamic local search intensification to enhance global exploration and local refinement.", "configspace": "", "generation": 45, "fitness": 0.3029848688946157, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.026. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.3151742226861366, 0.26670831325320643, 0.32707207074450406], "final_y": [0.0016279712689174454, 0.030181975199636855, 0.008414665266322629]}, "mutation_prompt": null}
{"id": "2e0035bc-74ff-4b5b-874b-f7f7e7db477c", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 2.0  # Slightly increased cognitive parameter\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.7 + 0.3 * np.random.rand()  # More dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 20:  # If stagnation persists, restart some particles\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance global exploration and adapt inertia weight more dynamically.", "configspace": "", "generation": 46, "fitness": 0.25552816348063045, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.004. And the mean value of best solutions found was 0.028 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.26140892182560804, 0.25132720822967936, 0.25384836038660397], "final_y": [0.020964235689021664, 0.03457756226375242, 0.029935145879065848]}, "mutation_prompt": null}
{"id": "238009aa-41e6-45ed-a9fd-5da71a04f7ba", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood = np.random.choice(self.num_particles, 5, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by introducing velocity scaling and improved restart strategy to better navigate the search space.", "configspace": "", "generation": 47, "fitness": 0.5512853927709077, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.551 with standard deviation 0.047. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "248fe180-24e6-4deb-9b09-f4ebbece7581", "metadata": {"aucs": [0.5983455095560161, 0.48753189950693665, 0.5679787692497704], "final_y": [2.2547767124043608e-10, 2.3047185282944155e-06, 9.698222673172155e-09]}, "mutation_prompt": null}
{"id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Improve convergence by introducing a dynamic neighborhood size for more adaptive exploration.", "configspace": "", "generation": 48, "fitness": 0.5661947644970992, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.566 with standard deviation 0.061. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "238009aa-41e6-45ed-a9fd-5da71a04f7ba", "metadata": {"aucs": [0.6483837459130848, 0.5017487574034845, 0.5484517901747283], "final_y": [6.106991930940881e-11, 1.2015718576798267e-06, 1.9759831864481816e-11]}, "mutation_prompt": null}
{"id": "fc3296fb-6c2e-47ea-8033-d3cf0e2de044", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n            \n            if np.random.rand() < 0.15:  # Quick re-evaluation mechanism\n                reeval_indices = np.random.choice(self.num_particles, 3, replace=False)\n                for idx in reeval_indices:\n                    score = func(positions[idx])\n                    num_evaluations += 1\n                    if score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = score\n                        personal_best_positions[idx] = positions[idx]\n                        if score < global_best_score:\n                            global_best_score = score\n                            global_best_position = positions[idx]\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance convergence by introducing a quick re-evaluation mechanism to reinforce exploration dynamics.", "configspace": "", "generation": 49, "fitness": 0.5494418588348369, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.549 with standard deviation 0.060. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.4645592215015536, 0.5927316565149332, 0.5910346984880239], "final_y": [1.560638639618015e-05, 1.7330815955199447e-10, 1.3385555992322005e-10]}, "mutation_prompt": null}
{"id": "5ce375ac-3427-48fc-8ed0-dc67b546e9d1", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.9 - 0.5 * (num_evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Adjusted restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Incorporate a dynamic inertia weight scheduling and adaptive restart mechanism to enhance convergence.", "configspace": "", "generation": 50, "fitness": 0.32329834389854517, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.323 with standard deviation 0.012. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.3121631145720193, 0.340265665769246, 0.31746625135437023], "final_y": [0.0008258061231198766, 0.0029873834159790513, 0.0027103056257156543]}, "mutation_prompt": null}
{"id": "3380ef74-d492-464d-9f76-804e51de2a13", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.7 + 0.2 * np.sin(num_evaluations / self.budget * np.pi)  # Dynamic inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                velocities[restart_indices] = np.random.uniform(-1, 1.2, (5, self.dim))  # Reset velocities on restart\n                stagnation_count = 0\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce a dynamic inertia weight strategy and improve the restart mechanism to enhance global exploration.", "configspace": "", "generation": 51, "fitness": 0.26345113253035946, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.263 with standard deviation 0.009. And the mean value of best solutions found was 0.040 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.2713122262693549, 0.25127703187684813, 0.2677641394448753], "final_y": [0.013949508476710138, 0.06660538519711526, 0.039060943264767556]}, "mutation_prompt": null}
{"id": "35e20843-49b0-43a0-b006-e54952f7d333", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + (0.5 * np.sin(num_evaluations/self.budget * np.pi))  # Adaptive inertia update\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= np.tanh(velocities[i])  # New adaptive velocity scaling\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance convergence by introducing adaptive velocity scaling and a more robust local search termination criterion.", "configspace": "", "generation": 52, "fitness": 0.0945260639527113, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.095 with standard deviation 0.014. And the mean value of best solutions found was 5.066 (0. is the best) with standard deviation 1.455.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.0836687262518162, 0.11464481111766545, 0.08526465448865228], "final_y": [6.123151179087031, 3.0084124331402227, 6.065165239741455]}, "mutation_prompt": null}
{"id": "4eb5a0de-e0c5-4692-bcf8-657a1da9781d", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.99  # More gradual reduction\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.75  # Adjusted scaling for better control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by implementing a dynamic inertia weight and velocity range adjustment for better convergence.", "configspace": "", "generation": 53, "fitness": 0.49344994289198585, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.493 with standard deviation 0.043. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.43399845573204177, 0.5148362483485163, 0.5315151245953995], "final_y": [3.0617858304286625e-08, 3.616045127375251e-08, 6.395699242480013e-09]}, "mutation_prompt": null}
{"id": "fae2e7de-33b8-4642-b818-c61f796b9dd9", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.95  # Change: More dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  \n                np.random.seed(i)  # Enhance diversity by seed-based mutation\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance particle diversity by introducing adaptive mutation and dynamic inertia weight resetting.", "configspace": "", "generation": 54, "fitness": 0.17423768694767436, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.174 with standard deviation 0.037. And the mean value of best solutions found was 0.994 (0. is the best) with standard deviation 0.901.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.1937334382402497, 0.2059983317812608, 0.12298129082151255], "final_y": [0.444827042023098, 0.27344694481267723, 2.263788896946358]}, "mutation_prompt": null}
{"id": "5a69538c-5eb3-4b80-8e06-dd5735f15c69", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            self.local_search_steps = 15 + stagnation_count  # Line modified for adaptive intensity\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive local search intensity based on global stagnation, improving search efficiency.", "configspace": "", "generation": 55, "fitness": 0.5490556045736353, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.549 with standard deviation 0.054. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.476592081354436, 0.6049713302799185, 0.5656034020865515], "final_y": [1.651373444599454e-07, 2.842720420732544e-10, 3.519670877894957e-10]}, "mutation_prompt": null}
{"id": "f0ce9331-c80e-4dab-9e8b-fe64bd8c39d4", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)  # Ensure inertia weight does not become too low\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] += np.random.normal(0, 0.1, self.dim)  # Introduce velocity randomization\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration-exploitation balance by introducing velocity randomization and adaptive inertia weight adjustment.", "configspace": "", "generation": 56, "fitness": 0.24430009405330677, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.017. And the mean value of best solutions found was 0.085 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.2342047036948356, 0.2679567489855721, 0.23073882947951263], "final_y": [0.1321197525606311, 0.044068945094150894, 0.07913424773444323]}, "mutation_prompt": null}
{"id": "eae1609b-69b2-446f-b2ac-8a02d4112da3", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                self.social_param = 0.9 + 0.8 * np.exp(-0.5 * stagnation_count)  # Dynamic social parameter\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Modified: Adaptive restart threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce a dynamic social parameter and adaptive restart strategy for improved convergence.", "configspace": "", "generation": 57, "fitness": 0.5527633054395474, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.553 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.563139768005393, 0.5536031127691354, 0.5415470355441141], "final_y": [3.040959641741647e-10, 4.854681809846509e-10, 1.0322057759725568e-09]}, "mutation_prompt": null}
{"id": "9d4a05a6-e314-4e49-8d23-99636ef0ea28", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i] + np.random.uniform(-0.05, 0.05, self.dim)  # Perturbation added\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by randomly perturbing the global best position to avoid premature convergence.", "configspace": "", "generation": 58, "fitness": 0.32863204472568874, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.329 with standard deviation 0.008. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.3397444510459573, 0.3192615989401807, 0.32689008419092824], "final_y": [0.0013623506809967124, 0.005447302045153025, 0.010837292403351545]}, "mutation_prompt": null}
{"id": "37515757-81b3-4bf3-becf-304eb91d62bb", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        momentum_factor = 0.8  # New: Introduce momentum factor\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (momentum_factor * velocities[i] +  # Change: Add momentum factor\n                                 self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by introducing a momentum factor to velocity updates for improved diversity and convergence.", "configspace": "", "generation": 59, "fitness": 0.2842522738462869, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.019. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.2698191220537024, 0.2718144911353688, 0.31112320834978935], "final_y": [0.013517453685848758, 0.01137710982354461, 0.004871246714076866]}, "mutation_prompt": null}
{"id": "1c604745-448a-41d9-b9f1-19ff4c514855", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.97  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.65  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Combine dynamic neighborhood size with adaptive learning rates for enhanced exploration and convergence in Particle Swarm Optimization.", "configspace": "", "generation": 60, "fitness": 0.3852430045017514, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.385 with standard deviation 0.147. And the mean value of best solutions found was 0.044 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.23516024783677547, 0.33504690042830687, 0.585521865240172], "final_y": [0.125277863179978, 0.007669626322384717, 2.409280503653707e-10]}, "mutation_prompt": null}
{"id": "7296a588-fd6d-43dd-8559-a013d69a33a8", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.8  # Adjusted to improve convergence\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance adaptive exploration by adjusting the cognitive parameter to improve convergence dynamics.", "configspace": "", "generation": 61, "fitness": 0.5411691324840284, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.541 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.5293169674162432, 0.507499695639587, 0.5866907343962551], "final_y": [2.4260122709757258e-08, 1.2192101181783165e-06, 7.125106407275337e-11]}, "mutation_prompt": null}
{"id": "0ae6fe0a-944e-4968-bec8-ec792e464eaa", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0  # Introduce stagnation count\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Adaptive neighborhood search\n                neighborhood_size = np.random.randint(3, 7)  # Dynamic size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                # Update velocity and position\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98  # Slightly more dynamic adjustment\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))  # Adjusted exploration factor\n                velocities[i] *= 0.7  # New: Scale velocity to enhance control\n                velocities[i] = np.clip(velocities[i], -1, 1)  # Change: Clip velocity to prevent excessive oscillations\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Evaluate and update personal best\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0  # Reset stagnation counter\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:  # Modified: Restart strategy threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search on the best solution found so far\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        for _ in range(self.local_search_steps):\n            candidate_position = best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce velocity clipping for particles to prevent excessive oscillations and improve convergence stability.", "configspace": "", "generation": 62, "fitness": 0.22850363332886267, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.044. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.155.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.1718612106978441, 0.2800988082728104, 0.23355088101593346], "final_y": [0.34849917530050284, 0.031070197024293547, 0.009167977770028117]}, "mutation_prompt": null}
{"id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Integrate an adaptive cooling schedule to the local search phase to enhance local exploration.", "configspace": "", "generation": 63, "fitness": 0.577765819567215, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.578 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "351fa9ae-1b54-414d-903c-cf5f7ce7a18c", "metadata": {"aucs": [0.5999099015051608, 0.556617735845512, 0.576769821350972], "final_y": [2.379767715014767e-10, 8.154313300352674e-10, 2.60522087515071e-12]}, "mutation_prompt": null}
{"id": "b337ea5d-0b14-4f98-b5ca-35843489604a", "solution": "class HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 1.1  # Adjusted: Increase velocity magnitude for broader exploration\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Allow velocities to exceed their previous clipping threshold for broader exploration.", "configspace": "", "generation": 64, "fitness": 0.4213458205452745, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.421 with standard deviation 0.080. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "metadata": {"aucs": [0.5042987634998028, 0.44703055177882134, 0.31270814635719935], "final_y": [1.0126867145727364e-07, 1.0618709945015013e-07, 0.03243451534721174]}, "mutation_prompt": null}
{"id": "2139b751-b085-4ac6-9dad-50d3b3273a71", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                adaptive_cognitive_param = 1.5 + 0.2 * (global_best_score / personal_best_scores[i])\n                adaptive_social_param = 1.3 + 0.2 * (personal_best_scores[i] / global_best_score)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 adaptive_cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive cognitive and social parameters to balance exploration and exploitation in the particle swarm optimization.", "configspace": "", "generation": 65, "fitness": 0.34615112006970755, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.346 with standard deviation 0.009. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "metadata": {"aucs": [0.3342925439658293, 0.3473129338505594, 0.356847882392734], "final_y": [0.004142882313434832, 0.0018192181962155718, 0.002749839623940487]}, "mutation_prompt": null}
{"id": "699a11a5-6929-4588-a30f-48e22f659649", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # Apply adaptive mutation\n                if np.random.rand() < 0.1:  # New mutation rate\n                    mutation = np.random.normal(0, 0.1, self.dim)  # New: Normal distribution mutation\n                    positions[i] += mutation\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95 \n        local_radius = self.local_search_radius\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  \n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Incorporate an adaptive mutation mechanism to enhance exploration while maintaining stability.", "configspace": "", "generation": 66, "fitness": 0.45278979008346765, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.453 with standard deviation 0.061. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "metadata": {"aucs": [0.4942427987727076, 0.4978890440629514, 0.3662375274147439], "final_y": [4.87662968555194e-07, 1.1196653612991287e-06, 0.004532408254974061]}, "mutation_prompt": null}
{"id": "7658ad7d-9f23-4494-9980-920aa8fbb015", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                velocities[restart_indices] = np.random.uniform(-1, 1.2, (5, self.dim))  # Reinitialize velocities\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n\n                if num_evaluations >= self.budget:\n                    return None\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance particle diversity by introducing random reinitialization when local search stagnates.", "configspace": "", "generation": 67, "fitness": 0.5266689370883096, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.527 with standard deviation 0.064. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "metadata": {"aucs": [0.45746729108834283, 0.5105171106268163, 0.6120224095497699], "final_y": [5.394409052657236e-06, 1.923029225922411e-08, 4.0440587114522883e-10]}, "mutation_prompt": null}
{"id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce early termination in local search when no improvement is found for consecutive steps.", "configspace": "", "generation": 68, "fitness": 0.6250733205188351, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.625 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b685cf8a-1781-4d31-b0f0-b17c09f13885", "metadata": {"aucs": [0.6420147155632825, 0.6323522278585304, 0.6008530181346925], "final_y": [3.4977965967439284e-13, 1.3004705031496242e-12, 9.0170302852564e-09]}, "mutation_prompt": null}
{"id": "f71800dd-011a-4719-9350-2d5bd2c66596", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.90  # Modified cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # Apply modified cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 4:  # Modified early termination condition\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Enhance local search by increasing adaptive radius reduction and altering early termination.", "configspace": "", "generation": 69, "fitness": 0.42604313673404753, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.426 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.42248360902520854, 0.3797969142384814, 0.4758488869384526], "final_y": [0.0005656123816902875, 0.00020165779004575378, 3.6687970198688046e-07]}, "mutation_prompt": null}
{"id": "30077946-9517-49c7-bb15-8584899a2bf9", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                \n                # Change: Dynamic inertia adjustment based on stagnation\n                if stagnation_count > 10:\n                    self.inertia_weight = max(self.inertia_weight * 1.1, 1.4) \n\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce dynamic inertia weight adjustment based on stagnation to enhance exploration and exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.5644960152829462, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.564 with standard deviation 0.110. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.6371538431193495, 0.40911346494362766, 0.6472207377858616], "final_y": [4.7367635540355256e-12, 0.00040065206250108014, 1.4040959438642264e-09]}, "mutation_prompt": null}
{"id": "09c96b35-1239-4dc2-9bf0-b96a922dbab5", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.93  # New: Adjusted cooling rate for better exploration\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Refine the cooling rate in local search to enhance convergence by slightly increasing exploration.", "configspace": "", "generation": 71, "fitness": 0.6206426879155175, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.621 with standard deviation 0.070. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.6763198252703573, 0.6636076580564149, 0.5220005804197799], "final_y": [2.8381568198974446e-13, 2.387909292997368e-12, 1.9154911085044564e-09]}, "mutation_prompt": null}
{"id": "b320eea3-7d6f-4271-9393-6b8bb36a7997", "solution": "import numpy as np\n\nclass HybridPSOEnhancedSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= (0.9 + 0.2 * np.random.rand())  # Adaptive scaling\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position", "name": "HybridPSOEnhancedSearch", "description": "Enhance global and local search by introducing random diversifications and adaptive velocity scaling.", "configspace": "", "generation": 72, "fitness": 0.5212478411900544, "feedback": "The algorithm HybridPSOEnhancedSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.521 with standard deviation 0.075. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.5155587721731941, 0.43249292206077805, 0.615691829336191], "final_y": [1.3260984054748901e-08, 1.2240482816044292e-07, 5.0258495667548144e-11]}, "mutation_prompt": null}
{"id": "11d86e09-a80b-459d-8857-6c7c347d25dd", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations, stagnation_count)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations, stagnation_count):  # Changed line\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95 - stagnation_count * 0.005  # New: Adjust cooling rate based on stagnation_count\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce an adaptive cooling rate for local search based on the number of stagnation steps.", "configspace": "", "generation": 73, "fitness": 0.5715766530235513, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.572 with standard deviation 0.110. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.41729423082534567, 0.6284687831792556, 0.6689669450660527], "final_y": [0.00020083099390190147, 1.1031817829573464e-11, 3.989423965935067e-14]}, "mutation_prompt": null}
{"id": "27c6c013-8199-4694-b4e1-a9ae842c7788", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 20 + dim  # Changed: Adaptive particle count\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.9 - (0.5 * num_evaluations / self.budget)  # Changed: Dynamic inertia update\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive particle count and dynamic inertia to enhance convergence in the PSO.", "configspace": "", "generation": 74, "fitness": 0.3015315852574318, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.302 with standard deviation 0.033. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.31824049214143024, 0.255866687640005, 0.3304875759908602], "final_y": [0.007584755257699958, 0.0012420034416318314, 9.282324144647255e-05]}, "mutation_prompt": null}
{"id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Use a dynamic social parameter and adaptive local search to enhance exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.6543669950715019, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.654 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cb8beaa5-e368-4f34-a32e-9bd81ba43244", "metadata": {"aucs": [0.6607505583066959, 0.6912983965297275, 0.6110520303780822], "final_y": [3.856748039580383e-13, 1.3503117786152556e-13, 1.088894227919544e-12]}, "mutation_prompt": null}
{"id": "4a5b5087-9ecb-4a64-a6e2-9fd1a4ac7d64", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            self.cognitive_param = 1.7 + 0.3 * np.random.rand()  # New: Dynamic cognitive parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce dynamic cognitive parameter for improved individual exploration.", "configspace": "", "generation": 76, "fitness": 0.6377366667717667, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.638 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6315189764421616, 0.6216977659594596, 0.6599932579136788], "final_y": [9.159182891579153e-12, 7.570163779739277e-12, 5.478524419261999e-12]}, "mutation_prompt": null}
{"id": "d3203134-610b-48d0-80f9-dcc5233701d5", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Reduce stagnation threshold\n                restart_indices = np.random.choice(self.num_particles, 10, replace=False)  # Increase diversity\n                positions[restart_indices] = np.random.uniform(lb, ub, (10, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Enhanced diversity preservation and adaptive restart mechanism to improve convergence in stagnation phases.", "configspace": "", "generation": 77, "fitness": 0.6276734273734786, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.628 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6176503372754761, 0.6391963394742348, 0.6261736053707252], "final_y": [3.169274840092574e-11, 7.630527969974113e-13, 2.245424329365208e-12]}, "mutation_prompt": null}
{"id": "0b96cf90-2fbb-4a43-9e2e-56880dffeb2f", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            self.cognitive_param = 1.7 + 0.3 * np.random.rand()  # New: Self-adaptive cognitive param\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                elite_particle = np.argmin(personal_best_scores)  # New: Elite particle restart\n                restart_indices = np.random.choice(self.num_particles, 4, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (4, self.dim))\n                positions[elite_particle] = global_best_position  # Preserve elite\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Incorporating a self-adaptive cognitive parameter and introducing a novel elite particle restart strategy to boost convergence robustness.", "configspace": "", "generation": 78, "fitness": 0.6281381470901303, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.628 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6362613293173586, 0.6164361485350444, 0.631716963417988], "final_y": [6.539568863232342e-13, 2.071055030263755e-11, 2.1419656685231204e-12]}, "mutation_prompt": null}
{"id": "963ee8d1-7e0f-425b-9377-79faca6f7ca0", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= self.inertia_weight * 0.7  # Modified: Dynamic velocity scaling\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Modified: Adaptive restart strategy\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce dynamic velocity scaling and adaptive restart strategy for improved exploration and exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.16174491887714068, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.162 with standard deviation 0.008. And the mean value of best solutions found was 1.070 (0. is the best) with standard deviation 0.215.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.16274982521788228, 0.1712721742823089, 0.15121275713123083], "final_y": [0.9994939398894657, 0.8493874700507086, 1.361956920236535]}, "mutation_prompt": null}
{"id": "ef9bb13f-f923-4d11-a96d-b89292557c70", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia reduction to balance exploration and exploitation over iterations.", "configspace": "", "generation": 80, "fitness": 0.6343766098219547, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.634 with standard deviation 0.013. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6525021948594365, 0.6206900714454118, 0.6299375631610156], "final_y": [2.281365624021228e-12, 1.202879765220595e-12, 1.0487961779581963e-12]}, "mutation_prompt": null}
{"id": "25eac6a0-9a6b-4fe4-b7b5-6a11927c8b6f", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98 + 0.02 * np.random.rand()  # Change: Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius = max(local_radius * cooling_rate, 0.01)  # Change: Maintain minimum radius\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia weight and enhanced local search with a dynamic step size to improve balance between exploration and exploitation. ", "configspace": "", "generation": 81, "fitness": 0.5681717062373699, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.568 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.5832908597763, 0.573912514758566, 0.5473117441772437], "final_y": [1.5673808549695442e-09, 7.717514644516885e-12, 1.933480467708809e-11]}, "mutation_prompt": null}
{"id": "ef6b4907-525c-406a-a2fd-331078178591", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                if not improvement_made:  # Dynamically adjust inertia weight\n                    self.inertia_weight *= 0.95\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Incorporate a self-adaptive mechanism to adjust inertia weight dynamically based on improvement trends for enhanced convergence.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'improvement_made' is not defined\").", "error": "NameError(\"name 'improvement_made' is not defined\")", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {}, "mutation_prompt": null}
{"id": "c72cb2d7-84f6-4672-b9ba-ee4a669879bd", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()\n            self.inertia_weight = 0.5 + (0.4 / (1 + np.exp(-0.1 * stagnation_count)))  # Adaptive inertia\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +  # Updated adaptive inertia\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.normal(0, local_radius, self.dim)  # Normal distribution for exploration\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Incorporate adaptive inertia within PSO and refined local search strategies for improved convergence.", "configspace": "", "generation": 83, "fitness": 0.3172312149734654, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.317 with standard deviation 0.015. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.3369611383371146, 0.3155254380217779, 0.2992070685615037], "final_y": [0.0010947239965571976, 0.0012956099068316975, 0.0005316944077544375]}, "mutation_prompt": null}
{"id": "60147c8d-e784-4a44-b367-52bd9e8ec098", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                if np.random.rand() < 0.1:  # Randomly reset global best\n                    global_best_position = np.random.uniform(lb, ub, self.dim)\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Integrate stochastic restart to the global best position to escape local minima.", "configspace": "", "generation": 84, "fitness": 0.6131085101243452, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.613 with standard deviation 0.047. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6582485192401428, 0.5486371605061904, 0.6324398506267024], "final_y": [8.581534287534701e-13, 4.7543521479669515e-11, 3.0939741178503164e-12]}, "mutation_prompt": null}
{"id": "460f9855-6afd-4c70-9c4f-4aeb1e0fe75e", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()\n            disturbance_factor = np.random.uniform(0.95, 1.05)  # New: Stochastic disturbance factor\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i] * disturbance_factor, lb, ub)  # Apply disturbance\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Introduce a stochastic disturbance factor to escape local optima and enhance global exploration.", "configspace": "", "generation": 85, "fitness": 0.482799809011139, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.483 with standard deviation 0.096. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.471012373555158, 0.6058697278440139, 0.371517325634245], "final_y": [6.275688418770967e-05, 4.209725570052621e-11, 0.004647193375882298]}, "mutation_prompt": null}
{"id": "fdf056e2-dbd9-493c-a095-9a16455d2988", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n\n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n\n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Reduced stagnation threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                for idx in restart_indices:\n                    positions[idx] = global_best_position + np.random.normal(0, 0.1, self.dim)  # New: Stochastic restart\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Enhance convergence by adaptive velocity dampening and stochastic restart mechanism.", "configspace": "", "generation": 86, "fitness": 0.6426233133590236, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.643 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6689708443292419, 0.6716220708252307, 0.5872770249225981], "final_y": [7.396812016044576e-14, 2.726281464039196e-12, 6.019208307417179e-12]}, "mutation_prompt": null}
{"id": "51384704-e5c5-4698-8256-95b380198c64", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98 * (0.95 + 0.1 * np.random.rand())  # Changed: Stochastic element added\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce a stochastic element in the inertia weight to enhance the exploration-exploitation trade-off.", "configspace": "", "generation": 87, "fitness": 0.6309946642635006, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.631 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6355762102607911, 0.6195981686741253, 0.6378096138555853], "final_y": [7.241841169882413e-11, 5.141918780794821e-12, 1.9043732905438746e-12]}, "mutation_prompt": null}
{"id": "f2fe7fda-e973-4863-9f50-e3a2b46774d2", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.90  # New: Optimized cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Refine the adaptive local search by optimizing the cooling rate, enhancing convergence to the global best.", "configspace": "", "generation": 88, "fitness": 0.5477340211959305, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.548 with standard deviation 0.140. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.3496226966766036, 0.6428885710921617, 0.6506907958190263], "final_y": [5.6127527018712436e-08, 1.4947828666381951e-13, 1.5144783192242692e-12]}, "mutation_prompt": null}
{"id": "6d198f78-a3d6-483a-9ab3-4a64fefac9ec", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(4, 8)  # Modified: Enhanced neighborhood size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + 0.4 * np.cos(num_evaluations / self.budget * np.pi)  # Modified: Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Enhanced neighborhood selection and adaptive inertia weight adjustment to improve exploration and exploitation balance.", "configspace": "", "generation": 89, "fitness": 0.27491526888326706, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.050. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.2822600351257173, 0.3321243755265725, 0.21036139599751136], "final_y": [0.0025078246509654357, 7.749423040788559e-05, 0.0009886688745923068]}, "mutation_prompt": null}
{"id": "ba6ca0ca-4977-4697-835d-b4dbf2b89c76", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Use a dynamic social parameter and adaptive local search to enhance exploration and exploitation balance.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6607505583066959, 0.6912983965297275, 0.6110520303780822], "final_y": [3.856748039580383e-13, 1.3503117786152556e-13, 1.088894227919544e-12]}, "mutation_prompt": null}
{"id": "c7176817-4ecf-4cf2-8eeb-da8e8dd73153", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.98)  # Change: Adaptive inertia weight\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, int(0.2 * self.num_particles), replace=False)  # Change: Adaptive restart\n                positions[restart_indices] = np.random.uniform(lb, ub, (len(restart_indices), self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia weight reduction and diversity-based restart strategy to prevent premature convergence.", "configspace": "", "generation": 91, "fitness": 0.25311050341391883, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.023. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.27022537733679186, 0.22066469583978832, 0.2684414370651763], "final_y": [0.002109925307301876, 0.00246015841824231, 0.0016456198141713335]}, "mutation_prompt": null}
{"id": "db227f76-a7dc-4311-a14b-f4d67da7db8c", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= np.random.uniform(0.5, 0.9)  # Modified: Adaptive velocity scaling\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.90  # Modified: Enhanced cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive velocity scaling and enhanced local search cooling to improve convergence efficiency.", "configspace": "", "generation": 92, "fitness": 0.6192221835643373, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6429300259104779, 0.6086722137201354, 0.6060643110623989], "final_y": [1.2769992929507757e-10, 1.4898700631400155e-11, 6.116510754648587e-11]}, "mutation_prompt": null}
{"id": "72a9506d-d76e-4c05-a303-19543b5bb33c", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = int(3 + np.random.rand() * 4)  # Adjusted: Learning-based neighborhood size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Integrate an adaptive inertia weight and introduce a learning-based neighborhood size adjustment to enhance search dynamics.", "configspace": "", "generation": 93, "fitness": 0.6445992822477801, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.645 with standard deviation 0.038. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6975775801648814, 0.6107643757614531, 0.6254558908170055], "final_y": [4.7848382029997664e-11, 5.166132183312625e-09, 1.7714528902182178e-12]}, "mutation_prompt": null}
{"id": "b63182d3-fd43-4fbc-ac54-e076b8298184", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight *= 0.98\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                # New: Introduce adaptive mutation strategy\n                if np.random.rand() < 0.1:  # 10% chance of mutation\n                    mutation_strength = np.random.uniform(-0.01, 0.01, self.dim)\n                    positions[i] = np.clip(positions[i] + mutation_strength, lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Enhance HybridPSOLocalSearch by incorporating an adaptive mutation strategy to increase diversity in the particle swarm.", "configspace": "", "generation": 94, "fitness": 0.6163653099238954, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.616 with standard deviation 0.037. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.6528269745587663, 0.5650805637673149, 0.6311883914456048], "final_y": [1.8950744238714385e-09, 1.839034945500577e-08, 1.2505628731662562e-08]}, "mutation_prompt": null}
{"id": "26d0306e-3a79-4a3c-a20f-8636955b7bb2", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        adaptive_stagnation_threshold = 10  # New: Adaptive threshold based on stagnation\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.4 + 0.5 * np.random.rand()  # Changed: Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > adaptive_stagnation_threshold:  # Changed: Use adaptive threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n                adaptive_stagnation_threshold += 2  # New: Increment threshold\n\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0\n                improvement_made = True\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:\n                break\n\n        return best_position if improvement_made else None", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia weight adjustment and stochastic restart to enhance convergence speed and diversity.", "configspace": "", "generation": 95, "fitness": 0.36186328129301915, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.362 with standard deviation 0.026. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.3921770081849466, 0.3294236897344073, 0.36398914595970344], "final_y": [0.00010171615586011793, 0.00047076430001012604, 0.0007522191434274483]}, "mutation_prompt": null}
{"id": "f9c583f5-8f2b-474f-884c-1376a2668475", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # Dynamic social parameter\n            for i in range(self.num_particles):\n                # Non-linear inertia weight decay\n                self.inertia_weight = 0.4 + 0.5 * np.exp(-0.02 * num_evaluations)\n                neighborhood_size = np.random.randint(4, 8)  # Dynamic neighborhood size\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # Cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Enhance exploration by introducing a non-linear inertia weight decay and dynamic neighborhood size for better diversity and convergence.", "configspace": "", "generation": 96, "fitness": 0.4289675512908217, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.429 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.4427874896072479, 0.4339027670747577, 0.4102123971904593], "final_y": [6.893248076327529e-06, 4.859478997577948e-06, 4.11620601024915e-06]}, "mutation_prompt": null}
{"id": "0ea7e555-630d-4aa0-8d7c-74d8ecaf65de", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + 0.5 * np.random.rand()  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 10:  # Adjusted stagnation threshold\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce restart mechanism and adaptive inertia to improve stagnation handling and convergence.", "configspace": "", "generation": 97, "fitness": 0.3281414846022113, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.328 with standard deviation 0.048. And the mean value of best solutions found was 0.006 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.29461479195494655, 0.293482515918142, 0.39632714593354534], "final_y": [0.003735126373035014, 0.014322346553060939, 0.0003097543209875234]}, "mutation_prompt": null}
{"id": "d713c1ad-d1a8-45a8-be29-2ffb1024f209", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = max(0.4, 0.9 - (num_evaluations / self.budget) * 0.5)  # New: Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] *= 0.7\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 98, "fitness": 0.29709760823925857, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.016. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.3071581647191788, 0.2743162581044811, 0.3098184018941158], "final_y": [0.0018028080239918753, 0.0006127342966377762, 0.0008854872099298522]}, "mutation_prompt": null}
{"id": "48bc6b31-9ffb-492d-8ebe-a448d5e301eb", "solution": "import numpy as np\n\nclass HybridPSOLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n        # PSO parameters\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.cognitive_param = 1.7\n        self.social_param = 1.5\n        \n        # Local search parameters\n        self.local_search_radius = 0.05\n        self.local_search_steps = 15\n\n    def __call__(self, func):\n        num_evaluations = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1.2, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([float('inf')] * self.num_particles)\n        \n        # Evaluate initial solutions\n        for i in range(self.num_particles):\n            score = func(positions[i])\n            num_evaluations += 1\n            personal_best_scores[i] = score\n            if num_evaluations >= self.budget:\n                return positions[i]\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        # Main loop\n        stagnation_count = 0\n        while num_evaluations < self.budget:\n            self.social_param = 1.5 + 0.5 * np.random.rand()  # New: Dynamic social parameter\n            for i in range(self.num_particles):\n                neighborhood_size = np.random.randint(3, 7)\n                neighborhood = np.random.choice(self.num_particles, neighborhood_size, replace=False)\n                neighborhood_best = personal_best_positions[neighborhood[np.argmin(personal_best_scores[neighborhood])]]\n                \n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                self.inertia_weight = 0.5 + (0.4 * (1 - num_evaluations / self.budget))  # Change: Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_param * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_param * r2 * (global_best_position - positions[i]) +\n                                 0.6 * r3 * (neighborhood_best - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5, 0.5)  # Change: Velocity clamping\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                score = func(positions[i])\n                num_evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_count = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    stagnation_count = 0\n\n                if num_evaluations >= self.budget:\n                    return global_best_position\n\n            stagnation_count += 1\n            if stagnation_count > 15:\n                restart_indices = np.random.choice(self.num_particles, 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (5, self.dim))\n                stagnation_count = 0\n\n            # Local Search with adaptive radius\n            new_best_position = self.local_search(global_best_position, func, lb, ub, num_evaluations)\n            if new_best_position is not None:\n                global_best_position = new_best_position\n\n        return global_best_position\n\n    def local_search(self, position, func, lb, ub, num_evaluations):\n        best_position = position\n        best_score = func(best_position)\n        num_evaluations += 1\n\n        if num_evaluations >= self.budget:\n            return None\n\n        cooling_rate = 0.95  # New: Introduce cooling rate\n        local_radius = self.local_search_radius\n        no_improvement_steps = 0\n        improvement_made = False  # New: Track improvements\n\n        for _ in range(self.local_search_steps):\n            local_radius *= cooling_rate  # New: Apply cooling schedule\n            candidate_position = best_position + np.random.uniform(-local_radius, local_radius, self.dim)\n            candidate_position = np.clip(candidate_position, lb, ub)\n            candidate_score = func(candidate_position)\n            num_evaluations += 1\n\n            if candidate_score < best_score:\n                best_position, best_score = candidate_position, candidate_score\n                no_improvement_steps = 0  # Reset if improvement is found\n                improvement_made = True  # New: Mark improvement\n\n                if num_evaluations >= self.budget:\n                    return None\n            else:\n                no_improvement_steps += 1\n\n            if no_improvement_steps > 5:  # Early termination condition\n                break\n\n        return best_position if improvement_made else None  # Only update if improvement was made", "name": "HybridPSOLocalSearch", "description": "Introduce adaptive inertia weight and velocity clamping to balance exploration and exploitation.", "configspace": "", "generation": 99, "fitness": 0.21275269807960143, "feedback": "The algorithm HybridPSOLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.020. And the mean value of best solutions found was 0.227 (0. is the best) with standard deviation 0.160.", "error": "", "parent_id": "dd3d528c-0dbf-4295-838c-6b7c03b2e784", "metadata": {"aucs": [0.19985511510811482, 0.1973500979765892, 0.24105288115410028], "final_y": [0.39948634983105585, 0.26677356002623737, 0.01345244683767435]}, "mutation_prompt": null}
