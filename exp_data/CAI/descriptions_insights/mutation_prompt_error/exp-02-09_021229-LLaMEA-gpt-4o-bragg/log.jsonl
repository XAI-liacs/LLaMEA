{"id": "174f059f-a19b-47ff-8242-b7929b1f708b", "solution": "import numpy as np\n\nclass DynamicAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = (ub - lb) / 10  # Initial step size as 1/10 of the search space range\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n\n        for _ in range(self.budget - 1):\n            candidate_solution = current_solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2  # Increase step size if improvement\n            else:\n                step_size *= 0.9  # Decrease step size if no improvement\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = DynamicAdaptiveSearch(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "DynamicAdaptiveSearch", "description": "The Dynamic Adaptive Search (DAS) algorithm combines random search with adaptive step-size control to efficiently explore and exploit the search space within limited evaluations.", "configspace": "", "generation": 0, "fitness": 0.2319235620550922, "feedback": "The algorithm DynamicAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.012. And the mean value of best solutions found was 0.245 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": null, "metadata": {"aucs": [0.22060932876889672, 0.22693903301820317, 0.2482223243781767], "final_y": [0.30448409178877456, 0.2645876736522609, 0.16485577190471146]}, "mutation_prompt": null}
{"id": "75819356-f939-4e8d-9bcb-cb9c892ab7cc", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.history = []  # To store past solutions for diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = (ub - lb) / 10\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n\n        for _ in range(self.budget - 1):\n            # Introduce diversity by perturbing the step size occasionally\n            if np.random.rand() < 0.1:\n                step_size = step_size * np.random.uniform(0.8, 1.2)\n            \n            candidate_solution = current_solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.1  # Less aggressive increase\n            else:\n                step_size *= 0.8  # More aggressive decrease\n                # Adaptively learn from history\n                if len(self.history) > 0:\n                    past_solution = self.history[np.random.randint(0, len(self.history))]\n                    candidate_solution = past_solution + np.random.uniform(-step_size, step_size, self.dim)\n                    candidate_solution = np.clip(candidate_solution, lb, ub)\n                    candidate_value = func(candidate_solution)\n                    if candidate_value < current_value:\n                        current_solution = candidate_solution\n                        current_value = candidate_value\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            self.history.append(current_solution)\n\n        return self.best_solution, self.best_value", "name": "EnhancedDynamicAdaptiveSearch", "description": "Enhanced Dynamic Adaptive Search (EDAS) introduces a diversity mechanism and adaptive learning rate for improved convergence in black-box optimization tasks.", "configspace": "", "generation": 1, "fitness": 0.21702824487910552, "feedback": "The algorithm EnhancedDynamicAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.333 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "174f059f-a19b-47ff-8242-b7929b1f708b", "metadata": {"aucs": [0.21030263770894964, 0.21585680197708557, 0.22492529495128133], "final_y": [0.38267718324300914, 0.33858257534683256, 0.2770908901730872]}, "mutation_prompt": null}
{"id": "e736fdcb-1a7d-43e9-8d20-6f16fba62b3e", "solution": "import numpy as np\n\nclass DynamicAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = (ub - lb) / 10  # Initial step size as 1/10 of the search space range\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n\n        for _ in range(self.budget - 1):  \n            candidate_solution = current_solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = 0.7 * candidate_solution + 0.3 * current_solution  # Line changed\n                current_value = candidate_value\n                step_size *= 1.2  # Increase step size if improvement\n            else:\n                step_size *= 0.9  # Decrease step size if no improvement\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = DynamicAdaptiveSearch(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "DynamicAdaptiveSearch", "description": "The Enhanced Dynamic Adaptive Search (EDAS) algorithm refines exploration by introducing a weighted average to balance the candidate and current solutions.", "configspace": "", "generation": 2, "fitness": 0.21765497902167993, "feedback": "The algorithm DynamicAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.008. And the mean value of best solutions found was 0.331 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "174f059f-a19b-47ff-8242-b7929b1f708b", "metadata": {"aucs": [0.21907631509102687, 0.20678405683978762, 0.22710456513422528], "final_y": [0.31510239786083705, 0.4139461014649176, 0.26404766481124353]}, "mutation_prompt": null}
{"id": "48e2051a-a489-48d7-8720-4c085876dc75", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = (ub - lb) / 10\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        inertia_weight = 0.9\n\n        for _ in range(self.budget - 1):\n            inertia_weight = max(0.4, inertia_weight * 0.99)  # Dynamic inertia weight decay\n            candidate_solution = (current_solution +\n                                  inertia_weight * np.random.uniform(-step_size, step_size, self.dim))\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.3  # Slightly larger increase multiplier\n            else:\n                step_size *= 0.8  # Slightly larger decrease multiplier\n\n            # Local exploitation\n            if np.random.rand() < 0.2:  # 20% chance for local exploitation\n                perturbation = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n                candidate_solution = np.clip(current_solution + perturbation, lb, ub)\n                candidate_value = func(candidate_solution)\n                if candidate_value < current_value:\n                    current_solution = candidate_solution\n                    current_value = candidate_value\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "EnhancedDynamicAdaptiveSearch", "description": "The Enhanced Dynamic Adaptive Search (EDAS) algorithm integrates a dynamic inertia weight mechanism and local exploitation to improve exploration and convergence efficiency in black box optimization.", "configspace": "", "generation": 3, "fitness": 0.23182158925175525, "feedback": "The algorithm EnhancedDynamicAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.017. And the mean value of best solutions found was 0.252 (0. is the best) with standard deviation 0.099.", "error": "", "parent_id": "174f059f-a19b-47ff-8242-b7929b1f708b", "metadata": {"aucs": [0.2389180924883293, 0.20885760358690875, 0.24768907168002774], "final_y": [0.2008197227226035, 0.39033451871155433, 0.16485577190522782]}, "mutation_prompt": null}
{"id": "12b75275-8aa1-42cb-a4b1-2d4e5a9c6f3e", "solution": "import numpy as np\n\nclass StochasticGradientExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = (ub - lb) / 10\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n\n        for _ in range(self.budget - 1):\n            noise = np.random.normal(size=self.dim)\n            candidate_solution = current_solution + step_size * noise\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                gradient_estimate = (candidate_value - current_value) / (step_size * np.linalg.norm(noise))\n                current_solution -= step_size * gradient_estimate * noise\n                current_value = func(current_solution)\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            if current_value < self.best_value:\n                self.best_solution = current_solution\n                self.best_value = current_value\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = StochasticGradientExploration(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "StochasticGradientExploration", "description": "The Stochastic Gradient Exploration (SGE) algorithm uses stochastic gradient estimation combined with step-size adaptation to balance exploration and exploitation, optimizing efficiently under budget constraints.", "configspace": "", "generation": 4, "fitness": 0.19663744740451225, "feedback": "The algorithm StochasticGradientExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.197 with standard deviation 0.002. And the mean value of best solutions found was 0.519 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "174f059f-a19b-47ff-8242-b7929b1f708b", "metadata": {"aucs": [0.1949776420652688, 0.19991737795612674, 0.19501732219214118], "final_y": [0.5377139665618866, 0.481916358621988, 0.5371982054806093]}, "mutation_prompt": null}
{"id": "c84a4d0d-246f-4214-9248-d59996341398", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim)\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = AdaptiveDifferentialSearch(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "AdaptiveDifferentialSearch", "description": "A novel Adaptive Differential Search (ADS) algorithm leverages differential vector-based mutation and adaptive step-size control for enhanced exploration and exploitation within limited evaluations.", "configspace": "", "generation": 5, "fitness": 0.24026776592234111, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.001. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "174f059f-a19b-47ff-8242-b7929b1f708b", "metadata": {"aucs": [0.23939358260585042, 0.2404667991558208, 0.24094291600535211], "final_y": [0.19089012417884488, 0.19347693802218657, 0.18994783110046642]}, "mutation_prompt": null}
{"id": "ceee3e8a-6cbd-4834-b1dc-7b0cf354c0a6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = min(5 * self.dim, self.budget // 2)  # Dynamic population size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.best_solution = population[np.argmin(fitness)]\n        self.best_value = np.min(fitness)\n\n        evaluations = population_size\n        step_size = (ub - lb) / 10\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Select three random indices different from i\n                indices = np.random.choice(population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(population_size, 3, replace=False)\n\n                x0, x1, x2 = population[indices]\n                mutation_vector = x0 + np.random.uniform(0.5, 1.0) * (x1 - x2)\n                candidate_solution = np.clip(mutation_vector, lb, ub)\n                candidate_value = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_value < fitness[i]:\n                    population[i] = candidate_solution\n                    fitness[i] = candidate_value\n\n                if candidate_value < self.best_value:\n                    self.best_solution = candidate_solution\n                    self.best_value = candidate_value\n\n            # Adaptive mutation scaling and step size adjustment\n            step_size *= 0.95 if evaluations < 0.7 * self.budget else 1.05\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = EnhancedAdaptiveDifferentialSearch(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "EnhancedAdaptiveDifferentialSearch", "description": "Enhanced Adaptive Differential Search (EADS) incorporates adaptive mutation scaling and dynamic population size adjustment to balance exploration and exploitation effectively within constrained evaluations.", "configspace": "", "generation": 6, "fitness": 0.23858274862107168, "feedback": "The algorithm EnhancedAdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c84a4d0d-246f-4214-9248-d59996341398", "metadata": {"aucs": [0.2396750707976003, 0.23662870261391866, 0.2394444724516961], "final_y": [0.16488568467036413, 0.16504495371090988, 0.16490874435003045]}, "mutation_prompt": null}
{"id": "8cfa39be-17bf-41d2-8113-ba0f2277d272", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim)\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            mutation_factor = np.random.uniform(0.4, 0.9)  # Dynamic mutation scaling\n            candidate_solution = current_solution + diff_vector + mutation_factor * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value\n\n# Example usage:\n# optimizer = AdaptiveDifferentialSearch(budget=100, dim=5)\n# best_solution, best_value = optimizer(your_func)", "name": "AdaptiveDifferentialSearch", "description": "An improved Adaptive Differential Search (IADS) with dynamic mutation scaling for enhanced convergence.", "configspace": "", "generation": 7, "fitness": 0.24025385991389747, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.001. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c84a4d0d-246f-4214-9248-d59996341398", "metadata": {"aucs": [0.24136704171965329, 0.23939276689611377, 0.24000177112592536], "final_y": [0.18863761986578886, 0.19281075227184463, 0.19366200165574954]}, "mutation_prompt": null}
{"id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())  # Change 1\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9  # Change 2\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "A refined Adaptive Differential Search (ADS) algorithm incorporates dynamic scaling of the differential vector to enhance convergence speed and solution quality within limited evaluations.", "configspace": "", "generation": 8, "fitness": 0.24097819377988083, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.001. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c84a4d0d-246f-4214-9248-d59996341398", "metadata": {"aucs": [0.24050272773464632, 0.24174530568859076, 0.24068654791640542], "final_y": [0.18854825021256538, 0.1887977354179068, 0.19059812241109741]}, "mutation_prompt": null}
{"id": "393bf1c7-6537-46b3-a4eb-f5f7a43d2da3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        success_rate = 0.0  # Added to track success rate\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * success_rate)  # Modified\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                success_rate = min(1.0, success_rate + 0.1)  # Increase success rate\n            else:\n                step_size *= 0.9\n                success_rate = max(0.0, success_rate - 0.1)  # Decrease success rate\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "An improved Adaptive Differential Search (ADS) algorithm introduces dynamic adaptation of the differential vector based on historical success rates to boost performance under evaluation constraints.", "configspace": "", "generation": 9, "fitness": 0.2408790525237092, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.001. And the mean value of best solutions found was 0.187 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.24205422510843788, 0.23936541812732126, 0.24121751433536842], "final_y": [0.17949592407811887, 0.19644795074267396, 0.1843800124899294]}, "mutation_prompt": null}
{"id": "b1b5b13a-082b-4edb-86db-c433ce5a1a2b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        temperature = 1.0  # Initial temperature for simulated annealing effect\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand()) \n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value or np.exp((current_value - candidate_value) / temperature) > np.random.rand():\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9  \n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            temperature *= 0.99  # Cooling schedule to reduce exploration over time\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "A refined Adaptive Differential Search algorithm enhances dynamic scaling by incorporating a temperature-like control mechanism, balancing exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.2064250902787782, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.206 with standard deviation 0.014. And the mean value of best solutions found was 0.436 (0. is the best) with standard deviation 0.117.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.19694032569190711, 0.1962549416688556, 0.2260800034755719], "final_y": [0.5149286020495365, 0.522678922540225, 0.27031172400478554]}, "mutation_prompt": null}
{"id": "60a0a62c-f384-49a5-999b-87c291ea6137", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())  \n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9 * (1.0 + 0.1 * np.random.randn())  # Change 1\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a small random perturbation to the step size adaptation for enhanced exploration.", "configspace": "", "generation": 11, "fitness": 0.24013938446689362, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.23998748133961367, 0.24050166705662368, 0.23992900500444347], "final_y": [0.1870789997549971, 0.19136370746382103, 0.19154049854088273]}, "mutation_prompt": null}
{"id": "a409e9f2-336d-45a6-b9c6-47743153c5ba", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iteration in range(self.budget - 1):\n            oscillation_factor = 1.0 + 0.5 * np.sin(2 * np.pi * iteration / (self.budget))  # Change 1\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand()) * oscillation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduces a dynamic oscillation factor to the differential vector, targeting more diverse exploration early in the search process.  ", "configspace": "", "generation": 12, "fitness": 0.2409781013677401, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.001. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.24050236044562312, 0.2417452455765159, 0.24068669808108123], "final_y": [0.18854874206555916, 0.18879809758669908, 0.19059803099996453]}, "mutation_prompt": null}
{"id": "d76125b3-76d0-4113-a411-5db6096a6eec", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.5 * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n            else:\n                step_size *= 0.9\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            # Incorporating an adaptive random perturbation\n            if np.random.rand() < 0.1:  # Change 1\n                current_solution = np.random.uniform(lb, ub, self.dim)  # Adding a random jump\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "A refined Adaptive Differential Search (ADS) algorithm incorporates dynamic scaling of the differential vector alongside adaptive random perturbation to enhance convergence speed and solution quality within limited evaluations.", "configspace": "", "generation": 13, "fitness": 0.2365950588343632, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.002. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.2382444551741918, 0.23392060568783712, 0.23762011564106067], "final_y": [0.19500590146250862, 0.21738429653125957, 0.20689563377931508]}, "mutation_prompt": null}
{"id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)  # Change 2\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)  # Change 3\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)  # Change 4\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved ADS with adaptive exploration-exploitation balance leveraging historical success to guide search dynamics.", "configspace": "", "generation": 14, "fitness": 0.2481801381067306, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b7a5298c-743e-47f1-b8b6-2f8abde747d7", "metadata": {"aucs": [0.24806644485183893, 0.24822943249149, 0.24824453697686288], "final_y": [0.16560941847199928, 0.16525723263143577, 0.16509314536921582]}, "mutation_prompt": null}
{"id": "cb0403d1-ee05-4a54-938c-d72330320ac0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim) \n            perturbation = np.random.randn(self.dim) * 0.1 * step_size  # Change 1\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) + perturbation  # Change 2\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.3  # Change 3\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85  # Change 4\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Adaptive Differential Search refined by incorporating dynamic step-size modulation and stochastic perturbations for diversified exploration.", "configspace": "", "generation": 15, "fitness": 0.24804472307387163, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.24803892032383423, 0.24808267645108117, 0.2480125724466995], "final_y": [0.1655478335649352, 0.16594201107014428, 0.16603632508093724]}, "mutation_prompt": null}
{"id": "5f654556-f39d-4ceb-a69f-7ce202a9fd08", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.population_size = 5  # Dynamic population size\n        self.local_search_steps = 3  # Local search steps\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        values = np.array([func(ind) for ind in population])\n\n        for _ in range(self.budget - self.population_size):\n            # Rank population\n            sorted_indices = np.argsort(values)\n            population = population[sorted_indices]\n            values = values[sorted_indices]\n\n            # Select parents and generate offspring\n            parent1, parent2 = population[:2]\n            diff_vector = (parent1 - parent2) * np.random.uniform(0.5, 1.0, self.dim)\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = parent1 + diff_vector + self.success_rate * (rand_solution - parent1)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            # Local search refinement\n            for _ in range(self.local_search_steps):\n                local_step = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                refined_candidate = np.clip(candidate_solution + local_step, lb, ub)\n                refined_value = func(refined_candidate)\n                if refined_value < candidate_value:\n                    candidate_solution, candidate_value = refined_candidate, refined_value\n\n            # Update population\n            if candidate_value < values[-1]:\n                population[-1] = candidate_solution\n                values[-1] = candidate_value\n\n            # Update best solution\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            # Update strategy parameters\n            if candidate_value < values[0]:\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n        return self.best_solution, self.best_value", "name": "EnhancedAdaptiveDifferentialSearch", "description": "Enhanced Adaptive Differential Search with dynamic population strategy and local search refinement for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.22499318470647603, "feedback": "The algorithm EnhancedAdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.012. And the mean value of best solutions found was 0.263 (0. is the best) with standard deviation 0.091.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.23468271964425935, 0.23184366999907746, 0.2084531644760913], "final_y": [0.19645522152486505, 0.1994005726332274, 0.391689358683991]}, "mutation_prompt": null}
{"id": "0414f095-13a2-4cf1-95f1-24904972ed79", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)  # Change 2\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 + 0.1 * np.std(candidate_solution)  # Change 5\n                self.success_rate = min(1.0, self.success_rate + 0.05)  # Change 3\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)  # Change 4\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS using dynamic step-size escalation based on historical variance to improve exploration.", "configspace": "", "generation": 17, "fitness": 0.23827945220973804, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.238 with standard deviation 0.008. And the mean value of best solutions found was 0.207 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.24346695412253272, 0.2275192852680672, 0.24385211723861422], "final_y": [0.18187809676836175, 0.25781008208793266, 0.18187809676834188]}, "mutation_prompt": null}
{"id": "2ff43b1e-0924-4fee-8ba8-6fd6f50a2967", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.population_size = 5  # Change 1\n        self.population = np.random.uniform(-1, 1, (self.population_size, dim))  # Change 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Change 3\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - self.population_size):  # Change 4\n            for i in range(self.population_size):  # Change 5\n                diff_vector = np.random.uniform(-step_size, step_size, self.dim)\n                rand_solution = np.random.uniform(lb, ub, self.dim)\n                candidate_solution = self.population[i] + diff_vector + self.success_rate * (rand_solution - self.population[i])  # Change 6\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_value = func(candidate_solution)\n\n                if candidate_value < func(self.population[i]):  # Change 7\n                    self.population[i] = candidate_solution\n                    step_size *= 1.1  # Change 8\n                else:\n                    step_size *= 0.8  # Change 9\n\n                if candidate_value < self.best_value:\n                    self.best_solution = candidate_solution\n                    self.best_value = candidate_value\n\n            self.success_rate = min(1.0, self.success_rate + 0.05)  # Change 10\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with dynamic population and adaptive scaling to improve search efficiency and exploration-exploitation trade-off.", "configspace": "", "generation": 18, "fitness": 0.22260331898663901, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.007. And the mean value of best solutions found was 0.289 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.21582554491524675, 0.23190397206153968, 0.22008043998313065], "final_y": [0.3217744122557823, 0.23666327332558512, 0.30851598931680246]}, "mutation_prompt": null}
{"id": "86ecc3ec-bfab-4c75-ac50-eff3c7d3b245", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.15  # Slightly tweak step size increase\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced dynamic adjustment of exploration-exploitation balance by fine-tuning the step size adaptation.", "configspace": "", "generation": 19, "fitness": 0.2440865433768364, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.006. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.23600913821987535, 0.248140549703326, 0.24810994220730787], "final_y": [0.21573895425551692, 0.16552787154998339, 0.16552761146355832]}, "mutation_prompt": null}
{"id": "12e52fc2-de2c-463a-aee8-b3126a5a1038", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)  # Change 2\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)  # Change 3\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)  # Change 4\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved ADS with adaptive exploration-exploitation balance leveraging historical success to guide search dynamics.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.24806644485183893, 0.24822943249149, 0.24824453697686288], "final_y": [0.16560941847199928, 0.16525723263143577, 0.16509314536921582]}, "mutation_prompt": null}
{"id": "54a13673-6340-4a66-bdae-161f9479f7cc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * np.random.uniform(0.9, 1.1)  # Change\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduce stochastic step size adaptation to enhance convergence speed and solution diversity in AdaptiveDifferentialSearch.", "configspace": "", "generation": 21, "fitness": 0.24564453582935838, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.004. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.24058059967679424, 0.2481891975409508, 0.24816381027033008], "final_y": [0.19450690451507724, 0.1652301946711522, 0.16522626012519714]}, "mutation_prompt": null}
{"id": "abeb3410-cc35-4b0f-b11a-11c9099c4612", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        momentum = np.zeros(self.dim)  # New variable for momentum\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) + 0.1 * momentum  # Modified line\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                momentum = candidate_solution - current_solution  # Update momentum\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by modifying the candidate solution generation formula to incorporate historical momentum.", "configspace": "", "generation": 22, "fitness": 0.24789148236954447, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.24768090293392264, 0.24830837671922268, 0.24768516745548808], "final_y": [0.1672894541665525, 0.16497597296468813, 0.1671289319417475]}, "mutation_prompt": null}
{"id": "eb398aaf-0892-49d8-9f12-72d80ffd0263", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5  # Change 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)  # Change 2\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * np.random.rand()  # Change 5\n                self.success_rate = min(1.0, self.success_rate + 0.05)  # Change 3\n            else:\n                step_size *= 0.9\n                self.success_rate = max(0.0, self.success_rate - 0.05)  # Change 4\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS by stochastic adaptation of step size to balance exploration-exploitation.", "configspace": "", "generation": 23, "fitness": 0.2369208835104277, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.009. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.22373607909949644, 0.2426973609664187, 0.24432921046536793], "final_y": [0.2843440379395241, 0.18682839792704675, 0.18032175131401806]}, "mutation_prompt": null}
{"id": "bcd23446-1736-445b-a727-6759cc282028", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback and dynamic step scaling based on performance trends.", "configspace": "", "generation": 24, "fitness": 0.24829372506550582, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a57f8697-8ba3-4910-894b-c9e8f5e596b8", "metadata": {"aucs": [0.248315577025909, 0.2483057740248522, 0.2482598241457562], "final_y": [0.16485577190470124, 0.16485577190470757, 0.16485577190470224]}, "mutation_prompt": null}
{"id": "2a9aad51-e6b3-4796-8b9f-c1853c4e95d1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.1 + 0.1 * np.random.rand()  # Change: Added stochastic modulation for step size\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.01)  # Change: Reduced penalty for unsuccessful trials\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with stochastic step size modulation and conditional success feedback for improved exploration.", "configspace": "", "generation": 25, "fitness": 0.24818454405321314, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24823823449118498, 0.24808996981312226, 0.2482254278553322], "final_y": [0.1649217263890599, 0.16496615868708597, 0.16496670610045594]}, "mutation_prompt": null}
{"id": "f86e195a-e167-47b7-a307-491f23e08302", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        solutions = [current_solution]  # Track solutions for clustering\n\n        for _ in range(self.budget - 1):\n            if len(solutions) > 2:   # Dynamic clustering adaptation\n                kmeans = KMeans(n_clusters=2).fit(solutions)\n                if len(set(kmeans.labels_)) > 1:\n                    step_size *= 0.8  # Exploitative step scaling\n\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                solutions.append(candidate_solution)  # Track for clustering\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive clustering and exploitative step scaling based on population diversity.", "configspace": "", "generation": 26, "fitness": 0.24713672197118722, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24769395823619045, 0.24760087054777613, 0.2461153371295951], "final_y": [0.16739796434548027, 0.16761938541705013, 0.17329928945390527]}, "mutation_prompt": null}
{"id": "b57ed948-60d3-4033-9e94-436a44ea696c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  # Change: Increased randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "A refined ADS with stochastic step adaptation and enhanced exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.2481770564203484, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24818034169196035, 0.24824997689055506, 0.24810085067852983], "final_y": [0.16548757169069805, 0.16517410141602928, 0.16544669841038528]}, "mutation_prompt": null}
{"id": "009aeaa7-258a-4b0c-8a90-62f76ca5ce34", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced stochastic perturbation in the differential vector for enhanced exploration.", "configspace": "", "generation": 28, "fitness": 0.24829372506550582, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.248315577025909, 0.2483057740248522, 0.2482598241457562], "final_y": [0.16485577190470124, 0.16485577190470757, 0.16485577190470224]}, "mutation_prompt": null}
{"id": "e69bf148-2643-45c8-bbea-cbdcc09acb52", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * (0.8 + 0.4 * np.random.rand())  # Change: Added randomness and scaling to step size\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback, introducing exploration-exploitation balance through stochastic step-size adaptation.", "configspace": "", "generation": 29, "fitness": 0.24612702651649532, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24827384910273376, 0.24176944241116693, 0.24833778803558526], "final_y": [0.1648557719047039, 0.18867041869354118, 0.16485577190470568]}, "mutation_prompt": null}
{"id": "68151acf-2ec0-4ca8-9fe5-f0b68087e0d5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05 * np.random.rand())  # Change: Added randomness in success rate increment\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback, dynamic step scaling based on performance trends, and randomization in success rate adjustment.", "configspace": "", "generation": 30, "fitness": 0.2462241986848612, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24823490958711547, 0.2421270178748458, 0.2483106685926223], "final_y": [0.16485577190470369, 0.18852610538475534, 0.16485577190470124]}, "mutation_prompt": null}
{"id": "96479039-2858-48f3-b926-fe6b1c3731e2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * np.random.rand()  # Change: Added stochastic factor for step size increase\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with stochastic step feedback for improved exploration and convergence.", "configspace": "", "generation": 31, "fitness": 0.23532371123498666, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.014. And the mean value of best solutions found was 0.232 (0. is the best) with standard deviation 0.079.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24501586737454562, 0.21525004378189505, 0.24570522254851934], "final_y": [0.17760695224238066, 0.34298750641771447, 0.17478844938407845]}, "mutation_prompt": null}
{"id": "df174657-7194-4ab1-93fe-a2589f48cc18", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.population = 10  # New: Initialize population size\n        self.archive = []  # New: Introduce archive to store diverse solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        solutions = np.random.uniform(lb, ub, (self.population, self.dim))  # New: Multiple initial solutions\n        values = np.array([func(sol) for sol in solutions])  # Evaluate all initial solutions\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - self.population):\n            # New: Select best solution from population for differential vector calculation\n            best_idx = np.argmin(values)\n            best_solution = solutions[best_idx]\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_idx = np.random.choice(self.population)\n            candidate_solution = best_solution + diff_vector + self.success_rate * (solutions[rand_idx] - best_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            # New: Dynamic crowding distance to maintain diversity\n            if candidate_value < max(values):\n                max_idx = np.argmax(values)\n                values[max_idx] = candidate_value\n                solutions[max_idx] = candidate_solution\n            else:\n                self.archive.append(candidate_solution)  # Store in archive if not adopted\n                \n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved ADS using dynamic crowding distance for adaptive exploration-exploitation balance and enhanced diversity.", "configspace": "", "generation": 32, "fitness": 0.24762461919671563, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24792497818750414, 0.24754004163815657, 0.2474088377644862], "final_y": [0.16581427216251066, 0.16594815533579477, 0.1664040211199007]}, "mutation_prompt": null}
{"id": "d4e0d11d-4323-44da-9741-42b0d2f0aecc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) \n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + 0.8 * self.success_rate * (rand_solution - current_solution)  # Change: Increased emphasis on successful direction\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.3  # Change: Increased step size multiplier on success\n                self.success_rate = min(1.0, self.success_rate + 0.1)  # Change: Faster increase in success rate\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  \n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Refined ADS with stochastic step adaptation and directional emphasis on previous success to improve convergence.  ", "configspace": "", "generation": 33, "fitness": 0.240757835834205, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.011. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.22581935348862858, 0.2481798801347238, 0.2482742738792626], "final_y": [0.27039543648175013, 0.16529156416347657, 0.16514474964626502]}, "mutation_prompt": null}
{"id": "732d7543-4af0-4b62-af95-e0d4c5f4e74f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            if np.random.rand() < 0.05:  # Change: Added strategic randomization to improve exploration\n                current_solution = np.random.uniform(lb, ub, self.dim)\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback, dynamic step scaling based on performance trends, and strategic randomization to improve exploration.", "configspace": "", "generation": 34, "fitness": 0.23305501653358537, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.012. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.060.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.2465443469005303, 0.2169470012839836, 0.23567370141624222], "final_y": [0.17165741288514824, 0.3165078343584473, 0.2183480963755966]}, "mutation_prompt": null}
{"id": "86091180-a368-4227-90e1-730304a718a0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            chaotic_factor = np.random.standard_normal(self.dim) * 0.1  # Change: Added chaotic perturbation\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) + chaotic_factor\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback and dynamic step scaling, introducing an additional element of chaotic perturbation.", "configspace": "", "generation": 35, "fitness": 0.24827427815895683, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24838047048816958, 0.24818196451308827, 0.24826039947561263], "final_y": [0.1648559096567851, 0.16485600053761218, 0.16485594546116122]}, "mutation_prompt": null}
{"id": "bd676a00-447d-4843-a5eb-367a3dfb4548", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.success_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n                self.success_history.append(1)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n                self.success_history.append(0)\n\n            self.success_rate = 0.5 * np.mean(self.success_history[-10:]) + 0.5 * self.success_rate\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved adaptive differential search using a dynamic success rate decay and step scaling based on a weighted average of historical success rates.", "configspace": "", "generation": 36, "fitness": 0.24093622512128265, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.010. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.22649012547867386, 0.24808602636002786, 0.24823252352514624], "final_y": [0.26648957233572457, 0.1654440750395153, 0.16518340914749075]}, "mutation_prompt": null}
{"id": "d1425d7a-599b-4a1e-8732-da0a8970f912", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            noise = np.random.normal(0, step_size / 5, self.dim)  # Change 1: Added noise component\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) + noise\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change 2: Modified randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with dynamic exploration by integrating noise-induced diversity and adaptive scaling.", "configspace": "", "generation": 37, "fitness": 0.24824895662110183, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.2482266315084849, 0.2482530317851377, 0.24826720656968293], "final_y": [0.1648557719047039, 0.1648557719047017, 0.1648557719047017]}, "mutation_prompt": null}
{"id": "0bcdf13b-07a4-4a07-a766-3d13cd52fd5c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling for success\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Refined ADS with adaptive success feedback and dynamic step scaling, incorporating feedback-driven randomization for improved exploration.", "configspace": "", "generation": 38, "fitness": 0.24626221694647543, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24828653469698647, 0.2421715125364814, 0.24832860360595843], "final_y": [0.16485577190470024, 0.18813064471368535, 0.16485577190470002]}, "mutation_prompt": null}
{"id": "070251b2-f3dc-4e4d-8706-4e0ba9bf4939", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size * np.random.rand(), step_size * np.random.rand(), self.dim)  # Change 1\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with randomized differential vectors and adaptive exploration-exploitation balance for improved convergence.", "configspace": "", "generation": 39, "fitness": 0.24824898469413725, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24828476095169094, 0.2482153178919667, 0.2482468752387541], "final_y": [0.1648557719047412, 0.16485577190474632, 0.16485577190475909]}, "mutation_prompt": null}
{"id": "4f2d4076-382f-41b4-936d-90bc1d421e7e", "solution": "# Description: Introduced adaptive mutation based on solution diversity to balance exploration and exploitation, improving convergence.\n# Code:\nimport numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.solution_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        self.solution_history.append(current_solution)\n\n        for _ in range(self.budget - 1):\n            diversity_factor = np.std(self.solution_history, axis=0).mean()  # Change\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) * diversity_factor  # Change\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            self.solution_history.append(candidate_solution)  # Change\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive mutation based on solution diversity to balance exploration and exploitation, improving convergence.", "configspace": "", "generation": 40, "fitness": 0.22724035102122264, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.019. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.134.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.2382900802398249, 0.24318086454932353, 0.2002501082745195], "final_y": [0.20412649669377125, 0.18210578106569775, 0.4771836464904835]}, "mutation_prompt": null}
{"id": "6e5a0c72-013f-443c-b1e4-1f8e7c3b1241", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.15  # Change: Adjusted step size increase factor for noise reduction\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.05 * np.random.rand()  # Change: Reduced randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Refined ADS with dynamic step scaling incorporating noise reduction for improved convergence.", "configspace": "", "generation": 41, "fitness": 0.2482059282643403, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24824344219079308, 0.248266621534731, 0.2481077210674968], "final_y": [0.16522007398624217, 0.16512233041341196, 0.16536210806477414]}, "mutation_prompt": null}
{"id": "ab2942d1-b28a-4480-a4c8-88d9a487e9df", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.diversification_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            # Create diversified exploration through adaptive radius\n            dynamic_radius = step_size * (0.5 + self.diversification_factor * np.random.rand())\n            diff_vector = np.random.uniform(-dynamic_radius, dynamic_radius, self.dim) * (0.5 + 0.5 * np.random.rand())\n            candidate_solution = current_solution + diff_vector + self.success_rate * (\n                np.random.uniform(lb, ub, self.dim) - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  # Adjusted variance in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n                \n            # Introduce a diversification strategy in step scaling\n            self.diversification_factor = (\n                self.diversification_factor * 0.9 + (1.0 - self.success_rate) * 0.1\n            )\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "EnhancedAdaptiveDifferentialSearch", "description": "Introduce diversified exploration with dynamic neighborhood radius and adaptive differential variations for fine-tuned convergence.  ", "configspace": "", "generation": 42, "fitness": 0.24115730891669407, "feedback": "The algorithm EnhancedAdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.010. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24819996621460028, 0.22696707551359563, 0.2483048850218863], "final_y": [0.16526480947774957, 0.26414058650173655, 0.16502845949528333]}, "mutation_prompt": null}
{"id": "4d97b6bf-5ec5-44e2-9790-0ad2a2cba1c5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * self.success_rate  # Change: Enhanced adaptation with success feedback\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive mutation strategy using historical success feedback to improve exploration.", "configspace": "", "generation": 43, "fitness": 0.24821790040346925, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.2482823504963303, 0.24822371875558635, 0.2481476319584911], "final_y": [0.16506780767815732, 0.16517307154471284, 0.16530366364920046]}, "mutation_prompt": null}
{"id": "e2b4e22a-7e4d-40bc-b44c-9c05f609f835", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand() / self.dim  # Change: Adapted step scaling based on dimension\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced ADS with adaptive success feedback and adaptive dimension-based step scaling for improved convergence.", "configspace": "", "generation": 44, "fitness": 0.24823144625289342, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24817877626333773, 0.24828009351921143, 0.24823546897613114], "final_y": [0.16536025562823709, 0.16506802810551913, 0.1650238866723548]}, "mutation_prompt": null}
{"id": "5779764c-4496-4120-8cf1-605d4e1deb61", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        momentum = 0.1  # Add a momentum factor\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + momentum * diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9 + 0.1 * np.random.rand()  # Change: Added randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduce a momentum factor to enhance exploration by adjusting the differential vector impact.", "configspace": "", "generation": 45, "fitness": 0.24671637354784062, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24829036792717485, 0.24351165561774513, 0.24834709709860192], "final_y": [0.1648557719047009, 0.1819733419494367, 0.16485577190470246]}, "mutation_prompt": null}
{"id": "e4632c69-faa9-4249-a42a-424a513fea82", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()  # Change: Enhanced randomness in step scaling\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Slight enhancement of randomness in step scaling for adaptability.", "configspace": "", "generation": 46, "fitness": 0.24832301972544735, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bcd23446-1736-445b-a727-6759cc282028", "metadata": {"aucs": [0.24836385084462764, 0.2483005362556311, 0.2483046720760833], "final_y": [0.16485577190493295, 0.16485577190478917, 0.16485577190471912]}, "mutation_prompt": null}
{"id": "c6546c47-62bc-4b5a-bbd9-6d6955a5c61b", "solution": "import numpy as np\n\nclass MomentumAdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.momentum = np.zeros(dim)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim)\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            \n            # Incorporate momentum\n            candidate_solution = current_solution + diff_vector + self.momentum + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                self.momentum = 0.9 * self.momentum + 0.1 * (candidate_solution - current_solution)  # Update momentum\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                self.momentum *= 0.9  # Decay momentum\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "MomentumAdaptiveDifferentialSearch", "description": "Introduce a momentum-based exploration mechanism to leverage historical success for enhanced adaptability.", "configspace": "", "generation": 47, "fitness": 0.2482856048450851, "feedback": "The algorithm MomentumAdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4632c69-faa9-4249-a42a-424a513fea82", "metadata": {"aucs": [0.2482871552735122, 0.24825759049946994, 0.24831206876227319], "final_y": [0.16485577190471912, 0.1648557719047088, 0.16485577190471246]}, "mutation_prompt": null}
{"id": "06a3dba6-997f-4d73-a44d-607e761d5ed7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        momentum = np.zeros(self.dim)  # Initial momentum\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) + 0.1 * momentum  # Added momentum\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                momentum = candidate_solution - current_solution  # Update momentum\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introducing momentum-like behavior in adaptation to enhance convergence speed.", "configspace": "", "generation": 48, "fitness": 0.2369191223736754, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.013. And the mean value of best solutions found was 0.221 (0. is the best) with standard deviation 0.066.", "error": "", "parent_id": "e4632c69-faa9-4249-a42a-424a513fea82", "metadata": {"aucs": [0.24829820169755135, 0.24300434234760282, 0.21945482307587205], "final_y": [0.164855771904728, 0.18471769403680094, 0.3129675804678701]}, "mutation_prompt": null}
{"id": "bfa7fd2e-1b18-4e34-a246-5e376972c878", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * (0.5 + 0.5 * np.random.rand())\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution) * (0.8 + 0.4 * np.random.rand())  # Change: Enhanced exploration via perturbation\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.3  # Change: Slightly increased step size adaptation\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.8 + 0.15 * np.random.rand()  # Original randomness retained but with a slightly decreased factor\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved step size adaptation and enhanced exploration via perturbation.", "configspace": "", "generation": 49, "fitness": 0.24369877181712943, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.003. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "e4632c69-faa9-4249-a42a-424a513fea82", "metadata": {"aucs": [0.24268891647130886, 0.24027183294977872, 0.24813556603030074], "final_y": [0.1858506660559881, 0.19477956327329782, 0.16523746538535522]}, "mutation_prompt": null}
{"id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9)  # Change: Introduced dynamic mutation factor\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a dynamic mutation factor to improve exploration and convergence balance.", "configspace": "", "generation": 50, "fitness": 0.24834072828051376, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4632c69-faa9-4249-a42a-424a513fea82", "metadata": {"aucs": [0.2483464102516254, 0.2483165865094914, 0.24835918808042445], "final_y": [0.1648557719047098, 0.16485577190481893, 0.16485577190509004]}, "mutation_prompt": null}
{"id": "9f363914-2dc2-48e4-a482-b667bd9afb77", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.3, 0.9)  # Change: Adjusted mutation factor range for improved exploration\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced the exploration capability by adjusting the mutation factor range to better balance exploration and exploitation.", "configspace": "", "generation": 51, "fitness": 0.24833550080547193, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2483538919465641, 0.2482995338284486, 0.24835307664140305], "final_y": [0.16485577190492995, 0.16485577190493994, 0.16485577190472378]}, "mutation_prompt": null}
{"id": "84ddaa8b-336f-4fd2-bd83-52d52780f902", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.3, 0.9)  # Change: Enhanced mutation factor range\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced mutation factor range to improve exploration capabilities.", "configspace": "", "generation": 52, "fitness": 0.24833550080547193, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2483538919465641, 0.2482995338284486, 0.24835307664140305], "final_y": [0.16485577190492995, 0.16485577190493994, 0.16485577190472378]}, "mutation_prompt": null}
{"id": "7d40d2bd-ebd9-4837-bb72-8e804ecb794c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.95)  # Change: Adjusted upper bound of mutation factor\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by adjusting the mutation factor's upper bound.", "configspace": "", "generation": 53, "fitness": 0.24833930880221378, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24834762519033926, 0.24832088648565553, 0.24834941473064653], "final_y": [0.1648557719047289, 0.16485577190471523, 0.16485577190484513]}, "mutation_prompt": null}
{"id": "894eaccc-441d-4438-ba40-82e4921897f8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.5, 0.9)  # Change: Adjusted mutation factor range\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.25  # Change: Slightly increased step size scaling\n                self.success_rate = min(1.0, self.success_rate + 0.07)  # Change: Adjusted success rate increment\n            else:\n                step_size *= 0.8 + 0.15 * np.random.rand()  # Change: Modified step size reduction\n                self.success_rate = max(0.0, self.success_rate - 0.03)  # Change: Adjusted success rate decrement\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploitation using adaptive step size scaling and variable mutation factor adjustments.", "configspace": "", "generation": 54, "fitness": 0.2479749670903143, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24809247001922108, 0.24809346928744214, 0.2477389619642797], "final_y": [0.16566141999390016, 0.16561567475787353, 0.16689987066370404]}, "mutation_prompt": null}
{"id": "c4254da1-0303-47e2-8a0e-36ca5dd67b59", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.previous_best_values = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.3, 0.8)  # Modified range for dynamic mutation factor\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n                self.previous_best_values.append(current_value)  # Store best values history\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            if len(self.previous_best_values) > 5:  # Use recent history to adjust strategy\n                if np.mean(self.previous_best_values[-5:]) > self.best_value:\n                    mutation_factor = np.random.uniform(0.5, 1.0)  # Increase exploration\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by incorporating a memory-based strategy and adaptive random scaling.", "configspace": "", "generation": 55, "fitness": 0.24833038236255825, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24835079877196908, 0.2483018158379171, 0.2483385324777886], "final_y": [0.16485577190475986, 0.16485577190477396, 0.16485577190492529]}, "mutation_prompt": null}
{"id": "5e301e1b-e0a4-4b22-9fc0-91e77c4ad6cc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.convergence_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.1 + 0.1 * np.random.rand()  # Change: Adaptive step size increase\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  # Change: Adaptive step size decrease\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n            self.convergence_history.append(current_value)  # Change: Track convergence history\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by introducing adaptive step size scaling based on convergence history.", "configspace": "", "generation": 56, "fitness": 0.24811118865218765, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24810931489778332, 0.24812959056513217, 0.24809466049364748], "final_y": [0.1657006584791425, 0.16548373941701355, 0.16570847466072403]}, "mutation_prompt": null}
{"id": "3227b669-41cc-499e-8c03-0ed529fdad7e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = 0.5 + 0.4 * self.success_rate  # Change: Used success rate to adjust mutation factor\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            if self.history:  # Change: Leverage successful history solutions\n                rand_solution = np.random.choice(self.history)\n            else:\n                rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                self.history.append(candidate_solution)\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced mutation strategy by utilizing historical knowledge of successful solutions to improve exploration.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {}, "mutation_prompt": null}
{"id": "d67a6a0e-a80f-462d-b965-43f3e5158793", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.3, 0.9)  # Change: Adjusted mutation factor range\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by adjusting mutation factor range to encourage more diverse candidate solutions.", "configspace": "", "generation": 58, "fitness": 0.24833550080547193, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2483538919465641, 0.2482995338284486, 0.24835307664140305], "final_y": [0.16485577190492995, 0.16485577190493994, 0.16485577190472378]}, "mutation_prompt": null}
{"id": "9a5ddbf7-9a40-4a83-8874-32e956b23df8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9)  # Change: Introduced dynamic mutation factor\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            adaptive_pressure = self.success_rate * np.random.rand()  # Change\n            candidate_solution = current_solution + diff_vector + adaptive_pressure * (rand_solution - current_solution)  # Change\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive selection pressure by varying the influence of random solutions based on success rate.", "configspace": "", "generation": 59, "fitness": 0.2374912150019135, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.009. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.041.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.23820333863719545, 0.2260463390891918, 0.24822396727935325], "final_y": [0.20421231757278713, 0.26498960954775064, 0.1648557719047571]}, "mutation_prompt": null}
{"id": "92b6199d-ee23-404d-9dbf-d0d4ed3065b6", "solution": "import numpy as np\n\nclass CooperativeParticleDynamics:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.particle_count = 5\n        self.speeds = np.zeros((self.particle_count, self.dim))\n        self.positions = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.particle_count, self.dim))\n        values = np.array([func(pos) for pos in self.positions])\n        \n        best_local_positions = np.copy(self.positions)\n        best_local_values = np.copy(values)\n        \n        global_best_position = self.positions[np.argmin(values)]\n        global_best_value = np.min(values)\n\n        for _ in range(self.budget - self.particle_count):\n            for i in range(self.particle_count):\n                inertia = 0.5 + np.random.rand() / 2\n                cognitive_term = np.random.rand(self.dim) * (best_local_positions[i] - self.positions[i])\n                social_term = np.random.rand(self.dim) * (global_best_position - self.positions[i])\n                \n                self.speeds[i] = inertia * self.speeds[i] + cognitive_term + social_term\n                self.positions[i] += self.speeds[i]\n                self.positions[i] = np.clip(self.positions[i], lb, ub)\n                \n                current_value = func(self.positions[i])\n                \n                if current_value < best_local_values[i]:\n                    best_local_positions[i] = self.positions[i]\n                    best_local_values[i] = current_value\n                \n                if current_value < global_best_value:\n                    global_best_position = self.positions[i]\n                    global_best_value = current_value\n        \n        self.best_solution = global_best_position\n        self.best_value = global_best_value\n\n        return self.best_solution, self.best_value", "name": "CooperativeParticleDynamics", "description": "This algorithm introduces a dynamic balance between exploration and exploitation by employing cooperative particle dynamics to adaptively adjust search directions.", "configspace": "", "generation": 60, "fitness": 0.2385982518409838, "feedback": "The algorithm CooperativeParticleDynamics got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.008. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24038135992972298, 0.24770904919169667, 0.2277043464015317], "final_y": [0.19222037937417336, 0.16507593737010207, 0.2578152324153522]}, "mutation_prompt": null}
{"id": "3f94c73b-4f63-498a-9c94-728fce2bb6b3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        def levy_flight(Lambda):\n            sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                     (np.math.gamma((1 + Lambda) / 2) * Lambda * 2**((Lambda - 1) / 2)))**(1 / Lambda)\n            u = np.random.normal(0, sigma, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            return u / np.abs(v)**(1 / Lambda)\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9)\n            # Change: Introduced Lévy flight\n            diff_vector = levy_flight(1.5) * step_size\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by incorporating a Lévy flight mechanism for better global search capabilities.", "configspace": "", "generation": 61, "fitness": 0.24506627377891502, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.002. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24356525640096427, 0.24334552651321284, 0.24828803842256797], "final_y": [0.18270576184240395, 0.1836408705501803, 0.16485577190479095]}, "mutation_prompt": null}
{"id": "73dcf7e3-f0ca-4268-b56f-cce786193481", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= np.random.uniform(1.1, 1.3)  # Change: Adaptive scaling\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive step size scaling based on convergence to enhance exploitation.", "configspace": "", "generation": 62, "fitness": 0.248320169600406, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.24833236444525109, 0.24828925644497668, 0.24833888791099024], "final_y": [0.1648557719047794, 0.16485577190481393, 0.16485577190488043]}, "mutation_prompt": null}
{"id": "c6f506bf-3e41-466e-b0a5-5abe4fd84d97", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            if np.random.rand() < 0.05:  # Change: Random restart mechanism\n                current_solution = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_solution)\n\n            mutation_factor = np.random.uniform(0.4, 0.9)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9  # Change: adaptive step size adjustment\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive step size and a random restart mechanism to escape local optima and enhance global exploration.", "configspace": "", "generation": 63, "fitness": 0.24586561207188154, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.001. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2466942035386468, 0.24384902686250054, 0.2470536058144973], "final_y": [0.168584619666459, 0.17003221240615685, 0.16792936269304648]}, "mutation_prompt": null}
{"id": "be89e247-8d19-497c-a6f8-b653e6e7d8f4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        learning_rate = 0.1\n\n        for _ in range(self.budget - 1):\n            mutation_factor = 0.4 + 0.5 * np.random.rand() * self.success_rate  # Change: Learning-based mutation factor\n            diff_vector = np.random.randn(self.dim) * mutation_factor * step_size  # Change: Gaussian distributed diff_vector\n            candidate_solution = current_solution + diff_vector\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1 + learning_rate  # Change: Learning rate affects step size increment\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.9  # Change: More conservative decrease in step size\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a variable adaptive search radius and learning-based mutation factor to enhance global exploration and local exploitation.", "configspace": "", "generation": 64, "fitness": 0.22626757299068337, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.011. And the mean value of best solutions found was 0.276 (0. is the best) with standard deviation 0.069.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.23002955221142052, 0.2116620981123073, 0.23711106864832232], "final_y": [0.2466770996625438, 0.371412477384063, 0.21069461447453475]}, "mutation_prompt": null}
{"id": "8b54ac1e-f840-417b-a252-3931f6963653", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n        self.population_size = 5  # New: Introduced population size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = [np.random.uniform(lb, ub, self.dim) for _ in range(self.population_size)]  # New: Use population\n\n        for i in range(self.budget - 1):\n            step_size = (ub - lb) / 10\n            new_population = []\n            for current_solution in population:\n                mutation_factor = np.random.uniform(0.4, 0.9)\n                diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n                rand_solution = np.random.uniform(lb, ub, self.dim)\n                candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_value = func(candidate_solution)\n\n                if candidate_value < func(current_solution):\n                    new_population.append(candidate_solution)\n                else:\n                    new_population.append(current_solution)\n\n            new_population.sort(key=func)  # New: Sort based on function value\n            population = new_population[:self.population_size]  # New: Keep best solutions\n\n            if func(population[0]) < self.best_value:\n                self.best_solution = population[0]\n                self.best_value = func(population[0])\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive population size with elitism to enhance exploration and exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.2400066820839035, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.001. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.23966729567997935, 0.23851723018030424, 0.24183552039142686], "final_y": [0.19374775230349572, 0.19402315734998288, 0.17131848159316998]}, "mutation_prompt": null}
{"id": "483a794d-4701-4ba4-90fe-5587818f9e87", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.5, 0.7)  # Change: Refined the mutation factor range\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Refined mutation factor range to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 66, "fitness": 0.24832247718758405, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2482816039873471, 0.24833413196990206, 0.24835169560550296], "final_y": [0.16485577190512413, 0.16485577190473577, 0.1648557719048559]}, "mutation_prompt": null}
{"id": "43197143-53b8-40a3-b9b1-3a235c90b8dc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n        recent_improvement = 0  # New variable to track improvements\n\n        for _ in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9 + 0.1 * recent_improvement)  # Change: Enhanced mutation factor adaptation\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n                recent_improvement = 1  # Increase improvement flag\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n                recent_improvement = max(0, recent_improvement - 0.1)  # Decrease improvement flag\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced the mutation factor adaptation by introducing a feedback mechanism based on recent improvements in solution quality.", "configspace": "", "generation": 67, "fitness": 0.24832822255329903, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2483577362910141, 0.24827871333314921, 0.24834821803573381], "final_y": [0.16485577190481004, 0.16485577190475753, 0.16485577190697887]}, "mutation_prompt": null}
{"id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor to adapt based on iteration count\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration-exploitation balance by adaptive mutation scaling based on iteration count.", "configspace": "", "generation": 68, "fitness": 0.24834127379017248, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5bda26e-c982-4c92-b4ae-a75bc22c04c6", "metadata": {"aucs": [0.2483499174241286, 0.24831486751466114, 0.24835903643172774], "final_y": [0.16485577190472422, 0.16485577190473255, 0.16485577190477407]}, "mutation_prompt": null}
{"id": "cd6c0308-c4f2-4bca-86bb-a2cd23fe49de", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05 * candidate_value / current_value)  # Modified line\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration-exploitation by introducing dynamic scaling of success rate based on historical performance.", "configspace": "", "generation": 69, "fitness": 0.24834127379017248, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.2483499174241286, 0.24831486751466114, 0.24835903643172774], "final_y": [0.16485577190472422, 0.16485577190473255, 0.16485577190477407]}, "mutation_prompt": null}
{"id": "b15e0db0-6a77-410d-8278-d74ec43d0329", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.07)  # Change 1\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.03)  # Change 2\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved convergence rate by dynamically adjusting the success rate based on continuous improvement.", "configspace": "", "generation": 70, "fitness": 0.24818492464043707, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24815243573215606, 0.2481274284315207, 0.24827490975763444], "final_y": [0.16502982258730547, 0.16519489859160064, 0.1649338092281315]}, "mutation_prompt": null}
{"id": "19d686aa-a2e3-4c36-92d9-dfb99e9f52e3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.5, 1.0) * (1 - iter_count / self.budget)  # Change 1\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.3  # Change 2\n                self.success_rate = min(1.0, self.success_rate + 0.06)  # Change 3\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  # Change 4\n                self.success_rate = max(0.0, self.success_rate - 0.04)  # Change 5\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved adaptation with dynamic step size adjustment and success-driven exploration.", "configspace": "", "generation": 71, "fitness": 0.2482707542394779, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24822945705333432, 0.2482781754414718, 0.2483046302236276], "final_y": [0.16505038442135744, 0.16505447422880926, 0.16494318889400472]}, "mutation_prompt": null}
{"id": "de522628-fce7-435d-b4ae-61e2bb5f41ff", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor and success-driven adaptation\n            mutation_factor = np.random.uniform(0.5, 1.0) * ((1 - iter_count / self.budget) + self.success_rate * 0.5)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.1)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Adaptive exploration with dynamic mutation scaling leveraging success history for improved convergence.", "configspace": "", "generation": 72, "fitness": 0.24811004709651585, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24802830974580903, 0.2481217048716613, 0.24818012667207723], "final_y": [0.16570982662172373, 0.16543409231223605, 0.1652736751136078]}, "mutation_prompt": null}
{"id": "95ba3512-0f01-4b2c-a1e1-5c8f9d6c6045", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor to adapt based on iteration count\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.1)  # Change: Adjusted success rate increment\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.1)  # Change: Adjusted success rate decrement\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced dynamic success rate adjustment and mutation factor reduction for enhanced adaptability.", "configspace": "", "generation": 73, "fitness": 0.24642156646890304, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24273478186782582, 0.24822441130214556, 0.24830550623673775], "final_y": [0.18640218198820202, 0.16485577190494072, 0.164855771904727]}, "mutation_prompt": null}
{"id": "b86de62b-6254-4309-a875-5ae42abc937f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor to adapt based on iteration count\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = 0.9 * self.success_rate + 0.1  # Change line 1\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate *= 0.9  # Change line 2\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduce a dynamic success rate based on a weighted history of successful vs. failed iterations to improve convergence.", "configspace": "", "generation": 74, "fitness": 0.24830416103934005, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.2483163458778035, 0.24826165993791371, 0.24833447730230296], "final_y": [0.1648557719351159, 0.16485577195484502, 0.1648557722063193]}, "mutation_prompt": null}
{"id": "559004b1-d2a3-4db1-8b2c-ec21e51573d4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.1 * (current_value - candidate_value) / current_value)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced selection strategy by incorporating dynamic success rate adjustment based on candidate improvement.", "configspace": "", "generation": 75, "fitness": 0.24644318887826008, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24272045150332466, 0.2482663745385898, 0.24834274059286576], "final_y": [0.1854562098650281, 0.16485577190471157, 0.16485577190470335]}, "mutation_prompt": null}
{"id": "96a1119c-a41b-4068-82ce-d25c34f2ac16", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor to adapt based on iteration count\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 + 0.1 * (self.success_rate - 0.5)  # Adjusted step size adaptation\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduce a dynamic step size adaptation based on success rate to enhance convergence speed.", "configspace": "", "generation": 76, "fitness": 0.24822453621170712, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24820601760874272, 0.2481869457931376, 0.248280645233241], "final_y": [0.16533047550656976, 0.16523188285049373, 0.1650748238462818]}, "mutation_prompt": null}
{"id": "3c4cc95a-2141-40ed-a170-3d5f9ea0e37f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Modified mutation factor and added inertia weight based on iteration count\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved adaptive strategy by incorporating a dynamic inertia weight to further enhance exploration-exploitation balance.", "configspace": "", "generation": 77, "fitness": 0.2483414155416859, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0be578bc-0267-4bb4-b457-9d3d2dea98d5", "metadata": {"aucs": [0.24834823773237957, 0.24832419409964623, 0.24835181479303192], "final_y": [0.1648557719048246, 0.1648557719048498, 0.16485577190483525]}, "mutation_prompt": null}
{"id": "8d8c27b0-6504-46d5-97b0-8e59e2655296", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            crossover_prob = 0.5 + 0.5 * np.random.rand() * (1 - iter_count / self.budget)  # New line\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = np.where(np.random.rand(self.dim) < crossover_prob,  # Modified line\n                                          current_solution + diff_vector + self.success_rate * (rand_solution - current_solution),\n                                          current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced adaptive strategy by introducing a dynamic crossover probability to boost solution diversity.", "configspace": "", "generation": 78, "fitness": 0.24676758819754605, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3c4cc95a-2141-40ed-a170-3d5f9ea0e37f", "metadata": {"aucs": [0.2436107659075727, 0.24838976976945648, 0.24830222891560894], "final_y": [0.18218013477516082, 0.1648557719047552, 0.16485577190472356]}, "mutation_prompt": null}
{"id": "8499e79d-68b2-4680-8adb-e0bc96a9c4ef", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Introduced adaptive learning rate for mutation factor\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget) * (0.5 + np.random.rand() / 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value or np.random.rand() < 0.1:  # Stochastic selection\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced adaptive strategy by incorporating adaptive learning rate for mutation factor and stochastic selection to improve solution diversity.", "configspace": "", "generation": 79, "fitness": 0.24598095286236407, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3c4cc95a-2141-40ed-a170-3d5f9ea0e37f", "metadata": {"aucs": [0.24793606468979523, 0.24190626571775187, 0.2481005281795451], "final_y": [0.16512549929429265, 0.1677706432996302, 0.16551986079208092]}, "mutation_prompt": null}
{"id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Introduced non-linear scaling factor for mutation_factor to enhance performance\n            mutation_factor = np.random.uniform(0.4, 0.9) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a non-linear scaling factor to mutation_factor to enhance convergence speed and solution diversity.", "configspace": "", "generation": 80, "fitness": 0.24834673086881842, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3c4cc95a-2141-40ed-a170-3d5f9ea0e37f", "metadata": {"aucs": [0.24836047331166666, 0.24832404773347627, 0.24835567156131233], "final_y": [0.16485577190474066, 0.16485577190480638, 0.1648557719047693]}, "mutation_prompt": null}
{"id": "f9ba757f-e7d0-402f-b699-e58e7f5ed102", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Introduced adaptive inertia weight decaying towards the end\n            mutation_factor = np.random.uniform(0.4, 0.9) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * ((iter_count / self.budget) ** 2)  # Modified line\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive inertia weight decaying towards the end to balance exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.24833995495215808, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.24834386037741685, 0.24832467247152312, 0.24835133200753423], "final_y": [0.16485577190473844, 0.16485577190486178, 0.16485577190475909]}, "mutation_prompt": null}
{"id": "19670374-a53d-429e-9d5e-2e5d7b629a6b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's range to improve exploration-exploitation balance\n            mutation_factor = np.random.uniform(0.3, 0.9) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced balance of exploration and exploitation by adjusting the mutation_factor's range.", "configspace": "", "generation": 82, "fitness": 0.2483164737717115, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.24827448806217767, 0.24832864072635674, 0.24834629252660012], "final_y": [0.16485577190473166, 0.16485577190480982, 0.16485577190477596]}, "mutation_prompt": null}
{"id": "dc6961e0-5a84-463f-a6e7-555dac9063a6", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Introduced a random walk component to the mutation factor for enhanced exploration\n            mutation_factor = np.random.uniform(0.4, 0.9) * ((1 - iter_count / self.budget) ** 2 + np.random.uniform(-0.1, 0.1))\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by integrating a random walk component to the mutation factor.", "configspace": "", "generation": 83, "fitness": 0.24142267785826058, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.010. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.24832726992258647, 0.22763602482053236, 0.24830473883166293], "final_y": [0.1648557719051883, 0.26036496975980505, 0.164855771905292]}, "mutation_prompt": null}
{"id": "df290f8b-8df0-4841-b0e4-3b865c1e2886", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.9) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                improvement_intensity = (current_value - candidate_value) / abs(current_value)  # Change 1\n                self.success_rate = min(1.0, self.success_rate + 0.05 + improvement_intensity * 0.1)  # Change 2\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05 * np.random.rand() * 0.5)  # Change 3\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Incorporated dynamic success_rate adjustment based on improvement intensity to enhance exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.24820020109080232, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.248171817288103, 0.2481802792736434, 0.24824850671066057], "final_y": [0.16518776788190415, 0.16495885678188138, 0.16519269641580636]}, "mutation_prompt": null}
{"id": "4a2fddd7-2d35-4523-b5d7-001affcdcbff", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Introduced linear decay to mutation_factor to enhance exploration\n            mutation_factor = np.random.uniform(0.4, 0.9) * (1 - iter_count / self.budget) \n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved mutation strategy by introducing linear decay to the mutation factor, enhancing exploration in the search space.", "configspace": "", "generation": 85, "fitness": 0.2483414155416859, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.24834823773237957, 0.24832419409964623, 0.24835181479303192], "final_y": [0.1648557719048246, 0.1648557719048498, 0.16485577190483525]}, "mutation_prompt": null}
{"id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound dynamically to improve performance\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Added a dynamic adjustment to the mutation factor's upper bound to improve exploration and exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.2483481396424488, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "24da1d2d-96cb-48c3-b127-f51de6f61128", "metadata": {"aucs": [0.24836071099931323, 0.24832839456000577, 0.2483553133680274], "final_y": [0.16485577190478162, 0.1648557719047118, 0.16485577190485956]}, "mutation_prompt": null}
{"id": "170ca8da-bd47-456e-bb09-e0dd71525b0f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted inertia_weight with a sinusoidal component for enhanced exploration.\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget) + 0.1 * np.sin(2 * np.pi * iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Improved adaptive strategy by incorporating dynamic adjustment of inertia weight with a sinusoidal component to enhance exploration capabilities.", "configspace": "", "generation": 87, "fitness": 0.248339938141399, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24834329111178433, 0.2483251381798195, 0.24835138513259325], "final_y": [0.16485577190557277, 0.16485577190478207, 0.16485577190474565]}, "mutation_prompt": null}
{"id": "215b1e5e-5831-4222-b2ca-39a7f20a16c1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound dynamically to improve performance\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * self.success_rate * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced differential mutation factor calculation by incorporating success rate dependency for improved convergence.", "configspace": "", "generation": 88, "fitness": 0.24830758282263662, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2482659764224373, 0.24832519996335545, 0.2483315720821171], "final_y": [0.16485577190475265, 0.16485577190481893, 0.16485577190480805]}, "mutation_prompt": null}
{"id": "e9dec179-2204-496d-8823-cd87b43bf14a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound slightly to improve exploration\n            mutation_factor = np.random.uniform(0.4, 0.65 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by slightly increasing the mutation factor's variability to improve the balance between exploration and exploitation.", "configspace": "", "generation": 89, "fitness": 0.2483273911910113, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24832285680987876, 0.24830848763841928, 0.24835082912473583], "final_y": [0.16485577190476153, 0.164855771904724, 0.16485577190475786]}, "mutation_prompt": null}
{"id": "097380b9-f0eb-4dc1-a092-f415f846edea", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Added feedback mechanism to adjust mutation factor dynamically\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            # Change: Adjusted inertia weight based on recent success rate\n            if self.success_rate > 0.7:\n                inertia_weight *= 0.95\n            else:\n                inertia_weight *= 1.05\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a feedback mechanism to dynamically adjust the exploration-exploitation trade-off based on recent success rates.", "configspace": "", "generation": 90, "fitness": 0.2483481396424488, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24836071099931323, 0.24832839456000577, 0.2483553133680274], "final_y": [0.16485577190478162, 0.1648557719047118, 0.16485577190485956]}, "mutation_prompt": null}
{"id": "5c23a4f9-4bc0-49c9-b9a1-884aa88a57a5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound dynamically to improve performance\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * self.success_rate  # Adjusted line\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced a scaling factor to the step size based on success rate to accelerate convergence when successful.", "configspace": "", "generation": 91, "fitness": 0.227079525846704, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.015. And the mean value of best solutions found was 0.280 (0. is the best) with standard deviation 0.101.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24060959679251936, 0.20596099211509333, 0.23466798863249927], "final_y": [0.19571606118938634, 0.4217108782234852, 0.22343227295363377]}, "mutation_prompt": null}
{"id": "ddd8dcb7-deb4-474b-bbf8-2436ed09a945", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05 * (1 - iter_count / self.budget)) # Change made here\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Added adaptive learning rate for the success rate to balance exploration and exploitation.", "configspace": "", "generation": 92, "fitness": 0.24834671076188894, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2483599016415945, 0.2483245247194552, 0.2483557059246171], "final_y": [0.16485577190471912, 0.16485577190487477, 0.1648557719047703]}, "mutation_prompt": null}
{"id": "c1c7a70e-373e-463d-bd9b-6cdd08af5d5a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * (0.9 + 0.1 * self.success_rate)  # Updated line\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand() * self.success_rate  # Updated line\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive step size scaling based on iteration success rate to enhance convergence precision over time.", "configspace": "", "generation": 93, "fitness": 0.2473771813596902, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2473455725631708, 0.24681882246520725, 0.2479671490506925], "final_y": [0.16831224730863048, 0.1698767360983925, 0.1661565295908526]}, "mutation_prompt": null}
{"id": "cdc59810-a1a9-4ac1-b956-51abf8dab4ca", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor with cosine-based decay for improved convergence\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - np.cos(np.pi * iter_count / self.budget))) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced the dynamic adjustment mechanism for mutation factor by including cosine-based decay to improve convergence speed.", "configspace": "", "generation": 94, "fitness": 0.24660534009658638, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2482725529848998, 0.24325643861878876, 0.24828702868607055], "final_y": [0.16485577190472867, 0.1833240276350272, 0.16485577190485423]}, "mutation_prompt": null}
{"id": "25658b54-ae8d-4d44-87fd-b52e3a427fac", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.1  # Changed from 1.2 to 1.1 for finer adjustment\n                self.success_rate = min(1.0, self.success_rate + 0.03)  # Changed from 0.05 to 0.03\n            else:\n                step_size *= 0.8 + 0.2 * np.random.rand()  # Adjusted to improve convergence\n                self.success_rate = max(0.0, self.success_rate - 0.03)  # Changed from 0.05 to 0.03\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration-exploitation balance by introducing a decay factor on success rate and dynamic step size adjustment.", "configspace": "", "generation": 95, "fitness": 0.242649220213883, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.008. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24818877148278584, 0.23164968551709075, 0.24810920364177236], "final_y": [0.1653331664072729, 0.2366739278786305, 0.16552745753427645]}, "mutation_prompt": null}
{"id": "4353be34-ff28-410a-8940-684d379a4f45", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's lower bound dynamically based on success_rate\n            mutation_factor = np.random.uniform(0.4 - 0.2 * self.success_rate, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration by dynamically adjusting the mutation factor's lower bound based on success rate.", "configspace": "", "generation": 96, "fitness": 0.24831496055115587, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.24826869239114246, 0.2483242805220871, 0.24835190874023805], "final_y": [0.16485577190475886, 0.1648557719049919, 0.16485577190470413]}, "mutation_prompt": null}
{"id": "033f9b2c-4327-43e8-b5b3-12f482bbed41", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound dynamically to improve performance\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.5 * (iter_count / self.budget)\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.1 * np.random.rand()  # Changed this line\n                self.success_rate = max(0.0, self.success_rate - 0.03)  # Changed this line\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Introduced adaptive step size scaling based on success history to enhance convergence speed.", "configspace": "", "generation": 97, "fitness": 0.24823675488795402, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2482244718729928, 0.2482592062249992, 0.24822658656587004], "final_y": [0.16505655282796128, 0.16509981568149468, 0.16517165281760382]}, "mutation_prompt": null}
{"id": "f7c22088-18e2-4e59-9dc0-a4fa9354c549", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            # Change: Adjusted mutation_factor's upper bound dynamically to improve performance\n            mutation_factor = np.random.uniform(0.4, 0.6 + 0.3 * (1 - iter_count / self.budget)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.45 * (iter_count / self.budget)  # Modified decay rate\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Slightly modified inertia weight update to improve convergence by altering its decay rate.", "configspace": "", "generation": 98, "fitness": 0.24834814382463424, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9c314e17-d703-42e6-b3e9-08b0875bd35c", "metadata": {"aucs": [0.2483605679927624, 0.24832837865680868, 0.24835548482433167], "final_y": [0.16485577190476497, 0.16485577190482703, 0.16485577190473355]}, "mutation_prompt": null}
{"id": "ba8050f6-4765-4412-8c73-2fa94b7779c7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = np.inf\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_solution)\n        step_size = (ub - lb) / 10\n\n        for iter_count in range(self.budget - 1):\n            mutation_factor = np.random.uniform(0.4, 0.7 + 0.3 * np.sin(iter_count / self.budget * np.pi)) * ((1 - iter_count / self.budget) ** 2)\n            inertia_weight = 0.9 - 0.45 * (iter_count / self.budget)  # Modified decay rate\n            diff_vector = np.random.uniform(-step_size, step_size, self.dim) * mutation_factor * inertia_weight\n            rand_solution = np.random.uniform(lb, ub, self.dim)\n            candidate_solution = current_solution + diff_vector + self.success_rate * (rand_solution - current_solution)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n\n            if candidate_value < current_value:\n                current_solution = candidate_solution\n                current_value = candidate_value\n                step_size *= 1.2 * np.random.uniform(0.9, 1.1)  # Stochastic step-size adjustment\n                self.success_rate = min(1.0, self.success_rate + 0.05)\n            else:\n                step_size *= 0.85 + 0.15 * np.random.rand()\n                self.success_rate = max(0.0, self.success_rate - 0.05)\n\n            if candidate_value < self.best_value:\n                self.best_solution = candidate_solution\n                self.best_value = candidate_value\n\n        return self.best_solution, self.best_value", "name": "AdaptiveDifferentialSearch", "description": "Enhanced exploration-exploitation balance by introducing adaptive local search and stochastic step-size adjustment.", "configspace": "", "generation": 99, "fitness": 0.23995354643560285, "feedback": "The algorithm AdaptiveDifferentialSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.012. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.058.", "error": "", "parent_id": "f7c22088-18e2-4e59-9dc0-a4fa9354c549", "metadata": {"aucs": [0.24832102462451533, 0.22318898837765266, 0.24835062630464055], "final_y": [0.16485577190480294, 0.2874077538084614, 0.16485577190483358]}, "mutation_prompt": null}
