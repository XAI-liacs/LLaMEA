{"id": "84882b9c-7638-4d33-8019-b72a0bf2a9d5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (np.linspace(lb, ub, self.dim) - lb) / (ub - lb)\n                        mutant = lb + (ub - lb) * (np.round(mutant / period) % 2) * period\n\n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "A hybrid Particle Swarm Optimization (PSO) with Differential Evolution (DE) incorporating a periodicity-based mutation strategy to balance exploration and exploitation for optimizing multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 65, in __call__\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n.", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 65, in __call__\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "An enhanced hybrid PSO-DE using a refined periodicity-based mutation strategy to improve the global exploration and convergence balance for multilayered photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.7290599394662763, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.729 with standard deviation 0.054. And the mean value of best solutions found was 0.220 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "84882b9c-7638-4d33-8019-b72a0bf2a9d5", "metadata": {"aucs": [0.7564020539059947, 0.7764923249733758, 0.6542854395194584], "final_y": [0.19506200816622743, 0.20116020425930192, 0.2628028642106083]}, "mutation_prompt": null}
{"id": "c39ebf9a-c81e-4e8d-96e7-51437abc8b6d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic inertia weight reduction\n            self.w = 0.9 - (0.5 * evaluations / self.budget)\n\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhance the hybrid PSO-DE by introducing a dynamic inertia weight reduction strategy for improved convergence and solution quality.", "configspace": "", "generation": 2, "fitness": 0.661192834793365, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.093. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.6149258079901825, 0.7908323889433031, 0.5778203074466096], "final_y": [0.22042096494617391, 0.1840472969329663, 0.28717022606484865]}, "mutation_prompt": null}
{"id": "b0e8d587-ad9f-478f-95fc-67fa8508157e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                F = 0.4 + 0.5 * np.random.rand()  # Adaptive scaling factor\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Introduce adaptive scaling and crossover rates to the HybridPSODE algorithm to dynamically balance exploration and exploitation during optimization.", "configspace": "", "generation": 3, "fitness": 0.6871320308878607, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.687 with standard deviation 0.067. And the mean value of best solutions found was 0.260 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.6559421291727654, 0.7806090669032903, 0.6248448965875264], "final_y": [0.2842741896738381, 0.19716189904720627, 0.29894146610401107]}, "mutation_prompt": null}
{"id": "991043fd-3421-4a8f-9594-ddb6faa6803b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.9   # Adaptive inertia weight\n        self.F = 0.6   # Adaptive DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Improved Hybrid PSO-DE with adaptive inertia weight and scale factor to enhance convergence and exploration balance.", "configspace": "", "generation": 4, "fitness": 0.5820357200426048, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.582 with standard deviation 0.106. And the mean value of best solutions found was 0.340 (0. is the best) with standard deviation 0.073.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.4528919397715163, 0.713081693172235, 0.5801335271840631], "final_y": [0.4397557486067297, 0.26749484398670065, 0.31392766846803477]}, "mutation_prompt": null}
{"id": "ed312907-192b-484c-89e8-700751b6060e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.9   # Inertia weight (adaptive)\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + (0.9 - 0.4) * (self.budget - evaluations) / self.budget  # Adaptive inertia\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Apply random perturbation\n                        perturbation = np.random.normal(0, 0.01, self.dim) if evaluations < self.budget else 0\n                        mutant += perturbation\n\n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Introduction of adaptive inertia weight and random perturbation to balance exploration and exploitation in HybridPSODE.", "configspace": "", "generation": 5, "fitness": 0.6649924212595119, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.665 with standard deviation 0.105. And the mean value of best solutions found was 0.253 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.6225634628773684, 0.8089582420295057, 0.5634555588716614], "final_y": [0.26246425964647413, 0.18296508400406453, 0.3144081835693666]}, "mutation_prompt": null}
{"id": "06442f4b-6856-4fba-be59-6ddaa6241329", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4    # Final inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.w_final + (self.w_initial - self.w_final) * ((self.budget - evaluations) / self.budget)\n\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "HybridPSODE with adaptive inertia weight strategy for improved convergence and exploration balance in photonic structure optimization.", "configspace": "", "generation": 6, "fitness": 0.661192834793365, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.093. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.6149258079901825, 0.7908323889433031, 0.5778203074466096], "final_y": [0.2204209649461749, 0.1840472969329663, 0.2871702260648459]}, "mutation_prompt": null}
{"id": "86f40cd4-daa5-43c3-8985-86e24e554839", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            diversity = np.std(population, axis=0).mean()  # Calculate population diversity\n            self.w = 0.5 + (0.5 * (1 - diversity))  # Adaptive inertia weight\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    self.F = 0.4 + (0.2 * diversity)  # Dynamic scale factor\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "HybridPSODE is enhanced by incorporating adaptive inertia weights and dynamic scale factors based on population diversity to balance exploration and exploitation more effectively.", "configspace": "", "generation": 7, "fitness": 0.4430991648470825, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.443 with standard deviation 0.032. And the mean value of best solutions found was 0.450 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.41584610300173286, 0.4887423048434897, 0.4247090866960248], "final_y": [0.47239265783783124, 0.41379549904142665, 0.46469205749927356]}, "mutation_prompt": null}
{"id": "d439df9a-e811-4033-9b02-cac5132f883c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.9   # Inertia weight (changed from 0.7)\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhanced hybrid PSO-DE with adaptive inertia weight for improved convergence in complex optimization landscapes.", "configspace": "", "generation": 8, "fitness": 0.5571859511957685, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.557 with standard deviation 0.112. And the mean value of best solutions found was 0.355 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.5002265016828992, 0.713081693172235, 0.4582496587321715], "final_y": [0.3868911368356335, 0.26749484398670065, 0.4095037561890241]}, "mutation_prompt": null}
{"id": "3dabce58-ad3c-4e59-8ef2-aab8840407f6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.9   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhanced hybrid PSO-DE with adaptive inertia weight for improved exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.5571859511957685, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.557 with standard deviation 0.112. And the mean value of best solutions found was 0.355 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.5002265016828992, 0.713081693172235, 0.4582496587321715], "final_y": [0.3868911368356335, 0.26749484398670065, 0.4095037561890241]}, "mutation_prompt": null}
{"id": "3c8af2d5-7755-4600-b1c7-b782f6b9884e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.5   # DE scale factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.c1 = 2.0 - evaluations / self.budget  # Adaptive cognitive coefficient\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)\n                        \n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Added an adaptive cognitive coefficient strategy for better local search based on iterations.", "configspace": "", "generation": 10, "fitness": 0.7198499595794653, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.720 with standard deviation 0.102. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.058.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.7246577812173415, 0.8419599859652005, 0.5929321115558543], "final_y": [0.20403848583373996, 0.18257883951708398, 0.3139497221697175]}, "mutation_prompt": null}
{"id": "59398c69-9468-4be8-b8f7-dce5a0513949", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 2.0)  # Refinement\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Improved balance between exploration and exploitation by adjusting velocity update and mutation strategies for enhanced convergence in multilayered photonic structure optimization.", "configspace": "", "generation": 11, "fitness": 0.7681675935063006, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.049. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "d5d2f76f-9247-42b5-a2fa-608d2e7128d8", "metadata": {"aucs": [0.7061781851504908, 0.8261500776133305, 0.7721745177550805], "final_y": [0.2578191300787135, 0.18237790250229735, 0.22805637588901762]}, "mutation_prompt": null}
{"id": "f69901f4-fa95-4f73-8d59-f4cec4740593", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)  # Modified Line 1\n                if np.random.rand() < adaptive_CR:  # Modified Line 2\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)  # Modified Line 3\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhanced local search through adaptive crossover probability and period adjustment for improved convergence.", "configspace": "", "generation": 12, "fitness": 0.8073441662939166, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.095. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "59398c69-9468-4be8-b8f7-dce5a0513949", "metadata": {"aucs": [0.9025079259439684, 0.6769291973160181, 0.842595375621763], "final_y": [0.1649604615520751, 0.28274671088134895, 0.18188866956142413]}, "mutation_prompt": null}
{"id": "b1cc2eb6-bc74-42b6-9121-299b6b9fd479", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - (0.4 * evaluations / self.budget)  # Dynamic adjustment of inertia weight\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)  # Modified Line 1\n                if np.random.rand() < adaptive_CR:  # Modified Line 2\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)  # Modified Line 3\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Introduce dynamic adjustment of inertia weight based on evaluations to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.6715974424422136, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.672 with standard deviation 0.090. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "f69901f4-fa95-4f73-8d59-f4cec4740593", "metadata": {"aucs": [0.5987548661648108, 0.7978084270097715, 0.6182290341520584], "final_y": [0.20101976513356212, 0.1827138217897416, 0.28292587780883527]}, "mutation_prompt": null}
{"id": "0bafd36f-a0d4-42d7-a71c-70f78d58f9a9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Adaptive inertia weight (Modified Line 1)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.3 * (1 - evaluations / self.budget)  # Adaptive w based on evaluations (Modified Line 2)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = personal_best[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)\n                if np.random.rand() < adaptive_CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Stochastic selection instead of deterministic (Modified Line 3)\n                        if mutant_fitness < fitness[i] and np.random.rand() < 0.5:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Introduced adaptive inertia weight and stochastic selection to enhance exploration-exploitation balance and convergence rate.  ", "configspace": "", "generation": 14, "fitness": 0.7210595331096229, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.721 with standard deviation 0.067. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "f69901f4-fa95-4f73-8d59-f4cec4740593", "metadata": {"aucs": [0.8063291163328123, 0.7153528816569208, 0.6414966013391357], "final_y": [0.16497359702215675, 0.18220385719473542, 0.28274747020223334]}, "mutation_prompt": null}
{"id": "f0e3c6db-7e49-4945-bdb4-70923581ce84", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(fitness)  # Modified Line\n            if fitness[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = population[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)  # Modified Line 1\n                if np.random.rand() < adaptive_CR:  # Modified Line 2\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)  # Modified Line 3\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Improved global best update mechanism to enhance convergence speed.", "configspace": "", "generation": 15, "fitness": 0.8620194853544562, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.031. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f69901f4-fa95-4f73-8d59-f4cec4740593", "metadata": {"aucs": [0.8956062688993633, 0.8214665212509846, 0.8689856659130203], "final_y": [0.16493009504524614, 0.18204756766102648, 0.16492892987857322]}, "mutation_prompt": null}
{"id": "db345f3e-1c21-4ddd-81ed-515bab8b4997", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = population[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)\n                if np.random.rand() < adaptive_CR:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)\n\n                        # Evaluate mutant\n                        mutant_fitness = func(mutant) + 1e-5 * np.linalg.norm(mutant - global_best)  # Modified Line 1\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhanced local search and adaptive mutation to improve convergence precision and speed.", "configspace": "", "generation": 16, "fitness": 0.8512758532176999, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.038. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f0e3c6db-7e49-4945-bdb4-70923581ce84", "metadata": {"aucs": [0.8862227376781142, 0.7986191560619657, 0.8689856659130203], "final_y": [0.16524548378493853, 0.18192773857605926, 0.16492892987857322]}, "mutation_prompt": null}
{"id": "e5966f1e-e1db-40ab-91f6-e4e8daf53436", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight (reduced for better exploration-exploitation balance)\n        self.F = 0.6   # DE scale factor (increased for stronger mutation influence)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and population (PSO)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Modified Line\n            velocity = (self.w * velocity\n                        + self.c1 * r1 * (personal_best - population)\n                        + self.c2 * r2 * (global_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal bests\n            better_fit = fitness < personal_best_scores\n            personal_best[better_fit] = population[better_fit]\n            personal_best_scores[better_fit] = fitness[better_fit]\n\n            # Update global best\n            current_best_idx = np.argmin(fitness)  # Modified Line\n            if fitness[current_best_idx] < personal_best_scores[global_best_idx]:\n                global_best_idx = current_best_idx\n                global_best = population[global_best_idx]\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                adaptive_CR = self.CR - (self.CR * evaluations / self.budget)  # Modified Line 1\n                if np.random.rand() < adaptive_CR:  # Modified Line 2\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n\n                    # Refined Periodicity-based Mutation\n                    if evaluations < self.budget:\n                        period = (ub - lb) / (self.dim * 1.5)  # Modified Line 3\n                        mutant = lb + np.abs((mutant - lb) % (2 * period) - period)  # Ensure symmetry\n                        \n                        # Evaluate mutant\n                        mutant_fitness = func(mutant)\n                        evaluations += 1\n\n                        # Selection\n                        if mutant_fitness < fitness[i]:\n                            population[i] = mutant\n                            fitness[i] = mutant_fitness\n                            if mutant_fitness < personal_best_scores[i]:\n                                personal_best[i] = mutant\n                                personal_best_scores[i] = mutant_fitness\n                                if mutant_fitness < personal_best_scores[global_best_idx]:\n                                    global_best_idx = i\n                                    global_best = mutant\n\n        return global_best", "name": "HybridPSODE", "description": "Enhance selection pressure by updating the inertia weight dynamically based on evaluations.", "configspace": "", "generation": 17, "fitness": 0.5991858246574775, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.599 with standard deviation 0.015. And the mean value of best solutions found was 0.220 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "f0e3c6db-7e49-4945-bdb4-70923581ce84", "metadata": {"aucs": [0.5955031001429305, 0.6193525408585385, 0.5827018329709635], "final_y": [0.20245129230942183, 0.23499649682144974, 0.22246256448452595]}, "mutation_prompt": null}
{"id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Adaptive Opposition-Based Evolutionary Algorithm (AOEA) using opposition-based learning for enhanced exploration and adaptive parameters for a balanced exploration-exploitation trade-off.", "configspace": "", "generation": 18, "fitness": 0.9618526860457594, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f0e3c6db-7e49-4945-bdb4-70923581ce84", "metadata": {"aucs": [0.9685842209039977, 0.9598315520100419, 0.9571422852232385], "final_y": [0.16634100319194534, 0.16738346316647124, 0.16744972734419827]}, "mutation_prompt": null}
{"id": "017f4df9-fecd-4d00-9c57-d49752208da0", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population with dynamic alpha\n            self.alpha = 0.3 + 0.7 * np.random.rand()  # Dynamic opposition learning rate\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced AOEA with dynamic opposition learning rate for improved adaptive exploration.", "configspace": "", "generation": 19, "fitness": 0.9542343447685063, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.007. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9585658076350152, 0.9440534648710015, 0.9600837617995022], "final_y": [0.1661770667699659, 0.16869967221866966, 0.16557289944021036]}, "mutation_prompt": null}
{"id": "f03e33ff-4d44-4c15-b137-e7340d601b62", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.alpha = 0.5 + 0.5 * np.random.rand()  # Dynamic opposition rate\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size//2]  # Select elite\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) with dynamic opposition learning rate and selective elitism for improved convergence efficiency.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 28 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 28 is out of bounds for axis 0 with size 15')", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {}, "mutation_prompt": null}
{"id": "c64aacb1-2120-42b6-958b-ae56bcf89396", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.15 * np.random.rand()  # Adjusted mutation rate range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced AOEA with self-adaptive mutation rates to improve exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.9562089410265422, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.005. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.953878573833809, 0.9634885070475796, 0.951259742198238], "final_y": [0.1689825709701558, 0.1679990803477075, 0.17018919735385252]}, "mutation_prompt": null}
{"id": "cb286342-3c2f-4abc-8385-66fb8bd6583e", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Dynamic population resizing\n            self.population_size = int(np.clip(self.population_size * (1 + np.random.uniform(-0.1, 0.1)), 20, 40))\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition Evolutionary Algorithm (EAOEA) utilizing dynamic population resizing for improved exploration-exploitation balance in black-box optimization.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 25').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 25')", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {}, "mutation_prompt": null}
{"id": "f43bcee3-4566-45d0-a918-56ea3b20098c", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand() * (1 - evaluations / self.budget)  # Self-adaptive mutation\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) with self-adaptive learning rate for mutation to improve convergence.  ", "configspace": "", "generation": 23, "fitness": 0.9588060982377002, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.003. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9625710249217023, 0.9583337173052137, 0.9555135524861845], "final_y": [0.16763897610164136, 0.16730802484398788, 0.16862754349570863]}, "mutation_prompt": null}
{"id": "0b3b4fcf-63c5-474b-a4ae-cbf96e6e31c3", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # Refined mutation rate adaptation\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Adaptive Opposition-Based Evolutionary Algorithm with refined mutation rate adaptation for better exploration-exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.959356081496395, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.005. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9658799760881827, 0.9593332386165845, 0.9528550297844176], "final_y": [0.1667120779012745, 0.16845982371724288, 0.1684169783500703]}, "mutation_prompt": null}
{"id": "8daedc7c-2271-4b92-95d3-5320acd9ba2f", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Dynamic population size adjustment\n            self.population_size = min(50, 10 + evaluations // (self.budget // 10))\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced AOEA with dynamic population size adjustment for improved convergence in black box optimization.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {}, "mutation_prompt": null}
{"id": "6ec4f16b-285d-418a-946f-1d8c31e6c477", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            \n            # Fitness-based dynamic mutation rate\n            self.mutation_rate = 0.1 + 0.4 * (np.max(fitness) - np.min(fitness)) / np.max(fitness)\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) incorporating fitness-based dynamic mutation rates to improve exploration while maintaining exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.950171584635187, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.007. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.959909648709925, 0.948326163518368, 0.942278941677268], "final_y": [0.16865512595804455, 0.1690181950286178, 0.17333958424394047]}, "mutation_prompt": null}
{"id": "95156d50-3714-4191-bc06-17547da47779", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.3 * np.random.rand()  # Modified mutation rate range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        # Gaussian mutation for improved local search\n                        mutation = np.random.normal(0, 0.05 * (ub - lb), self.dim)\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) incorporating Gaussian mutation for improved local search capabilities and modified adaptive parameters for exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.9556418608884588, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.005. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9632346563547548, 0.9506986807910095, 0.9529922455196125], "final_y": [0.16868792781732644, 0.17124884663861395, 0.17240237704474937]}, "mutation_prompt": null}
{"id": "768f1eb2-e832-407e-a016-9cdaff399caf", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.population_size = int(30 + 20 * (evaluations / self.budget))  # Dynamic population size adjustment\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) with dynamic population size adjustment for improved balance between exploration and exploitation.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {}, "mutation_prompt": null}
{"id": "737a64d7-6968-4bc9-b5e7-bc97e78e690a", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population + np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation_scale = (ub - lb) * 0.05 * (1 - evaluations / self.budget)\n                        mutation = np.random.uniform(-1, 1, self.dim) * mutation_scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population\n            opposite_population = lb + ub - population + np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Adaptive Opposition-Based Evolutionary Algorithm (AOEA) with stochastic opposition-based learning and dynamic mutation scaling for improved convergence.", "configspace": "", "generation": 29, "fitness": 0.9537789545003738, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.011. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9389591364968939, 0.9640574145165515, 0.9583203124876761], "final_y": [0.16909824082358416, 0.1654682188651887, 0.1662127320256238]}, "mutation_prompt": null}
{"id": "a96872f5-cfb5-4cff-a681-9033b0fbb741", "solution": "import numpy as np\n\nclass AdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        opposite_population = lb + ub - population  # Opposition-based learning\n        opposite_fitness = np.array([func(ind) for ind in opposite_population])\n        evaluations = self.population_size * 2\n\n        while evaluations < self.budget:\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update opposite population dynamically\n            opposite_population = lb + ub - population + np.random.uniform(-0.01, 0.01, (self.population_size, self.dim))\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n        return population[np.argmin(fitness)]", "name": "AdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with dynamic opposition rate to improve solution diversity and convergence.", "configspace": "", "generation": 30, "fitness": 0.9552407028509631, "feedback": "The algorithm AdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.003. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9513263633796383, 0.9593716371975342, 0.9550241079757168], "final_y": [0.16837348140823682, 0.16729897490031964, 0.1670346792758497]}, "mutation_prompt": null}
{"id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm (EAOEA) using dynamic opposition learning and elitism for improved convergence and solution quality.", "configspace": "", "generation": 31, "fitness": 0.9699886314842745, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84b265b0-2128-46fd-ad93-ffeea1f86cd5", "metadata": {"aucs": [0.9672909360434222, 0.9737728054300785, 0.9689021529793227], "final_y": [0.16681525358772564, 0.16532657765218928, 0.16644809828904805]}, "mutation_prompt": null}
{"id": "e040f98b-69bc-43e7-9565-3b9d11341717", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 1, self.dim) * (ub - lb) * 0.05  # Enhanced mutation\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Dynamic population size adjustment\n            if evaluations > self.budget * 0.5:  # Adjust after half the budget is used\n                self.population_size = int(self.population_size * 1.1)\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Enhanced Adaptive Opposition Evolutionary Algorithm (IEAOEA) with dynamic population size adjustment and enhanced mutation strategy for better exploration and exploitation balance.", "configspace": "", "generation": 32, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "metadata": {}, "mutation_prompt": null}
{"id": "6df6434d-7f3c-4cbf-93d9-74f9105580d6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        self.crossover_rate = 0.5 + 0.5 * np.random.rand()  # Line changed\n        self.mutation_rate = 0.1 + 0.4 * np.random.rand()  # Line changed\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate *= 0.95 if np.random.rand() < 0.5 else 1.05  # Line changed\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced adaptive learning rates for mutation and crossover to exploit exploration-exploitation balance dynamically.", "configspace": "", "generation": 33, "fitness": 0.9595314598819823, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.008. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "metadata": {"aucs": [0.9706944961533569, 0.9549295474917401, 0.95297033600085], "final_y": [0.16624203863861087, 0.1664160059224833, 0.1678642877013673]}, "mutation_prompt": null}
{"id": "92b85b8c-4a86-426c-858b-0f21313d00c9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.local_search_rate = 0.2  # New parameter for local search probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # Adjusted mutation rate range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            # Apply local search strategy\n            if np.random.rand() < self.local_search_rate:\n                best_idx = np.argmin(fitness)\n                best_solution = population[best_idx]\n                local_perturbation = np.random.uniform(-0.02, 0.02, self.dim) * (ub - lb)\n                improved_solution = np.clip(best_solution + local_perturbation, lb, ub)\n                offspring.append(improved_solution)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Adaptive Memetic Opposition Evolutionary Algorithm (AMOEA) incorporating local search and adaptive parameters for enhanced optimization of black box functions.", "configspace": "", "generation": 34, "fitness": 0.9654562694454875, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.007. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "metadata": {"aucs": [0.9704313577402413, 0.9700458306531113, 0.9558916199431099], "final_y": [0.16677882482894524, 0.1668330481396504, 0.16755737631408174]}, "mutation_prompt": null}
{"id": "59f31def-ce8d-4dee-95ed-7b2ed9569cce", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.neighborhood_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with dynamic neighborhood search\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()\n\n            # Generate offspring with neighborhood search\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.neighborhood_factor\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "An enhanced opposition-based evolutionary algorithm with dynamic neighborhood search and adaptive parameter control for improved convergence and diversity.", "configspace": "", "generation": 35, "fitness": 0.9548169584739995, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.011. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "metadata": {"aucs": [0.9391308711919012, 0.9641899139730316, 0.9611300902570661], "final_y": [0.17418137529084043, 0.1704250359004501, 0.17238709168352617]}, "mutation_prompt": null}
{"id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved dynamic opposition learning parameter to boost exploration capabilities.", "configspace": "", "generation": 36, "fitness": 0.9703057277972373, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.002. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "088e884b-8e08-49a9-a49b-7b75df65ced3", "metadata": {"aucs": [0.9714622960302198, 0.9725296567879397, 0.9669252305735524], "final_y": [0.1664295493549378, 0.1658105858908181, 0.16620149118824645]}, "mutation_prompt": null}
{"id": "b3686e86-4bed-4a21-adeb-6c9014f8c198", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)  # changed 0.2 to 0.15\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.02  # changed -1 to -0.5 and 0.05 to 0.02\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved opposition calculation and mutation strategy to enhance exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.9609219269130648, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.001. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9611753413226705, 0.9598264408708669, 0.961763998545657], "final_y": [0.1671022204356899, 0.1663350890847216, 0.16723480048460826]}, "mutation_prompt": null}
{"id": "c7a4c1e1-3477-4d0d-9ec8-5b8c53833ac7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Initial opposition learning rate\n        self.alpha_decay = 0.995  # Alpha decay factor\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with decay\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with diversity-based elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            diversity_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[diversity_indices]\n            fitness = combined_fitness[diversity_indices]\n            self.alpha *= self.alpha_decay  # Update alpha\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with opposition learning rate decay and diversity-based selection for superior exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.969511798412924, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.002. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9711326360538739, 0.9703275727517547, 0.9670751864331436], "final_y": [0.1658205971671528, 0.1664894949816409, 0.16644376549397644]}, "mutation_prompt": null}
{"id": "4edf3ac2-2d8f-4808-be98-7448d3033c36", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with enhanced adaptive noise\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)  # changed 0.2 to 0.15\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with refined randomness\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()  # changed 0.5 + 0.5 to 0.6 + 0.4\n            self.mutation_rate = 0.15 + 0.35 * np.random.rand()  # changed 0.1 + 0.4 to 0.15 + 0.35\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced parameter tuning for dynamic opposition and adaptive exploration in evolutionary optimization.", "configspace": "", "generation": 39, "fitness": 0.9653843097663096, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.008. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9697353595001121, 0.9727272303440392, 0.9536903394547775], "final_y": [0.16641465673080003, 0.16658823892012709, 0.16886052607613322]}, "mutation_prompt": null}
{"id": "e167dc0d-5ca6-497b-8d0c-5343510f60c3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.3, population.shape)  # Adjust noise variance\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.alpha = 0.3 + 0.4 * np.random.rand()  # Introduce adaptive alpha\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced adaptive alpha tuning and improved dynamic opposition noise variance to enhance exploration.", "configspace": "", "generation": 40, "fitness": 0.9576099170625562, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.018. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9315125094230334, 0.9718723030204053, 0.9694449387442298], "final_y": [0.1719586152835576, 0.16632721152208496, 0.1670646121110797]}, "mutation_prompt": null}
{"id": "cd266fd7-8305-4a21-aec4-0cb7db2b0120", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # Adjusted mutation range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced adaptive opposition learning with dynamically adjusted mutation strength for improved exploration.", "configspace": "", "generation": 41, "fitness": 0.9666511237372027, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9650942074106903, 0.9708360974851831, 0.964023066315735], "final_y": [0.1662822640506183, 0.16659710909388337, 0.1674961461197395]}, "mutation_prompt": null}
{"id": "8820021b-f167-412f-96fc-e4f90018af3a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Adaptive population size\n            self.population_size = int(30 * (1 + 0.5 * np.sin(evaluations / self.budget * np.pi)))  # added line\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Enhanced Adaptive Opposition-Based Evolutionary Algorithm with adaptive population size to balance exploration and exploitation effectively.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "a75f04c0-b659-4f0f-ad6e-09259ad1a8b2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=True)  # Changed from False to True\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation_scale = np.random.rand() * 0.1  # Added adaptive mutation scaling\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * mutation_scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved adaptive mutation scaling and random parent selection to enhance diversity and convergence.  ", "configspace": "", "generation": 43, "fitness": 0.9640002388537655, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.007. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9709684913277149, 0.9548660216515373, 0.9661662035820441], "final_y": [0.16614864625142423, 0.1663962836802786, 0.16612336229902214]}, "mutation_prompt": null}
{"id": "381ba607-05d2-43d3-a6d9-2a91a5403e78", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            dynamic_exploration_factor = np.random.uniform(0.1, 0.3)  # Changed factor to improve diversity\n            opposite_population = lb + ub - population + np.random.normal(0, dynamic_exploration_factor, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Incorporates a dynamic exploration factor to enhance the search diversity of the Enhanced Adaptive Opposition-Based Evolutionary Algorithm.", "configspace": "", "generation": 44, "fitness": 0.9649073399960377, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.002. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9651965923608709, 0.9619910678231185, 0.9675343598041241], "final_y": [0.16904891451463744, 0.16713796018964933, 0.1668203789397028]}, "mutation_prompt": null}
{"id": "00536e42-9f26-4c44-95e6-dd712711a113", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.alpha = 0.4 + 0.6 * np.random.rand()  # Dynamic alpha\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced dynamic alpha parameter tuning for improved exploration and exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.961073615513835, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9536531036806589, 0.9743134811770767, 0.9552542616837695], "final_y": [0.1669953704574989, 0.16624218493985243, 0.16705572683952874]}, "mutation_prompt": null}
{"id": "7246f960-0eb8-483f-947e-545ee7249bf1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.3, population.shape)  # changed 0.2 to 0.3\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.4 + 0.6 * np.random.rand()  # changed 0.5 to 0.4\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Dynamic Opposition-Based Learning Strategy with Dynamic Evolutionary Pressure for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 46, "fitness": 0.9600527394846097, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.006. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9612811163814217, 0.9670504008867277, 0.9518267011856797], "final_y": [0.16699142626292374, 0.1673970647518227, 0.16888457975697369]}, "mutation_prompt": null}
{"id": "65866f59-b18b-471f-aa80-763f39107173", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.initial_mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.local_search_probability = 0.3\n\n    def local_search(self, ind, func, lb, ub):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim) * (ub - lb)\n        new_ind = np.clip(ind + perturbation, lb, ub)\n        return new_ind if func(new_ind) < func(ind) else ind\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        mutation_rate = self.initial_mutation_rate\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with dynamic mutation\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            mutation_rate = 0.05 + 0.1 * (self.budget - evaluations) / self.budget\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n                \n                # Local search phase\n                if np.random.rand() < self.local_search_probability:\n                    offspring[-1] = self.local_search(offspring[-1], func, lb, ub)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Memetic Opposition-Based Evolutionary Algorithm with integrated local search phase and dynamic mutation to optimize exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "065b0f5c-931c-45c8-a3a7-53c3f71b37f5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.3, population.shape)  # change 0.2 to 0.3\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n            \n            # Adaptive parameter tuning with variance\n            self.crossover_rate = 0.4 + 0.6 * np.random.rand()  # change range of crossover_rate\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # change range of mutation_rate\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + np.random.uniform(0.4, 0.6) * (parent2 - parent1), lb, ub)  # change alpha method\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.1  # change mutation scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with selective elitism\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Dynamic Differentiated Opposition-Based Evolutionary Algorithm with enhanced exploration through variable learning parameters and selective elitism for improved solution quality.", "configspace": "", "generation": 48, "fitness": 0.9458333514453603, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.010. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9474298565469553, 0.9568851297778209, 0.9331850680113043], "final_y": [0.16806090428399334, 0.17048435127700456, 0.17528666741163068]}, "mutation_prompt": null}
{"id": "c63343b3-b137-46d1-8ca8-6419fd3f6f5a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb)  # Changed to Gaussian mutation\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Incorporate a Gaussian mutation mechanism in offspring generation to enhance local exploration capabilities.", "configspace": "", "generation": 49, "fitness": 0.9531329852659781, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.002. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9509214669460216, 0.9535328829801055, 0.9549446058718071], "final_y": [0.17305333932057998, 0.16933493885153494, 0.17393943666277767]}, "mutation_prompt": null}
{"id": "92299ebc-d8cb-473b-bf7f-c46422da0c78", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb) * 0.05  # Gaussian mutation\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced Gaussian mutation with adaptive scaling in offspring generation to enhance local search and convergence precision.", "configspace": "", "generation": 50, "fitness": 0.9448232398183768, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.006. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9370474113838799, 0.9520610105865885, 0.9453612974846621], "final_y": [0.17449703371929892, 0.17062752883049592, 0.17125468313763836]}, "mutation_prompt": null}
{"id": "8f9290a1-d055-416e-9b90-67054af5169f", "solution": "import numpy as np\n\nclass QuantumInspiredOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.45  # Opposition learning rate\n        self.mutation_rate = 0.15\n        self.crossover_rate = 0.75\n        self.quantum_rate = 0.1  # Quantum-inspired rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with quantum perturbation\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)\n            quantum_population = population + self.quantum_rate * np.random.normal(0, (ub - lb), population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            quantum_fitness = np.array([func(ind) for ind in quantum_population])\n            evaluations += 2 * self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, quantum_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, quantum_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "QuantumInspiredOppositionEvolutionaryAlgorithm", "description": "Hybrid Quantum-Inspired Opposition-Based Evolutionary Algorithm, combining quantum-inspired operators with dynamic opposition learning to enhance exploration and exploitation.", "configspace": "", "generation": 51, "fitness": 0.9291200694635621, "feedback": "The algorithm QuantumInspiredOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.022. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9557187605680574, 0.9015598527537564, 0.9300815950688724], "final_y": [0.16785448153341986, 0.18396854811172791, 0.16731866733080658]}, "mutation_prompt": null}
{"id": "d1beb31f-9eb9-419f-a5e1-6fcc865ccb4d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Adjust mutation scale based on diversity\n            diversity = np.std(population, axis=0)\n            mutation_scale = 0.05 * (1 + 0.5 * diversity / (ub - lb))\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * mutation_scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced adaptive mutation scale to enhance exploration and exploitation balance by allowing mutation scale to adapt based on population diversity.", "configspace": "", "generation": 52, "fitness": 0.9698089318659564, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.004. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9669336197600764, 0.975704879875002, 0.9667882959627907], "final_y": [0.1673607937682371, 0.16612530920101531, 0.1673920930459849]}, "mutation_prompt": null}
{"id": "586fb131-8f57-4e4c-aedf-a8bfb478da06", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    gaussian_noise = np.random.normal(0, 0.05, self.dim)  # Added Gaussian perturbation\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1) + gaussian_noise, lb, ub)  # Integrated Gaussian perturbation\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved exploration-exploitation balance by introducing adaptive crossover with Gaussian perturbation in offspring generation.", "configspace": "", "generation": 53, "fitness": 0.9648624851945623, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.007. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9737647914828506, 0.9629413289419108, 0.9578813351589255], "final_y": [0.1661140464249219, 0.1673803924729813, 0.17087688208192153]}, "mutation_prompt": null}
{"id": "abc76733-c54c-4634-b7ad-2173fea60358", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.alpha = 0.4 + 0.1 * np.random.rand()  # Dynamic alpha recalibration\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced dynamic alpha recalibration to improve convergence speed.", "configspace": "", "generation": 54, "fitness": 0.9581325063462951, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.011. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9626222194751137, 0.9682972022147528, 0.943478097349019], "final_y": [0.16807474043601767, 0.16613147029531494, 0.1703843905399035]}, "mutation_prompt": null}
{"id": "f9be7d53-924b-45b2-b758-261d03a28cd6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.25, population.shape)  # changed variance from 0.2 to 0.25\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Adaptive opposition-based evolutionary algorithm with enhanced variance in opposition learning for better exploration.", "configspace": "", "generation": 55, "fitness": 0.9681395360097378, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9659485859231115, 0.9720492698836137, 0.966420752222488], "final_y": [0.16652431679552193, 0.1659350259158957, 0.16629189489450202]}, "mutation_prompt": null}
{"id": "bf79bfdc-aa1a-4be5-827d-f6037dffdff7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.15 + 0.35 * np.random.rand()  # Changed from 0.1 + 0.4\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.05  # Changed from [-1, 1]\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            ranks = np.argsort(np.argsort(combined_fitness))  # Added stochastic ranking\n            best_indices = np.argsort(ranks)[:self.population_size]  # Changed from np.argsort(combined_fitness)\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced adaptive evolutionary algorithm with stochastic ranking and improved mutation strategy.", "configspace": "", "generation": 56, "fitness": 0.9642537720328352, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.008. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9557546899201914, 0.9740587535901842, 0.96294787258813], "final_y": [0.16687469562081636, 0.1654436470158278, 0.1661309329407875]}, "mutation_prompt": null}
{"id": "60ce0d30-6eb9-46b2-a3f4-ed34e025f330", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 1, self.dim) * (ub - lb) * 0.05  # Changed uniform to normal\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved diversity by introducing Gaussian noise in mutation.", "configspace": "", "generation": 57, "fitness": 0.9531329852659781, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.002. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9509214669460216, 0.9535328829801055, 0.9549446058718071], "final_y": [0.17305333932057998, 0.16933493885153494, 0.17393943666277767]}, "mutation_prompt": null}
{"id": "94ba24d2-e111-4f24-98d8-747b8ddf8ce6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.1 * np.random.rand()  # changed 0.4 to 0.1\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        step_size = np.random.uniform(0.01, 0.05)  # changed step size range\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * step_size\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            elite_count = max(1, self.population_size // 5)  # Preserve top 20% elite\n            elite_indices = np.argsort(combined_fitness)[:elite_count]\n            best_indices = np.argsort(combined_fitness)[elite_count:self.population_size]\n            population = np.vstack((combined_population[elite_indices], combined_population[best_indices]))\n            fitness = np.hstack((combined_fitness[elite_indices], combined_fitness[best_indices]))\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Adaptive Opposition-Based Evolutionary Algorithm with a dynamic mutation step size and enhanced elite preservation for optimizing diverse black-box problems.", "configspace": "", "generation": 58, "fitness": 0.9647524019830099, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.004. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9619891281087077, 0.9624986228770169, 0.9697694549633051], "final_y": [0.167473654229233, 0.16816883432942764, 0.16688472522639908]}, "mutation_prompt": null}
{"id": "d4d6456b-1ed1-48d4-be9a-e6949de436c7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  \n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Enhanced adaptive parameter tuning\n            self.crossover_rate = 0.4 + 0.6 * np.random.rand()  # Adjusted range\n            self.mutation_rate = 0.05 + 0.5 * np.random.rand()  # Adjusted range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        # Incorporating Lévy flight\n                        levy = np.random.normal(0, 0.1, self.dim) * (np.power(np.abs(parent1 - parent2), -1))\n                        child = np.clip(child + levy, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Incorporation of Lévy flight perturbations and enhanced adaptive parameter tuning for increased exploration and exploitation balance.", "configspace": "", "generation": 59, "fitness": 0.9545878947709155, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.007. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9467639696899967, 0.963884371221568, 0.9531153434011816], "final_y": [0.17165935878700667, 0.1663301433846176, 0.16952502988721063]}, "mutation_prompt": null}
{"id": "2ca6737b-6fbb-418a-97ba-527e26ec84ed", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8  # Differential Evolution weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with added perturbation\n            opposite_population = lb + ub - population + np.random.normal(0, 0.3, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with exploration-focused strategy\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            self.mutation_rate = 0.2 + 0.3 * np.random.rand()\n\n            # Generate offspring using Differential Evolution crossover\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices]\n                    mutant_vector = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        mutant_vector = np.clip(mutant_vector + mutation, lb, ub)\n                    offspring.append(mutant_vector)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Hybrid Differential Evolution with Opposition-Based Learning to enhance exploration and convergence.", "configspace": "", "generation": 60, "fitness": 0.8773305322342325, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.013. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.8761615973682579, 0.8941749380380958, 0.861655061296344], "final_y": [0.16851368230255503, 0.17044039768663444, 0.1706753851458921]}, "mutation_prompt": null}
{"id": "f296b31a-d5b3-4058-9afb-19557d3c7b1b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            dynamic_opp_rate = 0.3 + 0.4 * (evaluations / self.budget)\n            opposite_population = lb + ub - population + np.random.normal(0, dynamic_opp_rate, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Enhanced Adaptive Opposition-Based Evolutionary Algorithm with dynamic learning for opposition rate and adaptive exploration and exploitation balance.", "configspace": "", "generation": 61, "fitness": 0.9661525217340124, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9657174090740658, 0.9704053072491371, 0.9623348488788344], "final_y": [0.16739063101536278, 0.16582289397085315, 0.16803694209284992]}, "mutation_prompt": null}
{"id": "79f5c278-0ecf-4873-a0ef-1e9a5212572f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()  # changed from 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved dynamic opposition learning parameter and crossover rate adaptation for enhanced exploration.", "configspace": "", "generation": 62, "fitness": 0.9611283561675656, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.010. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9682483137630424, 0.9684747361750765, 0.9466620185645779], "final_y": [0.16704431390086794, 0.1663984801395626, 0.16804070175704733]}, "mutation_prompt": null}
{"id": "88da7c2e-df4d-4427-ba49-3cf081e41fd9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.05  # Modified mutation range\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size//2]  # Changed elitism strategy\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced exploitation through modified mutation and selection strategy for improved convergence and solution quality.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 27 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 27 is out of bounds for axis 0 with size 15')", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "8c934f5a-2df7-4226-9bec-9e34d678663c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            fitness_variance = np.var(fitness)\n            mutation_step_size = fitness_variance * 0.05  # Scaled mutation step size based on fitness variance\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * mutation_step_size\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition Evolutionary Algorithm with dynamic scaling of mutation step size based on fitness variance to improve convergence precision.", "configspace": "", "generation": 64, "fitness": 0.9218371568512326, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.034. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9320050364147927, 0.8760489255240665, 0.9574575086148385], "final_y": [0.1813538069919528, 0.200093753349338, 0.17245758782494502]}, "mutation_prompt": null}
{"id": "1201372b-b55b-4e2b-85dc-f1c10a675b24", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            dynamic_alpha = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Adaptive learning rate\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2 * dynamic_alpha, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced an adaptive learning rate for dynamic opposition to enhance exploration and convergence efficiency.", "configspace": "", "generation": 65, "fitness": 0.9695563467630842, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.002. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9710826912682182, 0.9706625711564006, 0.9669237778646333], "final_y": [0.16660910506400572, 0.16634206479951763, 0.16621576756957146]}, "mutation_prompt": null}
{"id": "804f96db-affc-41a6-8b4c-197f8f104b3c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.1  # changed 0.05 to 0.1\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Incorporating a slight boost in exploration by increasing mutation magnitude to enhance solution diversity at minimal code change.", "configspace": "", "generation": 66, "fitness": 0.9655639367181093, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9623414982196019, 0.9691722274016317, 0.9651780845330942], "final_y": [0.1704569397637703, 0.16892414356520735, 0.16826508553259578]}, "mutation_prompt": null}
{"id": "75b2e416-9052-475d-83aa-0376498b9936", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb)  # Changed to Gaussian perturbation\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Adaptive Opposition Evolutionary Algorithm with increased mutation diversity through Gaussian perturbation for enhanced exploration.", "configspace": "", "generation": 67, "fitness": 0.9531329852659781, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.002. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9509214669460216, 0.9535328829801055, 0.9549446058718071], "final_y": [0.17305333932057998, 0.16933493885153494, 0.17393943666277767]}, "mutation_prompt": null}
{"id": "09910560-69df-4cbf-a9c6-0d873eaa49a5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.1  # Changed 0.05 to 0.1\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with modified elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:int(self.population_size / 2)]  # Changed from self.population_size\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved mutation and elitism strategy for better exploitation and exploration balance.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 27 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 27 is out of bounds for axis 0 with size 15')", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "7e481f5e-69a0-4b73-ac0e-42070f5aa43e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with diversity consideration\n            std_dev = np.std(population, axis=0)\n            noise = np.random.normal(0, 0.2 + 0.1 * std_dev, population.shape)\n            opposite_population = lb + ub - population + noise\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with diversity monitoring\n            diversity_metric = np.mean(std_dev)\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * (1 - diversity_metric) * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Diversity-Driven Adaptive Opposition Evolutionary Algorithm incorporating diversity maintenance to improve exploration and convergence balance.", "configspace": "", "generation": 69, "fitness": 0.9506857506750711, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.011. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9519986945372195, 0.9633172940529368, 0.9367412634350574], "final_y": [0.16806288994423269, 0.16838255611365094, 0.16869861072439996]}, "mutation_prompt": null}
{"id": "a0e17005-e13a-42a5-9230-18b2b9a09ca5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with tournament selection\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            indices = np.random.choice(len(combined_fitness), size=(2*self.population_size, 2), replace=False)\n            tournament_winners = np.argmin(combined_fitness[indices], axis=1)\n            best_indices = indices[np.arange(2*self.population_size), tournament_winners][:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduced a diversity-preserving mechanism by incorporating tournament selection for maintaining robust exploration.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "f8ea9cfd-9cf5-4b40-9fb7-371c93578036", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)  # Reduced noise\n            \n            # Fitness-weighted opposition integration\n            weighted_opposite_population = (opposite_population + population * fitness[:, None]) / (1 + fitness[:, None])\n            opposite_fitness = np.array([func(ind) for ind in weighted_opposite_population])\n            \n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.35 * np.random.rand()  # Adjusted mutation range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb)  # Use normal distribution\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, weighted_opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with fitness-weighted opposition integration and improved mutation strategy for better local exploitation.", "configspace": "", "generation": 71, "fitness": 0.9641204118804639, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.007. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9638918813568219, 0.9722500778940218, 0.9562192763905482], "final_y": [0.1688803082714777, 0.16825051707807803, 0.17248561870261292]}, "mutation_prompt": null}
{"id": "abb00a21-2396-4f68-9bc2-5b1b060f099e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.5, self.dim) * (ub - lb) * 0.05  # changed uniform to normal\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Adjusted the mutation strategy in the Enhanced Adaptive Opposition-Based Evolutionary Algorithm for better exploration.", "configspace": "", "generation": 72, "fitness": 0.9544284889645951, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9556640092956669, 0.9645981089495582, 0.9430233486485601], "final_y": [0.16682994176485189, 0.16659310361810875, 0.16792459499685608]}, "mutation_prompt": null}
{"id": "355c60e6-1054-49ba-b966-2191b5eb3f9e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.25, population.shape)  # changed 0.2 to 0.25\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Slightly improved the dynamic opposition-based learning by adjusting the normal distribution scale for generating the opposite population.", "configspace": "", "generation": 73, "fitness": 0.9681395360097378, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9659485859231115, 0.9720492698836137, 0.966420752222488], "final_y": [0.16652431679552193, 0.1659350259158957, 0.16629189489450202]}, "mutation_prompt": null}
{"id": "bfc4a10b-71d8-454a-ac42-8d5b744b04f2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with crowding distance\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            sorted_indices = np.argsort(combined_fitness)\n            best_indices = sorted_indices[:self.population_size]\n            diversity_indices = sorted_indices[self.population_size:self.population_size*2]\n            population = np.vstack((combined_population[best_indices], combined_population[diversity_indices]))\n            fitness = np.hstack((combined_fitness[best_indices], combined_fitness[diversity_indices]))\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with diversity preservation through crowding distance to improve exploration and exploitation balance.", "configspace": "", "generation": 74, "fitness": 0.9543811681123252, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.009. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9575989648517389, 0.9632874269516462, 0.9422571125335903], "final_y": [0.16825777996819613, 0.1664862728999713, 0.16685937015850805]}, "mutation_prompt": null}
{"id": "baaabcc5-1289-4050-b390-af71db88c566", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning using chaotic map\n            self.crossover_rate = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            self.mutation_rate = 0.1 + 0.4 * np.cos(evaluations / self.budget * np.pi)\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + np.random.rand() * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved exploration through chaotic maps and improved offspring generation.", "configspace": "", "generation": 75, "fitness": 0.945641781340464, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.017. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9646415234132102, 0.9230957326513705, 0.949188087956811], "final_y": [0.1671792690856273, 0.17415005638947, 0.1692125190189545]}, "mutation_prompt": null}
{"id": "11559842-3930-4261-849c-3c75c05c9b36", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.mutation_scale = 0.05  # Added mutation scale\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with adaptive scale\n            scale_factor = 0.5 + 0.5 * np.random.rand()  # New scale factor\n            opposite_population = lb + ub - population + np.random.normal(0, scale_factor, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation_scale = self.mutation_scale * (1 + np.random.rand())  # Adaptive mutation scale\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * mutation_scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced dynamic opposition evolutionary algorithm with adaptive mutation scale to improve balance between exploration and exploitation.", "configspace": "", "generation": 76, "fitness": 0.9524318351765683, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.011. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9616516442134944, 0.9581689521429195, 0.9374749091732909], "final_y": [0.16814260523458302, 0.1676797041490129, 0.1706722693775582]}, "mutation_prompt": null}
{"id": "b32e8379-7ce5-444b-b5de-f8a35dd71a71", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.06  # changed 0.05 to 0.06\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Slightly increased the mutation intensity to enhance exploration capability while staying within minimal modification constraints.", "configspace": "", "generation": 77, "fitness": 0.9671516610697085, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9672142766434008, 0.9702316947162267, 0.9640090118494978], "final_y": [0.1663505915373642, 0.1665633066779093, 0.16776135923991664]}, "mutation_prompt": null}
{"id": "127faeff-7077-4745-8e62-c9973e0d5b61", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40  # Increased population size for better diversity\n        self.alpha = 0.6  # Adjusted opposition learning rate\n        self.mutation_rate = 0.2  # Increased mutation rate\n        self.crossover_rate = 0.8  # Increased crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning with added Gaussian noise\n            opposite_population = lb + ub - population + np.random.normal(0, 0.3, population.shape)  # Adjusted noise level\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning with diversity consideration\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()\n            self.mutation_rate = 0.2 + 0.3 * np.random.rand()\n\n            # Generate offspring with diversity preservation\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1) + np.random.normal(0, 0.05, self.dim), lb, ub)  # Added noise for diversity\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.1  # Adjusted mutation scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism and diversity\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved dynamic opposition and adaptive parameters with diversity preservation to enhance convergence and solution quality.", "configspace": "", "generation": 78, "fitness": 0.9556379637617071, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.008. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9505751643740301, 0.9494219477848688, 0.9669167791262221], "final_y": [0.1680821710057172, 0.1671702933122894, 0.16610864747076615]}, "mutation_prompt": null}
{"id": "f398bd03-8492-4828-b1ee-20dd7897f410", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.1  # increased range\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Modified mutation strategy to enhance exploration by increasing mutation range.", "configspace": "", "generation": 79, "fitness": 0.9655639367181093, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9623414982196019, 0.9691722274016317, 0.9651780845330942], "final_y": [0.1704569397637703, 0.16892414356520735, 0.16826508553259578]}, "mutation_prompt": null}
{"id": "cd18ae0b-5360-475a-a53a-fe9c2b47cbb6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # changed 0.1 to 0.05 and 0.4 to 0.45\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Enhanced Adaptive Opposition Evolutionary Algorithm with refined mutation adaptive tuning to enhance diversity and exploration.", "configspace": "", "generation": 80, "fitness": 0.9666511237372027, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9650942074106903, 0.9708360974851831, 0.964023066315735], "final_y": [0.1662822640506183, 0.16659710909388337, 0.1674961461197395]}, "mutation_prompt": null}
{"id": "2cf3f1d4-3f98-45d3-a147-cdf9f6df739c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * (0.05 + 0.05 * np.random.rand())  # adaptive mutation scaling\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introducing adaptive mutation scaling for more precise offspring exploration.", "configspace": "", "generation": 81, "fitness": 0.9613864272750169, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.006. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9666888034497986, 0.9649116345937874, 0.9525588437814649], "final_y": [0.16960957480754557, 0.16801678988180246, 0.1690466072921185]}, "mutation_prompt": null}
{"id": "ab2542cc-02d7-4307-9459-966de40d419f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.3 * np.random.rand()  # Changed mutation range\n\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation_strength = 0.02 if evaluations < self.budget / 2 else 0.05  # Dynamic mutation strength\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * mutation_strength\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved Adaptive Opposition-Based Evolutionary Algorithm with a more dynamic mutation strategy and adaptive population size for enhanced exploration and exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.9552549716412031, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.008. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9461435371339926, 0.9662379336834678, 0.9533834441061486], "final_y": [0.16875564956178013, 0.16694505692220174, 0.16840954892431104]}, "mutation_prompt": null}
{"id": "ff0db145-b8f9-41c3-b154-fabb31aae4e9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb)  # changed mutation strategy\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with an optimized mutation strategy to improve search efficiency.", "configspace": "", "generation": 83, "fitness": 0.9531329852659781, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.002. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9509214669460216, 0.9535328829801055, 0.9549446058718071], "final_y": [0.17305333932057998, 0.16933493885153494, 0.17393943666277767]}, "mutation_prompt": null}
{"id": "75d15426-09c4-4285-9e35-7585c9cf2c68", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)  # changed 0.2 to 0.15\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.4 + 0.6 * np.random.rand()  # changed range of crossover_rate adaptation\n            self.mutation_rate = 0.05 + 0.3 * np.random.rand()  # changed range of mutation_rate adaptation\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.05  # changed mutation range\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced evolutionary algorithm with adaptive crossover and mutation rates, incorporating opposition-based learning for improved search efficiency and convergence balance.", "configspace": "", "generation": 84, "fitness": 0.9531199389015989, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.020. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9732211695181, 0.960612579177531, 0.9255260680091658], "final_y": [0.16665289067037226, 0.1667317909764071, 0.17192967396861358]}, "mutation_prompt": null}
{"id": "e00f039c-a392-47ea-8921-282ce63025ee", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Hierarchical crossover\n            hierarchy_crossover_rate = 0.5 + 0.2 * np.random.rand()\n            self.crossover_rate = hierarchy_crossover_rate\n\n            # Adaptive mutation\n            self.mutation_rate = 0.05 + 0.3 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, 0.1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with hierarchical crossover and adaptive mutation for improved convergence.", "configspace": "", "generation": 85, "fitness": 0.963146275897948, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.006. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9547259754752192, 0.965949115448965, 0.9687637367696597], "final_y": [0.16928415562068666, 0.16635796189852348, 0.1668465892410006]}, "mutation_prompt": null}
{"id": "2818c773-6266-417b-8671-d80ba52f7fbc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        # Gaussian mutation instead of uniform mutation\n                        mutation = np.random.normal(0, 0.05, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with refined dynamic exploration by introducing Gaussian mutation to improve local search capabilities.", "configspace": "", "generation": 86, "fitness": 0.9448232398183768, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.006. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9370474113838799, 0.9520610105865885, 0.9453612974846621], "final_y": [0.17449703371929892, 0.17062752883049592, 0.17125468313763836]}, "mutation_prompt": null}
{"id": "961c3679-e04a-4639-a18e-c4e2dcd2aa82", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        # Introduced Lévy flight perturbation\n                        levy_perturbation = np.random.standard_cauchy(self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + levy_perturbation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introduces a novel perturbation mechanism with Lévy flight to enhance exploration and avoid local minima in the opposition-based evolutionary strategy.", "configspace": "", "generation": 87, "fitness": 0.9388393748079755, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.019. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9412537575955474, 0.9610042523184977, 0.9142601145098814], "final_y": [0.17788070072530549, 0.16975273041355354, 0.1834628611463075]}, "mutation_prompt": null}
{"id": "97c1a4ca-58d6-4d56-b140-4eaf7bd94684", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.6  # Adjusted opposition learning rate\n        self.mutation_rate = 0.15\n        self.crossover_rate = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            noise_factor = np.random.uniform(0.15, 0.25, population.shape)  # adjusted noise factor\n            opposite_population = lb + ub - population + np.random.normal(0, noise_factor)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.6 + 0.4 * np.random.rand()  # Adjusted range\n            self.mutation_rate = 0.05 + 0.45 * np.random.rand()  # Adjusted range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.8, 0.8, self.dim) * (ub - lb) * 0.05  # adjusted mutation\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with enhanced elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Integrates opposition-based learning with adaptive elitist selection and adaptive diversity maintenance for robust global searching.", "configspace": "", "generation": 88, "fitness": 0.9579352555617303, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9664818933330633, 0.9461950692546852, 0.9611288040974424], "final_y": [0.1655370508990902, 0.1683374893399423, 0.16553259834741219]}, "mutation_prompt": null}
{"id": "5a2aaac1-f397-4fda-badc-c5c6c8fdaded", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n            self.alpha = 0.3 + 0.4 * np.random.rand()  # Updated adaptive alpha\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved adaptive alpha for enhanced exploration and exploitation balance.", "configspace": "", "generation": 89, "fitness": 0.9519653693667566, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.004. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9460561672659412, 0.9553418180313187, 0.9544981228030097], "final_y": [0.16834049856536393, 0.16871316455204055, 0.16948100295758906]}, "mutation_prompt": null}
{"id": "972c9861-3ae7-44d0-87a3-ce91baaac058", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.normal(0, np.var(fitness), self.dim) * (ub - lb) * 0.05  # Modified line\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Incorporate Gaussian mutation scaled by fitness variance to enhance exploration and exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.9306852900260772, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.020. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9134116472387422, 0.9591962584052477, 0.9194479644342418], "final_y": [0.18772969334744605, 0.17165991281677562, 0.18399290003449287]}, "mutation_prompt": null}
{"id": "1921255b-659a-4fd9-8bac-006c5d6aef31", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  \n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation using tournament selection\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            tournament_indices = np.random.choice(len(combined_population), self.population_size, replace=False)\n            best_indices = tournament_indices[np.argsort(combined_fitness[tournament_indices])[:self.population_size]]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved selection strategy using tournament selection to enhance elitism and diversity.", "configspace": "", "generation": 91, "fitness": 0.8372769449403207, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.072. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9168879442303466, 0.7418660533627566, 0.8530768372278588], "final_y": [0.18606830566248778, 0.2592806284961635, 0.20689805027937191]}, "mutation_prompt": null}
{"id": "8b3173d1-d21a-4143-bcce-1c68959d5a0e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)  # changed 0.2 to 0.15\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = np.random.uniform(0.05, 0.5)  # changed mutation rate adaptive range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Optimized Enhanced Adaptive Opposition-Based Evolutionary Algorithm with refined opposition learning parameter and dynamic tuning of mutation and crossover rates to improve convergence reliability.", "configspace": "", "generation": 92, "fitness": 0.966226645097382, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9616982003241602, 0.9690241872608988, 0.967957547707087], "final_y": [0.16641651368536692, 0.16706147936616866, 0.16708939750671925]}, "mutation_prompt": null}
{"id": "457e501b-73be-460f-8c43-b9340c189878", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.25, population.shape)  # changed 0.2 to 0.25\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved the randomness in opposition-based learning to enhance exploration capabilities by slightly increasing the standard deviation of the normal distribution used for generating opposite population.", "configspace": "", "generation": 93, "fitness": 0.9681395360097378, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9659485859231115, 0.9720492698836137, 0.966420752222488], "final_y": [0.16652431679552193, 0.1659350259158957, 0.16629189489450202]}, "mutation_prompt": null}
{"id": "30c745bd-176c-4538-805a-1ce4bf86f47e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.25, population.shape)  # changed 0.2 to 0.25\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Improved exploration by increasing the opposition-based learning parameter to boost search capabilities.", "configspace": "", "generation": 94, "fitness": 0.9681395360097378, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9659485859231115, 0.9720492698836137, 0.966420752222488], "final_y": [0.16652431679552193, 0.1659350259158957, 0.16629189489450202]}, "mutation_prompt": null}
{"id": "8c2bf21b-a245-4284-8e00-5624aeb90599", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            dynamic_rate = np.random.rand() * 0.4 + 0.1  # Changed to add variability\n            opposite_population = lb + ub - population + np.random.normal(0, dynamic_rate, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.3 * np.random.rand()  # Fine-tuned mutation range\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * 0.1  # Increased mutation impact\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced Adaptive Opposition-Based Evolutionary Algorithm with dynamic opposition strategy, improved diversity maintenance, and fine-tuned mutation.", "configspace": "", "generation": 95, "fitness": 0.9606139137427413, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.007. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.965027132636533, 0.9661195534481686, 0.9506950551435221], "final_y": [0.16864493309777373, 0.16606161570578382, 0.17216496078540355]}, "mutation_prompt": null}
{"id": "a85486fc-b5e5-4d1c-bcf1-fbbc94e0693a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.15, population.shape)  # modified to 0.15\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.05 + 0.3 * np.random.rand()  # adjusted range to 0.05 to 0.35\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.1  # modified mutation scale\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with adaptive elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            elite_size = int(self.population_size * 0.9)  # modified to retain 90% of top solutions\n            best_indices = np.argsort(combined_fitness)[:elite_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Optimized Enhanced Adaptive Opposition-Based Evolutionary Algorithm with dynamic learning rates and adaptive elitism for improved convergence speed and solution quality.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 28 is out of bounds for axis 0 with size 27').", "error": "IndexError('index 28 is out of bounds for axis 0 with size 27')", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {}, "mutation_prompt": null}
{"id": "a0f1a0b4-2449-4048-996e-e5c376fe546d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.2, population.shape)  # changed 0.1 to 0.2\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:int(self.population_size * 1.1)]  # increased population size by 10%\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Refined Enhanced Adaptive Opposition-Based Evolutionary Algorithm with improved dynamic population size strategy for better exploration-exploitation balance.", "configspace": "", "generation": 97, "fitness": 0.9664127816455993, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.004. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9690854805340845, 0.9693049807030445, 0.9608478836996686], "final_y": [0.16565828965439977, 0.1673620980426661, 0.16644883241122133]}, "mutation_prompt": null}
{"id": "426713b7-ac5f-49a0-a455-37c7ea78968a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            scaling_factor = 0.5 + 0.5 * np.random.rand()  # New adaptive scaling factor\n            opposite_population = lb + ub - population * scaling_factor + np.random.normal(0, 0.2, population.shape)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Introducing an adaptive opposition-based scaling factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.9624526393120285, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.008. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9689524129750228, 0.9508243955490014, 0.9675811094120613], "final_y": [0.16757478608948817, 0.16652615234679247, 0.16643171874628315]}, "mutation_prompt": null}
{"id": "d459c1e1-8c8f-474a-950a-172fa910a8eb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveOppositionEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Opposition learning rate\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic opposition-based learning\n            opposite_population = lb + ub - population + np.random.normal(0, 0.1, population.shape)  # changed 0.2 to 0.1\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n\n            # Adaptive parameter tuning\n            self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n            self.mutation_rate = 0.1 + 0.4 * np.random.rand()\n\n            # Generate offspring\n            offspring = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    parent1, parent2 = population[parents]\n                    child = np.clip(parent1 + self.alpha * (parent2 - parent1), lb, ub)\n                    if np.random.rand() < self.mutation_rate:\n                        mutation = np.random.uniform(-1, 1, self.dim) * (ub - lb) * 0.05\n                        child = np.clip(child + mutation, lb, ub)\n                    offspring.append(child)\n\n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Combine and select next generation with elitism\n            combined_population = np.vstack((population, opposite_population, offspring))\n            combined_fitness = np.hstack((fitness, opposite_fitness, offspring_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[np.argmin(fitness)]", "name": "EnhancedAdaptiveOppositionEvolutionaryAlgorithm", "description": "Enhanced exploration and exploitation balance by adjusting opposition learning perturbation.", "configspace": "", "generation": 99, "fitness": 0.9699886314842745, "feedback": "The algorithm EnhancedAdaptiveOppositionEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "dfa68a4f-bd9e-455e-9bf9-ab3098429517", "metadata": {"aucs": [0.9672909360434222, 0.9737728054300785, 0.9689021529793227], "final_y": [0.16681525358772564, 0.16532657765218928, 0.16644809828904805]}, "mutation_prompt": null}
