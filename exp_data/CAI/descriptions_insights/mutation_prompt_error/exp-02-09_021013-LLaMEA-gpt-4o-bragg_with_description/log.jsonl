{"id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "A novel multi-stage adaptive gradient descent algorithm using stochastic sampling to explore and exploit the search space efficiently for optimal reflectivity in layered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.17269546079170406, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.887 (0. is the best) with standard deviation 0.108.", "error": "", "parent_id": null, "metadata": {"aucs": [0.18067212168008773, 0.16749111903145164, 0.1699231416635728], "final_y": [0.7377275451490993, 0.9876231070096514, 0.9359275201724241]}, "mutation_prompt": null}
{"id": "1bba9b5c-38c7-43e8-ab58-5a8c8024b742", "solution": "import numpy as np\n\nclass EnhancedAdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size, momentum, and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum_factor = 0.9\n        velocity = np.zeros(self.dim)\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation with momentum\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocity with momentum\n            velocity = momentum_factor * velocity + step_size * gradient\n            current_solution += velocity\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "EnhancedAdaptiveGradientDescent", "description": "An enhanced adaptive gradient descent algorithm incorporating momentum and adaptive exploration for improved convergence in optimizing layered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.17266572019286466, "feedback": "The algorithm EnhancedAdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060705980119052, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390040512621785, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "686d2934-b41d-48ba-8f84-21568af53374", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        exploration_decay = 0.99  # New line\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n            exploration_factor *= exploration_decay  # New line\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Enhanced multi-stage adaptive gradient descent algorithm with adaptive exploration factor to optimize layered photonic structures more effectively.", "configspace": "", "generation": 2, "fitness": 0.1726733862731773, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18062429219651133, 0.16748487884062013, 0.16991098778240044], "final_y": [0.738715274219207, 0.9877783872445356, 0.9361828586249001]}, "mutation_prompt": null}
{"id": "aba43660-0188-4938-81b5-ef5f3fcc307d", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = np.zeros(self.dim)  # Momentum term\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update with momentum\n            momentum = 0.9 * momentum + step_size * gradient\n            current_solution += momentum\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Enhanced adaptive gradient descent with momentum integration to improve convergence speed and robustness.", "configspace": "", "generation": 3, "fitness": 0.17266572019286466, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060705980119052, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390040512621785, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "aba97bf7-457e-4417-b81c-55cf534e34e8", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n                exploration_factor = max(0.01, exploration_factor * 0.9)  # Adjust exploration factor\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Enhanced multi-stage adaptive gradient descent algorithm with dynamic exploration adjustment for improved reflectivity optimization in layered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.17266075702927708, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060082197137817, 0.1674832513240424, 0.16989819779241067], "final_y": [0.7391062403209367, 0.9878139876729711, 0.9364494585614798]}, "mutation_prompt": null}
{"id": "a5db2437-6d5a-48e1-8473-2dc6ba44f005", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size, adaptive parameters, and momentum\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = 0.9  # Added momentum factor\n        velocity = np.zeros(self.dim)  # Velocity for momentum update\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update with momentum\n            velocity = momentum * velocity + step_size * gradient\n            current_solution += velocity\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Improved AdaptiveGradientDescent by incorporating momentum to enhance convergence speed and accuracy.", "configspace": "", "generation": 5, "fitness": 0.17266572019286466, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060705980119052, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390040512621785, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "b5c42225-01d3-46b3-9dc5-563d9f59bb62", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn() * (1 - evaluations / self.budget)  # Dynamic exploration\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update with smoothing\n            gradient = 0.5 * gradient + 0.5 * np.random.randn(self.dim) * exploration_factor\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Enhanced adaptive gradient descent with dynamic exploration factor and adaptive gradient smoothing for improved optimization.", "configspace": "", "generation": 6, "fitness": 0.1726810317476564, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.887 (0. is the best) with standard deviation 0.108.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.1806481234149464, 0.16748970363502524, 0.16990526819299756], "final_y": [0.7383237096926427, 0.9876685619994682, 0.9363030400756827]}, "mutation_prompt": null}
{"id": "13d6fe73-ce4d-48a8-952c-abba181adc72", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.05  # Reduced exploration factor for finer search\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size with slight boost\n            step_size *= decay_rate * 1.05  # Slight boost in decay to quickly respond to gradients\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "An enhanced adaptive gradient descent using stochastic sampling and dynamic exploration to optimize layered photonic structures with high efficiency.", "configspace": "", "generation": 7, "fitness": 0.1726460838086649, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18059073349357935, 0.1674775783121797, 0.16986993962023567], "final_y": [0.7392692040085158, 0.9879376364771593, 0.9370348759489517]}, "mutation_prompt": null}
{"id": "9ce0c3fa-7147-4c9d-89a6-520483ab3fdb", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = 0.9\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n        velocity = np.zeros(self.dim)\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update with momentum\n            velocity = momentum * velocity + step_size * gradient\n            current_solution += velocity\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size and adjust exploration factor\n            step_size *= decay_rate\n            exploration_factor *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "An enhanced adaptive gradient descent utilizing dynamic exploration factor adjustment and momentum to navigate complex optimization landscapes more effectively.", "configspace": "", "generation": 8, "fitness": 0.17266493844485373, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060471455715765, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390426142841124, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "8a4e4f0f-a308-40d5-8040-33526152fe74", "solution": "import numpy as np\n\nclass HybridStochasticAdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define CMA-ES inspired parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        cov_matrix = np.eye(self.dim)\n        \n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation with covariance adaptation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = exploration_factor * np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update covariance matrix based on gradient\n            cov_matrix = np.cov(np.vstack([current_solution, gradient]), rowvar=False)\n\n            # Adaptive step update\n            current_solution += step_size * np.dot(cov_matrix, gradient)\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "HybridStochasticAdaptiveGradientDescent", "description": "A hybrid stochastic adaptive gradient descent algorithm integrates a covariance matrix adaptation strategy and adaptive step sizes to efficiently navigate the search space and improve reflectivity in layered photonic structures.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: LinAlgError('SVD did not converge').", "error": "LinAlgError('SVD did not converge')", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {}, "mutation_prompt": null}
{"id": "29b8753f-5c9b-484c-9553-e3059c05f6b2", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Adjust exploration factor dynamically\n            dynamic_exploration = exploration_factor * (1.0 - evaluations / self.budget)\n            \n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = dynamic_exploration * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "A refined adaptive gradient descent algorithm enhancing exploration using dynamic perturbation scaling for optimizing layered photonic structures.", "configspace": "", "generation": 10, "fitness": 0.17268493266251742, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.887 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18064405638854897, 0.16748903021522188, 0.16992171138378143], "final_y": [0.738383604366609, 0.9876855633702502, 0.9359575628388808]}, "mutation_prompt": null}
{"id": "a4e8ac8a-0202-41c8-b86c-6f8d27c9d2ca", "solution": "import numpy as np\n\nclass EnhancedAdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size, momentum, and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = 0.9\n        velocity = np.zeros(self.dim)\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocity with momentum\n            velocity = momentum * velocity + step_size * gradient\n\n            # Adaptive step update with momentum\n            current_solution += velocity\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "EnhancedAdaptiveGradientDescent", "description": "An enhanced adaptive gradient descent algorithm integrating a momentum mechanism to accelerate convergence and improve exploration-exploitation balance in optimizing layered photonic structures.", "configspace": "", "generation": 11, "fitness": 0.17266572019286466, "feedback": "The algorithm EnhancedAdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060705980119052, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390040512621785, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "b06fee17-b8a2-4462-ba3d-4a299576e923", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Dynamic exploration factor and warm restarts\n            exploration_factor = 0.1 * (1 - evaluations / self.budget)\n            if evaluations % (self.budget // 5) == 0:\n                current_solution = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "This refined adaptive gradient descent algorithm introduces a dynamic exploration factor and warm restarts to improve the search space exploration and convergence rate.", "configspace": "", "generation": 12, "fitness": 0.1726849398757482, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.887 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.1806440657231746, 0.16748903248599656, 0.1699217214180735], "final_y": [0.7383834497264339, 0.9876855134148979, 0.9359573542314579]}, "mutation_prompt": null}
{"id": "75422d3e-b53b-4385-ab27-f8ad7c7d175a", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n            exploration_factor *= 0.98  # Refine by dynamically reducing exploration\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "Enhanced Adaptive Gradient Descent with dynamic exploration factor for better exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.17266619861586943, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060849507020482, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7389804520226203, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "1ca105d7-0f1d-4850-a006-f966d78e1260", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size, momentum, and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = 0.9\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n        \n        # Initialize velocity for momentum\n        velocity = np.zeros(self.dim)\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update with momentum\n            velocity = momentum * velocity + step_size * gradient\n            current_solution += velocity\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "An enhanced adaptive gradient descent algorithm utilizing momentum to improve convergence speed and solution quality in layered photonic structure optimization.", "configspace": "", "generation": 14, "fitness": 0.17266572019286466, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060705980119052, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390040512621785, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "2d11ac4f-82e2-4ba9-8064-86cd7e3f3f9e", "solution": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size and adaptive parameters\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn()\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive step update\n            current_solution += step_size * gradient\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n            # Update exploration factor dynamically\n            exploration_factor *= 0.9\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "AdaptiveGradientDescent", "description": "A refined adaptive gradient descent with a dynamic exploration factor that enhances exploitation and exploration balance for optimal reflectivity.", "configspace": "", "generation": 15, "fitness": 0.17266493844485373, "feedback": "The algorithm AdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060471455715765, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7390426142841124, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "4c56496e-f3a2-45a2-99fe-8665bd3ce87a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        best_solution = None\n        best_value = float('-inf')\n        evaluations = 0\n        \n        # Define step size, decay rate, and exploration factor\n        step_size = 0.1\n        decay_rate = 0.95\n        exploration_factor = 0.1\n        momentum = np.zeros(self.dim)\n        momentum_factor = 0.9\n\n        # Initialize random solution within bounds\n        current_solution = np.random.uniform(\n            func.bounds.lb, func.bounds.ub, self.dim\n        )\n\n        while evaluations < self.budget:\n            # Evaluate current solution\n            current_value = func(current_solution)\n            evaluations += 1\n\n            # Update best solution if current is better\n            if current_value > best_value:\n                best_value = current_value\n                best_solution = current_solution.copy()\n\n            # Generate stochastic gradient approximation with dynamic perturbation\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                perturbation = np.zeros(self.dim)\n                perturbation[i] = exploration_factor * np.random.randn() * (1 + np.abs(momentum[i]))\n                perturbed_solution = np.clip(\n                    current_solution + perturbation,\n                    func.bounds.lb, func.bounds.ub\n                )\n                gradient[i] = (func(perturbed_solution) - current_value) / perturbation[i]\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update momentum\n            momentum = momentum_factor * momentum + gradient\n\n            # Adaptive step update with momentum\n            current_solution += step_size * momentum\n            current_solution = np.clip(current_solution, func.bounds.lb, func.bounds.ub)\n            \n            # Decay step size\n            step_size *= decay_rate\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return best_solution, best_value", "name": "EnhancedAdaptiveGradientDescent", "description": "An enhanced adaptive stochastic gradient search with dynamic perturbation scaling and memory-based momentum for improved convergence in multilayer photonic structure optimization.", "configspace": "", "generation": 16, "fitness": 0.17266627634711554, "feedback": "The algorithm EnhancedAdaptiveGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.173 with standard deviation 0.006. And the mean value of best solutions found was 0.888 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.18060872826394314, 0.16748481840705554, 0.16990528237034797], "final_y": [0.7389766178374795, 0.9877797439861729, 0.9363027465091511]}, "mutation_prompt": null}
{"id": "f46bec4c-b8f6-4ce5-a34a-346fc1de5ba8", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.1\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Quantum-Inspired Particle Swarm (QIPS) optimization integrates quantum probability amplitudes to enhance global exploration for optimal reflectivity in multilayered photonic structures.", "configspace": "", "generation": 17, "fitness": 0.22398354396497747, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.006. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "f5693bdb-1bb1-4282-83df-b9b77bbd4af6", "metadata": {"aucs": [0.22208979615008828, 0.21796634660212744, 0.2318944891427167], "final_y": [0.2942982974174664, 0.3230409744512964, 0.23013718737674393]}, "mutation_prompt": null}
{"id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm by adjusting the quantum perturbation probability for better exploration.", "configspace": "", "generation": 18, "fitness": 0.2251498269542266, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.005. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "f46bec4c-b8f6-4ce5-a34a-346fc1de5ba8", "metadata": {"aucs": [0.23013497559812313, 0.21796634660212744, 0.2273481586624293], "final_y": [0.2402720592867048, 0.3230409744512964, 0.26117065409347984]}, "mutation_prompt": null}
{"id": "394e4994-a085-40c4-b9fb-6d9faedecb0f", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Dynamic adjustment of parameters\n            quantum_prob = 0.2 + 0.5 * (evaluations / self.budget)\n            omega = 0.5 - 0.3 * (evaluations / self.budget)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm with dynamic adjustment of quantum probability and inertia weight for improved exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.21914996581242097, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.005. And the mean value of best solutions found was 0.313 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21388960359144238, 0.21796634660212744, 0.22559394724369308], "final_y": [0.3425380667512614, 0.3230409744512964, 0.27205123480797067]}, "mutation_prompt": null}
{"id": "f335636a-c868-428e-8f04-b2eec1d7d15f", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_individuals = 50\n        evaluations = 0\n        F = 0.5  # Mutation factor\n        CR = 0.9  # Crossover rate\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_individuals, self.dim))\n        fitness = np.full(num_individuals, float('-inf'))\n\n        # Evaluate initial population\n        for i in range(num_individuals):\n            fitness[i] = func(population[i])\n            evaluations += 1\n\n        while evaluations < self.budget:\n            for i in range(num_individuals):\n                # Select indices for mutation\n                indices = np.random.choice(num_individuals, 3, replace=False)\n                x1, x2, x3 = population[indices[0]], population[indices[1]], population[indices[2]]\n\n                # Mutate and Crossover\n                mutant = x1 + F * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select between trial and current individual\n                if trial_fitness > fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic mutation factor adjustment based on convergence\n            if evaluations % (self.budget // 10) == 0:\n                F = 0.5 + 0.3 * (1 - evaluations / self.budget)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        best_idx = np.argmax(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridDifferentialEvolution", "description": "Hybrid Differential Evolution with Adaptive Focus, integrating both global and local search by dynamically adjusting mutation rates based on convergence progress for diverse exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.215421627439351, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.215 with standard deviation 0.003. And the mean value of best solutions found was 0.319 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21669456428243217, 0.21169225340659426, 0.2178780646290266], "final_y": [0.3179863297585168, 0.3294690189456577, 0.3105783168764097]}, "mutation_prompt": null}
{"id": "7948ed6b-5fa7-49fc-b29f-3168e86f1b1e", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_initial = 0.9  # Adaptive inertia weight start\n        omega_final = 0.4  # Adaptive inertia weight end\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            omega = omega_initial - (omega_initial - omega_final) * (evaluations / self.budget)  # Adaptive inertia\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm by integrating adaptive inertia weight for dynamic exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.21675848418828295, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.327 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.20910918520421862, 0.21799959194345653, 0.22316667541717372], "final_y": [0.36963748708990174, 0.32280285198465997, 0.2878341570437133]}, "mutation_prompt": null}
{"id": "72073628-b58f-428a-b755-cff801877e61", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (num_particles, self.dim))  # Better velocity scale\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            quantum_prob = max(0.1, quantum_prob * 0.99)  # Dynamic adjustment of quantum probability\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Improved exploration by dynamically adjusting quantum probability and better velocity initialization.", "configspace": "", "generation": 22, "fitness": 0.21907685099338517, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.004. And the mean value of best solutions found was 0.316 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21476556838367034, 0.21795416535527978, 0.22451081924120542], "final_y": [0.34594706086549876, 0.32266599541505103, 0.27930038694569914]}, "mutation_prompt": null}
{"id": "2d6f0da3-9a99-46ec-a5cd-4a1d5eaa0ade", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            # Adaptively adjust inertia weight\n            omega = 0.9 - (0.5 * evaluations / self.budget)\n\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm by introducing adaptive inertia weight for improved convergence.", "configspace": "", "generation": 23, "fitness": 0.21675848418828295, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.327 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.20910918520421862, 0.21799959194345653, 0.22316667541717372], "final_y": [0.36963748708990174, 0.32280285198465997, 0.2878341570437133]}, "mutation_prompt": null}
{"id": "e1928d15-0a93-495f-b0c3-6f131d0b030c", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_initial = 0.9  # Dynamic inertia weight (initial)\n        omega_final = 0.4    # Dynamic inertia weight (final)\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Calculate dynamic inertia weight\n                omega = omega_initial - (omega_initial - omega_final) * (evaluations / self.budget)\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm with dynamic inertia weight for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.21672448979981118, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.334 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.20900587578858476, 0.21799947902909722, 0.22316811458175156], "final_y": [0.3920577599972016, 0.3228036604465653, 0.28782497003000973]}, "mutation_prompt": null}
{"id": "38465c62-4139-46c0-9bdc-af1202fa40b0", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_initial = 0.9  # Initial inertia weight\n        omega_final = 0.4  # Final inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            # Dynamic inertia weight calculation\n            omega = omega_initial - (omega_initial - omega_final) * (evaluations / self.budget)\n            \n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Improved Quantum-Inspired Particle Swarm by modifying inertia weight dynamically for better balance between exploration and exploitation.", "configspace": "", "generation": 25, "fitness": 0.21675848418828295, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.327 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.20910918520421862, 0.21799959194345653, 0.22316667541717372], "final_y": [0.36963748708990174, 0.32280285198465997, 0.2878341570437133]}, "mutation_prompt": null}
{"id": "52d36591-1fb0-482f-8c0e-aa23574da437", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            phi_p = 0.5 + evaluations / (2 * self.budget)  # Dynamic update of phi_p\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Differential Evolution component\n                if np.random.rand() < 0.1:  # Probability for applying DE\n                    a, b, c = np.random.choice(num_particles, 3, replace=False)\n                    mutant_vector = particles[a] + 0.8 * (particles[b] - particles[c])\n                    mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                    if func(mutant_vector) > func(particles[i]):\n                        particles[i] = mutant_vector\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Introduce dynamic adaptation of PSO parameters and hybridize with differential evolution for enhancing exploration-exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.22169732361018527, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.004. And the mean value of best solutions found was 0.297 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.2166914778324106, 0.22264131977502144, 0.22575917322312378], "final_y": [0.33160887970620323, 0.288032416974464, 0.27124717832448]}, "mutation_prompt": null}
{"id": "0d0a6aef-527c-4d30-a413-f11cf0e7396f", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.7  # Inertia weight\n        phi_p = 0.6  # Personal influence\n        phi_g = 0.7  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm by tuning hyperparameters to improve exploration and convergence.", "configspace": "", "generation": 27, "fitness": 0.21770898293202526, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.004. And the mean value of best solutions found was 0.318 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21309729668107957, 0.21651451023191315, 0.22351514188308308], "final_y": [0.3373254240536554, 0.33043317435767827, 0.2854826307938174]}, "mutation_prompt": null}
{"id": "fac2ffc6-00d3-458d-8626-1fc4046457e5", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_start = 0.9  # Adaptive inertia weight start\n        omega_end = 0.4  # Adaptive inertia weight end\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            # Calculate adaptive inertia weight\n            omega = omega_end + (omega_start - omega_end) * ((self.budget - evaluations) / self.budget)\n\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Quantum-Inspired Particle Swarm with Adaptive Inertia Weight for Improved Convergence.", "configspace": "", "generation": 28, "fitness": 0.21675848418828295, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.006. And the mean value of best solutions found was 0.327 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.20910918520421862, 0.21799959194345653, 0.22316667541717372], "final_y": [0.36963748708990185, 0.32280285198465997, 0.2878341570437133]}, "mutation_prompt": null}
{"id": "41303b41-196d-4101-b56f-9d9d8860fd96", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.6  # Personal influence\n        phi_g = 0.6  # Global influence\n        quantum_prob = 0.2  # Adjusted for better exploration\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation\n                if np.random.rand() < quantum_prob:\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - global_best_position))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "QuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm by fine-tuning the personal and global influence factors for better convergence.", "configspace": "", "generation": 29, "fitness": 0.2183180854312702, "feedback": "The algorithm QuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.005. And the mean value of best solutions found was 0.317 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21376678086447098, 0.21630459582945227, 0.2248828795998874], "final_y": [0.33789373849040805, 0.33516994345210904, 0.27698816044891905]}, "mutation_prompt": null}
{"id": "ab3b94b8-bbd8-4f75-99ac-e97e71d243db", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved Quantum-Inspired Particle Swarm with Adaptive Quantum Probability and Elite Memory for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 30, "fitness": 0.2271720318437979, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.007. And the mean value of best solutions found was 0.263 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "75c8046c-fb89-4610-a21a-76afa1ca73c8", "metadata": {"aucs": [0.21770219107803335, 0.23331958206997871, 0.23049432238338163], "final_y": [0.3246428241890248, 0.22107494440446485, 0.24452722063540866]}, "mutation_prompt": null}
{"id": "b85ac7f1-759a-4877-9f0d-985624945710", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_init = 0.9  # Initial inertia weight\n        omega_final = 0.4  # Final inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 10  # Increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)\n            \n            # Calculate dynamic inertia weight\n            omega = omega_init - (omega_init - omega_final) * (evaluations / self.budget)\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced Improved Quantum-Inspired Particle Swarm with Dynamic Inertia Weight and Increased Elite Memory for Optimized Exploration and Exploitation.", "configspace": "", "generation": 31, "fitness": 0.217899909740178, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.004. And the mean value of best solutions found was 0.325 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "ab3b94b8-bbd8-4f75-99ac-e97e71d243db", "metadata": {"aucs": [0.2125321356096852, 0.21799947902909722, 0.22316811458175156], "final_y": [0.3639264482379727, 0.3228036604465653, 0.28782497003000973]}, "mutation_prompt": null}
{"id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced Adaptation by Dynamic Elite Memory Sizing and Adaptive Quantum Influence to Improve Exploration-Exploitation Balance.", "configspace": "", "generation": 32, "fitness": 0.2281630510914918, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.001. And the mean value of best solutions found was 0.252 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ab3b94b8-bbd8-4f75-99ac-e97e71d243db", "metadata": {"aucs": [0.22809350793387306, 0.22888913499656005, 0.22750651034404223], "final_y": [0.24729041285030284, 0.2462443850413567, 0.2612030308868052]}, "mutation_prompt": null}
{"id": "a708731f-7457-4ca5-b6d6-0e8254048229", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init * (1 - (evaluations / self.budget)**2) + quantum_prob_final  # Non-linear decay function\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved Exploration by Adjusting Quantum Influence with a Non-Linear Decay Function.", "configspace": "", "generation": 33, "fitness": 0.22321167191610106, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.004. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "metadata": {"aucs": [0.22475330166792717, 0.21796634660212744, 0.2269153674782486], "final_y": [0.27656920470171786, 0.3230409744512964, 0.26481175299016824]}, "mutation_prompt": null}
{"id": "90bf229e-1dc5-42a9-8363-5211e85bf6f0", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5 + (0.5 * (evaluations / self.budget))  # Global influence dynamically increased over time\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved exploration by adjusting global influence to dynamically increase over time.", "configspace": "", "generation": 34, "fitness": 0.2281630510914918, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.001. And the mean value of best solutions found was 0.252 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "metadata": {"aucs": [0.22809350793387306, 0.22888913499656005, 0.22750651034404223], "final_y": [0.24729041285030284, 0.2462443850413567, 0.2612030308868052]}, "mutation_prompt": null}
{"id": "dc674dec-1345-45c2-a269-88ed78a2f6a9", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega_initial = 0.9  # Initial inertia weight\n        omega_final = 0.4    # Final inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n            \n            # Calculate adaptive inertia weight\n            omega = omega_initial - ((omega_initial - omega_final) * (evaluations / self.budget))\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced diversity by dynamically varying inertia weight (omega) to improve exploration-exploitation trade-off.", "configspace": "", "generation": 35, "fitness": 0.220168347831999, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.220 with standard deviation 0.003. And the mean value of best solutions found was 0.307 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "metadata": {"aucs": [0.21817553047113536, 0.21799947902909722, 0.22433003399576446], "final_y": [0.3185524412493753, 0.3228036604465653, 0.2803832619533454]}, "mutation_prompt": null}
{"id": "ee3dafea-b206-45dc-b64f-3ce5c198f109", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * ((evaluations / self.budget) ** 1.3)  # Modified adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = (np.random.uniform(-1, 1, self.dim) \n                                     * (particles[i] - random_elite_member))\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Optimize the adaptive quantum probability calculation for enhanced exploration-exploitation balance in the particle swarm.", "configspace": "", "generation": 36, "fitness": 0.2263902901554823, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.001. And the mean value of best solutions found was 0.264 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "metadata": {"aucs": [0.2247277420868461, 0.22693661803555853, 0.22750651034404223], "final_y": [0.2655537195901879, 0.2637958416424627, 0.2612030308868052]}, "mutation_prompt": null}
{"id": "4cb8645f-8c74-4bb2-a50e-a74664b74351", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Introduced inertia weight decay and diversified quantum perturbation to enhance convergence dynamics and solution diversity.", "configspace": "", "generation": 37, "fitness": 0.22973346955707588, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.004. And the mean value of best solutions found was 0.245 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "5b8746d7-e0f8-458d-82cf-84da3b39eb9a", "metadata": {"aucs": [0.22989423153862432, 0.23398510356629587, 0.22532107356630748], "final_y": [0.24299298109014378, 0.21883498170412952, 0.27427299866364563]}, "mutation_prompt": null}
{"id": "e00e121b-e62a-434c-956d-bbdf114eb4f8", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Initial quantum probability\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.3  # Adjusted adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum probability adaptation by modifying its decay rate, improving exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.22933488344274114, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.003. And the mean value of best solutions found was 0.246 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "4cb8645f-8c74-4bb2-a50e-a74664b74351", "metadata": {"aucs": [0.22949888595406587, 0.2331846908078501, 0.22532107356630748], "final_y": [0.2416741978059188, 0.22237667597660493, 0.27427299866364563]}, "mutation_prompt": null}
{"id": "60e72efa-d55f-4f59-9d37-7950a45c827b", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability (increased slightly)\n        quantum_prob_final = 0.05  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.2 * self.dim)  # Slightly increased dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    random_elite_member = elite_memory_positions[np.random.randint(0, elite_memory_size)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation and adaptive elite memory for improved convergence and solution diversity.", "configspace": "", "generation": 39, "fitness": 0.22815158026676205, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.004. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "4cb8645f-8c74-4bb2-a50e-a74664b74351", "metadata": {"aucs": [0.22201020813596484, 0.23079785785959606, 0.23164667480472523], "final_y": [0.29418331400954345, 0.2426143287271687, 0.23260959116642654]}, "mutation_prompt": null}
{"id": "b16bd9b7-fb55-4b9b-a4f5-be9c392f5f61", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.argmax(elite_memory_values[elite_indices])]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation and particle selection mechanism to improve convergence and global search capabilities.", "configspace": "", "generation": 40, "fitness": 0.23050249813175663, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.003. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "4cb8645f-8c74-4bb2-a50e-a74664b74351", "metadata": {"aucs": [0.234485931763594, 0.22852305934111306, 0.22849850329056287], "final_y": [0.22285939050939707, 0.25200696451591964, 0.2546199016000096]}, "mutation_prompt": null}
{"id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation with elite sampling and variable inertia for improved diversification.", "configspace": "", "generation": 41, "fitness": 0.23314634635811485, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.006. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "b16bd9b7-fb55-4b9b-a4f5-be9c392f5f61", "metadata": {"aucs": [0.238528951875968, 0.22504887328161038, 0.23586121391676618], "final_y": [0.20117597095386663, 0.27529097448689965, 0.21375520213331478]}, "mutation_prompt": null}
{"id": "a673cc6c-f82e-4a6f-bc94-1326fe341a6b", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Adaptive local search adjustment\n                local_search_prob = 0.1 * (1 - evaluations / self.budget)\n                if np.random.rand() < local_search_prob:\n                    velocities[i] += 0.1 * (particles[i] - np.mean(particles, axis=0))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Integrate adaptive local search with quantum perturbations for enhanced local convergence.", "configspace": "", "generation": 42, "fitness": 0.22216740228048218, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.013. And the mean value of best solutions found was 0.303 (0. is the best) with standard deviation 0.089.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.21958089719995644, 0.20714669410893105, 0.23977461553255908], "final_y": [0.3063042817092183, 0.4106382404411585, 0.19158430827903217]}, "mutation_prompt": null}
{"id": "c9c50467-c300-4e0f-b37d-fb6fffbd7551", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.7 - 0.4 * (evaluations / self.budget)  # Adjusted inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation with elite sampling and adaptive inertia for improved diversification.", "configspace": "", "generation": 43, "fitness": 0.22382687884246266, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.003. And the mean value of best solutions found was 0.280 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.2271667300662361, 0.2199541041588361, 0.22435980230231578], "final_y": [0.2598750090620082, 0.30110564460815725, 0.2802987208919452]}, "mutation_prompt": null}
{"id": "f54abdcf-279d-4abb-8644-e3f38e925d7d", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.05  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory with adaptive strategy\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 2.0\n\n            for i in range(num_particles):\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum-inspired perturbation with dynamic exploration-exploitation balance and adaptive memory management for improved search efficiency.", "configspace": "", "generation": 44, "fitness": 0.22326332608352373, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.004. And the mean value of best solutions found was 0.285 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.21859528261566197, 0.22250949833057154, 0.22868519730433767], "final_y": [0.3155162164637878, 0.28515892918653496, 0.25339839114727813]}, "mutation_prompt": null}
{"id": "470dc729-f73a-4161-b848-ded6818d0abc", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n\n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n\n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n\n        global_best_position = None\n        global_best_value = float('-inf')\n\n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.7  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.2 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Quantum-Inspired Particle Swarm with Dynamic Elite Memory and Adaptive Perturbation for Enhanced Exploration.", "configspace": "", "generation": 45, "fitness": 0.23215454117768905, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.005. And the mean value of best solutions found was 0.235 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23842097547431618, 0.22509718894500652, 0.23294545911374442], "final_y": [0.20168076927533962, 0.27499075696951314, 0.22834188896342933]}, "mutation_prompt": null}
{"id": "c4e9ba05-002b-4545-9490-9059b49507e8", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.7  # Global influence increased\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 6 + int(0.1 * self.dim)  # Slightly increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Incorporate enhanced global influence and adaptive elite memory to improve convergence speed and solution quality.", "configspace": "", "generation": 46, "fitness": 0.22621912375353545, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.012. And the mean value of best solutions found was 0.276 (0. is the best) with standard deviation 0.079.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.20988193862966875, 0.23766197625373242, 0.23111345637720515], "final_y": [0.3865029553654301, 0.2035025719064898, 0.23800446435278777]}, "mutation_prompt": null}
{"id": "29033c51-4d99-4877-9013-a2c441e04e93", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.7  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced dynamic quantum probability control for better convergence in variable complex landscapes.", "configspace": "", "generation": 47, "fitness": 0.23234492022507425, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.006. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.238528951875968, 0.22504887328161038, 0.23345693551764435], "final_y": [0.20117597095386663, 0.27529097448689965, 0.2252575380136731]}, "mutation_prompt": null}
{"id": "8a463994-8870-4331-80e7-bbe3b461fa83", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.6  # Adjusted adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)  # Further diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced elite memory update and diversified velocity with adaptive quantum probability.", "configspace": "", "generation": 48, "fitness": 0.23224319346737488, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.006. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23842462791212615, 0.22506215061433865, 0.23324280187565982], "final_y": [0.2016715797323676, 0.27520844006498735, 0.2260775926696158]}, "mutation_prompt": null}
{"id": "9517fbe7-1da0-4f98-85f7-c25ba2842cb4", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_weights = elite_memory_values / elite_memory_values.sum()  # Weighted selection\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False, p=elite_weights)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced elite memory selection using a weighted probability approach for improved convergence.", "configspace": "", "generation": 49, "fitness": 0.23103954407167612, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.003. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22620181595086952, 0.23332410796069003, 0.2335927083034688], "final_y": [0.26052869634362463, 0.21195661564750412, 0.22528255335785874]}, "mutation_prompt": null}
{"id": "fded5271-3f31-4bb7-b124-848e2fe9a996", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        # Introduce chaotic map for exploration\n        chaotic_map = np.random.uniform(0, 1, num_particles)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n                \n                # Integrate chaotic map for exploration\n                velocities[i] *= chaotic_map[i]\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Update chaotic map\n                chaotic_map[i] = 4 * chaotic_map[i] * (1 - chaotic_map[i])  # Logistic map for chaos\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation with elite sampling and adaptive exploration using chaotic maps for improved diversification.", "configspace": "", "generation": 50, "fitness": 0.2320758681584141, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.006. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22400729615515058, 0.23251072479263024, 0.23970958352746152], "final_y": [0.2774294805835531, 0.22381597870750725, 0.18810474911145625]}, "mutation_prompt": null}
{"id": "a49bf275-49e4-4ac6-a88b-efa35f64d7b6", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Adjusted elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2, 2, self.dim)  # Further diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved Quantum-Inspired Particle Swarm with adaptive elite memory size and refined velocity update for enhanced exploration and convergence.", "configspace": "", "generation": 51, "fitness": 0.23287363239587736, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.006. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23842462791212615, 0.22506215061433865, 0.2351341186611673], "final_y": [0.2016715797323676, 0.27520844006498735, 0.21757342463912122]}, "mutation_prompt": null}
{"id": "bdac8735-08ef-4a31-b46c-ce448935b58b", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = max(30, int(0.1 * self.budget))  # Dynamic particle count\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.2 * self.dim)  # Increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Refined quantum swarm using dynamic particle count and adaptive elite memory for enhanced solution quality.", "configspace": "", "generation": 52, "fitness": 0.23141074853202123, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.003. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23019513791577395, 0.23524924166975203, 0.2287878660105377], "final_y": [0.2130533927742967, 0.19427357947849155, 0.24256529217785894]}, "mutation_prompt": null}
{"id": "e24c2cd8-488b-4663-ac0e-617b85311a68", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.35 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved quantum-inspired particle swarm with enhanced inertia decay for better exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.23313700995922873, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.006. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23853273896692906, 0.22503095227215697, 0.2358473386386002], "final_y": [0.20116211244018412, 0.2754024126214708, 0.21382598545170928]}, "mutation_prompt": null}
{"id": "441ef183-b6f4-49cc-9bd1-119931f7c20b", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.7  # Inertia weight\n        phi_p = 0.4  # Personal influence\n        phi_g = 0.6  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.7 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm with dynamic inertia and adaptive quantum perturbation for robust exploration.", "configspace": "", "generation": 54, "fitness": 0.22461096895471, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.006. And the mean value of best solutions found was 0.278 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.21740477034460948, 0.23083238249100058, 0.22559575402851995], "final_y": [0.32403020098374036, 0.23686436619416662, 0.2725912108106464]}, "mutation_prompt": null}
{"id": "cc2f434e-b77d-4229-833d-9eb755c2629f", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.1  # Final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.2 * self.dim)  # Adjusted dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)  # Enhanced quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n                    velocities[i] = np.clip(velocities[i], -2.0, 2.0)  # Dynamic velocity clamping\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved quantum PSO with multi-elitism and dynamic velocity clamping for optimized diversification.", "configspace": "", "generation": 55, "fitness": 0.22507065579482968, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.002. And the mean value of best solutions found was 0.249 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.2221463454613798, 0.2271509209648297, 0.2259147009582796], "final_y": [0.2716882620293455, 0.24737977039931947, 0.22741971311046139]}, "mutation_prompt": null}
{"id": "3ab1a4c9-2a85-4ab0-b624-fd43ed6b7120", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) ** 2  # Adjusted adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.4 * (evaluations / self.budget)  # Modified inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Adaptive exploration-exploitation balance emphasizing elite memory dynamics and stochastic perturbation for enhanced optimization.", "configspace": "", "generation": 56, "fitness": 0.2325236696604869, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.005. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23853650651326597, 0.22615667624370805, 0.23287782622448672], "final_y": [0.20114830097213698, 0.2608697984179834, 0.2272030094596158]}, "mutation_prompt": null}
{"id": "9bad6d58-4040-4c5a-8e09-e5d081aa4cd6", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.2  # Decreased initial quantum probability\n        quantum_prob_final = 0.05  # Decreased final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Optimized quantum perturbation probability and elite memory update strategy for enhanced convergence.", "configspace": "", "generation": 57, "fitness": 0.23084560854147382, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.007. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22131849682232474, 0.2350800465803189, 0.2361382822217778], "final_y": [0.2967803829855028, 0.2051555857348425, 0.20715585843477513]}, "mutation_prompt": null}
{"id": "3a67c3a4-735d-4fb1-92b9-c96a829d4945", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    distances = np.linalg.norm(elite_memory_positions - particles[i], axis=1)\n                    min_distance_idx = np.argmin(distances)\n                    random_elite_member = elite_memory_positions[min_distance_idx]  # Crowding-based selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation with elite sampling, variable inertia, and crowding-based diversity control for improved diversification.", "configspace": "", "generation": 58, "fitness": 0.23314634635811485, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.006. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.238528951875968, 0.22504887328161038, 0.23586121391676618], "final_y": [0.20117597095386663, 0.27529097448689965, 0.21375520213331478]}, "mutation_prompt": null}
{"id": "8ed99d63-7a1e-4f2d-b464-72d45f83914f", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.2  # Adjusted adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=4, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Introduce dynamic adjustment of the quantum probability and enhance elite selection for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.22699615695040812, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.001. And the mean value of best solutions found was 0.258 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22632643508152084, 0.22834551390088553, 0.226316521868818], "final_y": [0.2596295701734047, 0.24803390015989313, 0.2651562737457711]}, "mutation_prompt": null}
{"id": "ee5580e6-3e28-49d6-ab58-bfd63ee5ec63", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=True)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Adaptive inertia weight decay and enhanced elite sampling for improved exploration and exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.23138033352245416, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.006. And the mean value of best solutions found was 0.239 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22302363561078342, 0.23511403575291845, 0.23600332920366063], "final_y": [0.28382136028532434, 0.2169077072678366, 0.2158038176613204]}, "mutation_prompt": null}
{"id": "a82444a9-529b-49f5-988b-d9325f37cdff", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.1 * self.dim)  # Dynamic elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position with periodic boundary management\n                particles[i] = np.mod(particles[i] + velocities[i] - func.bounds.lb, func.bounds.ub - func.bounds.lb) + func.bounds.lb\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum perturbation with elite sampling, variable inertia, and periodic boundary management for improved diversification.", "configspace": "", "generation": 61, "fitness": 0.23234441310846546, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.006. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.23846790650607685, 0.22504887328161038, 0.23351645953770916], "final_y": [0.20146198928924675, 0.27529097448689965, 0.22309859628428852]}, "mutation_prompt": null}
{"id": "77941dbd-5030-49e5-868b-500d8987b579", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.6  # Inertia weight (modified)\n        phi_p = 0.5  # Personal influence\n        phi_g = 0.7  # Global influence (modified)\n        quantum_prob_init = 0.3  # Initial quantum probability (modified)\n        quantum_prob_final = 0.05  # Final quantum probability (modified)\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 8 + int(0.1 * self.dim)  # Dynamic elite memory size (modified)\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 2.0  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=5, replace=False)  # Enhanced sampling (modified)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Inertia weight decay (modified)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum-inspired particle swarm with adaptive memory reinforcement and dynamic exploration-exploitation balance for optimal convergence.", "configspace": "", "generation": 62, "fitness": 0.2252829216233344, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.002. And the mean value of best solutions found was 0.266 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22418104135417882, 0.2281343170229425, 0.2235334064928819], "final_y": [0.27588396434204676, 0.23666932897233517, 0.28536745720139267]}, "mutation_prompt": null}
{"id": "b2174150-50c4-4ee9-9ec1-b6fb840b284c", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 35  # Increased particle count for diversity\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.6  # Personal influence increased\n        phi_g = 0.5  # Global influence\n        quantum_prob_init = 0.25  # Initial quantum probability modified\n        quantum_prob_final = 0.1  # Final quantum probability modified\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget) * 1.5  # Increased adaptive quantum influence\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=4, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2, 2, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.4 * (evaluations / self.budget)  # More aggressive inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Incorporates dynamic diversity measures and hybrid mutation strategies to enhance exploration and convergence rates.", "configspace": "", "generation": 63, "fitness": 0.2311465473440584, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.003. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.22772619673059613, 0.23032250670519439, 0.2353909385963847], "final_y": [0.25648288111344, 0.24071222876783838, 0.20242406058014173]}, "mutation_prompt": null}
{"id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism and non-linear velocity adjustment for better convergence.", "configspace": "", "generation": 64, "fitness": 0.23429233477746303, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8d981ef3-982f-4271-afa9-b7a886111eb5", "metadata": {"aucs": [0.2343695107466358, 0.235882565117005, 0.23262492846874827], "final_y": [0.21349455847259902, 0.21279720591633533, 0.22341982588635978]}, "mutation_prompt": null}
{"id": "f57943c8-3d6c-40bf-918a-bd769ff83826", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=2, replace=False)  # Adjusted sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Refined quantum-inspired PSO with enhanced memory utilization and adaptive exploration for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.22205231558041616, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.004. And the mean value of best solutions found was 0.294 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21621858863923638, 0.22607289560912447, 0.22386546249288763], "final_y": [0.33501788801659127, 0.2673904858038171, 0.2804572070164003]}, "mutation_prompt": null}
{"id": "0f23f546-13e0-4783-8097-b619e0fedc2d", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2, 2, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhancement of quantum-inspired velocity diversification by increasing the range of quantum perturbation for improved exploration.", "configspace": "", "generation": 66, "fitness": 0.23343564473669723, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.002. And the mean value of best solutions found was 0.225 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23008688271322564, 0.23586731754954127, 0.2343527339473248], "final_y": [0.2433187373219, 0.21313681824712638, 0.2200060333403001]}, "mutation_prompt": null}
{"id": "f24d5b10-532c-4e65-858e-f105f080efeb", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.7 - 0.5 * (evaluations / self.budget)  # Improved non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism, non-linear velocity adjustment, and improved inertia weight decay for better convergence.", "configspace": "", "generation": 67, "fitness": 0.2265180126971654, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.006. And the mean value of best solutions found was 0.263 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23399163491183905, 0.2208019489318893, 0.2247604542477678], "final_y": [0.21534144093356677, 0.2973394494730697, 0.2751650585320684]}, "mutation_prompt": null}
{"id": "fecae60d-c4d3-4026-9a47-303c143b9101", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.3\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.7 - 0.5 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Quantum-inspired particle swarm optimization with enhanced elite memory management and dynamic velocity scaling for improved convergence.", "configspace": "", "generation": 68, "fitness": 0.22082727366232704, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.004. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21615283882544667, 0.2215685279137667, 0.2247604542477678], "final_y": [0.3359081637725495, 0.2911343743409023, 0.2751650585320684]}, "mutation_prompt": null}
{"id": "63e6301f-ccd3-4e9c-9894-de1cf6fc2db8", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.5  # Slight adjustment\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism, non-linear velocity adjustment, and improved quantum probability transition for better convergence.", "configspace": "", "generation": 69, "fitness": 0.23112003386123528, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.010. And the mean value of best solutions found was 0.244 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21657178479923778, 0.2359959140949648, 0.2407924026895033], "final_y": [0.33269743876238567, 0.2130094473817582, 0.18772403628927126]}, "mutation_prompt": null}
{"id": "238f5b02-3b42-42b1-96d8-23c781630a37", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (num_particles, self.dim))  # Reduced velocity range\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                new_position = particles[i] + velocities[i]\n                particles[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Local search enhancement\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n                    particles[i] = np.clip(particles[i] + perturbation, func.bounds.lb, func.bounds.ub)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced particle swarm optimization incorporating dynamic local search and adaptive velocity constraints for improved convergence and exploration.", "configspace": "", "generation": 70, "fitness": 0.22872254345369503, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.003. And the mean value of best solutions found was 0.240 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22507603369418994, 0.23250765347693736, 0.22858394318995778], "final_y": [0.2684751635061784, 0.214374225920119, 0.23634301306564443]}, "mutation_prompt": null}
{"id": "7fdd0583-bc27-4a5d-9584-802183099adb", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.8  # Increased personal influence\n        phi_g = 0.9  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.2 * self.dim)  # Increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=4, replace=False)  # Extended sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.5 - 0.3 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced Quantum-Inspired Particle Swarm with dynamic learning rates and extended elite memory influence for improved adaptability and convergence.", "configspace": "", "generation": 71, "fitness": 0.22142668199260032, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.006. And the mean value of best solutions found was 0.295 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2205665626685509, 0.22877308163598675, 0.21494040167326334], "final_y": [0.30238206377521837, 0.23814192521704702, 0.34465401040015975]}, "mutation_prompt": null}
{"id": "ddc67caa-1a3c-45f8-a24f-70c8ad651f3c", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=np.random.randint(2, 4), replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved quantum-inspired particle swarm optimization with enhanced elite sampling strategy for diversity.", "configspace": "", "generation": 72, "fitness": 0.22481103932023114, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.005. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21964961497369906, 0.22298556985112328, 0.23179793313587105], "final_y": [0.3102030899857575, 0.2860378768884405, 0.23608315159249427]}, "mutation_prompt": null}
{"id": "e429010f-bd99-4660-bc85-7dcba4e72e55", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.2, 1.2, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.7 - 0.5 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Fine-tuned quantum perturbation range and inertia weight decay to enhance convergence.", "configspace": "", "generation": 73, "fitness": 0.22664124369211414, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.006. And the mean value of best solutions found was 0.262 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23507354164315686, 0.22007663606583394, 0.2247735533673516], "final_y": [0.2096202044857387, 0.30268175338646586, 0.2750794349380755]}, "mutation_prompt": null}
{"id": "77009685-6f8e-4638-be4b-cb7a889e7978", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    std_dev = np.std(elite_memory_positions, axis=0)  # Calculate standard deviation of elite positions\n                    velocities[i] = np.random.uniform(-1.5 * std_dev, 1.5 * std_dev)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved adaptive elitism and PSO velocity update using the standard deviation of elite memory, enhancing exploration.", "configspace": "", "generation": 74, "fitness": 0.22310215356190688, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.011. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.074.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2096941908703539, 0.23755360074800058, 0.22205866906736615], "final_y": [0.3881218539587068, 0.20690713369169156, 0.29382941142758645]}, "mutation_prompt": null}
{"id": "965a5f21-073d-4ef1-8d0e-9590cb9aa0de", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.normal(0, 1.5, self.dim)  # Adaptive velocity perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum-inspired particle swarm optimization with improved elite sampling and adaptive velocity perturbation for enhanced exploration.", "configspace": "", "generation": 75, "fitness": 0.2252096792333854, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.005. And the mean value of best solutions found was 0.269 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21810831773303618, 0.22942092959726246, 0.2280997903698575], "final_y": [0.3192302236854817, 0.23580778810862957, 0.25145188365186577]}, "mutation_prompt": null}
{"id": "7bc24a84-1322-4e46-a19e-9f8f1d75c08c", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.8  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism and non-linear velocity adjustment for better convergence, now with increased global influence.", "configspace": "", "generation": 76, "fitness": 0.22495120100003027, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.002. And the mean value of best solutions found was 0.269 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22376653872643315, 0.22766701262214506, 0.22342005165151257], "final_y": [0.27324319655003804, 0.251022965680918, 0.283069278989443]}, "mutation_prompt": null}
{"id": "d3d518da-a15a-4c1b-852d-3d5ba04fa6ee", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        # Initialize a secondary elite memory\n        secondary_elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        secondary_elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n                # Update secondary elite memory\n                if value > np.min(secondary_elite_memory_values):\n                    min_secondary_index = np.argmin(secondary_elite_memory_values)\n                    secondary_elite_memory_values[min_secondary_index] = value\n                    secondary_elite_memory_positions[min_secondary_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved Quantum-Inspired Particle Swarm with dual adaptive memory for enhanced global exploration and convergence.", "configspace": "", "generation": 77, "fitness": 0.23429233477746303, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.001. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2343695107466358, 0.235882565117005, 0.23262492846874827], "final_y": [0.21349455847259902, 0.21279720591633533, 0.22341982588635978]}, "mutation_prompt": null}
{"id": "44c8c5a8-1e21-4a47-be02-e7bd13309c23", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i])) * (1 + np.random.normal(0, 0.1))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum-inspired particle swarm optimization with dynamic neighborhood topology and adaptive mutation for improved exploration and exploitation balance.", "configspace": "", "generation": 78, "fitness": 0.22992734469986173, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.008. And the mean value of best solutions found was 0.246 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2190477068928519, 0.23448597226761014, 0.2362483549391231], "final_y": [0.312993409742244, 0.216282245022957, 0.2080494175996226]}, "mutation_prompt": null}
{"id": "d302f1d1-8f8f-4457-b4e9-94778b9337fd", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.8  # Increased personal influence\n        phi_g = 0.8  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum-inspired particle swarm optimization with adaptive elitism and non-linear velocity adjustment, now featuring more dynamic quantum perturbation and learning coefficients for improved convergence.", "configspace": "", "generation": 79, "fitness": 0.2186086957247325, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.003. And the mean value of best solutions found was 0.318 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2150232566895145, 0.220349607764051, 0.22045322272063195], "final_y": [0.34450703525451265, 0.30535554598482484, 0.30313654831026815]}, "mutation_prompt": null}
{"id": "93cac1a9-2f2c-4154-acc9-c765a73b4070", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    perturbation = np.random.normal(loc=0, scale=0.5, size=self.dim)  # Changed to normal distribution\n                    velocities[i] = perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive perturbation and diversified elite sampling for improved convergence.", "configspace": "", "generation": 80, "fitness": 0.2208927514901151, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.007. And the mean value of best solutions found was 0.304 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21253829463079932, 0.22932125236161804, 0.22081870747792798], "final_y": [0.36408990922147844, 0.24601365422787635, 0.30129961194242294]}, "mutation_prompt": null}
{"id": "a4941581-07b2-4855-ad24-268376fb10c7", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[elite_indices].mean(axis=0)  # Crossover elite members\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Modified quantum particle swarm with dynamic inertia and elite crossover to enhance exploration and convergence.", "configspace": "", "generation": 81, "fitness": 0.2256233249812525, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.004. And the mean value of best solutions found was 0.265 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2213721682783938, 0.2312082671140766, 0.22428953955128716], "final_y": [0.29510038445096665, 0.22451983520355778, 0.2744763984222546]}, "mutation_prompt": null}
{"id": "773acacc-81d7-4b3a-b1e0-4aa1ca040071", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with stronger adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=2, replace=False)  # Reduced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.8, 1.8, self.dim)  # Increased quantum perturbation range\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced Quantum Particle Swarm Optimization with adjusted quantum perturbation and dynamic elite memory refinement.", "configspace": "", "generation": 82, "fitness": 0.22228032530650876, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.004. And the mean value of best solutions found was 0.292 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21624746604393275, 0.22622060131575294, 0.2243729085598406], "final_y": [0.3347997850605987, 0.2664806326459239, 0.27477644633404186]}, "mutation_prompt": null}
{"id": "dc159dca-9afb-4585-ad50-7af2e6261ff8", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.75  # Increased personal influence\n        phi_g = 0.75  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced particle swarm optimization with adaptive elitism and refined velocity adjustment for superior convergence.", "configspace": "", "generation": 83, "fitness": 0.22354904884779606, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.006. And the mean value of best solutions found was 0.278 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21917570063389658, 0.2197807692342102, 0.23169067667528143], "final_y": [0.3105901414558849, 0.2906426056584983, 0.23132873221284533]}, "mutation_prompt": null}
{"id": "11409a94-fc45-4a6a-b8cb-9519726cc6d2", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=2, replace=False)  # Optimized sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism and non-linear velocity adjustment for better convergence and optimized elite sampling.", "configspace": "", "generation": 84, "fitness": 0.22205231558041616, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.004. And the mean value of best solutions found was 0.294 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21621858863923638, 0.22607289560912447, 0.22386546249288763], "final_y": [0.33501788801659127, 0.2673904858038171, 0.2804572070164003]}, "mutation_prompt": null}
{"id": "1f6a65bf-85b0-440a-98c7-cd8d18c96d35", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-1.0, 1.0, self.dim)  # Adjusted quantum perturbation range\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)**1.1  # Slightly faster inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Further improved quantum-inspired particle swarm optimization with adaptive elite memory influence and dynamic velocity scaling.", "configspace": "", "generation": 85, "fitness": 0.2314332432668836, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.003. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2344153592724213, 0.232686941606444, 0.22719742892178552], "final_y": [0.2118662842215714, 0.23009746882950322, 0.24728254276771422]}, "mutation_prompt": null}
{"id": "11a950a7-a6cf-43b8-9867-7aa6eff66403", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n\n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.25  # Adjusted initial quantum probability\n        quantum_prob_final = 0.1  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n\n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n\n        global_best_position = None\n        global_best_value = float('-inf')\n\n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2, 2, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Refined quantum-inspired particle swarm optimization with dynamic elite sampling and enhanced velocity perturbation for improved convergence.", "configspace": "", "generation": 86, "fitness": 0.2294297101816866, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.001. And the mean value of best solutions found was 0.245 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22815630504932682, 0.23056850715916266, 0.22956431833657032], "final_y": [0.24629553688928296, 0.23930771477969615, 0.2481315126896405]}, "mutation_prompt": null}
{"id": "0e56fe07-d174-4025-856e-7a1b326c383d", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5 \n        phi_p = 0.7  \n        phi_g = 0.7  \n        quantum_prob_init = 0.3 \n        quantum_prob_final = 0.1  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (num_particles, self.dim))  # Reduced velocity range\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.2 * self.dim)  # Further increased elite memory size\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.3  # Adjusted exponent\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=2, replace=False)  # Reduced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)] \n                    velocities[i] = np.random.uniform(-1, 1, self.dim)  # Adjusted quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.3 * (evaluations / self.budget)  # Adjusted inertia decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced particle swarm optimization with dynamic hyperparameter adjustment and improved elite selection for better convergence.", "configspace": "", "generation": 87, "fitness": 0.22442588477026537, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.002. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22199461607708537, 0.2247933953407797, 0.22648964289293105], "final_y": [0.2939898242143768, 0.269681400281114, 0.26627787045317375]}, "mutation_prompt": null}
{"id": "28b1d3c8-a8d5-485a-9512-e2bff342becb", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            # Dynamically reduce the number of particles based on evaluations\n            num_particles = 30 - int(20 * (evaluations / self.budget))\n\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive memory influence and dynamic particle size reduction for better convergence.", "configspace": "", "generation": 88, "fitness": 0.23416364361969907, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.005. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23970700920638188, 0.23550051348847323, 0.22728340816424208], "final_y": [0.19190231321063833, 0.2154658395135921, 0.2585509246961546]}, "mutation_prompt": null}
{"id": "121fbcc3-c9fb-4c12-b7ad-ebc1ca07482c", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member1, random_elite_member2 = np.random.choice(elite_indices, 2, replace=False)  # Elite crossover\n                    velocities[i] = (elite_memory_positions[random_elite_member1] + elite_memory_positions[random_elite_member2]) / 2  # Crossover operation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with elite crossover for improved exploration.", "configspace": "", "generation": 89, "fitness": 0.2145326773756081, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.215 with standard deviation 0.002. And the mean value of best solutions found was 0.348 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21278619510244523, 0.21338822639020494, 0.21742361063417415], "final_y": [0.3623082607922934, 0.35635342065810516, 0.32633038163975236]}, "mutation_prompt": null}
{"id": "9c13dab8-1e78-4fc3-9e73-65cd2e7058e5", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.35 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved quantum particle swarm optimization with adaptive non-linear velocity adjustment and elite sampling for enhanced convergence.", "configspace": "", "generation": 90, "fitness": 0.23383692379236456, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.002. And the mean value of best solutions found was 0.220 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23435050761694287, 0.2359237139872169, 0.23123654977293395], "final_y": [0.21361413898337778, 0.2125998173055902, 0.23306136814420741]}, "mutation_prompt": null}
{"id": "6cb1a4b4-a646-4326-821a-70c3b241b88d", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 50\n        evaluations = 0\n\n        # DE Hyperparameters\n        F = 0.8  # Differential weight\n        CR_init = 0.9  # Initial crossover probability\n        CR_final = 0.5  # Final crossover probability\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations += population_size\n\n        # Initialize elite memory\n        elite_memory_size = 10\n        elite_memory = population[np.argsort(fitness)[:elite_memory_size]]\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Select three random distinct indices for mutation\n                indices = np.random.choice(population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                \n                # Mutation\n                mutant_vector = x1 + F * (x2 - x3)\n\n                # Ensure bounds\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                # Adapt crossover probability\n                CR = CR_init + (CR_final - CR_init) * (evaluations / self.budget)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant_vector, population[i])\n\n                # Ensure bounds for trial vector\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                    # Update elite memory\n                    if trial_fitness < np.max([func(elite) for elite in elite_memory]):\n                        worst_index = np.argmax([func(elite) for elite in elite_memory])\n                        elite_memory[worst_index] = trial_vector\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        # Return the best individual and its fitness\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridDifferentialEvolution", "description": "Hybrid Differential Evolution with Multi-Elite Selection and Adaptive Crossover for Diverse Exploration and Robust Convergence.", "configspace": "", "generation": 91, "fitness": 0.22035034836434889, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.220 with standard deviation 0.002. And the mean value of best solutions found was 0.238 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21786048239250821, 0.21993746141204829, 0.22325310128849019], "final_y": [0.27738150051146815, 0.2116575643919384, 0.22623041283047252]}, "mutation_prompt": null}
{"id": "f05a15ed-febd-436e-bff7-f10907e9d8d8", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5\n        phi_p = 0.7\n        phi_g = 0.7\n        quantum_prob_init = 0.3\n        quantum_prob_final = 0.15\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                value = func(particles[i])\n                evaluations += 1\n\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            neighborhood_size = 5  # New neighborhood size parameter\n\n            for i in range(num_particles):\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)\n                else:\n                    neighborhood_indices = np.random.choice(range(num_particles), size=neighborhood_size, replace=False)\n                    local_best = max(neighborhood_indices, key=lambda idx: personal_best_values[idx])\n                    \n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[local_best] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced particle swarm with adaptive neighborhood and oscillation-based velocity adjustments for improved convergence.", "configspace": "", "generation": 92, "fitness": 0.2274964009704923, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.007. And the mean value of best solutions found was 0.263 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22141065573323082, 0.23727684982036834, 0.2238016973578778], "final_y": [0.29898350864379997, 0.2082866810399986, 0.2818669133656443]}, "mutation_prompt": null}
{"id": "13d9c6a0-92df-4186-970e-e711c1be3715", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=5, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-2.0, 2.0, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with diversified random elite sampling and improved quantum perturbation for better exploration.", "configspace": "", "generation": 93, "fitness": 0.22373719088464214, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.001. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22289090149740576, 0.2249989639875425, 0.22332170716897815], "final_y": [0.28722629432631996, 0.2567274054243053, 0.28616479235946124]}, "mutation_prompt": null}
{"id": "5d5d5274-114d-4704-9870-6b6135afcf0f", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    phi_p = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Dynamic personal influence\n                    phi_g = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Dynamic global influence\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism, non-linear velocity adjustment, and dynamic learning rates for improved convergence.", "configspace": "", "generation": 94, "fitness": 0.23344425446456962, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.003. And the mean value of best solutions found was 0.221 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.23484415809669568, 0.23557411992877508, 0.2299144853682381], "final_y": [0.2177629591730602, 0.21380181290580247, 0.23042955051589786]}, "mutation_prompt": null}
{"id": "68af62f8-7ae6-4354-a7be-8dd99bcc79e0", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim) * np.random.choice([-1, 1])  # Chaotic perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * np.sin(evaluations / self.budget * np.pi / 2)  # Sine wave inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Refined quantum-inspired PSO with chaotic elitism and adaptive velocity bounds for enhanced convergence.", "configspace": "", "generation": 95, "fitness": 0.2247518279015743, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.003. And the mean value of best solutions found was 0.270 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.22271412383486444, 0.22867488458373586, 0.22286647528612258], "final_y": [0.29042577554792537, 0.2332603978886798, 0.2875926079195915]}, "mutation_prompt": null}
{"id": "c83fae57-3262-4042-b2b7-3732622a1560", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.75  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Improved convergence by slightly increasing the personal influence coefficient in PSO.", "configspace": "", "generation": 96, "fitness": 0.22487462850142717, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.005. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.226990788430935, 0.21770391717876192, 0.2299291798945846], "final_y": [0.25685723007568895, 0.3225016208699566, 0.24585601805989699]}, "mutation_prompt": null}
{"id": "16e955ed-85fe-4bbb-92a9-74ff048d8ed9", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.5  # Changed from 1.2 to 1.5\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced adaptive quantum probability with a non-linear decay factor for improved convergence efficiency.", "configspace": "", "generation": 97, "fitness": 0.23112003386123528, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.010. And the mean value of best solutions found was 0.244 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.21657178479923778, 0.2359959140949648, 0.2407924026895033], "final_y": [0.33269743876238567, 0.2130094473817582, 0.18772403628927126]}, "mutation_prompt": null}
{"id": "5858845f-d1d5-45df-9abb-db0889630405", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.6 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position with boundary reflection\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n                particles[i] = np.where(particles[i] == func.bounds.lb, func.bounds.lb + np.abs(velocities[i]), particles[i])\n                particles[i] = np.where(particles[i] == func.bounds.ub, func.bounds.ub - np.abs(velocities[i]), particles[i])\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Enhanced quantum particle swarm optimization with adaptive elitism, boundary reflection, and non-linear velocity adjustment for better convergence.", "configspace": "", "generation": 98, "fitness": 0.23207281943210545, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.002. And the mean value of best solutions found was 0.224 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2346763388183486, 0.22891719100921948, 0.23262492846874827], "final_y": [0.21407473342120498, 0.23311593049651258, 0.22341982588635978]}, "mutation_prompt": null}
{"id": "a832113b-a961-4fb4-9995-e06720148bfe", "solution": "import numpy as np\n\nclass ImprovedQuantumInspiredParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        num_particles = 30\n        evaluations = 0\n        \n        # PSO Hyperparameters\n        omega = 0.5  # Inertia weight\n        phi_p = 0.7  # Increased personal influence\n        phi_g = 0.7  # Increased global influence\n        quantum_prob_init = 0.3  # Adjusted initial quantum probability\n        quantum_prob_final = 0.15  # Adjusted final quantum probability\n\n        # Initialize particle positions and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        \n        # Initialize personal best and global best\n        personal_best_positions = particles.copy()\n        personal_best_values = np.full(num_particles, float('-inf'))\n        \n        global_best_position = None\n        global_best_value = float('-inf')\n        \n        # Initialize elite memory\n        elite_memory_size = 5 + int(0.15 * self.dim)  # Dynamic elite memory size with increased factor\n        elite_memory_positions = np.zeros((elite_memory_size, self.dim))\n        elite_memory_values = np.full(elite_memory_size, float('-inf'))\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Evaluate current particle\n                value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if value > personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if value > global_best_value:\n                    global_best_value = value\n                    global_best_position = particles[i]\n\n                # Update elite memory\n                if value > np.min(elite_memory_values):\n                    min_elite_index = np.argmin(elite_memory_values)\n                    elite_memory_values[min_elite_index] = value\n                    elite_memory_positions[min_elite_index] = particles[i]\n\n            # Calculate adaptive quantum probability with non-linear adjustment\n            quantum_prob = quantum_prob_init + (quantum_prob_final - quantum_prob_init) * (evaluations / self.budget)**1.2\n\n            # Update particle velocities and positions\n            for i in range(num_particles):\n                # Quantum-inspired perturbation with adaptive probability\n                if np.random.rand() < quantum_prob:\n                    elite_indices = np.random.choice(range(elite_memory_size), size=3, replace=False)  # Enhanced sampling\n                    random_elite_member = elite_memory_positions[np.random.choice(elite_indices)]  # Random elite selection\n                    velocities[i] = np.random.uniform(-1.5, 1.5, self.dim)  # Diversified quantum perturbation\n                else:\n                    r_p = np.random.rand(self.dim)\n                    r_g = np.random.rand(self.dim)\n                    omega = 0.65 - 0.4 * (evaluations / self.budget)  # Non-linear inertia weight decay\n                    velocities[i] = (omega * velocities[i] +\n                                     phi_p * r_p * (personal_best_positions[i] - particles[i]) +\n                                     phi_g * r_g * (global_best_position - particles[i]))\n\n                # Update position\n                particles[i] = np.clip(particles[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # Ensure not exceeding budget\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "name": "ImprovedQuantumInspiredParticleSwarm", "description": "Slightly optimized quantum particle swarm with improved inertia weight decay for enhanced search efficiency.", "configspace": "", "generation": 99, "fitness": 0.22093208491045754, "feedback": "The algorithm ImprovedQuantumInspiredParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.008. And the mean value of best solutions found was 0.303 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "d7800d63-21a0-4a45-ba5e-3e62bbc5a1e4", "metadata": {"aucs": [0.2161604668436342, 0.21452119509241563, 0.23211459279532276], "final_y": [0.33584971030992516, 0.34805900860064065, 0.22426349942541957]}, "mutation_prompt": null}
